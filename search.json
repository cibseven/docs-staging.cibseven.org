[
  {
    "id": "404.html",
    "title": "404 - Page Not Found | docs.cibseven.org",
    "content": "404 Requested page was not found.",
    "url": "/404.html"
  },
  {
    "id": "banners.html",
    "title": "Untitled",
    "content": "Have questions? You can get help at our Discussions",
    "url": "/banners.html"
  },
  {
    "id": "get-started/apache-maven/index.html",
    "title": "Apache Maven Coordinates | docs.cibseven.org",
    "content": "This page lists the most commonly used Apache Maven Coordinates for CIB seven. Since version 1.1.0 CIB seven artifacts are available at Maven Central. And extra tweaks of pom.xml or settings.xml are no longer essential. However you can use our public Sonatype Nexus Repository with all artifacts at artifacts.cibseven.org. Extra repository should be added to settings.xml or to the POM file: <repositories> <repository> <id>mvn-cibseven-public</id> <name>CIB seven Public Repository</name> <url>https://artifacts.cibseven.org/repository/public/</url> </repository> </repositories> This repository will be essential if you want to use 7.22.0-cibseven (1.0) transitional version of CIB seven. It is not available at Maven Cental repository. CIB seven BOM (Bill of Materials) <dependencyManagement> <dependencies> <dependency> <groupId>org.cibseven.bpm</groupId> <artifactId>cibseven-bom</artifactId> <version>1.1.0</version> <scope>import</scope> <type>pom</type> </dependency> </dependencies> </dependencyManagement> Use the BOM! Please import the CIB seven BOM if you use multiple CIB seven projects. The BOM defines versions for all CIB seven projects. This way it is ensured that no incompatible versions are imported. CIB seven Engine <dependency> <groupId>org.cibseven.bpm</groupId> <artifactId>cibseven-engine</artifactId> </dependency> CIB seven Engine Spring Integration The cibseven-engine Spring integration for Spring Framework 5: <dependency> <groupId>org.cibseven.bpm</groupId> <artifactId>cibseven-engine-spring</artifactId> </dependency> The cibseven-engine Spring integration for Spring Framework 6: <dependency> <groupId>org.cibseven.bpm</groupId> <artifactId>cibseven-engine-spring-6</artifactId> </dependency> CIB seven Engine CDI Integration <dependency> <groupId>org.cibseven.bpm</groupId> <artifactId>cibseven-engine-cdi</artifactId> </dependency> CIB seven DMN Engine BOM (Bill of Materials) This BOM allows to use the DMN engine standalone without the BPMN engine and the rest of the CIB seven platform. <dependencyManagement> <dependency> <groupId>org.cibseven.bpm.dmn</groupId> <artifactId>cibseven-engine-dmn-bom</artifactId> <version>1.1.0</version> <type>pom</type> <scope>import</scope> </dependency> </dependencyManagement> CIB seven DMN This dependency allows to use DMN engine standalone without the BPMN engine and the rest of the CIB seven platform. It is not needed when using cibseven-engine because that already contains the DMN engine. <dependency> <groupId>org.cibseven.bpm.dmn</groupId> <artifactId>cibseven-engine-dmn</artifactId> </dependency> Process Application EJB Client <dependency> <groupId>org.cibseven.bpm.javaee</groupId> <artifactId>cibseven-ejb-client</artifactId> </dependency> Browse CIB seven Artifact Storage In order to browse the CIB seven artifacts, here are the link you can use. https://artifacts.cibseven.org/service/rest/repository/browse/public/org/cibseven/ Other CIB seven Modules: DMN Engine Spin Connect Templating Engines Spring Boot Integration",
    "url": "/get-started/apache-maven/index.html"
  },
  {
    "id": "get-started/dmn/deploy/index.html",
    "title": "Evaluate, Deploy and Test the decision table | docs.cibseven.org",
    "content": "In this step, we use Java Code to evaluate the decision table. Then we deploy the web application to Apache Tomcat and verify the result in Cockpit. Evaluate the Decision Table To directly evaluate the decision table after deployment, add the following method to your Application class: package de.cibseven.getstarted.dmn; @ProcessApplication(\"Dinner App DMN\") public class DinnerApplication extends ServletProcessApplication { protected final static Logger LOGGER = Logger.getLogger(DinnerApplication.class.getName()); @PostDeploy public void evaluateDecisionTable(ProcessEngine processEngine) { DecisionService decisionService = processEngine.getDecisionService(); VariableMap variables = Variables.createVariables() .putValue(\"season\", \"Spring\") .putValue(\"guestCount\", 10); DmnDecisionTableResult dishDecisionResult = decisionService.evaluateDecisionTableByKey(\"dish\", variables); String desiredDish = dishDecisionResult.getSingleEntry(); LOGGER.log(Level.INFO, \"\\n\\nDesired dish: {0}\\n\\n\", desiredDish); } } Source Code Step-4 Catch up: Get the Sources of Step-4. Download as .zip or checkout the corresponding tag with Git. You can checkout the current state from the GitHub repository. If you have not cloned the repository yet, please execute the following command: git clone https://github.com/cibseven/cibseven-get-started-dmn.git To checkout the current state of the process application please execute the following command: git checkout -f Step-4 Or download as archive from here. Build the Web Application with Maven Select the pom.xml in the Package Explorer, perform a right-click and select Run As / Maven Install. This will generate a WAR file named dinner-dmn-0.1.0-SNAPSHOT.war in the target/ folder of your Maven project. Hint If the dinner-dmn-0.1.0-SNAPSHOT.war file is not visible after having performed the Maven build, you need to refresh the project (F5) in eclipse. Deploy to Apache Tomcat In order to deploy the process application, copy-paste the dinner-dmn-0.1.0-SNAPSHOT.war from your Maven project to the $CIBSEVEN_HOME/server/apache-tomcat/webapps folder. Check the log file of the Apache Tomcat server. If you see the following log message, the deployment was successful: INFO org.camunda.commons.logging.BaseLogger.logInfo ENGINE-07015 Detected @ProcessApplication class 'de.cibseven.getstarted.dish.DishApplication' INFO org.camunda.commons.logging.BaseLogger.logInfo ENGINE-08024 Found processes.xml file at ../webapps/dinner-dmn-0.1.0-SNAPSHOT/WEB-INF/classes/META-INF/processes.xml INFO org.camunda.commons.logging.BaseLogger.logInfo ENGINE-08023 Deployment summary for process archive 'dinner-dmn': dinnerDecisions.dmn INFO de.cibseven.getstarted.dmn.DinnerApplication.evaluateDecisionTable Desired dish: Stew INFO org.camunda.commons.logging.BaseLogger.logInfo ENGINE-08050 Process application Dinner App DMN successfully deployed Verify the Deployment with Cockpit Now, use Cockpit to check if the decision table is successfully deployed. Go to http://localhost:8080/camunda/app/cockpit. Log in with demo / demo. Go to “Decisions” section. Your decision table Dish should be listed as deployed decision definition. Verify the Evaluation with Cockpit Click on the decision Dish. This opens a dialog where you see when the decision table was evaluated. If you click on the id, you can see the historic data of the evaluation. The matched rules are highlighted and the input and output values are listed in the table below. Verify that the 5th rule was matched and the output value for the desired dish is “Stew”. Next Steps Congratulations, you have now successfully set up a project with your first DMN decision table. Next, see how you can evaluate the decision using the REST API, learn more about DMN by reading the DMN Reference, learn more about the Decision API exposed by CIB seven Process Engine, check how you can invoke the decision from a BPMN Business Rule Task, Bonus Step: Decision Requirements Graph",
    "url": "/get-started/dmn/deploy/index.html"
  },
  {
    "id": "get-started/dmn/drg/index.html",
    "title": "Model, Evaluate and Deploy a Decision Requirements Graph | docs.cibseven.org",
    "content": "In this step, we extend the previous example by a second decision Beverages which uses the Dish decision table as input. We model this dependency between the decisions within a Decision Requirements Graph (DRG) using the Camunda Modeler. Then, we adjust the Application class to evaluate the Beverages decision, deploy the web application to Apache Tomcat and verify the result in Cockpit. Decision Requirements Graph vs. Decision Requirements Diagram The visual representation of a Decision Requirements Graph (DRG) is called Decision Requirements Diagram (DRD). In the context of the Camunda Modeler, we name it DRD because we use the visual representation to model the DRG. Switch from Decision Table to DRD Open the Dish decision table from the previous step. Click on the button “View DRD” to see the Decision Requirements Diagram (DRD). It contains a single decision with the name Dish. Set the Name and the Id of the DRD Click somewhere on the canvas and open the Property Panel on the right. Change the id of the DRD to “dinnerDecisions”. Next, change the name of the DRD to “Dinner Decisions”. Create a new Decision in the DRD Click on the decision icon of the palette to create a new decision. Then, double-click on the decision and type Beverages to set the name. Change the type of the decision to Decision Table by clicking on the wrench icon next to the “Beverages” decision and selecting “Decision Table”. Use the Property Panel on the right side again to set the id to “beverages”. Next, connect the Dish decision to the Beverages decision to indicate that the Dish decision is a required decision of the Beverages decision. That means that it is used as an input for the decision and the output value “desiredDish” can be accessed there. Click on the top left icon of the Beverages decision to open the decision table. Configure the Decision Table and add the Rules Configure the Beverages decision table so that it has: one input with label “Dish”, input expression “desiredDish” and type “string”, second input with label “Guests with children”, input expression “guestsWithChildren” and type “boolean”, an output with label “Beverages”, name “beverages” and type “string”, the hit policy “COLLECT” (with collect operator LIST). Then, fill the table with the rules. Save your changes and replace the existing DMN file in the src/main/resources folder. Source Code Step-5 Catch up: Get the Sources of Step-5. Download as .zip or checkout the corresponding tag with Git. You can checkout the current state from the GitHub repository. If you have not cloned the repository yet, please execute the following command: git clone https://github.com/cibseven/cibseven-get-started-dmn.git To checkout the current state of the process application please execute the following command: git checkout -f Step-5 Or download as archive from here. Evaluate the Decision To evaluate the Beverages decision, we extend the existing method in your Application class and add a new variable “guestsWithChildren”. package de.cibseven.getstarted.dmn; @ProcessApplication(\"Dinner App DMN\") public class DinnerApplication extends ServletProcessApplication { protected final static Logger LOGGER = Logger.getLogger(DinnerApplication.class.getName()); @PostDeploy public void evaluateDecisionTable(ProcessEngine processEngine) { DecisionService decisionService = processEngine.getDecisionService(); VariableMap variables = Variables.createVariables() .putValue(\"season\", \"Spring\") .putValue(\"guestCount\", 10) .putValue(\"guestsWithChildren\", false); DmnDecisionTableResult dishDecisionResult = decisionService.evaluateDecisionTableByKey(\"dish\", variables); String desiredDish = dishDecisionResult.getSingleEntry(); LOGGER.log(Level.INFO, \"\\n\\nDesired dish: {0}\\n\\n\", desiredDish); DmnDecisionTableResult beveragesDecisionResult = decisionService.evaluateDecisionTableByKey(\"beverages\", variables); List<Object> beverages = beveragesDecisionResult.collectEntries(\"beverages\"); LOGGER.log(Level.INFO, \"\\n\\nDesired beverages: {0}\\n\\n\", beverages); } } Source Code Step-6 Catch up: Get the Sources of Step-6. Download as .zip or checkout the corresponding tag with Git. You can checkout the current state from the GitHub repository. If you have not cloned the repository yet, please execute the following command: git clone https://github.com/cibseven/cibseven-get-started-dmn.git To checkout the current state of the process application please execute the following command: git checkout -f Step-6 Or download as archive from here. Build and Deploy the Web Application Build the web application with Maven and replace the dinner-dmn-0.1.0-SNAPSHOT.war in the $CIBSEVEN_HOME/server/apache-tomcat/webapps folder. Check the log file of the Apache Tomcat server. If you see the following log message, the deployment was successful: INFO org.camunda.commons.logging.BaseLogger.logInfo ENGINE-07015 Detected @ProcessApplication class 'de.cibseven.getstarted.dish.DishApplication' INFO org.camunda.commons.logging.BaseLogger.logInfo ENGINE-08024 Found processes.xml file at ../webapps/dinner-dmn-0.1.0-SNAPSHOT/WEB-INF/classes/META-INF/processes.xml INFO org.camunda.commons.logging.BaseLogger.logInfo ENGINE-08023 Deployment summary for process archive 'dinner-dmn': dinnerDecisions.dmn INFO de.cibseven.getstarted.dmn.DinnerApplication.evaluateDecisionTable Desired dish: Stew INFO de.cibeven.getstarted.dmn.DinnerApplication.evaluateDecisionTable Desired beverages: [Guiness, Water] INFO org.camunda.commons.logging.BaseLogger.logInfo ENGINE-08050 Process application Dinner App DMN successfully deployed Verify the Evaluation with Cockpit Now, open Cockpit and go to the “Decisions” section. Then, click on the decision Beverages and select an id to see the historic data of the evaluation. Verify that both rules were matched and the output value for the beverages is “Guiness” and “Water”. Note that the Dish decision is evaluated as part of the evaluation of the Beverages decision. It provides the value “Stew” for the input expression “desiredDish”. Next Steps Next, learn more about DRG by reading the DMN Reference,",
    "url": "/get-started/dmn/drg/index.html"
  },
  {
    "id": "get-started/dmn/index.html",
    "title": "Get started with CIB seven and DMN 1.3 | docs.cibseven.org",
    "content": "This tutorial guides you through modeling your first DMN 1.3 decision table and executing it with the CIB seven. Standalone DMN engine Note that it is also possible to use the DMN engine independently from the CIB seven. Please refer to the User Guide and the example at Camunda GitHub for more details. Source Code Join in: Get the Sources for this guide. Download as .zip or checkout the corresponding tag with Git. In addition to this guide, the source code of the example project is also available on GitHub. You can directly download the whole project or clone it with git: git clone https://github.com/cibseven/cibseven-get-started-dmn.git To follow this guide, download the initial state or checkout the tag in the git repository: git checkout -f Start or every step in between: git checkout -f Step-X After every section in this guide you will find a box which contains a download link to the current state of the project and git instructions to checkout the current version of the repository. You will be guided through the following steps:",
    "url": "/get-started/dmn/index.html"
  },
  {
    "id": "get-started/dmn/install/index.html",
    "title": "Download and Installation | docs.cibseven.org",
    "content": "First you need to set up your development environment and install the CIB seven and the Camunda Modeler. Prerequisites Make sure you have the following set of tools installed: Java JDK 11+, Apache Maven (optional, if not installed you can use embedded Maven inside Eclipse.) A modern web browser (recent Firefox, Chrome or Microsoft Edge will work fine) Eclipse integrated development environment (IDE) CIB seven First, download a distribution of the CIB seven. You can choose from different distributions for various application servers. In this tutorial, we will use the Apache Tomcat based distribution. Download it from the download page. After having downloaded the distribution, unpack it inside a directory of your choice. We will call that directory $CIBSEVEN_HOME. After you have successfully unpacked your distribution of the CIB seven, execute the script named start-cibseven.bat (for Windows users), respectively start-cibseven.sh (for Unix users). This script will start the application server and open a welcome screen in your web browser. If the page does not open, go to http://localhost:8080/camunda-welcome/index.html. Getting Help If you have trouble setting up the CIB seven platform, you can ask for assistance in the Discussions. Camunda Modeler Download the Camunda Modeler from the Camunda Modeler download page. After downloading the Modeler, simply unzip the download in a folder of your choice. After you have successfully unpacked the zip, run camunda-modeler.exe (for Windows users), camunda-modeler.app (for Mac users), or camunda-modeler.sh (for Linux users).",
    "url": "/get-started/dmn/install/index.html"
  },
  {
    "id": "get-started/dmn/model/index.html",
    "title": "Create a DMN Decision Table | docs.cibseven.org",
    "content": "In this section you learn how to create your first DMN Decision Table with the Camunda Modeler. The table will contain the decision logic about the desired dish for a given season and guest count. Now start up the Camunda Modeler. Create a new Decision Diagram Create a new DMN diagram by clicking File > New File > DMN Diagram. Start with the Table Header Start by setting the name and the id of the decision. Select the decision, open the Properties Panel on the right side and change the text to “dish” as the technical id of the decision which is used to reference the decision inside the process application. Next, click on the field below and set the name of the decision to “Dish”. Now drill down into the decision table of the newly created decision by clicking the table icon on top of the decision. To set the label of the input double-click on the field under “When” and type “Season” in the uppermost field. Same for the output label, double-click on the field under “Then” and type “Dish” in the uppermost field. Configure the Input Expression and the Output Name Assuming that the input value for “Season” is provided by a variable with name “season”, the input expression should be “season”. Double-click on the “Season” field. In the modal menu that pops up, set “season” as expression and close it. Next, double-click on the “Dish” field and set “desiredDish” as output name. Configure the Type of the Input and Output Assuming that the input value for “Season” is provided as String, the type of the input value should be “string”. Double-click on the “Season” column header. Open the “Type” dropdown-menu in the modal menu and select “string”. Same for the output type, double-click on the “Dish” column header and choose “string” as type. Add Rules Now, add the first rule that specifies that the desired dish for season “Fall” is “Spareribs”. Click on the “+” button at the bottom of the table or just click anywhere on the last row. In the row that was added, type “Fall” in the input column and “Spareribs” in the output column. “Fall” is the condition (i.e., input entry) of the rule. It is an expression in FEEL which is applied and then checks if the input value (i.e., the variable “season”) is equal to “Fall”. “Spareribs” is the conclusion (i.e., output entry) of the rule. It is a simple expression in JUEL and returns the String “Spareribs”. Next, add a second input “How many guests” with the input expression “guestCount” and type “integer”. Fill the table with additional rules for the remaining seasons. Configure the Hit Policy Set the hit policy to “UNIQUE”, which specifies that only one rule can match. Verify that the decision table contains only one rule that can match the inputs. Click on the “Hit Policy” dropdown and choose the hit policy “UNIQUE”. Default Hit Policy The default hit policy is “UNIQUE”. If your rules are disjunct so only one rule can match then you don’t need to change the hit policy. Save the Decision Table When you are done, save your changes by clicking File > Save File As... In the dialogue that pops up, navigate to the application project directory (by default this is in your Eclipse workspace path). In the project directory, place the model in the src/main/resources folder. Return to Eclipse. Right-click the project folder and click Refresh. This synchronizes the new DMN file with Eclipse. For Eclipse to automatically synchronize the workspace with the filesystem, consider configuring auto-sync in eclipse. Source Code Step-3 Catch up: Get the Sources of Step-3. Download as .zip or checkout the corresponding tag with Git. You can checkout the current state from the GitHub repository. If you have not cloned the repository yet, please execute the following command: git clone https://github.com/cibseven/cibseven-get-started-dmn.git To checkout the current state of the process application please execute the following command: git checkout -f Step-3 Or download as archive from here.",
    "url": "/get-started/dmn/model/index.html"
  },
  {
    "id": "get-started/dmn/project-setup/index.html",
    "title": "Setup a Java Project for DMN | docs.cibseven.org",
    "content": "Now you are ready to set up your first process application project in the IDE of your choice, the following description uses Eclipse. Terminology - Process vs. Decisions DMN is a modeling language for decisions, whereas BPMN is a language for processes. This tutorial is about decisions. However, due to BPMN-focused heritage of CIB seven, the Java project contains classes and files with names like ProcessApplication and processes.xml. These are in fact generally applicable and can be used with both processes and decisions. Create a new Maven Project Fancy to save work and use a project template instead? You don’t have to setup the project manually but can also use a Maven Archetype (which is like a project template), see Maven Archetypes for details. The archetype will create a project according to our best practices. In Eclipse, go to File / New / Other .... This opens the New Project Wizard. In the New Project Wizard select Maven / Maven Project. Click Next. On the first page of the New Maven Project Wizard select Create a simple project (skip archetype selection). Click Next. On the second page (see screenshot), configure the Maven coordinates for the project. Since we are setting up a WAR Project, make sure to select Packaging: war. When you are done, click Finish. Eclipse sets up a new Maven project. The project appears in the Project Explorer View. Add CIB seven Maven Dependencies The next step consists of setting up the Maven dependencies for your new process application. Add the following dependencies to the pom.xml file of your project: <project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"> <modelVersion>4.0.0</modelVersion> <groupId>de.cibseven.getstarted</groupId> <artifactId>dinner-dmn</artifactId> <version>0.1.0-SNAPSHOT</version> <packaging>war</packaging> <properties> <cibseven.version>7.22.0-cibseven</cibseven.version> <maven.compiler.release>11</maven.compiler.release> </properties> <repositories> <repository> <id>mvn-cibseven-public</id> <name>CIB seven Public Repository</name> <url>https://artifacts.cibseven.org/repository/public</url> </repository> </repositories> <dependencyManagement> <dependencies> <dependency> <groupId>org.camunda.bpm</groupId> <artifactId>camunda-bom</artifactId> <version>${cibseven.version}</version> <scope>import</scope> <type>pom</type> </dependency> </dependencies> </dependencyManagement> <dependencies> <dependency> <groupId>org.camunda.bpm</groupId> <artifactId>camunda-engine</artifactId> <scope>provided</scope> </dependency> <dependency> <groupId>jakarta.servlet</groupId> <artifactId>jakarta.servlet-api</artifactId> <version>5.0.0</version> </dependency> </dependencies> <build> <plugins> <plugin> <groupId>org.apache.maven.plugins</groupId> <artifactId>maven-compiler-plugin</artifactId> <version>3.11.0</version> </plugin> <plugin> <groupId>org.apache.maven.plugins</groupId> <artifactId>maven-war-plugin</artifactId> <version>3.3.2</version> <configuration> <failOnMissingWebXml>false</failOnMissingWebXml> </configuration> </plugin> </plugins> </build> </project> Now you can perform the first build. Select the pom.xml in the Package Explorer, perform a right-click and select Run As / Maven Install. Source Code Step-1 Catch up: Get the Sources of Step-1. Download as .zip or checkout the corresponding tag with Git. You can checkout the current state from the GitHub repository. If you have not cloned the repository yet, please execute the following command: git clone https://github.com/cibseven/cibseven-get-started-dmn.git To checkout the current state of the process application please execute the following command: git checkout -f Step-1 Or download as archive from here. Add a Process Application Class Next, you need to create a package, e.g., de.cibseven.getstarted.dmn and add a Process Application class to it. The Process Application class constitutes the interface between your application and the process engine. package de.cibseven.getstarted.dmn; import org.camunda.bpm.application.ProcessApplication; import org.camunda.bpm.application.impl.ServletProcessApplication; @ProcessApplication(\"Dinner App DMN\") public class DinnerApplication extends ServletProcessApplication { //empty implementation } Add a META-INF/processes.xml Deployment Descriptor The last step to set up the process application is to add the META-INF/processes.xml deployment descriptor file. This file allows us to provide a declarative configuration of the deployment(s) this process application makes to the process engine. This file needs to be added to the src/main/resources/META-INF folder of the Maven project. <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <process-application xmlns=\"http://www.camunda.org/schema/1.0/ProcessApplication\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <process-archive name=\"dinner-dmn\"> <process-engine>default</process-engine> <properties> <property name=\"isDeleteUponUndeploy\">false</property> <property name=\"isScanForProcessDefinitions\">true</property> </properties> </process-archive> </process-application> At this point you have successfully set up the process application and you can start modeling your first decision table. Source Code Step-2 Catch up: Get the Sources of Step-2. Download as .zip or checkout the corresponding tag with Git. You can checkout the current state from the GitHub repository. If you have not cloned the repository yet, please execute the following command: git clone https://github.com/cibseven/cibseven-get-started-dmn.git To checkout the current state of the process application please execute the following command: git checkout -f Step-2 Or download as archive from here.",
    "url": "/get-started/dmn/project-setup/index.html"
  },
  {
    "id": "get-started/dmn11/deploy/index.html",
    "title": "/get-started/dmn/deploy/",
    "content": "No content available",
    "url": "/get-started/dmn11/deploy/index.html"
  },
  {
    "id": "get-started/dmn11/drg/index.html",
    "title": "/get-started/dmn/drg/",
    "content": "No content available",
    "url": "/get-started/dmn11/drg/index.html"
  },
  {
    "id": "get-started/dmn11/index.html",
    "title": "/get-started/dmn/",
    "content": "No content available",
    "url": "/get-started/dmn11/index.html"
  },
  {
    "id": "get-started/dmn11/install/index.html",
    "title": "/get-started/dmn/install/",
    "content": "No content available",
    "url": "/get-started/dmn11/install/index.html"
  },
  {
    "id": "get-started/dmn11/model/index.html",
    "title": "/get-started/dmn/model/",
    "content": "No content available",
    "url": "/get-started/dmn11/model/index.html"
  },
  {
    "id": "get-started/dmn11/project-setup/index.html",
    "title": "/get-started/dmn/project-setup/",
    "content": "No content available",
    "url": "/get-started/dmn11/project-setup/index.html"
  },
  {
    "id": "get-started/index.html",
    "title": "Getting started with CIB seven platform | docs.cibseven.org",
    "content": "There are different ways to get started with CIB seven. Choose from the following guides:",
    "url": "/get-started/index.html"
  },
  {
    "id": "get-started/quick-start/complete/index.html",
    "title": "Congratulation! | docs.cibseven.org",
    "content": "Your first process instance is running successfully! Now that you got the process running you may move on to step four to learn how you can involve humans in your process. Feel free to remove the Desktop.getDesktop().browse() line if you don’t want to open this page again.",
    "url": "/get-started/quick-start/complete/index.html"
  },
  {
    "id": "get-started/quick-start/decision-automation/index.html",
    "title": "Leverage business rules (6/6) | docs.cibseven.org",
    "content": "In this section, you’ll learn how to add decision automation to your process by using BPMN 2.0 Business Rule Tasks and DMN 1.3 Decision Tables. Add a Business Rule Task to the Process Use the Camunda Modeler to open the Payment Retrieval process then click on the Approve Payment Task. Change the activity type to Business Rule Task in the wrench button menu. Next, link the Business Rule Task to a DMN table by changing Implementation to DMN and Decision Ref to approve-payment in the properties panel. In order to retrieve the result of the evaluation and save it automatically as a process instance variable in our process, we also need to change the Result Variable to approved and use singleEntry as the Map Decision Result in the properties panel. Save your changes and deploy the updated process using the Deploy Button in the Camunda Modeler. Create a DMN table using the Camunda Modeler First, create a new DMN diagram by clicking File > New File > DMN Diagram (Camunda 7). Now the newly created diagram will already have a decision element added to it. Select it by clicking it and then give it a name of Approve Payment and an ID of approve-payment (the decision ID must match the the Decision Ref in your BPMN process). Next, create a new DMN table by clicking the table button. Specify the DMN table First, specify the input expressions for the DMN table. In this example, we’ll decide whether a payment is approved based on the item name. Your rules can also make use of the FEEL Expression Language, JUEL or Script. If you like, you can read more about Expressions in the DMN Engine. Double click Input to configure the input column. Use Item as the Input Label and item as the Input Expression: Next, set up the output column. Use Approved as the Output Label and approved as the Output Name for the output column “Approved”: Let’s create some rules by clicking on the plus icon on the left side of the DMN table. We should also change the Output Column to the Data Type boolean: After setup, your DMN table should look like this: Deploy the DMN table To deploy the Decision Table, click on the Deploy button in the Camunda Modeler, give it Deployment Name “Payment Retrieval Decision”, then hit the Deploy button. Verify the Deployment with Cockpit Now, use Cockpit to see if the decision table was successfully deployed. Go to http://localhost:8080/camunda/app/cockpit/. Log in with the credentials demo / demo. Navigate to the “Decisions” section. Your decision table Approve Payment should be listed as deployed decision definition. Inspect using Cockpit and Tasklist Next, use Tasklist to start two new Process Instances and verify that depending on your input, the Process Instance will be routed differently. To do so, go to http://localhost:8080/camunda/app/tasklist/. Log in with demo / demo. Click on the Start process button to start a process instance and choose the Payment process. Use the generic form to add the variables as follows: Hit the Start Instance button. Next, click again on the Start process button to start another process instance and choose the Payment process. Use the generic form to add the variables as follows: You’ll see that depending on the input, the worker will either charge or not charge the credit card. You can also verify that the DMN tables were evaluated by using Camunda Cockpit. Go to http://localhost:8080/camunda/app/cockpit/. Log in with the credentials demo / demo. Navigate to the “Decisions” section and click on Approve Payment. Check the different Decision Instances that were evaluated by clicking on the ID in the table. A single DMN table that was executed could look like this in Camunda Cockpit: Success! Congratulations! You’ve successfully completed the CIB seven Platform Quick Start. Ready to continue? We recommend the Platform documentation. Source Code Step-5 Catch up: Get the Sources of Step-5. Download as .zip or checkout the corresponding tag with Git. You can checkout the current state from the GitHub repository. If you have not cloned the repository yet, please execute the following command: git clone https://github.com/cibseven/cibseven-get-started-quickstart.git To checkout the current state of the process application please execute the following command: git checkout -f Step-5 Or download as archive from here.",
    "url": "/get-started/quick-start/decision-automation/index.html"
  },
  {
    "id": "get-started/quick-start/deploy/index.html",
    "title": "Deploy the Process (3/6) | docs.cibseven.org",
    "content": "In the next step, you’ll deploy the Process and start a new instance so you can see that your simple process is working correctly. Deployment Support BPMN diagrams must be created for the process engine they intend to be deployed on. You cannot run a BPMN diagram modeled for Camunda Platform in Camunda Cloud, or vice versa, at this time. Use the Camunda Modeler to Deploy the Process In order to deploy the Process, click on the deploy button in the Camunda Modeler, then give it the Deployment Name “Payment Retrieval” and click the Deploy button. From version 3.0.0 on, you will be required to provide an URL for an Endpoint Configuration along with Deployment Details. This can be either the root endpoint to the REST API (e.g. http://localhost:8080/engine-rest) or an exact endpoint to the deployment creation method (e.g. http://localhost:8080/engine-rest/deployment/create). You should see a success message in the Camunda Modeler: More details regarding the deployment from Camunda Modeler you can find here. For Camunda Modeler 2.2.4 and earlier, read this blog post. Verify the Deployment with Cockpit Next, use Cockpit to see if the process was successfully deployed. Go to http://localhost:8080/camunda/app/cockpit/ and log in with the credentials demo / demo. Your process Payment Retrieval should be visible on the dashboard. Start a Process Instance In Camunda, there are different ways to start a new process instance. You can leverage the Camunda REST API to start a new process instance by sending a POST Request. a) curl curl -H \"Content-Type: application/json\" -X POST -d '{\"variables\": {\"amount\": {\"value\":555,\"type\":\"integer\"}, \"item\": {\"value\":\"item-xyz\"} } }' http://localhost:8080/engine-rest/process-definition/key/payment-retrieval/start In your worker, you should now see the output in your console. This means you have successfully started and executed your first simple process. b) REST Client If you don’t feel comfortable using curl for the REST request, you can instead make use of any REST client. Make a POST request to the following endpoint: http://localhost:8080/engine-rest/process-definition/key/payment-retrieval/start The JSON Body should look like this: { \"variables\": { \"amount\": { \"value\":555, \"type\":\"integer\" }, \"item\": { \"value\": \"item-xyz\" } } } Hint: Make sure you are setting the headers correctly to Content-Type: application/json Here’s what the request might look like in Postman: In your worker console (which we started in the previous section), you should now see an output. This means you have successfully started and executed your first simple process. Next Step In some cases, we’ll want to involve humans in our process. Move onto the next step to learn how you can involve humans in your process.",
    "url": "/get-started/quick-start/deploy/index.html"
  },
  {
    "id": "get-started/quick-start/gateway/index.html",
    "title": "Add Gateways to the Process (5/6) | docs.cibseven.org",
    "content": "In this section, you’ll learn how to make your process more dynamic by using BPMN 2.0 Exclusive Gateways. Add Two Gateways We want to modify our process so that it’s more dynamic. To do so, open the process in the Camunda Modeler. Next, from the Modeler’s left-hand menu, select the gateway shape (diamond) and drag it into position between the Start Event and the Service Task. Use the create space tool again as needed. Move the User Task down and add another Gateway after it. Lastly, adjust the Sequence Flows so that the model looks like this: Now also name the new elements accordingly: Configure the Gateways Next, open the properties panel and select the <1000 € Sequence Flow after the Gateway on the canvas. This will update the selection in the properties panel. Scroll to the property named Condition Type and change it to Expression. Then input ${amount<1000} as the Expression. We are using the Java Unified Expression Language to evaluate the Gateway. Next, change the Expressions for the other Sequence Flows, too. For the >=1000 € Sequence Flow, use the Expression ${amount>=1000}: For the Yes Sequence Flow, use the Expression ${approved}: For the No Sequence Flow, use the Expression ${!approved}: Deploy the Process Use the Deploy Button in the Camunda Modeler to deploy the updated process to Camunda. Work on the Task Go to Tasklist (http://localhost:8080/camunda/app/tasklist/) and log in with the credentials “demo / demo”. Click on the Start process button to start a process instance for the Payment Retrieval Process. Next, set variables for the process instance using the generic form as we learned in the User Tasks section. Fill in the form as shown in the screenshot and make sure you use an amount that is larger or equal to 1000 in order to see the User Task Approve Payment. When you are done, click Start. You should see the Approve Payment task when you click on All Tasks. In this quick start, we’re logged into Tasklist as an admin user, and so we can see all tasks associated with our processes. However, it’s possible to create filters in Tasklist to determine which users can see which tasks based on user authorization as well as other criteria. To work on the task, select the Form tab and check the approved checkbox so that our payment retrieval gets approved. We should see that our worker prints something to the console. Next, repeat the same steps, and this time, reject the payment. You should also create one instance with an amount less than 1000 to confirm that the first gateway works correctly. Next Step Now you’re ready for Decision Automation. Let’s have a look how you can add Business Rules to your Process. Source Code Step-4 Catch up: Get the Sources of Step-4. Download as .zip or checkout the corresponding tag with Git. You can checkout the current state from the GitHub repository. If you have not cloned the repository yet, please execute the following command: git clone https://github.com/cibseven/cibseven-get-started-quickstart.git To checkout the current state of the process application please execute the following command: git checkout -f Step-4 Or download as archive from here.",
    "url": "/get-started/quick-start/gateway/index.html"
  },
  {
    "id": "get-started/quick-start/index.html",
    "title": "Get started with CIB seven | docs.cibseven.org",
    "content": "This tutorial guides you through modeling and implementing your first workflow with the CIB seven. In this guide, you’ll choose between implementing executable processes in Java or JavaScript (NodeJS) using one of CIB seven’s ready-to-go task clients. Source Code Join in: Get the Sources for this guide. Download as .zip or checkout the corresponding tag with Git. In addition to this guide, the source code of the example project is also available on GitHub. You can directly download the whole project or clone it with git: git clone https://github.com/cibseven/cibseven-get-started-quickstart.git To follow this guide, download the initial state or checkout the tag in the git repository: git checkout -f Start or every step in between: git checkout -f Step-X After every section in this guide you will find a box which contains a download link to the current state of the project and git instructions to checkout the current version of the repository. You will be guided through the following six steps:",
    "url": "/get-started/quick-start/index.html"
  },
  {
    "id": "get-started/quick-start/install/index.html",
    "title": "Download and Installation (1/6) | docs.cibseven.org",
    "content": "First, you need to install the CIB seven Platform and the Camunda Modeler. In the following section, we’ll describe how to install the CIB seven platform locally on your machine. Hint If you prefer, you can also run the CIB seven with Docker: docker pull cibseven/cibseven:run-latest docker run -d --name cibseven -p 8080:8080 cibseven/cibseven:run-latest Afterwards, you can install the Camunda Modeler. Prerequisites Please make sure you have the following installed: Java Runtime Environment 11 You can verify this by using your terminal, shell, or command line: java -version If you need to install Java Runtime Environment, you can find the download from Oracle here. Supported Java versions Make sure to use a Java version from Camunda’s list of supported environments. CIB seven platform First, download a distribution of the CIB seven. You can choose from different distributions for various application servers. In this tutorial, we’ll use CIB seven Run. Download it from the download page. After downloading the distribution, unpack it inside a directory of your choice. After you’ve successfully unpacked your distribution of the CIB seven, execute the script named start.bat (for Windows users) or start.sh (for Unix users). This script will start the application server. Open your web browser and navigate to http://localhost:8080/ to visit the Welcome Page. Camunda Modeler Download the Camunda Modeler from the Camunda Modeler download page. After downloading the Modeler, simply unzip the download in a folder of your choice. After you have successfully unpacked the zip, run camunda-modeler.exe (for Windows users), camunda-modeler.app (for Mac users), or camunda-modeler.sh (for Linux users). Next Step Once you’ve installed the CIB seven and the Camunda Modeler, you can move to the next step to model and execute your first process.",
    "url": "/get-started/quick-start/install/index.html"
  },
  {
    "id": "get-started/quick-start/service-task/index.html",
    "title": "Executing automated steps (2/6) | docs.cibseven.org",
    "content": "In this section, you’ll learn how to create your first BPMN 2.0 process with the Camunda Modeler and how to execute automated steps. Start by opening up Camunda Modeler. Create a new BPMN Diagram Create a new BPMN diagram by clicking File > New File > BPMN Diagram (Camunda 7). Start with a Simple Process Start by modeling a simple process. Double-click on the Start Event. A text box will open. Name the Start Event Payment Retrieval Requested. Hint When editing Labels, you can add line breaks using Shift + Enter. Click on the start event. From its context menu, select the activity shape (rounded rectangle). It will be placed automatically on the canvas, and you can drag it to your preferred position. Name it Charge Credit Card. Change the activity type to Service Task by clicking on the activity shape and using the wrench button. Add an End Event named Payment Received. Configure the Service Task There are different ways to execute service tasks using CIB seven. In this guide, we’ll use the external task pattern. Open the Properties Panel within the Camunda Modeler and click on the Service Task you just created. Change the Implementation to External and use charge-card as the Topic. Configure Properties for Execution Because we’re modeling an executable process, we should give it an ID and set the isExecutable property to true. On the right-hand side of the canvas, you find the properties panel. When you click on empty space on the modeling canvas, the properties panel will display the properties of the process itself. First, configure an ID for the process. Type payment-retrieval in the property field Id. The property ID is used by the process engine as an identifier for the executable process, and it’s best practice to set it to a human-readable name. Second, configure the Name of the process. Type Payment Retrieval in the property field Name. Finally, make sure the box next to the Executable property is checked. If you don’t check this box, the process definition is ignored by the process engine. Save the BPMN Diagram When you’re done, save your changes by clicking File > Save File As... In the dialogue that appears, navigate to a folder of your choice and save the diagram as something like payment.bpmn. Source Code Step-1 Catch up: Get the Sources of Step-1. Download as .zip or checkout the corresponding tag with Git. You can checkout the current state from the GitHub repository. If you have not cloned the repository yet, please execute the following command: git clone https://github.com/cibseven/cibseven-get-started-quickstart.git To checkout the current state of the process application please execute the following command: git checkout -f Step-1 Or download as archive from here. Implement an external task worker After modeling the process, we want to execute some business logic. CIB seven platform is built so that your business logic can be implemented in different languages. You have the choice which language suits your project best. In this quick start, we’ll show you how to use ready-to-go task clients for CIB seven in: Java JavaScript (NodeJS) If you’ve never worked with Java before, we recommend using the JavaScript (NodeJS) task client in this tutorial. Hint If you prefer a different programming language, you can also use REST API to access CIB seven API operations via HTTP. a) Using Java In this section, you’ll learn how to implement an external task worker in Java. Prerequisites Make sure you have the following tools installed: JDK 11 An IDE for Java projects (e.g. Eclipse) Create a new Maven project Start by creating a new Maven project in your IDE. If you’re using Eclipse, you can follow these steps: In Eclipse, go to File / New / Other …. This opens the New Project Wizard. In the New Project Wizard, select Maven / Maven Project. Click Next. On the first page of the New Maven Project Wizard, select Create a simple project (you can skip archetype selection). Click Next. On the second page (see screenshot), configure the Maven coordinates for the project. Since we are setting up a JAR Project, make sure to select Packaging: jar. When you’re done, click Finish. Eclipse will set up a new Maven project. The project appears in the Project Explorer View. Add CIB seven External Task Client Dependency The next step consists of setting up the Maven dependency to the external task client for your new process application. Your pom.xml file of your project should look like this: <project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"> <modelVersion>4.0.0</modelVersion> <groupId>de.cibseven.getstarted</groupId> <artifactId>charge-card-worker</artifactId> <version>0.0.1-SNAPSHOT</version> <properties> <external-task-client.version>7.22.0-cibseven</external-task-client.version> <maven.compiler.source>11</maven.compiler.source> <maven.compiler.target>11</maven.compiler.target> </properties> <repositories> <repository> <id>mvn-cibseven-public</id> <name>CIB seven Public Repository</name> <url>https://artifacts.cibseven.org/repository/public</url> </repository> </repositories> <dependencies> <dependency> <groupId>org.camunda.bpm</groupId> <artifactId>camunda-external-task-client</artifactId> <version>${external-task-client.version}</version> </dependency> <dependency> <groupId>org.slf4j</groupId> <artifactId>slf4j-simple</artifactId> <version>1.7.36</version> </dependency> <dependency> <groupId>jakarta.xml.bind</groupId> <artifactId>jakarta.xml.bind-api</artifactId> <version>4.0.2</version> </dependency> </dependencies> </project> Add the Java class Next, we will create a new ExternalTaskClient which subscribes to the charge-card topic. When the process engine encounters a service task that is configured to be externally handled, it creates an external task instance on which our handler will react. We are using Long Polling in the ExternalTaskClient to make the communication more efficient. Next, you need to create a package, e.g., de.cibseven.getstarted.chargecard and add a Java class, e.g. ChargeCardWorker, to it. package de.cibseven.getstarted.chargecard; import java.util.logging.Logger; import java.awt.Desktop; import java.net.URI; import org.camunda.bpm.client.ExternalTaskClient; public class ChargeCardWorker { private final static Logger LOGGER = Logger.getLogger(ChargeCardWorker.class.getName()); public static void main(String[] args) { ExternalTaskClient client = ExternalTaskClient.create() .baseUrl(\"http://localhost:8080/engine-rest\") .asyncResponseTimeout(10000) // long polling timeout .build(); // subscribe to an external task topic as specified in the process client.subscribe(\"charge-card\") .lockDuration(1000) // the default lock duration is 20 seconds, but you can override this .handler((externalTask, externalTaskService) -> { // Put your business logic here // Get a process variable String item = externalTask.getVariable(\"item\"); Integer amount = externalTask.getVariable(\"amount\"); LOGGER.info(\"Charging credit card with an amount of '\" + amount + \"'€ for the item '\" + item + \"'...\"); try { Desktop.getDesktop().browse(new URI(\"https://docs.cibseven.de/get-started/quick-start/complete\")); } catch (Exception e) { e.printStackTrace(); } // Complete the task externalTaskService.complete(externalTask); }) .open(); } } Run the worker You can run the Java application by right clicking on the class ChargeCardWorker and choosing Run as Java. Note that the worker should remain running throughout the entirety of this quick start guide. Next Step Once your worker is running, you can continue to deploy your process and start some instances. Source Code Step-2a Catch up: Get the Sources of Step-2a. Download as .zip or checkout the corresponding tag with Git. You can checkout the current state from the GitHub repository. If you have not cloned the repository yet, please execute the following command: git clone https://github.com/cibseven/cibseven-get-started-quickstart.git To checkout the current state of the process application please execute the following command: git checkout -f Step-2a Or download as archive from here. b) Using JavaScript (NodeJS) In this section, you’ll learn how to implement an external task worker in NodeJS. Prerequisites Make sure you have the following tools installed: NodeJS >= v16 (Download available here) Editor for JavaScript files (e.g. Atom) Create a new NodeJS project mkdir charge-card-worker cd ./charge-card-worker npm init -y Update package.json to enable ES modules Add the following “type” field to your package.json file: { // ... \"main\": \"index.js\", \"type\": \"module\", \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\" }, // ... } Add Camunda External Task Client JS library npm install camunda-external-task-client-js npm install -D open Implement the NodeJS script Next, we’ll create a new ExternalTaskClient that subscribes to the charge-card topic. When the process engine encounters a service task that’s configured to be externally handled, it creates an external task instance on which our handler will react. We use Long Polling in the ExternalTaskClient to make the communication more efficient. Next, you need to create a new JavaScript file, e.g. worker.js, that looks like the following: import { Client, logger } from 'camunda-external-task-client-js'; import open from 'open'; // configuration for the Client: // - 'baseUrl': url to the Process Engine // - 'logger': utility to automatically log important events // - 'asyncResponseTimeout': long polling timeout (then a new request will be issued) const config = { baseUrl: 'http://localhost:8080/engine-rest', use: logger, asyncResponseTimeout: 10000 }; // create a Client instance with custom configuration const client = new Client(config); // susbscribe to the topic: 'charge-card' client.subscribe('charge-card', async function({ task, taskService }) { // Put your business logic here // Get a process variable const amount = task.variables.get('amount'); const item = task.variables.get('item'); console.log(`Charging credit card with an amount of ${amount}€ for the item '${item}'...`); open('https://docs.camunda.org/get-started/quick-start/success'); // Complete the task await taskService.complete(task); }); Run the NodeJS script You can run the NodeJS script with: node ./worker.js Note that the worker should remain running throughout the entirety of this quick start guide. Next Step Once your worker is running, you can move onto the next step to deploy your process and start some instances. Source Code Step-2b Catch up: Get the Sources of Step-2b. Download as .zip or checkout the corresponding tag with Git. You can checkout the current state from the GitHub repository. If you have not cloned the repository yet, please execute the following command: git clone https://github.com/cibseven/cibseven-get-started-quickstart.git To checkout the current state of the process application please execute the following command: git checkout -f Step-2b Or download as archive from here.",
    "url": "/get-started/quick-start/service-task/index.html"
  },
  {
    "id": "get-started/quick-start/success/index.html",
    "title": "Congratulation! | docs.cibseven.org",
    "content": "Your first process instance is running successfully! Now that you got the process running you may move on to step four to learn how you can involve humans in your process. Feel free to remove the open() line if you don’t want to open this page again.",
    "url": "/get-started/quick-start/success/index.html"
  },
  {
    "id": "get-started/quick-start/user-task/index.html",
    "title": "Add a User Task to the Process (4/6) | docs.cibseven.org",
    "content": "In this section, you’ll learn how to involve humans in your process by using BPMN 2.0 User Tasks. Add a User Task We want to modify our process so that we can involve humans. To do so, open the process in the Camunda Modeler. Select the create/remove space tool (<||>) from the Modeler’s left-hand menu, and use it to create space between the Start Event and the “Charge Credit Card” Service Task (click and drag the cursor to the right). Next, from the Modeler’s left-hand menu, select the activity shape (rounded rectangle) and drag it into position between the Start Event and the “Charge Credit Card” Service Task. Name it Approve Payment. Change the activity type to User Task by clicking on it and using the wrench button menu. Configure a User Task Next, open the properties view. If the properties view is not already visible, click on the “Properties Panel” label on the right-hand side of the Modeler canvas. Select the User Task on the canvas. This will update the selection in the properties view. Scroll to the property named Assignee. Type demo to automatically assign the task to the demo user once the process runs. Configure a basic form in the User Task This step will also take place in the properties panel. If the panel is not already visible, click on the “Properties Panel” label on the right-hand side of the Modeler canvas. Select the User Task on the canvas. This will update the selection in the properties view. Click on the Tab Forms in the properties panel. This guide uses Camunda Forms to add a form to the process. We will create a form file called payment.form. Set the following fields to link this process to the form you are about to create: Type: Camunda Forms Form Ref: payment-form Binding: deployment Now, create a new form by clicking File > New File > Form (Camunda 7) and add payment-form as the Id field. You can add form fields by dragging and dropping elements from the FORM ELEMENTS LIBRARY on the left. Add the following three form fields: Field 1: Type: Number Key: amount Field Label: Amount Field 2: Type: Text Field Key: item Field Label: Item Field 3: Type: Checkbox Key: approved Label: Approved? Now, select Camunda Platform as the execution platform in the lower left corner of the modeler and hit Apply. Finally, save the form as payment.form. Deploy the Process Switch back to the process diagram Click the Deploy button in the Camunda Modeler In the deployment panel, select the payment.form file under include additional files Click Deploy Work on the Task Go to Tasklist (http://localhost:8080/camunda/app/tasklist/) and log in with the credentials “demo / demo”. Click on the Start process button to start a process instance. This opens a dialog where you can select Payment Retrieval from the list. Now you can set variables for the process instance using a generic form. The generic form can be used whenever you have not added a dedicated form for a User Task or a Start Event. Click on the Add a variable button to create a new row. Fill in the form as shown in the screenshot. When you’re done, click Start. Hint If you don’t see any tasks in your Tasklist, you might need a filter. Add one by clicking Add a simple filter on the left. You should now see the Approve Payment task in your Tasklist. Select the task and click on the Diagram tab. This displays the process diagram highlighting the User Task that’s waiting to be worked on. To work on the task, select the Form tab. Because we defined the variables in the Form Tab in the Camunda Modeler, the Tasklist has automatically generated form fields for us. Next Step Next, we’ll make the process more dynamic and only show a User Task in certain situations. Let’s have a look how you can add Gateways to your Process. Source Code Step-3 Catch up: Get the Sources of Step-3. Download as .zip or checkout the corresponding tag with Git. You can checkout the current state from the GitHub repository. If you have not cloned the repository yet, please execute the following command: git clone https://github.com/cibseven/cibseven-get-started-quickstart.git To checkout the current state of the process application please execute the following command: git checkout -f Step-3 Or download as archive from here.",
    "url": "/get-started/quick-start/user-task/index.html"
  },
  {
    "id": "get-started/spring-boot/configuration/index.html",
    "title": "Configure a Spring Boot Project | docs.cibseven.org",
    "content": "The CIB seven Spring Boot Application created in previous step uses the default and best practice configuration, embedded in a starter. There are several ways to customize or override the configuration. The easiest is to provide a set of parameters in the application.yaml (or application.properties) file. The full list of supported configuration parameters can be found here. Customize Configuration Let’s create an application.yaml file in the src/main/resources folder with the following content: camunda.bpm: admin-user: id: demo password: demo firstName: Demo filter: create: All tasks This configuration will result in the following: Admin user “demo” with the provided password and first name will be created. Default filter with the name “All tasks” will be created for Tasklist. Build and Run Now you can rebuild and rerun the application again. Don’t forget to call mvn clean before calling mvn install again. Now when you open http://localhost:8080/ in your browser, it does not ask you for admin user creation, but asks for login and password. You can use “demo/demo”, which we configured before, to access the CIB seven web applications. After you logged in, you can go to Tasklist and see that a filter named “All tasks” was created, though it does not contain any tasks so far. Source Code Step-2 Catch up: Get the Sources of Step-2. Download as .zip or checkout the corresponding tag with Git. You can checkout the current state from the GitHub repository. If you have not cloned the repository yet, please execute the following command: git clone https://github.com/cibseven/cibseven-get-started-spring-boot.git To checkout the current state of the process application please execute the following command: git checkout -f Step-2 Or download as archive from here.",
    "url": "/get-started/spring-boot/configuration/index.html"
  },
  {
    "id": "get-started/spring-boot/index.html",
    "title": "Get started with CIB seven and the Spring Boot | docs.cibseven.org",
    "content": "This tutorial guides you through your first steps of using CIB seven Platform in a Spring Boot application. Target Audience: In this tutorial we assume that you are familiar with the basics of Java web application development and Spring Boot. We also assume that you have installed an Eclipse distribution and the Camunda Modeler. Source Code Join in: Get the Sources for this guide. Download as .zip or checkout the corresponding tag with Git. In addition to this guide, the source code of the example project is also available on GitHub. You can directly download the whole project or clone it with git: git clone https://github.com/cibseven/cibseven-get-started-spring-boot.git To follow this guide, download the initial state or checkout the tag in the git repository: git checkout -f Start or every step in between: git checkout -f Step-X After every section in this guide you will find a box which contains a download link to the current state of the project and git instructions to checkout the current version of the repository. You will be guided through the following steps:",
    "url": "/get-started/spring-boot/index.html"
  },
  {
    "id": "get-started/spring-boot/model/index.html",
    "title": "Modeling a BPMN 2.0 Process | docs.cibseven.org",
    "content": "In this section we learn how to deploy a process and invoke a Spring Bean from a BPMN 2.0 Service Task. Deploy and Invoke BPMN Process Now that we know how to bootstrap the process engine within a Spring Boot Application, we can add a BPMN 2.0 process model and interact with the process from inside our Spring beans. In this section, we will Model an executable BPMN 2.0 process. Use Spring Boot Starter auto-deployment for BPMN 2.0 processes. Create a process application. Start a process instance from our process application. Model an Executable BPMN 2.0 Process and Deploy It Start by modeling an executable process using the Camunda Modeler. The process should look as depicted in the screenshot below. Hint If you are unfamiliar with modeling an executable process, you can read the Model a Process section of the Quick Start tutorial. When you are done, save the process model in the src/main/resources folder of your Eclipse project. Make sure to refresh the Eclipse project afterwards. Once it is saved in the application classpath, it will be automatically deployed on engine startup. Create Process Application We recommend to declare the process application in your CIB seven Spring Boot application, which gives additional configuration possibilities and will help us in the current demo to catch the “post-deploy” event to start the process instance at that point. To declare the process application, just add the @EnableProcessApplication annotation on your WebappExampleProcessApplication class and put the empty processes.xml file in the src/main/resources/META-INF folder. The file is required by the CIB seven engine for every process application, but in our case it will stay empty. Start a Process Instance after Process Application has been Deployed The next step consists of starting a process instance from our process application class. For this, we will process PostDeployEvent, which is fired as soon as our process application has been deployed to the CIB seven engine. ... @Autowired private RuntimeService runtimeService; @EventListener private void processPostDeploy(PostDeployEvent event) { runtimeService.startProcessInstanceByKey(\"loanApproval\"); } ... Note that we can easily inject the CIB seven engine service via the @Autowired annotation. Rebuild and test If you rebuild and restart the application, you should see the task “Check the request” in Tasklist under the “All tasks” filter: Source Code Step-3 Catch up: Get the Sources of Step-3. Download as .zip or checkout the corresponding tag with Git. You can checkout the current state from the GitHub repository. If you have not cloned the repository yet, please execute the following command: git clone https://github.com/cibseven/cibseven-get-started-spring-boot.git To checkout the current state of the process application please execute the following command: git checkout -f Step-3 Or download as archive from here.",
    "url": "/get-started/spring-boot/model/index.html"
  },
  {
    "id": "get-started/spring-boot/project-setup/index.html",
    "title": "Setup a Spring Boot Project | docs.cibseven.org",
    "content": "First, let’s set up your first process application project in the IDE of your choice, the following description uses Eclipse. Requirements The project requires Java 17/21. Set Up a Java Project We will start by setting up a Spring Boot application as an Apache Maven Project inside Eclipse. This consists of three steps: Create a new Maven Project in Eclipse Add the CIB seven & Spring Boot dependencies Add a main class as an entry point for launching the Spring Boot application. In the following sections, we go through this process step by step. Create a new Maven Project First, we set up a new Apache Maven based project. Let’s call it loan-approval-spring-boot. The screenshot below illustrates the settings we choose in Eclipse. When you are done, click Finish. Eclipse sets up a new Maven project. The project appears in the Project Explorer view. Add CIB seven & Spring Boot Dependencies The next step consists of setting up the Maven dependencies for the new project. Maven dependencies need to be added to the pom.xml file of the project. We add the Spring Boot BOM in the “dependency management” section and the CIB seven Spring Boot Starter for Webapps, which will automatically include the CIB seven engine and webapps in the app. We also use spring-boot-maven-plugin, which does all the magic for packaging Spring Boot application content together. <project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"> <modelVersion>4.0.0</modelVersion> <groupId>org.camunda.bpm.getstarted</groupId> <artifactId>loan-approval-spring-boot</artifactId> <version>0.0.1-SNAPSHOT</version> <properties> <camunda.spring-boot.version>7.22.0-cibseven</camunda.spring-boot.version> <spring-boot.version>3.3.5</spring-boot.version> <maven.compiler.release>17</maven.compiler.release> </properties> <repositories> <repository> <id>mvn-cibseven-public</id> <name>CIB seven Public Repository</name> <url>https://artifacts.cibseven.org/repository/public</url> </repository> </repositories> <dependencyManagement> <dependencies> <dependency> <groupId>org.springframework.boot</groupId> <artifactId>spring-boot-dependencies</artifactId> <version>${spring-boot.version}</version> <type>pom</type> <scope>import</scope> </dependency> </dependencies> </dependencyManagement> <dependencies> <dependency> <groupId>org.camunda.bpm.springboot</groupId> <artifactId>camunda-bpm-spring-boot-starter-webapp</artifactId> <version>${camunda.spring-boot.version}</version> </dependency> <dependency> <groupId>com.h2database</groupId> <artifactId>h2</artifactId> </dependency> <dependency> <groupId>com.sun.xml.bind</groupId> <artifactId>jaxb-impl</artifactId> <version>4.0.3</version> </dependency> </dependencies> <build> <plugins> <plugin> <groupId>org.springframework.boot</groupId> <artifactId>spring-boot-maven-plugin</artifactId> <version>${spring-boot.version}</version> <configuration> <layout>ZIP</layout> </configuration> <executions> <execution> <goals> <goal>repackage</goal> </goals> </execution> </executions> </plugin> <plugin> <groupId>org.apache.maven.plugins</groupId> <artifactId>maven-compiler-plugin</artifactId> <version>3.11.0</version> </plugin> </plugins> </build> </project> Add Main Class to our Spring Boot Application Next, we add an application class with a main method that will be the entry point for launching the Spring Boot application. The class has the annotation @SpringBootApplication on it, which implicitly adds several convenient features (autoconfiguration, component scan, etc. - see Spring Boot docs). The class is added in the src/main/java folder in the de.cibseven.getstarted.loanapproval package. package de.cibseven.getstarted.loanapproval; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class WebappExampleProcessApplication { public static void main(String... args) { SpringApplication.run(WebappExampleProcessApplication.class, args); } } Build and Run Now you can perform the first build. Select the pom.xml in the Package Explorer, perform a right-click and select Run As / Maven Install. Our first CIB seven Spring Boot application is ready now. As a result of the build, you will have a JAR-file in your target folder. This JAR is a Spring Boot application, which embeds inside Tomcat as a web container, CIB seven engine and web applications resources. When started, it will use an in-memory H2 database for CIB seven engine needs. You can run the application by right-clicking on the WebappExampleProcessApplication class and selecting Run as / Java application. Wait until you see a similar line in the console: Started WebappExampleProcessApplication in 10.584 seconds Then go to http://localhost:8080/ in your browser and enjoy the CIB seven webapps. Another way to run the app is to simply run the JAR-file with a java -jar command. Source Code Step-1 Catch up: Get the Sources of Step-1. Download as .zip or checkout the corresponding tag with Git. You can checkout the current state from the GitHub repository. If you have not cloned the repository yet, please execute the following command: git clone https://github.com/cibseven/cibseven-get-started-spring-boot.git To checkout the current state of the process application please execute the following command: git checkout -f Step-1 Or download as archive from here.",
    "url": "/get-started/spring-boot/project-setup/index.html"
  },
  {
    "id": "index.html",
    "title": "Untitled",
    "content": "No content available",
    "url": "/index.html"
  },
  {
    "id": "manual/index.html",
    "title": "Untitled",
    "content": "No content available",
    "url": "/manual/index.html"
  },
  {
    "id": "manual/installation/index.html",
    "title": "Untitled",
    "content": "No content available",
    "url": "/manual/installation/index.html"
  },
  {
    "id": "manual/latest/examples/index.html",
    "title": "Examples | docs.cibseven.org",
    "content": "Completed the Getting Started Guides? Now discover what you can build with CIB seven. This page collects links to hands-on examples around Camunda. They are still actual for CIB seven as well. Camunda Examples (Github) Camunda Consulting Examples (Github)",
    "url": "/manual/latest/examples/index.html"
  },
  {
    "id": "manual/latest/index.html",
    "title": "CIB seven Documentation | docs.cibseven.org",
    "content": "Welcome to the CIB seven Manual! CIB seven is a light-weight, open-source platform for Business Process Management. The Manual introduces key concepts in CIB seven, provides installation procedures as well as a comprehensive reference section. CIB seven is an open-source fork of discontinued since 2025 Camunda 7 business process management platform. Getting Started The Guide Get started with CIB seven is the quickest and easiest way to get up and running with CIB seven. Alternatives include: BPMN 2.0 DMN 1.3 Spring Boot Apache Maven Once you completed a Getting Started Guide, you may find the following topics useful: Introduction Overview Download Architecture Supported Environments Guides Installation User Guide Web Applications Update & Migration References REST Api Javadoc BPMN 2.0 CMMN 1.1 DMN 1.3 HTML Forms Getting Help In case you get stuck on a problem make sure to ask for Help in the Discussios. Community Extensions A number of Community Extensions enhance CIB seven with additional capabilities. CIB seven is still compatible with Camunda, so you can browse the Camunda Community Hub for information on building a CIB seven compatible Community Extension, discover Community Extension open source projects to contribute to, and more.",
    "url": "/manual/latest/index.html"
  },
  {
    "id": "manual/latest/installation/cibseven-run/index.html",
    "title": "Install CIB seven Run | docs.cibseven.org",
    "content": "What is a Remote Engine Distribution? If you need a Remote or Shared Engine Distribution depends on your use-case. Check out the architecture overview for more information. This page describes the steps to execute CIB seven Run. Requirements Please make sure that you have the Java Runtime Environment 17 installed. You can verify this by using your terminal, shell, or command line: java -version If you need to install Java Runtime Environment, you can find the download from Oracle here. Installation Procedure Download the pre-packed distribution from the [download site] (https://cibseven.org/download/). Unpack the distro to a directory. Configure the distro as described in the User Guide. Start CIB seven Run by executing the start script (start.bat for Windows, start.sh for Linux/Mac). Access the CIB seven webapps (Cockpit, Tasklist, Admin) via http://localhost:8080/camunda/app/. Access the REST API via http://localhost:8080/engine-rest (e.g. http://localhost:8080/engine-rest/engine).",
    "url": "/manual/latest/installation/cibseven-run/index.html"
  },
  {
    "id": "manual/latest/installation/database-schema/index.html",
    "title": "Install the Database Schema | docs.cibseven.org",
    "content": "This document will guide you through the installation and update of the CIB seven database schema used by the process engine. Regardless of the architecture of your application setup, the process engine always requires this database schema. In a production environment, we recommend setting up this schema yourself and reference the prepared database instance in your application configuration. Consult the installation guide related to your setup to configure the database for a remote engine, shared engine, or embedded engine accordingly. This guide will not detail how to set up an instance of your target database or how to create a schema object on it. Consult the documentation of your target database on how to do that. CIB seven supports a variety of databases that are documented in the supported environments. CIB seven supports the following ways of installing the database schema: Use the database migration tool Liquibase with the provided changelog for a semi-automatic installation and update. Liquibase keeps track of database schema changes. This allows you to focus on when changes should be applied rather than also on which changes are relevant. Starting with version 7.16.0, CIB seven comes with a curated changelog file that Liquibase can consume. Use the provided SQL scripts with the tools related to your database for a fully manual installation and update. A manual procedure allows you to fully control the SQL statements that are executed on your database instance and to adjust those statements to your needs if necessary. Isolation level READ COMMITED is the required isolation level for database systems to run CIB seven with. You may have to change the default setting on your database when installing CIB seven. For more information see the documentation on isolation levels. Installation You can either install your database schema using Liquibase or using the provided SQL scripts manually. You can switch between those mechanisms when updating your CIB seven version at a later stage if desired. However, this might come with additional preparation work to work reliably. The update paragraph provides more details on this topic. Liquibase installation CIB seven comes with a maintained changelog file that Liquibase can consume. This changelog defines which SQL statements to execute on a database. You can find the changelog and its referenced resources on our Artifact Repository. Select the respective version ($PLATFORM_VERSION) and download the resources as a zip or tar.gz file. Open the cibseven-sql-scripts-$PLATFORM_VERSION/liquibase folder to find the changelog. In case you are using a pre-packaged distribution, the Liquibase resources already reside in the sql/liquibase folder of the distribution. The liquibase folder contains the following resources: camunda-changelog.xml baseline directory Liquibases uses these resources in combination with the scripts in the upgrade folder next to the liquibase folder to install the schema. Perform the following steps to install the database schema on your database instance: Setup Liquibase, e.g. by downloading Liquibase CLI Run Liquibase’s update command referencing the camunda-changelog.xml. You can pass on the connection details to your database instance via parameters as described in the Liquibase documentation or create a properties file. Liquibase creates two additional tables to keep track of the changes that have been applied to your database. The DATABASECHANGELOG table keeps track of all applied changes. The DATABASECHANGELOGLOCK table prevents conflicts from concurrent updates on your database instance by multiple Liquibase instances. You can read more about it in the Liquibase guide. As you create the tables externally via Liquibase, you have to configure the engine to not create tables at startup as well. Set the databaseSchemaUpdate property to false (or, in case you are using Oracle, to noop). Consult the manual installation guide of your distribution for further information on how to achieve that. Heads Up! Liquibase provides additional commands to preview all changes that will be applied by commands that execute SQL statements on a database. For the update command, you can execute the updateSql command. This will let you inspect all statements that Liquibase will issue on your database without actually executing them. Furthermore, if you have defined a specific prefix for the entities of your database, you will have to manually adjust the create scripts in the liquibase/baseline directory accordingly so that the tables are created with the prefix. Manual installation To install the database schema required for CIB seven, we provide a set of scripts with prepared DDL statements. Those scripts create all required tables and default indices. You can find the provided SQL scripts on our Artifact Repository. Select the respective version ($PLATFORM_VERSION) and download the scripts as a zip or tar.gz file. Open the cibseven-sql-scripts-$PLATFORM_VERSION/create folder to find all available scripts. In case you are using a pre-packaged distribution, the SQL scripts already reside in the sql/create folder of the distribution. The create folder contains the following SQL scripts: $DATABASENAME_engine_$PLATFORM_VERSION.sql $DATABASENAME_identity_$PLATFORM_VERSION.sql There are individual SQL scripts for each supported database ($DATABASENAME). Select the appropriate scripts for your database and run them with your database administration tool (e.g., SqlDeveloper for Oracle). As you create the tables manually, you have to configure the engine to not create tables at startup as well. Set the databaseSchemaUpdate property to false (or, in case you are using Oracle, to noop). Consult the manual installation guide of your distribution for further information on how to achieve that. Heads Up! If you have defined a specific prefix for the entities of your database, you will have to manually adjust the create scripts accordingly so that the tables are created with the prefix. Update Updating to a newer CIB seven minor version also requires a database schema update. You can reuse all the options available for a schema installation here as well. If you are switching from one option to another, you might need to perform additional preparation work to update reliably. The individual sections on the mechanisms will provide details if necessary. In case you are just updating to a newer patch level of your CIB seven installation, a schema update might not be necessary. Liquibase update This section assumes you are already set up with Liquibase as described in the installation section. In case you have not set up Liquibase itself yet and want to update a database that you manually installed and updated until now, please consult the migration section first. Camunda comes with a maintained changelog file that Liquibase can consume. This changelog helps Liquibase to keep track of the changes that have been made to your database already. Based on that changelog and the tracking tables, Liquibase determines which changes it needs to apply when you instruct it to update your schema. Perform the following steps to update the database schema on your database instance: Select the respective version you want to update to ($Y) on our Artifact Repository and download the resources as a zip or tar.gz file. Open the cibseven-sql-scripts-$Y/liquibase folder to find the changelog file. In case you are using a pre-packaged distribution, the Liquibase resources already reside in the sql/liquibase folder of the distribution with version $Y. Run Liquibase’s update command referencing the new camunda-changelog.xml of version $Y. Liquibase takes care of determining the necessary changes and applying them to your database according to the new changelog. You can pass on the connection details to your database instance via parameters as described in the Liquibase documentation or create a properties file. We highly recommend updating to the latest patch version that is within the bounds of the new minor version you are updating to ($Y). Dry run Liquibase provides additional commands to preview all changes applied by commands that execute SQL statements on a database. For the update command, you can execute the updateSql command to inspect all statements that Liquibase will issue on your database without actually executing them. Migrate to Liquibase Liquibase provides workflows to update databases that were not set up using Liquibase from the very beginning. For such a scenario to work, you need to populate a tracking table that represents the current state of your database with regards to the changelog file you want to update against. In other words, you need to let Liquibase know which parts of the changelog your database already contains. Perform the following steps to migrate your manual installation to Liquibase: Setup Liquibase, e.g. by downloading Liquibase CLI Identify your current database schema version. You can extract this information from the ACT_GE_SCHEMA_LOG table. Find the row with the highest value in the ID_ column and use the value of this row’s VERSION_ column. Run Liquibase’s changelogSyncToTag command referencing the camunda-changelog.xml and using your current database schema version as the tag. You can pass on the connection details to your database instance via parameters as described in the Liquibase documentation or create a properties file. Liquibase uses this information to create the tracking tables and mark all changesets until the tag you defined as executed. Liquibase determines if there are any changes that it needs to apply to your database for any subsequent update commands. You have migrated your manual installation to Liquibase. Manual update Updating from your current minor version ($X) to its follow-up version ($Y) requires updating the database schema as well. Follow the outlined procedure to perform this update: Check for available database patch scripts for your database that are within the bounds of your update path. You can find the scripts on our Artifact Repository. Select the respective version you want to update to ($Y) and download the scripts as a zip or tar.gz file. Open the cibseven-sql-scripts-$Y/upgrade folder to find all available scripts. In case you are using a pre-packaged distribution, the SQL scripts already reside in the sql/upgrade folder of the distribution with version $Y. We highly recommend executing these patches before updating. Execute those related to your database type ($DATABASENAME) in ascending order by version number. The naming pattern is $DATABASENAME_engine_$X_patch_*.sql. Execute the corresponding update scripts named $DATABASENAME_engine_$X_to_$Y.sql. The scripts update the database from one minor version to the next and change the underlying database structure. So make sure to backup your database in case there are any failures during the update process. We highly recommend checking for any existing patch scripts for your database that are within the bounds of the new minor version you are updating to ($Y). Execute them in ascending order by version number. The procedure is the same as in step 1, only for the new minor version. Patch level update This section explains how to perform a patch-level update for your database schema. The patch level is the version number “after the second dot”. For example, update from 7.14.2 to 7.14.3. Between patch levels, the structure of the database schema does not change. The database structure of all patch releases is backward compatible with the corresponding minor version. For example, the database schema of all 7.14.x versions are backward compatible with the 7.14.0 schema. The one exception to this is a bug in the database schema itself. If you are affected by such a bug, you have the option to run a patch script. The following list contains all available patch scripts, information on what the fixes are related to, and a link to the corresponding Camunda Jira issue: Camunda Version Patch file Description Affected databases Issue link 7.1 engine_7.1_patch_7.1.4_to_7.1.5.sql Add a missing index on foreign key to prevent deadlocks H2, MySQL, Oracle, PostgreSQL CAM-2567 7.1 engine_7.1_patch_7.1.9_to_7.1.10.sql Add a missing index on foreign key to prevent deadlocks DB2, SQL Server CAM-3565 7.2 engine_7.2_patch_7.2.4_to_7.2.5.sql Add a missing index on foreign key to prevent deadlocks. This is the same patch as engine_7.1_patch_7.1.9_to_7.1.10.sql. DB2, SQL Server CAM-3565 7.2 engine_7.2_patch_7.2.6_to_7.2.7.sql Add indices to improve deployment performance. All databases CAM-4497 7.3 engine_7.3_patch_7.3.0_to_7.3.1.sql Adjust column size of ACT_HI_JOB_LOG.ACT_ID_ to 255. All databases CAM-4037 7.3 engine_7.3_patch_7.3.2_to_7.3.3_1.sql Add a missing index on ACT_RU_AUTHORIZATION#RESOURCE_ID_ to prevent deadlocks. All databases CAM-4440 7.3 engine_7.3_patch_7.3.2_to_7.3.3_2.sql Add indices to improve deployment performance. This is the same patch as engine_7.2_patch_7.2.6_to_7.2.7.sql. All databases CAM-4497 7.3 engine_7.3_patch_7.3.5_to_7.3.6_1.sql Adjust column size of ACT_RU_JOB.PROCESS_DEF_KEY_ to 255. All databases CAM-4328 7.3 engine_7.3_patch_7.3.5_to_7.3.6_2.sql Add indices to improve performance of group authorizations. All databases CAM-5364 7.4 engine_7.4_patch_7.4.2_to_7.4.3_1.sql Add index to improve historic activity instance statistics query performance. All databases CAM-5257 7.4 engine_7.4_patch_7.4.2_to_7.4.3_2.sql Add a missing index on ACT_RU_EXT_TASK#EXECUTION_ID_ to prevent deadlocks. All databases CAM-5440 7.4 engine_7.4_patch_7.4.2_to_7.4.3_3.sql Add indices to improve performance of group authorizations. This is the same patch as engine_7.3_patch_7.3.5_to_7.3.6_2.sql. All databases CAM-5364 7.4 engine_7.4_patch_7.4.5_to_7.4.6.sql Adjust column size of ACT_RU_JOB.PROCESS_DEF_KEY_ to 255. This is the same patch as engine_7.3_patch_7.3.5_to_7.3.6_1.sql. All databases CAM-4328 7.6 engine_7.6_patch_7.6.0_to_7.6.1.sql Adjust column size of ACT_RU_EVENT_SUBSCR.ACTIVITY_ID_ to 255. All databases CAM-6788 7.6 engine_7.6_patch_7.6.2_to_7.6.3_1.sql Add a missing index on ACT_RU_EXT_TASK#ERROR_DETAILS_ID_ to prevent deadlocks. All databases CAM-7263 7.6 engine_7.6_patch_7.6.2_to_7.6.3_2.sql Remove an incorrect index ACT_RU_JOB#ACT_IDX_JOB_HANDLER for MSSQL Server. MSSQL Server CAM-7442 7.7 engine_7.7_patch_7.7.3_to_7.7.4.sql Insert new startup.lock in ACT_GE_PROPERTY. All databases CAM-8162 7.7 engine_7.7_patch_7.7.4_to_7.7.5_1.sql Add indices to improve performance of history cleanup All databases CAM-8184 7.7 engine_7.7_patch_7.7.4_to_7.7.5_2.sql Increase the field length of ACT_RU_AUTHORIZATION.RESOURCE_ID_ All databases CAM-8177 7.7 engine_7.7_patch_7.7.5_to_7.7.6.sql Add indices to improve historic activity instance statistics All databases CAM-8485 7.7 engine_7.7_patch_7.7.8_to_7.7.9_1.sql Add indexes on Process Definition ID and End Time for Historic Process Instance and Historic Activity Instance All databases CAM-8833 7.7 engine_7.7_patch_7.7.8_to_7.7.9_2.sql Add a missing index on foreign key to prevent deadlocks. DB2, SQL Server CAM-9165 7.8 engine_7.8_patch_7.8.0_to_7.8.1.sql Add indices to improve historic activity instance statistics. This is the same patch as engine_7.7_patch_7.7.5_to_7.7.6.sql. All databases CAM-8485 7.8 engine_7.8_patch_7.8.4_to_7.8.5.sql Add indexes on Process Definition ID and End Time for Historic Process Instance and Historic Activity Instance. This is the same patch as engine_7.7_patch_7.7.8_to_7.7.9_1.sql. All databases CAM-8833 7.8 engine_7.8_patch_7.8.7_to_7.8.8.sql Add a missing index on foreign key to prevent deadlocks. This is the same patch as engine_7.7_patch_7.7.8_to_7.7.9_2.sql. DB2, SQL Server CAM-9165 7.8 engine_7.8_patch_7.8.8_to_7.8.9.sql Drop ACT_IDX_JOB_HANDLER index causing issues on DB2. DB2 CAM-7676 7.8 engine_7.8_patch_7.8.11_to_7.8.12.sql Add index to improve history cleanup performance. All databases CAM-9435 7.8 engine_7.8_patch_7.8.12_to_7.8.13_1.sql Add support for Optimize 2.3. All databases CAM-9523 7.8 engine_7.8_patch_7.8.12_to_7.8.13_2.sql Add support for Optimize 2.3. All databases CAM-9525 7.9 engine_7.9_patch_7.9.0_to_7.9.1.sql Add index to improve historic operation logs performance. All databases CAM-9006 7.9 engine_7.9_patch_7.9.1_to_7.9.2.sql Add a missing index on foreign key to prevent deadlocks. This is the same patch as engine_7.8_patch_7.8.7_to_7.8.8.sql. DB2, SQL Server CAM-9165 7.9 engine_7.9_patch_7.9.2_to_7.9.3.sql Drop ACT_IDX_JOB_HANDLER index causing issues on DB2. This is the same patch as engine_7.8_patch_7.8.8_to_7.8.9.sql. DB2 CAM-7676 7.9 engine_7.9_patch_7.9.5_to_7.9.6.sql Add index to improve history cleanup performance. This is the same patch as engine_7.8_patch_7.8.11_to_7.8.12.sql. All databases CAM-9435 7.9 engine_7.9_patch_7.9.6_to_7.9.7_1.sql Add support for Optimize 2.3. This is the same patch as engine_7.8_patch_7.8.12_to_7.8.13_1.sql. All databases CAM-9523 7.9 engine_7.9_patch_7.9.6_to_7.9.7_2.sql Add support for Optimize 2.3. This is the same patch as engine_7.8_patch_7.8.12_to_7.8.13_2.sql. All databases CAM-9525 7.9 engine_7.9_patch_7.9.11_to_7.9.12.sql Add support for Optimize 2.5. All databases CAM-10264 7.10 engine_7.10_patch_7.10.5_to_7.10.6.sql Add support for Optimize 2.5. This is the same patch as engine_7.9_patch_7.9.11_to_7.9.12.sql. All databases CAM-10264 7.10 engine_7.10_patch_7.10.6_to_7.10.7.sql Add index to improve history cleanup performance. This patch script is introduced in 7.10.9. If your current patch is 7.10.6, 7.10.7 or 7.10.8, please execute the script to upgrade to 7.10.9+. All databases CAM-10616 7.10 engine_7.10_patch_7.10.13_to_7.10.14.sql Add index to improve Historic Activity Instance query performance. All databases CAM-11117 7.11 engine_7.11_patch_7.11.2_to_7.11.3.sql Add index to improve history cleanup performance. This is the same patch as engine_7.10_patch_7.10.6_to_7.10.7.sql. All databases CAM-10616 7.11 engine_7.11_patch_7.11.7_to_7.11.8.sql Add index to improve Historic Activity Instance query performance. This is the same patch as engine_7.10_patch_7.10.13_to_7.10.14.sql. All databases CAM-11117 7.11 engine_7.11_patch_7.11.18_to_7.11.19.sql Introducing new engine lock properties All databases CAM-12590 7.12 engine_7.12_patch_7.12.0_to_7.12.1.sql Add index to improve Historic Activity Instance query performance. This is the same patch as engine_7.11_patch_7.11.7_to_7.11.8.sql. All databases CAM-11117 7.12 engine_7.12_patch_7.12.10_to_7.12.11.sql Add support for Optimize 3.2. All databases CAM-12383 7.12 engine_7.12_patch_7.12.11_to_7.12.12.sql Introducing new engine lock properties This is the same patch as engine_7.11_patch_7.11.18_to_7.11.19.sql. All databases CAM-12590 7.13 engine_7.13_patch_7.13.4_to_7.13.5_1.sql Add index to improve Task query performance. All databases CAM-4441 7.13 engine_7.13_patch_7.13.4_to_7.13.5_2.sql Add support for Optimize 3.2. This is the same patch as engine_7.12_patch_7.12.10_to_7.12.11.sql. All databases CAM-12383 7.13 engine_7.13_patch_7.13.5_to_7.13.6.sql Introducing new engine lock properties This is the same patch as engine_7.12_patch_7.12.11_to_7.12.12.sql. All databases CAM-12590 7.14 engine_7.14_patch_7.14.2_to_7.14.3.sql Re-define ACT_IDX_JOB_HANDLER index to make it work with extended data types on Oracle. Oracle CAM-12832 Liquibase patch level update CIB seven comes with a maintained changelog file that Liquibase can consume. This changelog helps Liquibase to keep track of the changes that have been made to your database already. Based on that changelog and the tracking tables, Liquibase determines which changes it needs to apply when instructing it to update your schema. Therefore, the procedure for patch-level updates is equivalent to that for minor version updates. Manual patch level update You can find the necessary scripts on our Artifact Repository. Select the respective patch version you want to update to ($Y) and download the scripts as a zip or tar.gz file. Open the cibseven-sql-scripts-$Y/upgrade folder to find all available patch scripts. In case you are using a pre-packaged distribution, the SQL scripts reside in the sql/upgrade folder of the distribution you want to update to. The patch scripts are named $DATABASENAME_engine_$MINOR_patch_$A_to_$B, with $A being the patch level version to update from, $B the patch level to update to, and $MINOR the minor version they are on, e.g., 7.16. If you do choose to apply a database patch, then you must apply all patch scripts that are within the bounds of your update path. This means if your current patch version is X.X.1 and you update to X.X.5 you have to execute all patch scripts first where $A ≥ X.X.1 and $B ≤ X.X.5. Note: Some patches are provided for multiple versions. It is not required to execute them more than once. See the description of the patch version list for information on duplicate fixes.",
    "url": "/manual/latest/installation/database-schema/index.html"
  },
  {
    "id": "manual/latest/installation/docker/index.html",
    "title": "Run CIB seven using Docker | docs.cibseven.org",
    "content": "Docker images can be found on GitHub and Docker Hub. Please note that by default the Apache Tomcat distribution is used. For a guide on how to use one of the other distributions, see the tag schema. For example, tags like 1.1.0 or latest without explicit distribution mark are delivering Tomcat version of CIB seven. Start CIB seven Run using Docker To start CIB seven Run execute the following commands: docker pull cibseven/cibseven:run-latest docker run -d --name cibseven -p 8080:8080 cibseven/cibseven:run-latest or following command to use explicit version 1.1.0: docker pull cibseven/cibseven:run-1.1.0 docker run -d --name cibseven -p 8080:8080 cibseven/cibseven:run-1.1.0 Start CIB seven (Tomcat) using Docker To start CIB seven Tomcat version, execute the following commands: docker pull cibseven/cibseven:tomcat-latest docker run -d --name cibseven -p 8080:8080 cibseven/cibseven:tomcat-latest or following command to use explicit version 1.1.0: docker pull cibseven/cibseven:tomcat-1.1.0 docker run -d --name cibseven -p 8080:8080 cibseven/cibseven:tomcat-1.1.0 Start CIB seven (Wildfly) using Docker To start CIB seven Wildfly version, execute the following commands: docker pull cibseven/cibseven:wildfly-latest docker run -d --name cibseven -p 8080:8080 cibseven/cibseven:wildfly-latest or following command to use explicit version 1.1.0: docker pull cibseven/cibseven:wildfly-1.1.0 docker run -d --name cibseven -p 8080:8080 cibseven/cibseven:wildfly-1.1.0",
    "url": "/manual/latest/installation/docker/index.html"
  },
  {
    "id": "manual/latest/installation/full/index.html",
    "title": "Install the Shared Engine Distribution | docs.cibseven.org",
    "content": "What is a Shared Engine Distribution? If you need a Remote or Shared Engine Distribution depends on your use-case. Check out the architecture overview for more information. The Full Distribution includes a Shared Process engine and (optionally) the Web Applications. The distribution is supported on a broad range of containers:",
    "url": "/manual/latest/installation/full/index.html"
  },
  {
    "id": "manual/latest/installation/full/jboss/configuration/index.html",
    "title": "Configure the Full Distribution for JBoss EAP/WildFly | docs.cibseven.org",
    "content": "This page explains how to configure the full distribution for the JBoss EAP/WildFly application server. LDAP In order to setup LDAP for the JBoss EAP/WildFly Application Server distribution, you have to perform the following steps: Adjust the Process Engine Configuration Edit the file standalone.xml (or domain.xml) provided by the JBoss EAP/WildFly Application Server and add the LDAP Identity Provider Plugin and the Administrator Authorization Plugin. <subsystem xmlns=\"urn:org.cibseven.bpm.jboss:1.1\"> <process-engines> <process-engine name=\"default\" default=\"true\"> ... <properties>...</properties> <plugins> <plugin> <class>org.cibseven.bpm.identity.impl.ldap.plugin.LdapIdentityProviderPlugin</class> <properties> <property name=\"serverUrl\">ldap://localhost:4334/</property> <property name=\"managerDn\">uid=jonny,ou=office-berlin,o=camunda,c=org</property> <property name=\"managerPassword\">s3cr3t</property> <property name=\"baseDn\">o=camunda,c=org</property> <property name=\"userSearchBase\">ou=employees</property> <property name=\"userSearchFilter\">(objectclass=person)</property> <property name=\"userIdAttribute\">uid</property> <property name=\"userFirstnameAttribute\">cn</property> <property name=\"userLastnameAttribute\">sn</property> <property name=\"userEmailAttribute\">mail</property> <property name=\"userPasswordAttribute\">userpassword</property> <property name=\"groupSearchBase\">ou=roles</property> <property name=\"groupSearchFilter\">(objectclass=groupOfNames)</property> <property name=\"groupIdAttribute\">ou</property> <property name=\"groupNameAttribute\">cn</property> <property name=\"groupMemberAttribute\">member</property> </properties> </plugin> <plugin> <class>org.cibseven.bpm.engine.impl.plugin.AdministratorAuthorizationPlugin</class> <properties> <property name=\"administratorUserName\">admin</property> </properties> </plugin> </plugins> </process-engine> </process-engines> ... </subsystem> The administratorUserName property should contain the user id of the LDAP user you want to grant administrator authorizations to. You can then use this user to log in to the web application and grant authorizations to additional users. See our user guide for complete documentation on the LDAP Identity Provider Plugin and the Administrator Authorization Plugin. HAL Resource Caching If you use LDAP as Identity Provider, you should consider activating caching of Users and Groups in the CIB seven web application. In order to activate this, add the following configuration to the web.xml file of the CIB seven web application (camunda-webapp-wildfly-$PLATFORM_VERSION.war/WEB-INF/lib or camunda-webapp-jboss-$PLATFORM_VERSION.war/WEB-INF/lib): <?xml version=\"1.0\" encoding=\"UTF-8\"?> <web-app version=\"2.5\" xmlns=\"http://java.sun.com/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd\"> <!-- ... --> <listener> <listener-class>org.cibseven.bpm.engine.rest.hal.cache.HalRelationCacheBootstrap</listener-class> </listener> <context-param> <param-name>org.cibseven.bpm.engine.rest.hal.cache.config</param-name> <param-value> { \"cacheImplementation\": \"org.cibseven.bpm.engine.rest.hal.cache.DefaultHalResourceCache\", \"caches\": { \"org.cibseven.bpm.engine.rest.hal.user.HalUser\": { \"capacity\": 100, \"secondsToLive\": 900 }, \"org.cibseven.bpm.engine.rest.hal.group.HalGroup\": { \"capacity\": 100, \"secondsToLive\": 900 } } } </param-value> </context-param> <!-- ... --> </web-app> Add Custom Engine Plugins Add an additional engine plugin as a module to the folder $WILDFLY_HOME/modules/ Add the module dependency to the file $WILDFLY_HOME/modules/org/cibseven/bpm/cibseven-engine-plugins/main/module.xml and set the attribute export=\"true\" to make sure that the module is visible in the classpath of Camunda’s subsystem <module xmlns=\"urn:jboss:module:1.0\" name=\"org.cibseven.bpm.cibseven-engine-plugins\"> <dependencies> <!-- ... --> <module name=\"org.cibseven.bpm.SOME-SPECIAL-PLUGIN-NAME\" export=\"true\" /> </dependencies> </module> The module.xml file is included in the CIB seven distribution. If you install CIB seven on a vanilla WildFly container, this file needs to be created manually. Configure the process engine plugin in the standalone.xml/domain.xml configuration file Session Cookie in Webapps The deployment descriptor of the Web applications needs to be adjusted to configure the Session Cookie. You can find it under WEB-INF/web.xml. Please watch out for the following section: ... <session-config> <cookie-config> <secure>false</secure> <http-only>true</http-only> </cookie-config> </session-config> ... Please note that security-related configurations for the Session Cookie can only be applied with the Deployment Descriptor (web.xml) version set to 3.0. To adjust the SameSite flag of the session cookie, you can configure a SameSiteCookieHandler as described in related the WildFly documentation. This can be used with WildFly versions >= 19.1.0. Security-related HTTP headers in Webapps To customize the configuration of security-related HTTP headers in the web applications its deployment descriptor needs to be adjusted. You can find it under WEB-INF/web.xml. Please watch out for the following section: ... <filter> <filter-name>HttpHeaderSecurity</filter-name> <filter-class> org.cibseven.bpm.webapp.impl.security.filter.headersec.HttpHeaderSecurityFilter </filter-class> </filter> <filter-mapping> <filter-name>HttpHeaderSecurity</filter-name> <url-pattern>/*</url-pattern> <dispatcher>REQUEST</dispatcher> </filter-mapping> ... You can change the default behavior by adding configuration parameters to the servlet filter configuration: ... <filter> <filter-name>HttpHeaderSecurity</filter-name> <filter-class> org.cibseven.bpm.webapp.impl.security.filter.headersec.HttpHeaderSecurityFilter </filter-class> <init-param> <param-name>contentSecurityPolicyValue</param-name> <param-value> base-uri 'self'; default-src 'self' 'unsafe-inline' </param-value> </init-param> </filter> ... Please also see the detailed overview about the HTTP Header Security configuration settings.",
    "url": "/manual/latest/installation/full/jboss/configuration/index.html"
  },
  {
    "id": "manual/latest/installation/full/jboss/index.html",
    "title": "Install the Full Distribution for JBoss EAP/WildFly | docs.cibseven.org",
    "content": "This document describes the installation of the Full Distribution for WildFly Application Server / JBoss EAP. There are different options for installing the Full Distribution:",
    "url": "/manual/latest/installation/full/jboss/index.html"
  },
  {
    "id": "manual/latest/installation/full/jboss/manual/index.html",
    "title": "Install the Full Distribution on a JBoss EAP/WildFly Application Server manually  | docs.cibseven.org",
    "content": "This document describes the installation of CIB seven and its components on a vanilla WildFly Application Server or JBoss EAP 7 / 8. Reading this Guide This guide uses a number of variables to denote common path names and constants: $WILDFLY_HOME points to the JBoss EAP/WildFly application server main directory. $WILDFLY_VERSION denotes the version of WildFly application server. $WILDFLY_DISTRIBUTION represents the downloaded pre-packaged CIB seven distribution for WildFly, e.g. cibseven-bpm-wildfly-$PLATFORM_VERSION.zip or cibseven-bpm-wildfly-$PLATFORM_VERSION.tar.gz. $PLATFORM_VERSION denotes the version of CIB seven you want to install or already have installed, e.g. 7.0.0. Setup For WildFly ≥27 / JBoss EAP 8, the name of the artifact is cibseven-webapp-wildfly-1.1.0.war. For WildFly ≤26 / JBoss EAP 7, the name of the artifact is cibseven-webapp-jboss-1.1.0.war. Copy Modules Copy the modules from the modules/ folder of the CIB seven distribution, or extract the camunda-wildfly-modules archive, to the $WILDFLY_HOME/modules/ of your WildFly application server. Replace H2 Database The WildFly distribution ships a different version of the H2 database than the one that is shipped with WildFly itself. The version shipped with CIB seven is the version that the process engine is tested on and it is strongly recommended to use Camunda’s version. To do so, make sure to delete the folder $WILDFLY_HOME/modules/system/layers/base/com/h2database Adjust the Configuration Next, a number of changes need to be performed in the application server’s configuration file. In most cases this is $WILDFLY_HOME/standalone/configuration/standalone.xml. Add the CIB seven subsystem as extension: <server xmlns=\"urn:jboss:domain:20.0\"> <extensions> ... <extension module=\"org.cibseven.bpm.wildfly.camunda-wildfly-subsystem\"/> Configure the thread pool for the Camunda Job Executor: Since CIB seven.5, the configuration of the thread pool is done in the CIB seven subsystem, not in the JBoss Threads subsystem anymore like it was done before 7.5. The thread pool creation and shutdown is now controlled through the CIB seven subsystem. You are able to configure it through the following new configuration elements in the job-executor element of the subsystem XML configuration. Mandatory configuration elements are: <core-threads>3</core-threads> <max-threads>5</max-threads> <queue-length>10</queue-length> Optional configuration elements are: <keepalive-time>10</keepalive-time> (in seconds) <allow-core-timeout>true</allow-core-timeout> Shown values are the default ones. The below example also configures the default process engine. <subsystem xmlns=\"urn:org.cibseven.bpm.jboss:1.1\"> <process-engines> <process-engine name=\"default\" default=\"true\"> <datasource>java:jboss/datasources/ProcessEngine</datasource> <history-level>full</history-level> <properties> <property name=\"jobExecutorAcquisitionName\">default</property> <property name=\"isAutoSchemaUpdate\">true</property> <property name=\"authorizationEnabled\">true</property> <property name=\"jobExecutorDeploymentAware\">true</property> </properties> </process-engine> </process-engines> <job-executor> <core-threads>3</core-threads> <max-threads>5</max-threads> <queue-length>10</queue-length> <job-acquisitions> <job-acquisition name=\"default\"> <properties> <property name=\"lockTimeInMillis\">300000</property> <property name=\"waitTimeInMillis\">5000</property> <property name=\"maxJobsPerAcquisition\">3</property> </properties> </job-acquisition> </job-acquisitions> </job-executor> </subsystem> Create the Database Schema By default, the database schema is automatically created in an H2 database when the engine starts up for the first time. If you do not want to use the H2 database, you have to Create a database schema for CIB seven yourself. Install the database schema to create all required tables and default indices using our database schema installation guide. When you create the tables manually, then you can also configure the engine to not create tables at startup by setting the isAutoSchemaUpdate property to false (or, in case you are using Oracle, to noop). In WildFly, this is done in the standalone.xml, located in the $WILDFLY_DISTRIBUTION\\server\\wildfly-$WILDFLY_VERSION\\standalone\\configuration\\ folder. Create a Datasource You need to create a datasource named java:jboss/datasources/ProcessEngine. The following datasource shows an example of using the built-in H2 database for this, using a file within the ./ folder, typically bin. <datasource jta=\"true\" enabled=\"true\" use-java-context=\"true\" use-ccm=\"true\" jndi-name=\"java:jboss/datasources/ProcessEngine\" pool-name=\"ProcessEngine\"> <connection-url>jdbc:h2:./camunda-h2-dbs/process-engine;DB_CLOSE_DELAY=-1;DB_CLOSE_ON_EXIT=FALSE</connection-url> <driver>h2</driver> <security user-name=\"sa\" password=\"sa\"/> <!-- for WildFly ≥27 / JBoss EAP 8 --> <!-- for WildFly ≤26 / JBoss EAP 7 <security> <user-name>sa</user-name> <password>sa</password> </security> --> </datasource> Using H2 as a database is ideal for development purposes but is not recommended for usage in a productive environment. These links point you to resources for other databases: How to configure an Oracle database How to configure a MySQL database Optional Components This section describes how to install optional dependencies. None of these are required to work with the core platform. Before continuing, make sure that CIB seven is already installed according to this step for WildFly / JBoss EAP. Cockpit, Tasklist, and Admin The following steps are required to deploy the web application: Download the Camunda web application that contains the web applications from our Maven Artifactory. Optionally, you may change the context path to which the application will be deployed (default is /camunda). Edit the file WEB-INF/jboss-web.xml in the war file and update the context-root element accordingly. Copy the war file to $WILDFLY_HOME/standalone/deployments. Startup WildFly. Access Cockpit, Tasklist, and Admin via /camunda/app/cockpit, /camunda/app/tasklist and /camunda/app/admin, or under the context path you configured. REST API The following steps are required to deploy the REST API: Download the REST API web application archive from our Maven Artifactory. For WildFly ≥27 / JBoss EAP 8, the name of the artifact is cibseven-engine-rest-jakarta-1.1.0-wildfly.war. For WildFly ≤26 / JBoss EAP 7, the name of the artifact is cibseven-engine-rest-1.1.0-wildfly.war. Optionally, you may change the context path to which the REST API will be deployed (default is /engine-rest). Edit the file WEB-INF/jboss-web.xml in the war file and update the context-root element accordingly. Copy the war file to $WILDFLY_HOME/standalone/deployments. Startup WildFly. Access the REST API on the context path you configured. For example, http://localhost:8080/engine-rest/engine should return the names of all engines of the platform, provided that you deployed the application in the context /engine-rest. CIB seven Connect Plugin Add the following modules (if not existing) from the folder $WILDFLY_DISTRIBUTION/modules/ to the folder $WILDFLY_HOME/modules/: org/cibseven/bpm/cibseven-engine-plugin-connect org/cibseven/commons/cibeven-commons-utils To activate CIB seven Connect functionality for a process engine, a process engine plugin has to be registered in $WILDFLY_HOME/standalone/configuration/standalone.xml as follows: <subsystem xmlns=\"urn:org.cibseven.bpm.jboss:1.1\"> ... <process-engines> <process-engine name=\"default\" default=\"true\"> ... <plugins> ... existing plugins ... <plugin> <class>org.cibseven.connect.plugin.impl.ConnectProcessEnginePlugin</class> </plugin> </plugins> ... </process-engine> </process-engines> ... </subsystem> Spin You can use the Spin plugin to extend the engine functionality to de-/serialize object variables from and to JSON and XML. For more information, see the Spin Reference. Setup Spin Add the following modules (if not existing) from the folder $WILDFLY_DISTRIBUTION/modules/ to the folder $WILDFLY_HOME/modules/: org/cibseven/spin/cibseven-spin-core org/cibseven/spin/cibseven-spin-dataformat-json-jackson org/cibseven/spin/cibseven-spin-dataformat-xml-dom-jakarta Heads-up: add this module only for WildFly ≥27 / JBoss EAP 8. org/cibseven/spin/cibseven-spin-dataformat-xml-dom Heads-up: add this module only for WildFly ≤26 / JBoss EAP 7. org/cibseven/bpm/cibseven-engine-plugin-spin org/cibseven/commons/cibseven-commons-utils com/fasterxml/jackson/core/jackson-core com/fasterxml/jackson/core/jackson-databind com/fasterxml/jackson/core/jackson-annotations com/jayway/jsonpath/json-path In order to activate Spin functionality for a process engine, a process engine plugin has to be registered in $WILDFLY_HOME/standalone/configuration/standalone.xml as follows: <subsystem xmlns=\"urn:org.cibseven.bpm.jboss:1.1\"> ... <process-engines> <process-engine name=\"default\" default=\"true\"> ... <plugins> ... existing plugins ... <plugin> <class>org.cibseven.spin.plugin.impl.SpinProcessEnginePlugin</class> </plugin> </plugins> ... </process-engine> </process-engines> ... </subsystem> Problems with Jackson Annotations The usage of Jackson annotations on WildFly together with the Spin JSON serialization can lead to problems. WildFly implicitly adds the JAX-RS subsystem to each new deployment, if JAX-RS annotations are present (see the WildFly documentation for more information). This JAX-RS subsystem includes the Jackson library, the version of which does not match with the version used by the SPIN Plugin. As a result, Jackson annotations will be ignored. Note that this problem does not necessarily have to emerge upon direct usage of Spin. The Spin plugin also comes into play when JSON variables are set or read by the CIB seven Process Engine. See one of the following ways to fix this: Change the Jackson main slot to the version which is used by the Spin Plugin. Make sure that Resteasy can work with this Jackson version, as we cannot give any guarantees on this. Exclude implicitly added JAX-RS dependencies. Add a jboss-deployment-structure.xml file to you application in the WEB-INF folder. Exclude the JAX-RS subsystem and add the Jackson dependencies, with the version which is used by the Spin Plugin. This solution is also shown in the Jackson Annotation Example for WildFly for Camunda in the Camunda example repository. See this Camunda Forum Post for other approaches and information. Problem With Deployments Using the REST API Spin is not available in scripts if a process definition is deployed via REST API. Because WildFly handles dependencies using its module system and CIB seven engine module has no module dependency on the spin module. Groovy Scripting Add the following modules (if not existing) from the folder $WILDFLY_DISTRIBUTION/modules/ to the folder $WILDFLY_HOME/modules/: org/apache/groovy/groovy-all Freemarker Integration Add the following modules (if not existing) from the folder $WILDFLY_DISTRIBUTION/modules/ to the folder $WILDFLY_HOME/modules/: org/cibseven/template-engines/cibseven-template-engines-freemarker org/freemarker/freemarker org/cibseven/commons/cibseven-commons-logging org/cibseven/commons/cibseven-commons-utils GraalVM JavaScript Integration Add the following modules (if not existing) from the folder $WILDFLY_DISTRIBUTION/modules/ to the folder $WILDFLY_HOME/modules/: org/graalvm/js/js org/graalvm/js/js-scriptengine org/graalvm/regex/regex org/graalvm/sdk/graal-sdk org/graalvm/truffle/truffle-api com/ibm/icu/icu4j",
    "url": "/manual/latest/installation/full/jboss/manual/index.html"
  },
  {
    "id": "manual/latest/installation/full/tomcat/configuration/index.html",
    "title": "Configure the Full Distribution for Tomcat | docs.cibseven.org",
    "content": "This page explains how to configure the full distribution for Tomcat Application Server. LDAP In order to setup LDAP for the Tomcat distribution, you have to perform the following steps: Add the LDAP Library Make sure the camunda-identity-ldap-$PLATFORM_VERSION.jar is present in the $TOMCAT_DISTRIBUTION/lib/ folder. Pre packaged distribution Note: If you use the pre-packaged distribution, the ldap plugin is already present and you can skip this step. Adjust the Process Engine Configuration Edit the file bpm-platform.xml located inside the folder $TOMCAT_HOME/conf and add the LDAP Identity Provider Plugin and the Administrator Authorization Plugin. <?xml version=\"1.0\" encoding=\"UTF-8\"?> <bpm-platform xmlns=\"http://www.camunda.org/schema/1.0/BpmPlatform\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.camunda.org/schema/1.0/BpmPlatform http://www.camunda.org/schema/1.0/BpmPlatform \"> ... <process-engine name=\"default\"> ... <properties>...</properties> <plugins> <plugin> <class>org.cibseven.bpm.identity.impl.ldap.plugin.LdapIdentityProviderPlugin</class> <properties> <property name=\"serverUrl\">ldap://localhost:4334/</property> <property name=\"managerDn\">uid=jonny,ou=office-berlin,o=camunda,c=org</property> <property name=\"managerPassword\">s3cr3t</property> <property name=\"baseDn\">o=camunda,c=org</property> <property name=\"userSearchBase\"></property> <property name=\"userSearchFilter\">(objectclass=person)</property> <property name=\"userIdAttribute\">uid</property> <property name=\"userFirstnameAttribute\">cn</property> <property name=\"userLastnameAttribute\">sn</property> <property name=\"userEmailAttribute\">mail</property> <property name=\"userPasswordAttribute\">userpassword</property> <property name=\"groupSearchBase\"></property> <property name=\"groupSearchFilter\">(objectclass=groupOfNames)</property> <property name=\"groupIdAttribute\">ou</property> <property name=\"groupNameAttribute\">cn</property> <property name=\"groupMemberAttribute\">member</property> </properties> </plugin> <plugin> <class>org.cibseven.bpm.engine.impl.plugin.AdministratorAuthorizationPlugin</class> <properties> <property name=\"administratorUserName\">admin</property> </properties> </plugin> </plugins> </process-engine> </bpm-platform> The administratorUserName property should contain the user id of the LDAP user you want to grant administrator authorizations to. You can then use this user to log in to the web application and grant authorizations to additional users. See our user guide for complete documentation on the LDAP Identity Provider Plugin and the Administrator Authorization Plugin. HAL Resource Caching If you use LDAP as Indentity Provider, you should consider activating caching of Users and Groups in the Camunda webapplication. In order to activate this, add the following configuration to the web.xml file of Camunda webapplication (camunda-webapp-tomcat-$PLATFORM_VERSION.war/WEB-INF/web.xml): <?xml version=\"1.0\" encoding=\"UTF-8\"?> <web-app version=\"2.5\" xmlns=\"http://java.sun.com/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd\"> <!-- ... --> <listener> <listener-class>org.cibseven.bpm.engine.rest.hal.cache.HalRelationCacheBootstrap</listener-class> </listener> <context-param> <param-name>org.cibseven.bpm.engine.rest.hal.cache.config</param-name> <param-value> { \"cacheImplementation\": \"org.cibseven.bpm.engine.rest.hal.cache.DefaultHalResourceCache\", \"caches\": { \"org.cibseven.bpm.engine.rest.hal.user.HalUser\": { \"capacity\": 100, \"secondsToLive\": 900 }, \"org.cibseven.bpm.engine.rest.hal.group.HalGroup\": { \"capacity\": 100, \"secondsToLive\": 900 } } } </param-value> </context-param> <!-- ... --> </web-app> Session Cookie in Webapps To configure the Session Cookie, you can adjust the deployment descriptor of the Web applications. You can find it in the WEB-INF/web.xml in the following section: ... <session-config> <cookie-config> <secure>false</secure> <http-only>true</http-only> </cookie-config> </session-config> ... Please note that security-related configurations for the Session Cookie can only be applied with the Deployment Descriptor (web.xml) version set to 3.0. To customize the SameSite attribute of the session cookie, you can adjust the SessionCookieFilter. You can find it in the WEB-INF/web.xml as well in the following section: ... <filter> <filter-name>SessionCookieFilter</filter-name> <filter-class>org.cibseven.bpm.webapp.impl.security.filter.SessionCookieFilter</filter-class> </filter> <filter-mapping> <filter-name>SessionCookieFilter</filter-name> <url-pattern>/*</url-pattern> </filter-mapping> ... By default, the SameSite flag will be set to LAX by the filter. You can change the default behavior by adding configuration parameters to the servlet filter configuration: ... <filter> <filter-name>SessionCookieFilter</filter-name> <filter-class>org.cibseven.bpm.webapp.impl.security.filter.SessionCookieFilter</filter-class> <init-param> <param-name>sameSiteCookieValue</param-name> <param-value>Strict</param-value> </init-param> </filter> ... Note that the filter only adds the SameSite attribute to the cookie if this attribute is not present yet. It does not alter any existing value that has been set prior to the filter execution. The servlet filter accepts several initialization parameters besides the one describes above. The following list describes all possible parameters you can use for the filter configuration: Name Description Default value enableSecureCookie If set to true, the cookie flag Secure is enabled for the Session Cookie. Note: If the Secure flag is set in the cookie by any other means already, this property will not remove it by setting it to false. false enableSameSiteCookie If set to false, the cookie flag SameSite is disabled. The default value of the SameSite cookie is LAX and it can be changed via same-site-cookie-option configuration property. Note: If the SameSite flag is set in the cookie by any other means already, this property will not adjust or remove it. true sameSiteCookieOption Can be configured either to STRICT or LAX. Note: Is ignored when enable-same-site-cookie is set to false Cannot be set in conjunction with same-site-cookie-value Will not change the value of the SameSite flag if it is set already by any other means Not set sameSiteCookieValue A custom value for the cookie property. Note: Is ignored when enable-same-site-cookie is set to false Cannot be set in conjunction with same-site-cookie-option Will not change the value of the SameSite flag if it is set already by any other means Not set cookieName A custom value to configure the name of the session cookie to adjust. JSESSIONID Please also see the detailed overview about the Cookie Security. Security-related HTTP headers in Webapps To customize the configuration of security-related HTTP headers in the web applications its deployment descriptor needs to be adjusted. You can find it under WEB-INF/web.xml. Please watch out for the following section: ... <filter> <filter-name>HttpHeaderSecurity</filter-name> <filter-class> org.cibseven.bpm.webapp.impl.security.filter.headersec.HttpHeaderSecurityFilter </filter-class> </filter> <filter-mapping> <filter-name>HttpHeaderSecurity</filter-name> <url-pattern>/*</url-pattern> <dispatcher>REQUEST</dispatcher> </filter-mapping> ... You can change the default behavior by adding configuration parameters to the servlet filter configuration: ... <filter> <filter-name>HttpHeaderSecurity</filter-name> <filter-class> org.cibseven.bpm.webapp.impl.security.filter.headersec.HttpHeaderSecurityFilter </filter-class> <init-param> <param-name>contentSecurityPolicyValue</param-name> <param-value> base-uri 'self'; default-src 'self' 'unsafe-inline' </param-value> </init-param> </filter> ... Please also see the detailed overview about the HTTP Header Security configuration settings.",
    "url": "/manual/latest/installation/full/tomcat/configuration/index.html"
  },
  {
    "id": "manual/latest/installation/full/tomcat/index.html",
    "title": "Install the Full Distribution for Tomcat | docs.cibseven.org",
    "content": "This document describes the installation of the Full Distribution for Apache Tomcat Application Server. There are different options for installing the Full Distribution:",
    "url": "/manual/latest/installation/full/tomcat/index.html"
  },
  {
    "id": "manual/latest/installation/full/tomcat/manual/index.html",
    "title": "Install the Full Distribution on a Tomcat Application Server manually | docs.cibseven.org",
    "content": "This section describes how you can install CIB seven and its components on a vanilla Apache Tomcat, if you are not able to use the pre-packaged Tomcat distribution. In addition, download a Tomcat distribution to fetch the required CIB seven modules. Reading the Guide Throughout this guide we will use a number of variables to denote common path names and constants: $TOMCAT_HOME points to the main directory of the tomcat server. $TOMCAT_VERSION denotes the version of Tomcat server. $PLATFORM_VERSION denotes the version of CIB seven you want to install or already have installed, e.g. 7.0.0. $TOMCAT_DISTRIBUTION represents the downloaded pre-packaged CIB seven distribution for Tomcat, e.g. cibseven-bpm-tomcat-$PLATFORM_VERSION.zip or cibseven-bpm-tomcat-$PLATFORM_VERSION.tar.gz. Known Limitations in Tomcat 10 Weld Class Loading Issues In deployment scenarios involving one or more process applications with managed beans, classloading issues may occur if the WELD library is directly embedded in the WAR’s /WEB-INF/lib folder. To resolve this, move the weld library away from the war and place it into the $CATALINA_HOME/lib folder. The above workaround is not guaranteed to work for cases with bean references between WAR deployments (WAR A referencing a bean from WAR B). The following test scenarios fail on Tomcat 10: CallActivityContextSwitchTest CdiBeanCallActivityResolutionTest Setup Before you can install the CIB seven components, you need to perform a number of required setup steps. Create the Database Schema and Tables In the default configuration of the distribution, the database schema and all required tables are automatically created in an H2 database when the engine starts up for the first time. If you do not want to use the H2 database, you have to Create a database schema for CIB seven yourself. Install the database schema to create all required tables and default indices using our database schema installation guide. When you create the tables manually, then you have to configure the engine to not create tables at startup by setting the databaseSchemaUpdate property to false (or, in case you are using Oracle, to noop). In Tomcat, this is done in the bpm-platform.xml, located in the $TOMCAT_DISTRIBUTION\\server\\apache-tomcat-$VERSION\\conf\\ folder. Add BPM Bootstrap Server Listener Add the entry org.cibseven.bpm.container.impl.tomcat.TomcatBpmPlatformBootstrap as Listener before the GlobalResourcesLifecycleListener in your $TOMCAT_HOME/conf/server.xml. This class is responsible for starting and stopping Camunda as Tomcat is started and stopped. <Server port=\"8005\" shutdown=\"SHUTDOWN\"> ... <Listener className=\"org.cibseven.bpm.container.impl.tomcat.TomcatBpmPlatformBootstrap\" /> ... Configure a JDBC Resource To configure a JDBC Resource you have to edit the file $TOMCAT_HOME/conf/server.xml. This could look like the following example for an H2 database: <Server> ... <GlobalNamingResources> ... <Resource name=\"jdbc/ProcessEngine\" auth=\"Container\" type=\"javax.sql.DataSource\" factory=\"org.apache.tomcat.jdbc.pool.DataSourceFactory\" uniqueResourceName=\"process-engine\" driverClassName=\"org.h2.Driver\" url=\"jdbc:h2:./camunda-h2-dbs/process-engine;TRACE_LEVEL_FILE=0\" defaultTransactionIsolation=\"READ_COMMITTED\" username=\"sa\" password=\"sa\" maxActive=\"20\" minIdle=\"5\" maxIdle=\"20\" /> </GlobalNamingResources> </Server> For more information on the creation of JDBC datasources have a look at the documentation of your Tomcat version: 9.0. Add Camunda Services Copy the following blocks from ${TOMCAT_DISTRIBUTION}/server/apache-tomcat-${TOMCAT_VERSION}/conf/server.xml into ${TOMCAT_HOME}/conf/server.xml: <Resource name=\"global/camunda-bpm-platform/process-engine/ProcessEngineService!org.cibseven.bpm.ProcessEngineService\" auth=\"Container\" type=\"org.cibseven.bpm.ProcessEngineService\" description=\"CIB seven Platform Process Engine Service\" factory=\"org.cibseven.bpm.container.impl.jndi.ProcessEngineServiceObjectFactory\" /> <Resource name=\"global/camunda-bpm-platform/process-engine/ProcessApplicationService!org.cibseven.bpm.ProcessApplicationService\" auth=\"Container\" type=\"org.cibseven.bpm.ProcessApplicationService\" description=\"CIB seven Platform Process Application Service\" factory=\"org.cibseven.bpm.container.impl.jndi.ProcessApplicationServiceObjectFactory\" /> Add Required Libraries Copy all libraries from the $TOMCAT_DISTRIBUTION/lib/ folder to the Tomcat library folder $TOMCAT_HOME/lib: Furthermore, you have to merge your corresponding JDBC driver into the folder $TOMCAT_HOME/lib. Add bpm-platform.xml You have to add the file bpm-platform.xml to the folder $TOMCAT_HOME/conf or, optionally, you can configure the location through some available mechanisms, see Configure location of the bpm-platform.xml file: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <bpm-platform xmlns=\"http://www.camunda.org/schema/1.0/BpmPlatform\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.camunda.org/schema/1.0/BpmPlatform http://www.camunda.org/schema/1.0/BpmPlatform \"> <job-executor> <job-acquisition name=\"default\" /> </job-executor> <process-engine name=\"default\"> <job-acquisition>default</job-acquisition> <configuration>org.cibseven.bpm.engine.impl.cfg.StandaloneProcessEngineConfiguration</configuration> <datasource>java:jdbc/ProcessEngine</datasource> <properties> <property name=\"history\">full</property> <property name=\"databaseSchemaUpdate\">true</property> <property name=\"authorizationEnabled\">true</property> <property name=\"jobExecutorDeploymentAware\">true</property> </properties> </process-engine> </bpm-platform> Secure Tomcat Follow the Tomcat Security Howto of your Tomcat version: 9.0, 10.1. In particular, go to ${TOMCAT_HOME}/webapps/ and remove the directories ROOT, docs, examples, manager and host-manager. Optional Components This section describes how to install optional CIB seven dependencies onto a Tomcat server. None of these are required to work with the core platform. Cockpit, Tasklist and Admin The following steps are required to deploy the applications: Download the CIB seven web application that contains both applications from our Artifact Repository. Choose the correct version named cibseven-engine-rest-1.1.0-tomcat.war. For Tomcat 10, the name of the artifact is cibseven-engine-rest-jakarta-1.1.0-tomcat.war. For Tomcat 9, the name of the artifact is cibseven-engine-rest-1.1.0-tomcat.war. Copy the war file to $TOMCAT_HOME/webapps/cibseven.war. Optionally you may name it differently or extract it to a folder to deploy it to a different context path. Startup Tomcat. Access Cockpit and Tasklist via /camunda/app/cockpit and /camunda/app/tasklist or under the context path you configured. REST API The following steps are required to deploy the REST API: Download the REST API web application archive from our Artifact Repository. Copy the war file to $TOMCAT_HOME/webapps. Optionally you may rename it or extract it to a folder to deploy it to a specific context like /engine-rest. Startup Tomcat. Access the REST API on the context you configured. For example, http://localhost:8080/engine-rest/engine should return the names of all engines of the platform, provided that you deployed the application in the context /engine-rest. Enable authentication as described in the REST API documentation CIB seven Connect Plugin Add the following artifacts (if not existing) from the folder $TOMCAT_DISTRIBUTION/lib/ to the folder $TOMCAT_HOME/lib/: cibseven-engine-plugin-connect-$PLATFORM_VERSION.jar cibseven-commons-utils-$PLATFORM_VERSION.jar In order to activate CIB seven Connect functionality for a process engine, a process engine plugin has to be registered in $TOMCAT_HOME/conf/bpm-platform.xml as follows: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <bpm-platform ...> <process-engine name=\"default\"> ... <plugins> ... existing plugins ... <plugin> <class>org.cibseven.connect.plugin.impl.ConnectProcessEnginePlugin</class> </plugin> </plugins> ... </process-engine> </bpm-platform> Spin Add the following artifacts (if not existing) from the folder $TOMCAT_DISTRIBUTION/lib/ to the folder $TOMCAT_HOME/lib/: cibseven-spin-dataformat-all-$PLATFORM_VERSION.jar cibseven-spin-core-$PLATFORM_VERSION.jar cibseven-engine-plugin-spin-$PLATFORM_VERSION.jar cibseven-commons-utils-$PLATFORM_VERSION.jar In order to activate Spin functionality for a process engine, a process engine plugin has to be registered in $TOMCAT_HOME/conf/bpm-platform.xml as follows: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <bpm-platform ...> ... <process-engine name=\"default\"> ... <plugins> ... existing plugins ... <plugin> <class>org.cibseven.spin.plugin.impl.SpinProcessEnginePlugin</class> </plugin> </plugins> ... </process-engine> ... </bpm-platform> Groovy Scripting Add the following artifacts (if not existing) from the folder $TOMCAT_DISTRIBUTION/lib/ to the folder $TOMCAT_HOME/lib/: groovy-$GROOVY_VERSION.jar groovy-jsr223-$GROOVY_VERSION.jar groovy-json-$GROOVY_VERSION.jar groovy-xml-$GROOVY_VERSION.jar groovy-templates-$GROOVY_VERSION.jar groovy-dateutil-$GROOVY_VERSION.jar groovy-datetime-$GROOVY_VERSION.jar Freemarker Integration Add the following artifacts (if not existing) from the folder $TOMCAT_DISTRIBUTION/lib/ to the folder $TOMCAT_HOME/lib/: cibseven-template-engines-freemarker-$PLATFORM_VERSION.jar freemarker-2.3.31.jar cibseven-commons-utils-$PLATFORM_VERSION.jar GraalVM JavaScript Integration Add the following artifacts (if not existing) from the folder $TOMCAT_DISTRIBUTION/lib/ to the folder $TOMCAT_HOME/lib/: graal-sdk-21.1.0.jar icu4j-68.2.jar js-21.1.0.jar js-scriptengine-21.1.0.jar regex-21.1.0.jar truffle-api-21.1.0.jar",
    "url": "/manual/latest/installation/full/tomcat/manual/index.html"
  },
  {
    "id": "manual/latest/installation/full/tomcat/pre-packaged/index.html",
    "title": "Install the Pre-Packaged Distribution | docs.cibseven.org",
    "content": "Installation Procedure Download the pre-packaged distribution from https://cibseven.org/download/. Unpack the distro to a directory. Adjust the datasource according to your needs (see Manual Installation). Startup the server by running cibseven-welcome.bat or by using the $TOMCAT_HOME/bin/startup.{bat/sh} script.",
    "url": "/manual/latest/installation/full/tomcat/pre-packaged/index.html"
  },
  {
    "id": "manual/latest/installation/index.html",
    "title": "Install CIB seven | docs.cibseven.org",
    "content": "These documents contain information about how to install different components and distributions of Camunda. Supported Environments Before installing a distribution, first check the list of Supported Environments. Choose from the following distributions and components:",
    "url": "/manual/latest/installation/index.html"
  },
  {
    "id": "manual/latest/installation/karaf-osgi/index.html",
    "title": "Run CIB seven using Karaf / OSGi | docs.cibseven.org",
    "content": "Community Edition If you want to run Camunda with Karaf / OSGi, you can find the corresponding distributions on GitHub.",
    "url": "/manual/latest/installation/karaf-osgi/index.html"
  },
  {
    "id": "manual/latest/installation/spring-boot/index.html",
    "title": "Run CIB seven using Spring Boot | docs.cibseven.org",
    "content": "To learn how to run CIB seven with Spring Boot, please consult the Spring Boot user guide.",
    "url": "/manual/latest/installation/spring-boot/index.html"
  },
  {
    "id": "manual/latest/introduction/architecture/index.html",
    "title": "Architecture Overview | docs.cibseven.org",
    "content": "Camunda is a Java-based framework. The main components are written in Java and we have a general focus on providing Java developers with the tools they need for designing, implementing and running business processes and workflows on the JVM. Nevertheless, we also want to make the process engine technology available to non-Java developers. This is why Camunda also provides a REST API which allows you to build applications connecting to a remote process engine. Camunda can be used both as a standalone process engine server or embedded inside custom Java applications. The embeddability requirement is at the heart of many architectural decisions within Camunda. For instance, we work hard to make the process engine component a lightweight component with as little dependencies on third-party libraries as possible. Furthermore, the embeddability motivates programming model choices such as the capabilities of the process engine to participate in Spring Managed or JTA transactions and the threading model. Process Engine Architecture Process Engine Public API: Service-oriented API allowing Java applications to interact with the process engine. The different responsibilities of the process engine (i.e., Process Repository, Runtime Process Interaction, Task Management, …) are separated into individual services. The public API features a command-style access pattern: Threads entering the process engine are routed through a Command Interceptor which is used for setting up Thread Context such as Transactions. BPMN 2.0 Core Engine: This is the core of the process engine. It features a lightweight execution engine for graph structures (PVM - Process Virtual Machine), a BPMN 2.0 parser which transforms BPMN 2.0 XML files into Java Objects and a set of BPMN Behavior implementations (providing the implementation for BPMN 2.0 constructs such as Gateways or Service Tasks). Job Executor: The Job Executor is responsible for processing asynchronous background work such as Timers or asynchronous continuations in a process. The Persistence Layer: The process engine features a persistence layer responsible for persisting process instance state to a relational database. We use the MyBatis mapping engine for object relational mapping. Required Third-Party Libraries See the section on third-party libraries. Camunda Architecture Camunda is a flexible framework which can be deployed in different scenarios. This section provides an overview of the most common deployment scenarios. Embedded Process Engine In this case, the process engine is added as an application library to a custom application. This way, the process engine can easily be started and stopped with the application lifecycle. It is possible to run multiple embedded process engines on top of a shared database. Shared, Container-Managed Process Engine In this case, the process engine is started inside the runtime container (Servlet Container, Application Server, …). The process engine is provided as a container service and can be shared by all applications deployed inside the container. The concept can be compared to a JMS Message Queue which is provided by the runtime and can be used by all applications. There is a one-to-one mapping between process deployments and applications: the process engine keeps track of the process definitions deployed by an application and delegates execution to the application in question. Standalone (Remote) Process Engine Server In this case, the process engine is provided as a network service. Different applications running on the network can interact with the process engine through a remote communication channel. The easiest way to make the process engine accessible remotely is to use the built-in REST API. Different communication channels such as SOAP Webservices or JMS are possible but need to be implemented by users. Clustering Model In order to provide scale-up or fail-over capabilities, the process engine can be distributed to different nodes in a cluster. Each process engine instance must then connect to a shared database. The individual process engine instances do not maintain session state across transactions. Whenever the process engine runs a transaction, the complete state is flushed out to the shared database. This makes it possible to route subsequent requests which do work in the same process instance to different cluster nodes. This model is very simple and easy to understand and imposes limited restrictions when it comes to deploying a cluster installation. As far as the process engine is concerned, there is no difference between setups for scale-up and setups for fail-over (as the process engine keeps no session state between transactions). Session State in a Clustered Environment Camunda doesn’t provide load-balancing capabilities or session replication capabilities out of the box. The load-balancing function would need to be provided by a third-party system, and session replication would need to be provided by the host application server. In a clustered setup, if users are going to login to the web applications, an extra step will need to be taken to ensure that users aren’t asked to login multiple times. Two options exist: “Sticky sessions” could be configured and enabled within your load balancing solution. This would ensure that all requests from a given user are directed to the same instance over a configurable period of time. Session sharing can be enabled in your application server such that the application server instances share session state. This would allow users to connect to multiple instances in the cluster without being asked to login multiple times. If neither of the above approaches are implemented in a cluster setup, connections to multiple nodes - intentionally or via a load-balancing solution - will result in multiple login requests. The Job Executor in a Clustered Environment The process engine job executor is also clustered and runs on each node. This way, there is no single point of failure as far as the process engine is concerned. The job executor can run in both homogeneous and heterogeneous clusters. Time zones The are some limitations on time zone usage in a cluster. Multi-Tenancy Models To serve multiple, independent parties with one Camunda installation, the process engine supports multi-tenancy. The following multi tenancy models are supported: Table-level data separation by using different database schemas or databases Row-level data separation by using a tenant marker Users should choose the model which fits their data separation needs. Camunda’s APIs provide access to processes and related data specific to each tenant. More details can be found in the multi-tenancy section. Web Application Architecture The Camunda web applications are based on a RESTful architecture. Frameworks used: JAX-RS based Rest API AngularJS RequireJS jQuery Twitter Bootstrap Additional custom frameworks developed by Camunda hackers and compatible with CIB seven: camunda-bpmn.js: Camunda BPMN 2.0 JavaScript libraries ngDefine: integration of AngularJS into RequireJS powered applications angular-data-depend: toolkit for implementing complex, data heavy AngularJS applications",
    "url": "/manual/latest/introduction/architecture/index.html"
  },
  {
    "id": "manual/latest/introduction/downloading-cibseven/index.html",
    "title": "Download | docs.cibseven.org",
    "content": "Prerequisites Before downloading CIB seven, make sure you have a JRE (Java Runtime Environment), or better, a JDK (Java Development Kit) installed. Please check the supported Java versions. Download JDK Download the Runtime CIB seven is a flexible framework which can be used in different contexts. See Architecture Overview for more details. Based on how you want to use CIB seven, you can choose a different distribution. It is also possible to run CIB seven with Spring Boot and Docker. Full Distribution Download the full distribution if you want to use a shared process engine or if you want to get to know CIB seven quickly, without any additional setup or installation steps required. The full distribution bundles Process Engine configured as shared process engine, Runtime Web Applications (Tasklist, Cockpit, Admin), Rest Api, Container / Application Server itself. Server/Container If you download the full distribution for an open-source application server/container, the container itself is included. For example, if you download the Tomcat distribution, Tomcat itself is included and the CIB seven binaries (process engine and web apps) are pre-installed in the container. This is not true for the the Oracle WebLogic and IBM WebSphere downloads; these downloads do not include the application servers themselves. Wildfly Application Server Wildfly Application Server is provided as part of the archives as a convenience. For a copy of the source code, the full set of attribution notices, and other relevant information please see https://github.com/wildfly/wildfly. We will also provide you with a copy of the source code if you contact our Open-Source Compliance Team at any time within three years of you downloading an archive (for which we may charge a nominal sum). Wildfly Application Server is copyright © JBoss, Home of Professional Open Source, 2010, Red Hat Middleware LLC [..and contributors]. See the Installation Guide for additional details.",
    "url": "/manual/latest/introduction/downloading-cibseven/index.html"
  },
  {
    "id": "manual/latest/introduction/extensions/index.html",
    "title": "Extensions | docs.cibseven.org",
    "content": "CIB seven is developed by CIB software and Camunda as an open source project in collaboration with the community. Community Extensions CIB seven supports the community in its effort to build additional community extensions under the CIB seven umbrella. Such community extensions are maintained by the community and are not part of the CIB seven product. The Camunda Community Hub is a GitHub organization that serves as the home of Camunda open source, community-contributed extensions. You can migrate an extension you’ve built to the Hub, search for existing extensions, or get started with open source by helping community extension maintainers with open issue or pull request triage. Building a Community Extension Do you have a great idea around open source BPM you want to share with the world? Awesome! Camunda will support you in building your own community extension. Have a look at our process for creating a new community extension to find out how to propose a community project. You can also visit the Camunda Community Hub community repository to learn more about migrating your community extension into the community hub, benefits to joining the Camunda Community Hub organization, contributing to an extension, and much more. The Camunda Community Hub enables developers to have a centralized home for their Camunda community extensions, and aids new contributors to open source software in discovering new projects to work on. You can also learn about contributing code to the core Camunda codebase.",
    "url": "/manual/latest/introduction/extensions/index.html"
  },
  {
    "id": "manual/latest/introduction/implemented-standards/index.html",
    "title": "Implemented Standards | docs.cibseven.org",
    "content": "Camunda implements three different standards in the Business Process Management scope: BPMN 2.0, CMMN 1.1 and DMN 1.3. These three standards are defined by the Object Management Group with active collaboration of Camunda. Camunda provides open source implementations of execution. BPMN Business Process Model and Notation (BPMN) is a standard for Workflow and Process Automation. Camunda supports the 2.0 version of BPMN. Getting started implementing BPMN Processes: Quick Start (Java / JS) Getting to Know BPMN as a Modeling Language: BPMN Modeling Tutorial Modeling BPMN: BPMN Modeling Reference Implementing BPMN Processes: BPMN Implementation Reference Executing BPMN: Process Engine CMMN Case Management Model and Notation (CMMN) is a standard for Case Management. Camunda supports the 1.1 version of CMMN. Implementing CMMN Cases: CMMN Implementation Reference Executing CMMN: Process Engine DMN Decision Model and Notation (DMN) is a standard for Business Decision Management. Camunda supports the 1.1 version of DMN. Getting started implementing DMN decision tables: DMN Getting Started Getting to Know DMN: DMN Modeling Tutorial Implementing DMN Decisions: DMN Implementation Reference Executing DMN: DMN Engine",
    "url": "/manual/latest/introduction/implemented-standards/index.html"
  },
  {
    "id": "manual/latest/introduction/index.html",
    "title": "Introduction | docs.cibseven.org",
    "content": "Welcome to the CIB seven Manual! CIB seven is a Java-based framework supporting BPMN for workflow and process automation, CMMN for Case Management and DMN for Business Decision Management forrked from Camunda 7 BPM. Also see: Implemented Standards. This document contains information about the features provided by CIB seven. To give you an overview of CIB seven, the following illustration shows the most important components along with some typical user roles. Process Engine & Infrastructure Process Engine The process engine is a Java library responsible for executing BPMN 2.0 processes, CMMN 1.1 cases and DMN 1.3 decisions. It has a lightweight POJO core and uses a relational database for persistence. ORM mapping is provided by the MyBatis mapping framework. Spring Framework Integration CDI/Java EE Integration Runtime Container Integration (Integration with application server infrastructure.) Modeler Camunda Modeler: Modeling tool for BPMN 2.0 and CMMN 1.1 diagrams as well as DMN 1.3 decision tables. bpmn.io: Open-source project for the modeling framework and toolkits. Web Applications REST API The REST API allows you to use the process engine from a remote application or a JavaScript application. (Note: The documentation of the REST API is factored out into own documents.) CIB seven Tasklist A web application for human workflow management and user tasks that allows process participants to inspect their workflow tasks and navigate to task forms in order to work on the tasks and provide data input. CIB seven Cockpit A web application for process monitoring and operations that allows you to search for process instances, inspect their state and repair broken instances. CIB seven Admin A web application that allows you to manage users, groups and authorizations.",
    "url": "/manual/latest/introduction/index.html"
  },
  {
    "id": "manual/latest/introduction/licenses/index.html",
    "title": "Licenses | docs.cibseven.org",
    "content": "CIB seven CIB seven is a Java-based framework. Community Edition If you are using the community edition, the entire software is provided under various open source licenses (mainly Apache 2.0 and MIT). Which components are published under an open source license is clearly stated in the licensing header of a source file or a LICENSE file present in the root directory of the software source code repository. Third-Party Libraries CIB seven includes libraries developed by third parties. See the following resources: Third-Party Libraries: An overview of the dependencies CIB seven distributes. Additionally, this page points out particularly important third-party licenses to be aware of. CIB seven License Book (HTML): A list of all dependencies CIB seven distributes with the CIB seven artifacts, including their licenses and notices. CIB seven License Book (plain text): A plain text version of the license book. GPL Cooperation Commitment Our Commitment Before filing or continuing to prosecute any legal proceeding or claim (other than a Defensive Action) arising from termination of a Covered License, CIB commits to extend to the person or entity (“you”) accused of violating the Covered License the following provisions regarding cure and reinstatement, taken from GPL version 3. As used here, the term ‘this License’ refers to the specific Covered License being enforced. However, if you cease all violation of this License, then your license from a particular copyright holder is reinstated (a) provisionally, unless and until the copyright holder explicitly and finally terminates your license, and (b) permanently, if the copyright holder fails to notify you of the violation by some reasonable means prior to 60 days after the cessation. Moreover, your license from a particular copyright holder is reinstated permanently if the copyright holder notifies you of the violation by some reasonable means, this is the first time you have received notice of violation of this License (for any work) from that copyright holder, and you cure the violation prior to 30 days after your receipt of the notice. CIB may modify this Commitment by publishing a new edition on this page or a successor location. Definitions ‘Covered License’ means the GNU General Public License, version 2 (GPLv2), the GNU Lesser General Public License, version 2.1 (LGPLv2.1), or the GNU Library General Public License, version 2 (LGPLv2), all as published by the Free Software Foundation. ‘Defensive Action’ means a legal proceeding or claim that CIB brings against you in response to a prior proceeding or claim initiated by you or your affiliate. CIB’ means CIB software and its subsidiaries. This work is available under a Creative Commons Attribution-ShareAlike 4.0 International license. Contact If you have a question specifically about the licensing or distribution of CIB seven software and it has not been answered by this page, please contact the Open Source Compliance team at info@cib.de.",
    "url": "/manual/latest/introduction/licenses/index.html"
  },
  {
    "id": "manual/latest/introduction/public-api/index.html",
    "title": "Public API | docs.cibseven.org",
    "content": "Camunda provides a public API. This section covers the definition of the public API and backwards compatibility for version updates. Definition of Public API The Camunda public API is limited to the following items: Java API: All non-implementation Java packages (package name does not contain impl) of the following modules. cibseven-engine cibseven-engine-spring cibseven-engine-cdi cibseven-engine-dmn cibseven-bpmn-model cibseven-cmmn-model cibseven-dmn-model cibseven-spin-core cibseven-connect-core cibseven-commons-typed-values HTTP API (REST API): cibseven-engine-rest: HTTP interface (set of HTTP requests accepted by the REST API as documented in REST API reference. Java classes are not part of the public API. Backwards Compatibility for Public API The CIB seven versioning scheme follows the MAJOR.MINOR.PATCH pattern put forward by Semantic Versioning. CIB seven will maintain public API backwards compatibility for MINOR version updates. Example: Update from version 1.1.x to 1.2.x will not break the public API.",
    "url": "/manual/latest/introduction/public-api/index.html"
  },
  {
    "id": "manual/latest/introduction/supported-environments/index.html",
    "title": "Supported Environments | docs.cibseven.org",
    "content": "Run Camunda in every Java-runnable environment. CIB seven is supported with our QA infrastructure in the following environments. Supported Environments Please note that the environments listed in this section depend on the version of CIB seven. Please select the corresponding version of this documentation to see the environment that fits to your version of CIB seven. e.g., supported environments for version 1.1 Container/Application Server for Runtime Components Application-Embedded Process Engine All Java application servers Camunda Spring Boot Starter: Embedded Tomcat Supported versions Deployment scenarios CIB seven engine Quarkus Extension Supported versions Deployment scenarios Container-Managed Process Engine and Camunda Cockpit, Tasklist, Admin Apache Tomcat 9.0 / 10.1 JBoss EAP 7.4 / 8.0 WildFly Application Server 23.0 / 26.0 / 33.0 Databases Supported Database Products MySQL 8.0 Oracle 19c / 23ai IBM DB2 11.5 (excluding IBM z/OS for all versions) PostgreSQL 14 / 15 / 16 Amazon Aurora PostgreSQL compatible with PostgreSQL 14 / 15 Microsoft SQL Server 2017 / 2019 / 2022 (see Configuration Note) Microsoft Azure SQL with Camunda-supported SQL Server compatibility levels (see Configuration Note): SQL Server on Azure Virtual Machines Azure SQL Managed Instance Azure SQL Database H2 2.3 (not recommended for Cluster Mode - see Deployment Note) Database Clustering & Replication Clustered or replicated databases are supported given the following conditions. The communication between Camunda and the database cluster has to match with the corresponding non-clustered / non-replicated configuration. It is especially important that the configuration of the database cluster guarantees the equivalent behavior of READ-COMMITTED isolation level. Web Browser Google Chrome latest Mozilla Firefox latest Microsoft Edge latest Java Java 11 / 17 / 21 (if supported by your application server/container) Java Runtime Oracle JDK 11 / 17 / 21 OpenJDK 11 / 17 / 21, including builds of the following products: Oracle OpenJDK Eclipse Temurin JDK Amazon Corretto Azul Zulu Maintenance Policy Adding Environments Whenever a new version of one of the following environments is released, we target support of that new version with the next minor release of Camunda. A new released environment has to be available three months before the next Camunda minor release to be considered. Java Language (LTS) Spring Boot Wildfly Application Server Oracle Database (LTS) PostgreSQL The exact release in which we support a new environment depends on factors such as the release date of the environment and the required implementation effort. Version support for other environments is decided case by case, much of which is based on the demand in our user base. Removing Environments Whenever a new version of one of the following environments is supported, we usually discontinue support of the oldest version with the same release: Wildfly Application Server Note that we may decide to deviate from this policy on a case-by-case basis.",
    "url": "/manual/latest/introduction/supported-environments/index.html"
  },
  {
    "id": "manual/latest/introduction/third-party-libraries/cibseven-bpm-platform-license-book/index.html",
    "title": "CIB seven License Book | docs.cibseven.org",
    "content": "Java Dependencies logback-classic@1.5.7(EPL 1.0)Copyright (C) 1999-2024, QOS.ch. All rights reserved. logback-core@1.5.7(EPL 1.0)Copyright (C) 1999-2024, QOS.ch. All rights reserved. jackson-annotations@2.15.2(Apache 2.0)Copyright 2007-, Tatu Saloranta (tatu.saloranta@iki.fi) Jackson is a high-performance, Free/Open Source JSON processing library. It was originally written by Tatu Saloranta (tatu.saloranta@iki.fi), and has been in development since 2007. It is currently developed by a community of developers: jackson-annotations@2.17.2(Apache 2.0)Copyright 2007-, Tatu Saloranta (tatu.saloranta@iki.fi) Jackson is a high-performance, Free/Open Source JSON processing library. It was originally written by Tatu Saloranta (tatu.saloranta@iki.fi), and has been in development since 2007. It is currently developed by a community of developers: jackson-core@2.15.2(Apache 2.0)Copyright 2007-, Tatu Saloranta (tatu.saloranta@iki.fi) Jackson is a high-performance, Free/Open Source JSON processing library. It was originally written by Tatu Saloranta (tatu.saloranta@iki.fi), and has been in development since 2007. It is currently developed by a community of developers: https://github.com/FasterXML/jackson-core/blob/2.16/release-notes/CREDITS-2.x jackson-core@2.17.2(Apache 2.0)Copyright 2007-, Tatu Saloranta (tatu.saloranta@iki.fi) Jackson is a high-performance, Free/Open Source JSON processing library. It was originally written by Tatu Saloranta (tatu.saloranta@iki.fi), and has been in development since 2007. It is currently developed by a community of developers: jackson-databind@2.15.2(Apache 2.0)Copyright 2007-, Tatu Saloranta (tatu.saloranta@iki.fi) Jackson is a high-performance, Free/Open Source JSON processing library. It was originally written by Tatu Saloranta (tatu.saloranta@iki.fi), and has been in development since 2007. It is currently developed by a community of developers: https://github.com/FasterXML/jackson-databind/blob/2.16/release-notes/CREDITS-2.x jackson-databind@2.17.2(Apache 2.0)Copyright 2007-, Tatu Saloranta (tatu.saloranta@iki.fi) Jackson is a high-performance, Free/Open Source JSON processing library. It was originally written by Tatu Saloranta (tatu.saloranta@iki.fi), and has been in development since 2007. It is currently developed by a community of developers: jackson-dataformat-csv@2.15.2(Apache 2.0)Copyright 2007-, Tatu Saloranta (tatu.saloranta@iki.fi) Jackson is a high-performance, Free/Open Source JSON processing library. It was originally written by Tatu Saloranta (tatu.saloranta@iki.fi), and has been in development since 2007. It is currently developed by a community of developers: https://github.com/FasterXML/jackson-dataformats-text/blob/2.16/release-notes/CREDITS-2.x jackson-dataformat-csv@2.17.2(Apache 2.0)Copyright 2007-, Tatu Saloranta (tatu.saloranta@iki.fi) Jackson is a high-performance, Free/Open Source JSON processing library. It was originally written by Tatu Saloranta (tatu.saloranta@iki.fi), and has been in development since 2007. It is currently developed by a community of developers: jackson-datatype-jdk8@2.17.2(Apache 2.0)Copyright 2007-, Tatu Saloranta (tatu.saloranta@iki.fi) Jackson is a high-performance, Free/Open Source JSON processing library. It was originally written by Tatu Saloranta (tatu.saloranta@iki.fi), and has been in development since 2007. It is currently developed by a community of developers: jackson-datatype-jsr310@2.15.2(Apache 2.0)Copyright 2007-, Tatu Saloranta (tatu.saloranta@iki.fi) Jackson is a high-performance, Free/Open Source JSON processing library. It was originally written by Tatu Saloranta (tatu.saloranta@iki.fi), and has been in development since 2007. It is currently developed by a community of developers: https://github.com/FasterXML/jackson-modules-java8/blob/2.16/release-notes/CREDITS-2.x jackson-datatype-jsr310@2.17.2(Apache 2.0)Copyright 2007-, Tatu Saloranta (tatu.saloranta@iki.fi) Jackson is a high-performance, Free/Open Source JSON processing library. It was originally written by Tatu Saloranta (tatu.saloranta@iki.fi), and has been in development since 2007. It is currently developed by a community of developers: jackson-jakarta-rs-base@2.15.2(Apache 2.0)Copyright 2007-, Tatu Saloranta (tatu.saloranta@iki.fi) Jackson is a high-performance, Free/Open Source JSON processing library. It was originally written by Tatu Saloranta (tatu.saloranta@iki.fi), and has been in development since 2007. It is currently developed by a community of developers: https://github.com/FasterXML/jackson-jakarta-rs-providers/blob/2.16/release-notes/CREDITS-2.x jackson-jakarta-rs-base@2.17.2(Apache 2.0)Copyright 2007-, Tatu Saloranta (tatu.saloranta@iki.fi) Jackson is a high-performance, Free/Open Source JSON processing library. It was originally written by Tatu Saloranta (tatu.saloranta@iki.fi), and has been in development since 2007. It is currently developed by a community of developers: jackson-jakarta-rs-json-provider@2.15.2(Apache 2.0)Copyright 2007-, Tatu Saloranta (tatu.saloranta@iki.fi) Jackson is a high-performance, Free/Open Source JSON processing library. It was originally written by Tatu Saloranta (tatu.saloranta@iki.fi), and has been in development since 2007. It is currently developed by a community of developers: https://github.com/FasterXML/jackson-jakarta-rs-providers/blob/2.16/release-notes/CREDITS-2.x jackson-jakarta-rs-json-provider@2.17.2(Apache 2.0)Copyright 2007-, Tatu Saloranta (tatu.saloranta@iki.fi) Jackson is a high-performance, Free/Open Source JSON processing library. It was originally written by Tatu Saloranta (tatu.saloranta@iki.fi), and has been in development since 2007. It is currently developed by a community of developers: jackson-jaxrs-base@2.15.2(Apache 2.0)Copyright 2007-, Tatu Saloranta (tatu.saloranta@iki.fi) Jackson is a high-performance, Free/Open Source JSON processing library. It was originally written by Tatu Saloranta (tatu.saloranta@iki.fi), and has been in development since 2007. It is currently developed by a community of developers: https://github.com/FasterXML/jackson-jaxrs-providers/blob/2.16/release-notes/CREDITS-2.x jackson-jaxrs-json-provider@2.15.2(Apache 2.0)Copyright 2007-, Tatu Saloranta (tatu.saloranta@iki.fi) Jackson is a high-performance, Free/Open Source JSON processing library. It was originally written by Tatu Saloranta (tatu.saloranta@iki.fi), and has been in development since 2007. It is currently developed by a community of developers: https://github.com/FasterXML/jackson-jaxrs-providers/blob/2.16/release-notes/CREDITS-2.x jackson-module-jakarta-xmlbind-annotations@2.15.2(Apache 2.0)Copyright 2007-, Tatu Saloranta (tatu.saloranta@iki.fi) Jackson is a high-performance, Free/Open Source JSON processing library. It was originally written by Tatu Saloranta (tatu.saloranta@iki.fi), and has been in development since 2007. It is currently developed by a community of developers: https://github.com/FasterXML/jackson-modules-base/blob/2.16/release-notes/CREDITS-2.x jackson-module-jakarta-xmlbind-annotations@2.17.2(Apache 2.0)Copyright 2007-, Tatu Saloranta (tatu.saloranta@iki.fi) Jackson is a high-performance, Free/Open Source JSON processing library. It was originally written by Tatu Saloranta (tatu.saloranta@iki.fi), and has been in development since 2007. It is currently developed by a community of developers: jackson-module-jaxb-annotations@2.15.2(Apache 2.0)Copyright 2007-, Tatu Saloranta (tatu.saloranta@iki.fi) Jackson is a high-performance, Free/Open Source JSON processing library. It was originally written by Tatu Saloranta (tatu.saloranta@iki.fi), and has been in development since 2007. It is currently developed by a community of developers: https://github.com/FasterXML/jackson-modules-base/blob/2.16/release-notes/CREDITS-2.x jackson-module-parameter-names@2.17.2(Apache 2.0)Copyright 2007-, Tatu Saloranta (tatu.saloranta@iki.fi) Jackson is a high-performance, Free/Open Source JSON processing library. It was originally written by Tatu Saloranta (tatu.saloranta@iki.fi), and has been in development since 2007. It is currently developed by a community of developers: java-uuid-generator@4.3.0(Apache 2.0)Java UUID generator library has been written by Tatu Saloranta (tatu.saloranta@iki.fi) Other developers who have contributed code are: Eric Bie contributed extensive unit test suite which has helped ensure high implementation quality classmate@1.7.0(Apache 2.0)Copyright 2007-, Tatu Saloranta (tatu.saloranta@iki.fi) Jackson is a high-performance, Free/Open Source JSON processing library. It was originally written by Tatu Saloranta (tatu.saloranta@iki.fi), and has been in development since 2007. It is currently developed by a community of developers jcip-annotations@1.0-1(Creative Commons Attribution)Copyright: 2005 Brian Goetz and Tim Peierls gson@2.8.9(Apache 2.0)Copyright: 2008 Google Inc. h2@2.3.232(EPL 1.0)Copyright 2004-2024 H2 Group asyncutil@0.1.0(Apache 2.0)Copyright (c) IBM Corporation 2017. All Rights Reserved icu4j@68.2(Unicode)Copyright © 2016 and later Unicode, Inc. and others. See this link for third-party software notices and/or additional terms for licensed third-party software components included within ICU libraries: https://github.com/unicode-org/icu/edit/main/icu4c/LICENSE json-path@2.9.0(Apache 2.0)Copyright 2011 the original author or authors fastparse_2.13@3.0.2(MIT)Copyright (c) 2014 Li Haoyi (haoyi.sg@gmail.com) geny_2.13@1.0.0(MIT)Copyright (c) 2016 Li Haoyi (haoyi.sg@gmail.com) sourcecode_2.13@0.3.0(MIT)Copyright (c) 2014 Li Haoyi (haoyi.sg@gmail.com) content-type@2.2(Apache 2.0)Copyright 2020, Connect2id Ltd. lang-tag@1.7(Apache 2.0)Copyright 2012-2022, Connect2id Ltd. nimbus-jose-jwt@9.37.3(Apache 2.0)Copyright 2012 - 2022, Connect2id Ltd. oauth2-oidc-sdk@9.43.4(Apache 2.0)Copyright 2012-2022, Connect2id Ltd and contributors. jakarta.activation@1.2.2(EDL 1.0)Copyright (c) 2018 Oracle and/or its affiliates. All rights reserved jaxb-core@4.0.5(BSD-3-Clause)Copyright (c) 2018 Oracle and/or its affiliates. All rights reserved. jaxb-impl@2.3.6(EDL 1.0)Copyright (c) 2018 Oracle and/or its affiliates. All rights reserved. jaxb-impl@4.0.5(BSD-3-Clause)Copyright (c) 2018 Oracle and/or its affiliates. All rights reserved. HikariCP@5.1.0(Apache 2.0)Copyright (C) Brett Wooldridge commons-codec@1.15(Apache 2.0)Notice file: ====================================================================== Apache Commons Codec Copyright 2002-2021 The Apache Software Foundation This product includes software developed at The Apache Software Foundation (https://www.apache.org/). src/test/org/apache/commons/codec/language/DoubleMetaphoneTest.java contains test data from http://aspell.net/test/orig/batch0.tab. Copyright (C) 2002 Kevin Atkinson (kevina@gnu.org) The content of package org.apache.commons.codec.language.bm has been translated from the original php source code available at http://stevemorse.org/phoneticinfo.htm with permission from the original authors. Original source copyright: Copyright (c) 2008 Alexander Beider & Stephen P. Morse. ====================================================================== commons-codec@1.16.1(Apache 2.0)Apache Commons Codec Copyright 2002-2021 The Apache Software Foundation This product includes software developed at The Apache Software Foundation (https://www.apache.org/). src/test/org/apache/commons/codec/language/DoubleMetaphoneTest.java contains test data from http://aspell.net/test/orig/batch0.tab. Copyright (C) 2002 Kevin Atkinson (kevina@gnu.org) The content of package org.apache.commons.codec.language.bm has been translated from the original php source code available at http://stevemorse.org/phoneticinfo.htm with permission from the original authors. Original source copyright: Copyright (c) 2008 Alexander Beider & Stephen P. Morse. commons-fileupload@1.5(Apache 2.0)Notice file Apache Commons FileUpload Copyright 2002-2023 The Apache Software Foundation This product includes software developed at The Apache Software Foundation (http://www.apache.org/). commons-io@2.8.0(Apache 2.0)Notice file ====================================================================== Apache Commons IO Copyright 2002-2020 The Apache Software Foundation This product includes software developed at The Apache Software Foundation (https://www.apache.org/). ====================================================================== commons-logging@1.1.1(Apache 2.0)Copyright: 2003-2014 The Apache Software Foundation This product includes software developed at The Apache Software Foundation (http://www.apache.org/) commons-logging@1.2(Apache 2.0)Notice file: ==================================================================== Apache Commons Logging Copyright 2003-2016 The Apache Software Foundation This product includes software developed at The Apache Software Foundation (http://www.apache.org/). Copyright 2003-2016 The Apache Software Foundation ==================================================================== micrometer-commons@1.13.3(Apache 2.0)Copyright (c) 2017-Present VMware, Inc. All Rights Reserved. micrometer-observation@1.13.3(Apache 2.0)Copyright (c) 2017-Present VMware, Inc. All Rights Reserved. jakarta.activation-api@1.2.2(BSD-3-Clause)Copyright (c) 2018 Oracle and/or its affiliates. All rights reserved. Notice file: ================================================================== # Notices for Jakarta Activation This content is produced and maintained by Jakarta Activation project. * Project home: https://projects.eclipse.org/projects/ee4j.jaf ## Copyright All content is the property of the respective authors or their employers. For more information regarding authorship of content, please consult the listed source code repository logs. ## Declared Project Licenses This program and the accompanying materials are made available under the terms of the Eclipse Distribution License v. 1.0, which is available at http://www.eclipse.org/org/documents/edl-v10.php. SPDX-License-Identifier: BSD-3-Clause ## Source Code The project maintains the following source code repositories: * https://github.com/eclipse-ee4j/jaf ## Third-party Content This project leverages the following third party content. JUnit (4.12) * License: Eclipse Public License ==================================================================== jakarta.activation-api@2.1.0(BSD-3-Clause)Copyright (c) 2018 Oracle and/or its affiliates. All rights reserved. jakarta.activation-api@2.1.3(BSD-3-Clause)Copyright (c) 2018 Oracle and/or its affiliates. All rights reserved. jakarta.annotation-api@1.3.5(EPL 2.0)Notice file: ================================================================== # Notices for Jakarta Activation This content is produced and maintained by Jakarta Activation project. * Project home: https://projects.eclipse.org/projects/ee4j.jaf ## Copyright All content is the property of the respective authors or their employers. For more information regarding authorship of content, please consult the listed source code repository logs. ## Declared Project Licenses This program and the accompanying materials are made available under the terms of the Eclipse Distribution License v. 1.0, which is available at http://www.eclipse.org/org/documents/edl-v10.php. SPDX-License-Identifier: BSD-3-Clause ## Source Code The project maintains the following source code repositories: * https://github.com/eclipse-ee4j/jaf ## Third-party Content This project leverages the following third party content. JUnit (4.12) * License: Eclipse Public License ==================================================================== Copyright (C) Oracle and/or its affiliates. All rights reserved. jakarta.annotation-api@2.1.1(EPL 2.0)Copyright (c) Jakarta Annotations™ jakarta.el-api@4.0.0(EPL 2.0)Copyright (c) Jakarta Annotations™ jakarta.inject-api@2.0.1(Apache 2.0)Copyright (c) Eclipse Jakarta Dependency Injection project. All content is the property of the respective authors or their employers. For more information regarding authorship of content, please consult the listed source code repository logs jakarta.servlet-api@6.0.0(EPL 2.0)Copyright (c) 1997, 2021 Oracle and/or its affiliates. All rights reserved. jakarta.validation-api@2.0.2(Apache 2.0)Copyright: various authors (https://github.com/eclipse-ee4j/beanvalidation-api/blob/master/copyright.txt) jakarta.validation-api@3.0.2(Apache 2.0)Copyright (c) https://github.com/jakartaee/validation/blob/master/copyright.txt jakarta.ws.rs-api@2.1.6(EPL 2.0)Notice file: ================================================================== # Notices for Jakarta Activation This content is produced and maintained by Jakarta Activation project. * Project home: https://projects.eclipse.org/projects/ee4j.jaf ## Copyright All content is the property of the respective authors or their employers. For more information regarding authorship of content, please consult the listed source code repository logs. ## Declared Project Licenses This program and the accompanying materials are made available under the terms of the Eclipse Distribution License v. 1.0, which is available at http://www.eclipse.org/org/documents/edl-v10.php. SPDX-License-Identifier: BSD-3-Clause ## Source Code The project maintains the following source code repositories: * https://github.com/eclipse-ee4j/jaf ## Third-party Content This project leverages the following third party content. JUnit (4.12) * License: Eclipse Public License ==================================================================== Copyright (C) Oracle and/or its affiliates. All rights reserved. jakarta.ws.rs-api@3.1.0(EPL 2.0)Copyright: Oracle and/or its affiliates. All rights reserved. Licensed under EPL 2.0 jakarta.xml.bind-api@2.3.3(EDL 1.0)Copyright:(c) 2017, 2018 Oracle and/or its affiliates. All rights reserved. Notice file: https://github.com/eclipse-ee4j/jaxb-api/blob/master/NOTICE.md jakarta.xml.bind-api@3.0.1(EPL 2.0)Copyright (c) 1997, 2021 Oracle and/or its affiliates. All rights reserved. jakarta.xml.bind-api@4.0.0(BSD-3-Clause)Copyright (c) 2018 Oracle and/or its affiliates. All rights reserved jakarta.xml.bind-api@4.0.2(EPL 2.0)Copyright (c) 1997, 2024 Oracle and/or its affiliates. All rights reserved. joda-time@2.12.5(Apache 2.0)============================================================================= = NOTICE file corresponding to section 4d of the Apache License Version 2.0 = ============================================================================= This product includes software developed by Joda.org (https://www.joda.org/). accessors-smart@2.5.0(Apache 2.0)Copyright 2011-2023 JSON-SMART authors accessors-smart@2.5.1(Apache 2.0)Copyright 2011-2024 JSON-SMART authors json-smart@2.5.0(Apache 2.0)Copyright 2011-2023 JSON-SMART authors json-smart@2.5.1(Apache 2.0)Copyright 2011-2023 JSON-SMART authors commons-lang3@3.14.0(Apache 2.0)Apache Commons Codec Copyright 2002-2021 The Apache Software Foundation This product includes software developed at The Apache Software Foundation (https://www.apache.org/). src/test/org/apache/commons/codec/language/DoubleMetaphoneTest.java contains test data from http://aspell.net/test/orig/batch0.tab. Copyright (C) 2002 Kevin Atkinson (kevina@gnu.org) The content of package org.apache.commons.codec.language.bm has been translated from the original php source code available at http://stevemorse.org/phoneticinfo.htm with permission from the original authors. Original source copyright: Copyright (c) 2008 Alexander Beider & Stephen P. Morse groovy-datetime@4.0.22(Apache 2.0)Copyright 2003-2023 The Apache Software Foundation Licensed under Apache 2.0 Notice This product includes software developed at The Apache Software Foundation (http://www.apache.org/). The Java source files in src/main/java/org/apache/groovy/util/concurrent/concurrentlinkedhashmap/ are from https://github.com/ben-manes/concurrentlinkedhashmap and the following notice applies: Copyright 2010-2012 Google Inc. All Rights Reserved. The Java source file src/main/java/org/apache/groovy/util/concurrent/ConcurrentReferenceHashMap is from https://github.com/hazelcast/hazelcast and the following notice applies: Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved. This product bundles icons from the famfamfam.com silk icons set http://www.famfamfam.com/lab/icons/silk/ Licensed under the Creative Commons Attribution Licence v2.5 http://creativecommons.org/licenses/by/2.5/ groovy-dateutil@4.0.22(Apache 2.0)Copyright 2003-2023 The Apache Software Foundation Licensed under Apache 2.0 Notice This product includes software developed at The Apache Software Foundation (http://www.apache.org/). The Java source files in src/main/java/org/apache/groovy/util/concurrent/concurrentlinkedhashmap/ are from https://github.com/ben-manes/concurrentlinkedhashmap and the following notice applies: Copyright 2010-2012 Google Inc. All Rights Reserved. The Java source file src/main/java/org/apache/groovy/util/concurrent/ConcurrentReferenceHashMap is from https://github.com/hazelcast/hazelcast and the following notice applies: Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved. This product bundles icons from the famfamfam.com silk icons set http://www.famfamfam.com/lab/icons/silk/ Licensed under the Creative Commons Attribution Licence v2.5 http://creativecommons.org/licenses/by/2.5/ groovy-json@4.0.22(Apache 2.0)Copyright 2003-2023 The Apache Software Foundation Licensed under Apache 2.0 Notice This product includes software developed at The Apache Software Foundation (http://www.apache.org/). The Java source files in src/main/java/org/apache/groovy/util/concurrent/concurrentlinkedhashmap/ are from https://github.com/ben-manes/concurrentlinkedhashmap and the following notice applies: Copyright 2010-2012 Google Inc. All Rights Reserved. The Java source file src/main/java/org/apache/groovy/util/concurrent/ConcurrentReferenceHashMap is from https://github.com/hazelcast/hazelcast and the following notice applies: Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved. This product bundles icons from the famfamfam.com silk icons set http://www.famfamfam.com/lab/icons/silk/ Licensed under the Creative Commons Attribution Licence v2.5 http://creativecommons.org/licenses/by/2.5/ groovy-jsr223@4.0.22(Apache 2.0)Copyright 2003-2023 The Apache Software Foundation Licensed under Apache 2.0 Notice This product includes software developed at The Apache Software Foundation (http://www.apache.org/). The Java source files in src/main/java/org/apache/groovy/util/concurrent/concurrentlinkedhashmap/ are from https://github.com/ben-manes/concurrentlinkedhashmap and the following notice applies: Copyright 2010-2012 Google Inc. All Rights Reserved. The Java source file src/main/java/org/apache/groovy/util/concurrent/ConcurrentReferenceHashMap is from https://github.com/hazelcast/hazelcast and the following notice applies: Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved. This product bundles icons from the famfamfam.com silk icons set http://www.famfamfam.com/lab/icons/silk/ Licensed under the Creative Commons Attribution Licence v2.5 http://creativecommons.org/licenses/by/2.5/ groovy-templates@4.0.22(Apache 2.0)Copyright 2003-2023 The Apache Software Foundation Licensed under Apache 2.0 Notice This product includes software developed at The Apache Software Foundation (http://www.apache.org/). The Java source files in src/main/java/org/apache/groovy/util/concurrent/concurrentlinkedhashmap/ are from https://github.com/ben-manes/concurrentlinkedhashmap and the following notice applies: Copyright 2010-2012 Google Inc. All Rights Reserved. The Java source file src/main/java/org/apache/groovy/util/concurrent/ConcurrentReferenceHashMap is from https://github.com/hazelcast/hazelcast and the following notice applies: Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved. This product bundles icons from the famfamfam.com silk icons set http://www.famfamfam.com/lab/icons/silk/ Licensed under the Creative Commons Attribution Licence v2.5 http://creativecommons.org/licenses/by/2.5/ groovy-xml@4.0.22(Apache 2.0)Copyright 2003-2023 The Apache Software Foundation Licensed under Apache 2.0 Notice This product includes software developed at The Apache Software Foundation (http://www.apache.org/). The Java source files in src/main/java/org/apache/groovy/util/concurrent/concurrentlinkedhashmap/ are from https://github.com/ben-manes/concurrentlinkedhashmap and the following notice applies: Copyright 2010-2012 Google Inc. All Rights Reserved. The Java source file src/main/java/org/apache/groovy/util/concurrent/ConcurrentReferenceHashMap is from https://github.com/hazelcast/hazelcast and the following notice applies: Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved. This product bundles icons from the famfamfam.com silk icons set http://www.famfamfam.com/lab/icons/silk/ Licensed under the Creative Commons Attribution Licence v2.5 http://creativecommons.org/licenses/by/2.5/ groovy@4.0.22(Apache 2.0)Copyright 2003-2023 The Apache Software Foundation Licensed under Apache 2.0 Notice This product includes software developed at The Apache Software Foundation (http://www.apache.org/). The Java source files in src/main/java/org/apache/groovy/util/concurrent/concurrentlinkedhashmap/ are from https://github.com/ben-manes/concurrentlinkedhashmap and the following notice applies: Copyright 2010-2012 Google Inc. All Rights Reserved. The Java source file src/main/java/org/apache/groovy/util/concurrent/ConcurrentReferenceHashMap is from https://github.com/hazelcast/hazelcast and the following notice applies: Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved. This product bundles icons from the famfamfam.com silk icons set http://www.famfamfam.com/lab/icons/silk/ Licensed under the Creative Commons Attribution Licence v2.5 http://creativecommons.org/licenses/by/2.5/ httpclient@4.5.14(Apache 2.0)Copyright The Apache Software Foundation httpcore@4.4.16(Apache 2.0)Copyright The Apache Software Foundation log4j-api@2.23.1(Apache 2.0)Copyright The Apache Software Foundation log4j-to-slf4j@2.23.1(Apache 2.0)Copyright The Apache Software Foundation tomcat-embed-core@10.1.28(Apache 2.0)Copyright 1999-2024 The Apache Software Foundation tomcat-embed-el@10.1.28(Apache 2.0)Copyright 1999-2024 The Apache Software Foundation tomcat-embed-websocket@10.1.28(Apache 2.0)Copyright 1999-2024 The Apache Software Foundation tomcat@10.1.30(Apache 2.0)Copyright 1999-2024 The Apache Software Foundation angus-activation@1.0.0(BSD-3-Clause)Copyright (c) 2018 Oracle and/or its affiliates. All rights reserved. angus-activation@2.0.2(BSD-3-Clause)Copyright (c) 2018 Oracle and/or its affiliates. All rights reserved. freemarker@2.3.31(Apache 2.0)Copyright: Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. expressly@5.0.0(EPL 2.0)Copyright (c) 2022 Contributors to the Eclipse Foundation. Copyright (c) 1997, 2021 Oracle and/or its affiliates and others. aopalliance-repackaged@2.6.1(EPL-2.0)Copyright (c) 2013, 2018 Oracle and/or its affiliates. All rights reserved. Copyright (c) 2019 Payara Services Ltd. aopalliance-repackaged@3.0.6(EPL 2.0)Copyright (c) 2013, 2018 Oracle and/or its affiliates. All rights reserved. Copyright (c) 2019 Payara Services Ltd jakarta.inject@2.6.1(EPL-2.0)Copyright (c) 2010, 2018 Oracle and/or its affiliates. All rights reserved. class-model@3.0.6(EPL 2.0)Copyright (c) 2010, 2018 Oracle and/or its affiliates. All rights reserved. Copyright (c) 2019, 2020 Payara Services Ltd. hk2-api@2.6.1(EPL-2.0)Copyright (c) 2010, 2018 Oracle and/or its affiliates. All rights reserved. Copyright (c) 2019 Payara Services Ltd. hk2-api@3.0.6(EPL 2.0)Copyright (c) 2010, 2018 Oracle and/or its affiliates. All rights reserved. Copyright (c) 2019, 2020 Payara Services Ltd. hk2-core@3.0.6(EPL 2.0)Copyright (c) 2010, 2018 Oracle and/or its affiliates. All rights reserved. Copyright (c) 2019 Payara Services Ltd hk2-locator@2.6.1(EPL-2.0)Copyright (c) 2010, 2018 Oracle and/or its affiliates. All rights reserved. Copyright (c) 2019 Payara Services Ltd. hk2-locator@3.0.6(EPL 2.0)Copyright (c) 2010, 2018 Oracle and/or its affiliates. All rights reserved. Copyright (c) 2019, 2020 Payara Services Ltd hk2-runlevel@3.0.6(EPL 2.0)Copyright (c) 2010, 2018 Oracle and/or its affiliates. All rights reserved. Copyright (c) 2019 Payara Services Ltd. hk2-utils@2.6.1(EPL-2.0)Copyright (c) 2010, 2018 Oracle and/or its affiliates. All rights reserved. Copyright (c) 2019 Payara Services Ltd. hk2-utils@3.0.6(EPL 2.0)Copyright (c) 2010, 2018 Oracle and/or its affiliates. All rights reserved. Copyright (c) 2019, 2020 Payara Services Ltd. hk2@3.0.6(EPL 2.0)Copyright (c) 2010, 2018 Oracle and/or its affiliates. All rights reserved. osgi-resource-locator@1.0.3(EPL-2.0)Copyright (c) 2018, 2019 Oracle and/or its affiliates. All rights reserved. spring-bridge@3.0.6(EPL 2.0)Copyright (c) 2013, 2018 Oracle and/or its affiliates. All rights reserved. Copyright (c) 2019, 2020 Payara Services Ltd. jersey-container-servlet-core@2.34(EPL-2.0)Copyright (c) 2012, 2021 Oracle and/or its affiliates. All rights reserved Further third-party content may be included: https://github.com/eclipse-ee4j/jersey/blob/2.34/NOTICE.md#third-party-content jersey-container-servlet-core@3.1.8(EPL-2.0)Copyright (c) 2010, 2024 Oracle and/or its affiliates. All rights reserved. jersey-container-servlet@2.34(EPL-2.0)Copyright (c) 2012, 2021 Oracle and/or its affiliates. All rights reserved Further third-party content may be included: https://github.com/eclipse-ee4j/jersey/blob/2.34/NOTICE.md#third-party-content jersey-container-servlet@3.1.8(EPL-2.0)Copyright (c) 2010, 2024 Oracle and/or its affiliates. All rights reserved. jersey-client@2.34(EPL-2.0)Copyright (c) 2012, 2021 Oracle and/or its affiliates. All rights reserved Further third-party content may be included: https://github.com/eclipse-ee4j/jersey/blob/2.34/NOTICE.md#third-party-content jersey-client@3.1.8(EPL-2.0)Copyright (c) 2010, 2024 Oracle and/or its affiliates. All rights reserved. jersey-common@2.34(EPL-2.0)Copyright (c) 2010, 2021 Oracle and/or its affiliates. All rights reserved Further third-party content may be included: https://github.com/eclipse-ee4j/jersey/blob/2.34/NOTICE.md#third-party-content jersey-common@3.1.8(EPL-2.0)Copyright (c) 2010, 2024 Oracle and/or its affiliates. All rights reserved. jersey-server@2.34(EPL-2.0)Copyright (c) 2010, 2021 Oracle and/or its affiliates. All rights reserved Further third-party content may be included: https://github.com/eclipse-ee4j/jersey/blob/2.34/NOTICE.md#third-party-content jersey-server@3.1.8(EPL-2.0)Copyright (c) 2010, 2024 Oracle and/or its affiliates. All rights reserved. jersey-bean-validation@3.1.8(EPL-2.0)Copyright (c) 2010, 2024 Oracle and/or its affiliates. All rights reserved. jersey-entity-filtering@3.1.8(EPL-2.0)Copyright (c) 2010, 2024 Oracle and/or its affiliates. All rights reserved. jersey-spring6@3.1.8(EPL-2.0)Copyright (c) 2010, 2024 Oracle and/or its affiliates. All rights reserved. jersey-hk2@2.34(EPL-2.0)Copyright (c) 2017, 2021 Oracle and/or its affiliates. All rights reserved Further third-party content may be included: https://github.com/eclipse-ee4j/jersey/blob/2.34/NOTICE.md#third-party-content jersey-hk2@3.1.8(EPL-2.0)Copyright (c) 2010, 2024 Oracle and/or its affiliates. All rights reserved. jersey-media-json-jackson@3.1.8(EPL-2.0)Copyright (c) 2010, 2024 Oracle and/or its affiliates. All rights reserved. js-scriptengine@21.1.0(UPL)Copyright (c) 2019, Oracle and/or its affiliates https://github.com/oracle/graaljs/blob/master/3rd_party_licenses.txt See this link for third-party software notices and/or additional terms for licensed third-party software components included within graaljis libraries js@21.1.0(UPL)Copyright (c) 2019, Oracle and/or its affiliates https://github.com/oracle/graaljs/blob/master/3rd_party_licenses.txt See this link for third-party software notices and/or additional terms for licensed third-party software components included within graaljis libraries regex@21.1.0(UPL)Copyright (c) 2021, Oracle and/or its affiliates graal-sdk@21.1.0(UPL)Copyright (c) Oracle and/or its affiliates. See this link for third-party software notices and/or additional terms for licensed third-party software components included within the LLVM Project. The LLVM Project is under the Apache License v2.0 with LLVM Exceptions:https://github.com/oracle/graal/blob/master/sdk/3rd_party_license_llvm-toolchain.txt truffle-api@21.1.0(UPL)Copyright (c) Oracle and/or its affiliates. hibernate-validator@8.0.1.Final(Apache 2.0)Copyright various authors https://github.com/hibernate/hibernate-validator/blob/main/copyright.txt javassist@3.25.0-GA(Apache 2.0)Copyright: (C) 1999-2020 by Shigeru Chiba, All rights reserved. javassist@3.30.2-GA(Apache 2.0)Copyright (C) 1999-2023 by Shigeru Chiba, All rights reserved. jboss-logging@3.4.1.Final(Apache 2.0)Copyright JBoss, Home of Professional Open Source Copyright 2010 Red Hat, Inc., and individual contributorsas indicated by the @author tags. jboss-logging@3.5.0.Final(Apache 2.0)Copyright 2010 Red Hat, Inc. jboss-logging@3.5.3.Final(Apache 2.0)Copyright 2023 Red Hat, Inc. resteasy-core-spi@6.2.3.Final(Apache 2.0)Copyright 2010 Red Hat, Inc. resteasy-core@6.2.3.Final(Apache 2.0)Copyright 2013 Red Hat, Inc., and individual contributors resteasy-jaxrs@3.15.6.Final(Apache 2.0)Copyright: list of conributors https://github.com/resteasy/resteasy/graphs/contributors jboss-annotations-api_1.3_spec@2.0.1.Final(EPL-2.0)Copyright (c) 2012, 2019 Oracle and/or its affiliates. All rights reserved. jboss-jaxrs-api_2.1_spec@2.0.1.Final(EPL-2.0)Notice file: ===================================================================================== Notices for the Jakarta RESTful Web Services Project This content is produced and maintained by the Jakarta RESTful Web Services project. Project home: https://projects.eclipse.org/projects/ee4j.jaxrs Trademarks Jakarta RESTful Web Services is a trademark of the Eclipse Foundation. Copyright All content is the property of the respective authors or their employers. For more information regarding authorship of content, please consult the listed source code repository logs. Declared Project Licenses This program and the accompanying materials are made available under the terms of the Eclipse Public License v. 2.0 which is available at http://www.eclipse.org/legal/epl-2.0. This Source Code may also be made available under the following Secondary Licenses when the conditions for such availability set forth in the Eclipse Public License v. 2.0 are satisfied: GNU General Public License, version 2 with the GNU Classpath Exception which is available at https://www.gnu.org/software/classpath/license.html. SPDX-License-Identifier: EPL-2.0 OR GPL-2.0 WITH Classpath-exception-2.0 Source Code The project maintains the following source code repositories: https://github.com/eclipse-ee4j/jaxrs-api Third-party Content This project leverages the following third party content. javaee-api (7.0) License: Apache-2.0 AND W3C JUnit (4.11) License: Common Public License 1.0 Mockito (2.16.0) Project: http://site.mockito.org Source: https://github.com/mockito/mockito/releases/tag/v2.16.0 Cryptography Content may contain encryption software. The country in which you are currently may have restrictions on the import, possession, and use, and/or re-export to another country, of encryption software. BEFORE using any encryption software, please check the country’s laws, regulations and policies concerning the import, possession, or use, and re-export of encryption software, to see if this is permitted. https://github.com/jboss/jboss-jakarta-jaxrs-api_spec Copyright: Jakarta RESTful Web Services Project, Eclipse Foundation List of contributors: https://projects.eclipse.org/projects/ee4j.jaxrs/who jboss-jaxb-api_2.3_spec@2.0.1.Final(Apache 2.0)Copyright Red Hat jandex@2.4.3.Final(Apache 2.0)Copyright 2013 Red Hat, Inc., and individual contributors mybatis@3.5.15(Apache 2.0)Copyright various authors: https://mybatis.org/mybatis-3/team.html iBATIS This product includes software developed by The Apache Software Foundation (https://www.apache.org/). Copyright 2010 The Apache Software Foundation Licensed under the Apache License, Version 2.0 (the “License”); you may not use this file except in compliance with the License. You may obtain a copy of the License at https://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an “AS IS” BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. OGNL //————————————————————————– // Copyright (c) 2004, Drew Davidson and Luke Blanshard // All rights reserved. // // Redistribution and use in source and binary forms, with or without // modification, are permitted provided that the following conditions are // met: // // Redistributions of source code must retain the above copyright notice, // this list of conditions and the following disclaimer. // Redistributions in binary form must reproduce the above copyright // notice, this list of conditions and the following disclaimer in the // documentation and/or other materials provided with the distribution. // Neither the name of the Drew Davidson nor the names of its contributors // may be used to endorse or promote products derived from this software // without specific prior written permission. // // THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS // “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT // LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS // FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE // COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, // INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, // BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS // OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED // AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, // OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF // THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH // DAMAGE. //————————————————————————– Refactored SqlBuilder class (SQL, AbstractSQL) This product includes software developed by Adam Gent (https://gist.github.com/3650165) Copyright 2010 Adam Gent Licensed under the Apache License, Version 2.0 (the “License”); you may not use this file except in compliance with the License. You may obtain a copy of the License at https://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an “AS IS” BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. asm-commons@9.6(BSD-3-Clause)Copyright (c) 2000-2011 INRIA, France Telecom asm@9.6(BSD-3-Clause)Copyright (c) 2000-2011 INRIA, France Telecom reactive-streams@1.0.3(CC0)CopyrightWaiver:https://github.com/reactive-streams/reactive-streams-jvm/blob/master/CopyrightWaivers.txt reactive-streams@1.0.4(MIT)Copyright 2014 Reactive Streams scala-library@2.13.12(Apache 2.0)Copyright (c) 2002-2024 EPFL Copyright (c) 2011-2024 Lightbend, Inc. Scala includes software developed at LAMP/EPFL (https://lamp.epfl.ch/) and Lightbend, Inc. (https://www.lightbend.com/). Licensed under the Apache License, Version 2.0 (the “License”). Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an “AS IS” BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. This software includes projects with other licenses – see doc/LICENSE.md. jul-to-slf4j@2.0.16(MIT)Copyright (c) 2004-2023 QOS.ch slf4j-api@1.7.25(MIT)Copyright (c) 2004-2017 QOS.ch slf4j-api@1.7.26(MIT)Copyright: (c) 2004-2017 QOS.ch slf4j-api@1.7.36(MIT)Copyright (c) 2004-2017 QOS.ch slf4j-api@2.0.16(MIT)Copyright (c) 2004-2023 QOS.ch slf4j-jdk14@1.7.26(MIT)Copyright (c) 2004-2017 QOS.ch spring-boot-autoconfigure@3.3.3(Apache 2.0)Copyright © 2015-2021 the original authors. spring-boot-starter-jdbc@3.3.3(Apache 2.0)Copyright © 2015-2021 the original authors. spring-boot-starter-jersey@3.3.3(Apache 2.0)Copyright © 2015-2021 the original authors. spring-boot-starter-json@3.3.3(Apache 2.0)Copyright © 2015-2021 the original authors. spring-boot-starter-logging@3.3.3(Apache 2.0)Copyright © 2015-2021 the original authors. spring-boot-starter-oauth2-client@3.3.3(Apache 2.0)Copyright © 2015-2021 the original authors. spring-boot-starter-security@3.3.3(Apache 2.0)Copyright © 2015-2021 the original authors. spring-boot-starter-tomcat@3.3.3(Apache 2.0)Copyright © 2015-2021 the original authors. spring-boot-starter-validation@3.3.3(Apache 2.0)Copyright © 2015-2021 the original authors. spring-boot-starter-web@3.3.3(Apache 2.0)Copyright © 2015-2021 the original authors. spring-boot-starter@3.3.3(Apache 2.0)Copyright © 2015-2021 the original authors. spring-boot@3.3.3(Apache 2.0)Copyright © 2015-2021 the original authors. spring-security-config@6.3.3(Apache 2.0)Copyright © 2015-2021 the original authors. spring-security-core@6.3.3(Apache 2.0)Copyright © 2015-2021 the original authors. spring-security-crypto@6.3.3(Apache 2.0)Copyright © 2015-2021 the original authors. spring-security-oauth2-client@6.3.3(Apache 2.0)Copyright © 2015-2021 the original authors. spring-security-oauth2-core@6.3.3(Apache 2.0)Copyright © 2015-2021 the original authors. spring-security-oauth2-jose@6.3.3(Apache 2.0)Copyright © 2015-2021 the original authors. spring-security-web@6.3.3(Apache 2.0)Copyright © 2015-2021 the original authors. spring-aop@5.3.36(Apache 2.0)Copyright © 2015-2021 the original authors. spring-aop@6.1.12(Apache 2.0)Copyright © 2015-2021 the original authors. spring-beans@5.3.36(Apache 2.0)Copyright © 2015-2021 the original authors. spring-beans@6.1.12(Apache 2.0)Copyright © 2015-2021 the original authors. spring-context@5.3.36(Apache 2.0)Copyright © 2015-2021 the original authors. spring-context@6.1.12(Apache 2.0)Copyright © 2015-2021 the original authors. spring-core@5.3.36(Apache 2.0)Copyright © 2015-2021 the original authors. spring-core@6.1.12(Apache 2.0)Copyright © 2015-2021 the original authors. spring-expression@5.3.36(Apache 2.0)Copyright © 2015-2021 the original authors. spring-expression@6.1.12(Apache 2.0)Copyright © 2015-2021 the original authors. spring-jcl@5.3.36(Apache 2.0)Copyright © 2015-2021 the original authors. spring-jcl@6.1.12(Apache 2.0)Copyright © 2015-2021 the original authors. spring-jdbc@5.3.36(Apache 2.0)Copyright © 2015-2021 the original authors. spring-jdbc@6.1.12(Apache 2.0)Copyright © 2015-2021 the original authors. spring-orm@5.3.36(Apache 2.0)Copyright © 2015-2021 the original authors. spring-orm@6.1.12(Apache 2.0)Copyright © 2015-2021 the original authors. spring-tx@5.3.36(Apache 2.0)Copyright © 2015-2021 the original authors. spring-tx@6.1.12(Apache 2.0)Copyright © 2015-2021 the original authors. spring-web@6.1.12(Apache 2.0)Copyright © 2015-2021 the original authors. spring-webmvc@6.1.12(Apache 2.0)Copyright © 2015-2021 the original authors. wildfly-dist@33.0.1.Final(Apache 2.0)Copyright The WildFly Authors wildfly-galleon-pack@33.0.1.Final(Apache 2.0)Copyright The WildFly Authors snakeyaml@2.2(Apache 2.0)Copyright (c) 2008, SnakeYAML Camunda Web Applications Javascript Dependencies @bpmn-io/align-to-origin@0.7.0 (MIT)The MIT License (MIT) Copyright (c) 2019-present Camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @bpmn-io/cm-theme@0.1.0-alpha.2 (MIT)Copyright (c) 2023-present Camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @bpmn-io/diagram-js-ui@0.2.2 (MIT)The MIT License (MIT) Copyright (c) 2022-present Camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @bpmn-io/dmn-migrate@0.5.0 (MIT)The MIT License (MIT) Copyright (c) 2020-present Camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @bpmn-io/dmn-variable-resolver@0.4.0 (MIT)The MIT License (MIT) Copyright (c) 2023-present Camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @bpmn-io/draggle@4.1.0 (MIT)The MIT License (MIT) Copyright © 2015-2016 Nicolas Bevacqua Copyright © 2023 bpmn-io Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @bpmn-io/feel-editor@1.4.0 (MIT)The MIT License (MIT) Copyright (c) 2015 camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @bpmn-io/feel-lint@1.2.0 (MIT)The MIT License (MIT) Copyright (c) 2022 camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @bpmn-io/form-js@1.8.7 (SEE LICENSE IN LICENSE)Copyright (c) 2021-present Camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. The source code responsible for displaying the bpmn.io project watermark that links back to https://bpmn.io as part of rendered diagrams MUST NOT be removed or changed. When this software is being used in a website or application, the watermark must stay fully visible and not visually overlapped by other elements. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @bpmn-io/form-js-editor@1.8.7 (SEE LICENSE IN LICENSE)Copyright (c) 2021-present Camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. The source code responsible for displaying the bpmn.io project watermark that links back to https://bpmn.io as part of rendered diagrams MUST NOT be removed or changed. When this software is being used in a website or application, the watermark must stay fully visible and not visually overlapped by other elements. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @bpmn-io/form-js-playground@1.8.7 (SEE LICENSE IN LICENSE)Copyright (c) 2021-present Camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. The source code responsible for displaying the bpmn.io project watermark that links back to https://bpmn.io as part of rendered diagrams MUST NOT be removed or changed. When this software is being used in a website or application, the watermark must stay fully visible and not visually overlapped by other elements. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @bpmn-io/form-js-viewer@1.8.7 (SEE LICENSE IN LICENSE)Copyright (c) 2021-present Camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. The source code responsible for displaying the bpmn.io project watermark that links back to https://bpmn.io as part of rendered diagrams MUST NOT be removed or changed. When this software is being used in a website or application, the watermark must stay fully visible and not visually overlapped by other elements. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @bpmn-io/properties-panel@3.18.2 (MIT)The MIT License (MIT) Copyright (c) 2021-present Camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @codemirror/autocomplete@6.16.0 (MIT)MIT License Copyright (C) 2018-2021 by Marijn Haverbeke marijn@haverbeke.berlin and others Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @codemirror/commands@6.5.0 (MIT)MIT License Copyright (C) 2018-2021 by Marijn Haverbeke marijn@haverbeke.berlin and others Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @codemirror/lang-json@6.0.1 (MIT)MIT License Copyright (C) 2018-2021 by Marijn Haverbeke marijnh@gmail.com and others Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @codemirror/language@6.10.1 (MIT)MIT License Copyright (C) 2018-2021 by Marijn Haverbeke marijn@haverbeke.berlin and others Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @codemirror/lint@6.7.1 (MIT)MIT License Copyright (C) 2018-2021 by Marijn Haverbeke marijn@haverbeke.berlin and others Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @codemirror/search@6.5.6 (MIT)MIT License Copyright (C) 2018-2021 by Marijn Haverbeke marijn@haverbeke.berlin and others Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @codemirror/state@6.4.1 (MIT)MIT License Copyright (C) 2018-2021 by Marijn Haverbeke marijn@haverbeke.berlin and others Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @codemirror/view@6.26.3 (MIT)MIT License Copyright (C) 2018-2021 by Marijn Haverbeke marijn@haverbeke.berlin and others Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @ibm/plex@6.4.0 (OFL-1.1)Copyright © 2017 IBM Corp. with Reserved Font Name \"Plex\" This Font Software is licensed under the SIL Open Font License, Version 1.1. This license is copied below, and is also available with a FAQ at: http://scripts.sil.org/OFL SIL OPEN FONT LICENSE Version 1.1 - 26 February 2007 PREAMBLE The goals of the Open Font License (OFL) are to stimulate worldwide development of collaborative font projects, to support the font creation efforts of academic and linguistic communities, and to provide a free and open framework in which fonts may be shared and improved in partnership with others. The OFL allows the licensed fonts to be used, studied, modified and redistributed freely as long as they are not sold by themselves. The fonts, including any derivative works, can be bundled, embedded, redistributed and/or sold with any software provided that any reserved names are not used by derivative works. The fonts and derivatives, however, cannot be released under any other type of license. The requirement for fonts to remain under this license does not apply to any document created using the fonts or their derivatives. DEFINITIONS “Font Software” refers to the set of files released by the Copyright Holder(s) under this license and clearly marked as such. This may include source files, build scripts and documentation. “Reserved Font Name” refers to any names specified as such after the copyright statement(s). “Original Version” refers to the collection of Font Software components as distributed by the Copyright Holder(s). “Modified Version” refers to any derivative made by adding to, deleting, or substituting – in part or in whole – any of the components of the Original Version, by changing formats or by porting the Font Software to a new environment. “Author” refers to any designer, engineer, programmer, technical writer or other person who contributed to the Font Software. PERMISSION & CONDITIONS Permission is hereby granted, free of charge, to any person obtaining a copy of the Font Software, to use, study, copy, merge, embed, modify, redistribute, and sell modified and unmodified copies of the Font Software, subject to the following conditions: Neither the Font Software nor any of its individual components, in Original or Modified Versions, may be sold by itself. Original or Modified Versions of the Font Software may be bundled, redistributed and/or sold with any software, provided that each copy contains the above copyright notice and this license. These can be included either as stand-alone text files, human-readable headers or in the appropriate machine-readable metadata fields within text or binary files as long as those fields can be easily viewed by the user. No Modified Version of the Font Software may use the Reserved Font Name(s) unless explicit written permission is granted by the corresponding Copyright Holder. This restriction only applies to the primary font name as presented to the users. The name(s) of the Copyright Holder(s) or the Author(s) of the Font Software shall not be used to promote, endorse or advertise any Modified Version, except to acknowledge the contribution(s) of the Copyright Holder(s) and the Author(s) or with their explicit written permission. The Font Software, modified or unmodified, in part or in whole, must be distributed entirely under this license, and must not be distributed under any other license. The requirement for fonts to remain under this license does not apply to any document created using the Font Software. TERMINATION This license becomes null and void if any of the above conditions are not met. DISCLAIMER THE FONT SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT OF COPYRIGHT, PATENT, TRADEMARK, OR OTHER RIGHT. IN NO EVENT SHALL THE COPYRIGHT HOLDER BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, INCLUDING ANY GENERAL, SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF THE USE OR INABILITY TO USE THE FONT SOFTWARE OR FROM OTHER DEALINGS IN THE FONT SOFTWARE. @kurkle/color@0.3.2 (MIT)The MIT License (MIT) Copyright (c) 2018-2021 Jukka Kurkela Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @lezer/common@1.2.1 (MIT)MIT License Copyright (C) 2018 by Marijn Haverbeke marijn@haverbeke.berlin and others Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @lezer/highlight@1.2.0 (MIT)MIT License Copyright (C) 2018 by Marijn Haverbeke marijn@haverbeke.berlin and others Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @lezer/json@1.0.2 (MIT)MIT License Copyright (C) 2020 by Marijn Haverbeke marijn@haverbeke.berlin, Arun Srinivasan rulfzid@gmail.com, and others Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @lezer/lr@1.4.0 (MIT)MIT License Copyright (C) 2018 by Marijn Haverbeke marijn@haverbeke.berlin and others Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @lezer/markdown@1.3.0 (MIT)MIT License Copyright (C) 2020 by Marijn Haverbeke marijn@haverbeke.berlin and others Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @xlts.dev/angular@1.9.3 (SEE LICENSE IN LICENSE.md)# The code in this repository is governed by two licenses Portions of the code found here was obtained from Google and is provided under and subject to the terms of the MIT License set forth below and all other portions of the code are original works of XLTS.dev and are provided subject to the terms of an end user license agreement, which may be obtained from XLTS.dev. Find more details at https://xlts.dev/angularjs. For code sourced from https://github.com/angular/angular.js The MIT License Copyright (c) 2010-2021 Google LLC. http://angularjs.org Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. For all other code The XLTS for AngularJS Software End User License Agreement Copyright (c) 2022 XLTS.dev All Rights Reserved. The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. Use of this source code is governed by a commercial license that must be obtained from XLTS.dev. Find more details at https://xlts.dev/angularjs. @xlts.dev/angular-animate@1.9.3 (SEE LICENSE IN LICENSE.md)# The code in this repository is governed by two licenses Portions of the code found here was obtained from Google and is provided under and subject to the terms of the MIT License set forth below and all other portions of the code are original works of XLTS.dev and are provided subject to the terms of an end user license agreement, which may be obtained from XLTS.dev. Find more details at https://xlts.dev/angularjs. For code sourced from https://github.com/angular/angular.js The MIT License Copyright (c) 2010-2021 Google LLC. http://angularjs.org Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. For all other code The XLTS for AngularJS Software End User License Agreement Copyright (c) 2022 XLTS.dev All Rights Reserved. The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. Use of this source code is governed by a commercial license that must be obtained from XLTS.dev. Find more details at https://xlts.dev/angularjs. @xlts.dev/angular-cookies@1.9.3 (SEE LICENSE IN LICENSE.md)# The code in this repository is governed by two licenses Portions of the code found here was obtained from Google and is provided under and subject to the terms of the MIT License set forth below and all other portions of the code are original works of XLTS.dev and are provided subject to the terms of an end user license agreement, which may be obtained from XLTS.dev. Find more details at https://xlts.dev/angularjs. For code sourced from https://github.com/angular/angular.js The MIT License Copyright (c) 2010-2021 Google LLC. http://angularjs.org Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. For all other code The XLTS for AngularJS Software End User License Agreement Copyright (c) 2022 XLTS.dev All Rights Reserved. The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. Use of this source code is governed by a commercial license that must be obtained from XLTS.dev. Find more details at https://xlts.dev/angularjs. @xlts.dev/angular-resource@1.9.3 (SEE LICENSE IN LICENSE.md)# The code in this repository is governed by two licenses Portions of the code found here was obtained from Google and is provided under and subject to the terms of the MIT License set forth below and all other portions of the code are original works of XLTS.dev and are provided subject to the terms of an end user license agreement, which may be obtained from XLTS.dev. Find more details at https://xlts.dev/angularjs. For code sourced from https://github.com/angular/angular.js The MIT License Copyright (c) 2010-2021 Google LLC. http://angularjs.org Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. For all other code The XLTS for AngularJS Software End User License Agreement Copyright (c) 2022 XLTS.dev All Rights Reserved. The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. Use of this source code is governed by a commercial license that must be obtained from XLTS.dev. Find more details at https://xlts.dev/angularjs. @xlts.dev/angular-route@1.9.3 (SEE LICENSE IN LICENSE.md)# The code in this repository is governed by two licenses Portions of the code found here was obtained from Google and is provided under and subject to the terms of the MIT License set forth below and all other portions of the code are original works of XLTS.dev and are provided subject to the terms of an end user license agreement, which may be obtained from XLTS.dev. Find more details at https://xlts.dev/angularjs. For code sourced from https://github.com/angular/angular.js The MIT License Copyright (c) 2010-2021 Google LLC. http://angularjs.org Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. For all other code The XLTS for AngularJS Software End User License Agreement Copyright (c) 2022 XLTS.dev All Rights Reserved. The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. Use of this source code is governed by a commercial license that must be obtained from XLTS.dev. Find more details at https://xlts.dev/angularjs. @xlts.dev/angular-sanitize@1.9.3 (SEE LICENSE IN LICENSE.md)# The code in this repository is governed by two licenses Portions of the code found here was obtained from Google and is provided under and subject to the terms of the MIT License set forth below and all other portions of the code are original works of XLTS.dev and are provided subject to the terms of an end user license agreement, which may be obtained from XLTS.dev. Find more details at https://xlts.dev/angularjs. For code sourced from https://github.com/angular/angular.js The MIT License Copyright (c) 2010-2021 Google LLC. http://angularjs.org Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. For all other code The XLTS for AngularJS Software End User License Agreement Copyright (c) 2022 XLTS.dev All Rights Reserved. The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. Use of this source code is governed by a commercial license that must be obtained from XLTS.dev. Find more details at https://xlts.dev/angularjs. angular-data-depend@1.0.0 (MIT)The MIT License (MIT) Copyright (c) 2013 Nico Rehwaldt Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. angular-moment@1.3.0 (MIT)The MIT License (MIT) Copyright (c) 2013-2016 Uri Shaked and contributors Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. angular-translate@2.19.0 (MIT)The MIT License (MIT) Copyright (c) 2013-2017 The angular-translate team and Pascal Precht Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. angular-ui-bootstrap@2.5.6 (MIT)The MIT License Copyright (c) 2012-2017 the AngularUI Team, https://github.com/organizations/angular-ui/teams/291112 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. array-move@3.0.1 (MIT)MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. big.js@6.2.1 (MIT)The MIT License (MIT) ===================== Copyright © <2022> Michael Mclaughlin Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. bootstrap@3.4.1 (MIT)The MIT License (MIT) Copyright (c) 2011-2019 Twitter, Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. bpmn-font@0.12.1 (SIL)Copyright (c) 2014-present, Camunda Services GmbH This Font Software is licensed under the SIL Open Font License, Version 1.1. This license is copied below, and is also available with a FAQ at: http://scripts.sil.org/OFL SIL OPEN FONT LICENSE Version 1.1 - 26 February 2007 PREAMBLE The goals of the Open Font License (OFL) are to stimulate worldwide development of collaborative font projects, to support the font creation efforts of academic and linguistic communities, and to provide a free and open framework in which fonts may be shared and improved in partnership with others. The OFL allows the licensed fonts to be used, studied, modified and redistributed freely as long as they are not sold by themselves. The fonts, including any derivative works, can be bundled, embedded, redistributed and/or sold with any software provided that any reserved names are not used by derivative works. The fonts and derivatives, however, cannot be released under any other type of license. The requirement for fonts to remain under this license does not apply to any document created using the fonts or their derivatives. DEFINITIONS “Font Software” refers to the set of files released by the Copyright Holder(s) under this license and clearly marked as such. This may include source files, build scripts and documentation. “Reserved Font Name” refers to any names specified as such after the copyright statement(s). “Original Version” refers to the collection of Font Software components as distributed by the Copyright Holder(s). “Modified Version” refers to any derivative made by adding to, deleting, or substituting – in part or in whole – any of the components of the Original Version, by changing formats or by porting the Font Software to a new environment. “Author” refers to any designer, engineer, programmer, technical writer or other person who contributed to the Font Software. PERMISSION & CONDITIONS Permission is hereby granted, free of charge, to any person obtaining a copy of the Font Software, to use, study, copy, merge, embed, modify, redistribute, and sell modified and unmodified copies of the Font Software, subject to the following conditions: Neither the Font Software nor any of its individual components, in Original or Modified Versions, may be sold by itself. Original or Modified Versions of the Font Software may be bundled, redistributed and/or sold with any software, provided that each copy contains the above copyright notice and this license. These can be included either as stand-alone text files, human-readable headers or in the appropriate machine-readable metadata fields within text or binary files as long as those fields can be easily viewed by the user. No Modified Version of the Font Software may use the Reserved Font Name(s) unless explicit written permission is granted by the corresponding Copyright Holder. This restriction only applies to the primary font name as presented to the users. The name(s) of the Copyright Holder(s) or the Author(s) of the Font Software shall not be used to promote, endorse or advertise any Modified Version, except to acknowledge the contribution(s) of the Copyright Holder(s) and the Author(s) or with their explicit written permission. The Font Software, modified or unmodified, in part or in whole, must be distributed entirely under this license, and must not be distributed under any other license. The requirement for fonts to remain under this license does not apply to any document created using the Font Software. TERMINATION This license becomes null and void if any of the above conditions are not met. DISCLAIMER THE FONT SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT OF COPYRIGHT, PATENT, TRADEMARK, OR OTHER RIGHT. IN NO EVENT SHALL THE COPYRIGHT HOLDER BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, INCLUDING ANY GENERAL, SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF THE USE OR INABILITY TO USE THE FONT SOFTWARE OR FROM OTHER DEALINGS IN THE FONT SOFTWARE. bpmn-js@16.5.0 (SEE LICENSE IN LICENSE)Copyright (c) 2014-present Camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. The source code responsible for displaying the bpmn.io project watermark that links back to https://bpmn.io as part of rendered diagrams MUST NOT be removed or changed. When this software is being used in a website or application, the watermark must stay fully visible and not visually overlapped by other elements. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. bpmn-moddle@8.1.0 (MIT)The MIT License (MIT) Copyright (c) 2014 camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. call-bind@1.0.2 (MIT)MIT License Copyright (c) 2020 Jordan Harband Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. camunda-bpm-webapp@7.22.0-SNAPSHOT ()Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership. Camunda licenses this file to you under the Apache License, Version 2.0; you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an “AS IS” BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. camunda-dmn-js@1.8.0 (MIT)The MIT License (MIT) Copyright (c) 2022-present Camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. camunda-dmn-moddle@1.3.0 (MIT)The MIT License (MIT) Copyright (c) 2014-2018 camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. chart.js@4.4.1 (MIT)The MIT License (MIT) Copyright (c) 2014-2022 Chart.js Contributors Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. classnames@2.5.1 (MIT)The MIT License (MIT) Copyright (c) 2018 Jed Watson Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. clipboard@2.0.11 (MIT)MIT License Copyright (c) Zeno Rocha Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. clsx@2.1.0 (MIT)MIT License Copyright (c) Luke Edwards luke.edwards05@gmail.com (lukeed.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. cmmn-js@0.20.0 (SEE LICENSE IN LICENSE)Copyright (c) 2014-present Camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. The source code responsible for displaying the bpmn.io project watermark that links back to https://bpmn.io as part of rendered diagrams MUST NOT be removed or changed. When this software is being used in a website or application, the watermark must stay fully visible and not visually overlapped by other elements. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. cmmn-moddle@5.0.0 (MIT)The MIT License (MIT) Copyright (c) 2014 camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. codemirror@6.0.1 (MIT)MIT License Copyright (C) 2018-2021 by Marijn Haverbeke marijnh@gmail.com and others Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. component-emitter@1.3.1 (MIT)(The MIT License) Copyright (c) 2014 Component contributors dev@component.io Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. crelt@1.0.6 (MIT)Copyright (C) 2020 by Marijn Haverbeke Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. css.escape@1.5.1 (MIT)Copyright Mathias Bynens Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. diagram-js@13.4.0 (MIT)The MIT License (MIT) Copyright (c) 2014-present Camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. diagram-js-direct-editing@2.1.2 (MIT)The MIT License (MIT) Copyright (c) 2014-2017 camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. diagram-js-grid@0.2.0 (MIT)The MIT License (MIT) Copyright (c) 2023-present camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. diagram-js-origin@1.4.0 (MIT)The MIT License (MIT) Copyright (c) 2014 Nico Rehwaldt Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. didi@4.0.0 (MIT)The MIT License Copyright (C) 2013 Vojta Jína. Copyright (C) 2015-present Nico Rehwaldt. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. dmn-font@0.6.2 (SIL)Copyright (c) 2014, camunda Services GmbH This Font Software is licensed under the SIL Open Font License, Version 1.1. This license is copied below, and is also available with a FAQ at: http://scripts.sil.org/OFL SIL OPEN FONT LICENSE Version 1.1 - 26 February 2007 PREAMBLE The goals of the Open Font License (OFL) are to stimulate worldwide development of collaborative font projects, to support the font creation efforts of academic and linguistic communities, and to provide a free and open framework in which fonts may be shared and improved in partnership with others. The OFL allows the licensed fonts to be used, studied, modified and redistributed freely as long as they are not sold by themselves. The fonts, including any derivative works, can be bundled, embedded, redistributed and/or sold with any software provided that any reserved names are not used by derivative works. The fonts and derivatives, however, cannot be released under any other type of license. The requirement for fonts to remain under this license does not apply to any document created using the fonts or their derivatives. DEFINITIONS “Font Software” refers to the set of files released by the Copyright Holder(s) under this license and clearly marked as such. This may include source files, build scripts and documentation. “Reserved Font Name” refers to any names specified as such after the copyright statement(s). “Original Version” refers to the collection of Font Software components as distributed by the Copyright Holder(s). “Modified Version” refers to any derivative made by adding to, deleting, or substituting – in part or in whole – any of the components of the Original Version, by changing formats or by porting the Font Software to a new environment. “Author” refers to any designer, engineer, programmer, technical writer or other person who contributed to the Font Software. PERMISSION & CONDITIONS Permission is hereby granted, free of charge, to any person obtaining a copy of the Font Software, to use, study, copy, merge, embed, modify, redistribute, and sell modified and unmodified copies of the Font Software, subject to the following conditions: Neither the Font Software nor any of its individual components, in Original or Modified Versions, may be sold by itself. Original or Modified Versions of the Font Software may be bundled, redistributed and/or sold with any software, provided that each copy contains the above copyright notice and this license. These can be included either as stand-alone text files, human-readable headers or in the appropriate machine-readable metadata fields within text or binary files as long as those fields can be easily viewed by the user. No Modified Version of the Font Software may use the Reserved Font Name(s) unless explicit written permission is granted by the corresponding Copyright Holder. This restriction only applies to the primary font name as presented to the users. The name(s) of the Copyright Holder(s) or the Author(s) of the Font Software shall not be used to promote, endorse or advertise any Modified Version, except to acknowledge the contribution(s) of the Copyright Holder(s) and the Author(s) or with their explicit written permission. The Font Software, modified or unmodified, in part or in whole, must be distributed entirely under this license, and must not be distributed under any other license. The requirement for fonts to remain under this license does not apply to any document created using the Font Software. TERMINATION This license becomes null and void if any of the above conditions are not met. DISCLAIMER THE FONT SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT OF COPYRIGHT, PATENT, TRADEMARK, OR OTHER RIGHT. IN NO EVENT SHALL THE COPYRIGHT HOLDER BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, INCLUDING ANY GENERAL, SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF THE USE OR INABILITY TO USE THE FONT SOFTWARE OR FROM OTHER DEALINGS IN THE FONT SOFTWARE. dmn-js@15.1.0 (SEE LICENSE IN LICENSE)Copyright (c) 2014-present Camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. The source code responsible for displaying the bpmn.io project watermark that links back to https://bpmn.io as part of rendered diagrams MUST NOT be removed or changed. When this software is being used in a website or application, the watermark must stay fully visible and not visually overlapped by other elements. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. dmn-js-decision-table@15.1.0 (SEE LICENSE IN LICENSE)Copyright (c) 2014-present Camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. The source code responsible for displaying the bpmn.io project watermark that links back to https://bpmn.io as part of rendered diagrams MUST NOT be removed or changed. When this software is being used in a website or application, the watermark must stay fully visible and not visually overlapped by other elements. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. dmn-js-drd@15.1.0 (SEE LICENSE IN LICENSE)Copyright (c) 2014-present Camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. The source code responsible for displaying the bpmn.io project watermark that links back to https://bpmn.io as part of rendered diagrams MUST NOT be removed or changed. When this software is being used in a website or application, the watermark must stay fully visible and not visually overlapped by other elements. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. dmn-js-literal-expression@15.1.0 (SEE LICENSE IN LICENSE)Copyright (c) 2014-present Camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. The source code responsible for displaying the bpmn.io project watermark that links back to https://bpmn.io as part of rendered diagrams MUST NOT be removed or changed. When this software is being used in a website or application, the watermark must stay fully visible and not visually overlapped by other elements. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. dmn-js-properties-panel@3.2.1 (MIT)The MIT License (MIT) Copyright (c) 2015-2018 camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. dmn-js-shared@15.1.0 (SEE LICENSE IN LICENSE)Copyright (c) 2014-present Camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. The source code responsible for displaying the bpmn.io project watermark that links back to https://bpmn.io as part of rendered diagrams MUST NOT be removed or changed. When this software is being used in a website or application, the watermark must stay fully visible and not visually overlapped by other elements. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. dmn-moddle@10.0.0 (MIT)The MIT License (MIT) Copyright (c) 2015-2017 camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. dom4@2.1.6 (MIT)Copyright (C) 2013-2015 by Andrea Giammarchi - @WebReflection Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. dompurify@3.1.3 ((MPL-2.0 OR Apache-2.0))DOMPurify Copyright 2024 Dr.-Ing. Mario Heiderich, Cure53 DOMPurify is free software; you can redistribute it and/or modify it under the terms of either: a) the Apache License Version 2.0, or b) the Mozilla Public License Version 2.0 Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION Definitions. “License” shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. “Licensor” shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. “Legal Entity” shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, “control” means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. “You” (or “Your”) shall mean an individual or Legal Entity exercising permissions granted by this License. “Source” form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. “Object” form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. “Work” shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). “Derivative Works” shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. “Contribution” shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, “submitted” means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as “Not a Contribution.” “Contributor” shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a “NOTICE” text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an “AS IS” BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets “[]” replaced with your own identifying information. (Don’t include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same “printed page” as the copyright notice for easier identification within third-party archives. Copyright [yyyy] [name of copyright owner] Licensed under the Apache License, Version 2.0 (the “License”); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an “AS IS” BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. Mozilla Public License, version 2.0 Definitions 1.1. “Contributor” means each individual or legal entity that creates, contributes to the creation of, or owns Covered Software. 1.2. “Contributor Version” means the combination of the Contributions of others (if any) used by a Contributor and that particular Contributor’s Contribution. 1.3. “Contribution” means Covered Software of a particular Contributor. 1.4. “Covered Software” means Source Code Form to which the initial Contributor has attached the notice in Exhibit A, the Executable Form of such Source Code Form, and Modifications of such Source Code Form, in each case including portions thereof. 1.5. “Incompatible With Secondary Licenses” means a. that the initial Contributor has attached the notice described in Exhibit B to the Covered Software; or b. that the Covered Software was made available under the terms of version 1.1 or earlier of the License, but not also under the terms of a Secondary License. 1.6. “Executable Form” means any form of the work other than Source Code Form. 1.7. “Larger Work” means a work that combines Covered Software with other material, in a separate file or files, that is not Covered Software. 1.8. “License” means this document. 1.9. “Licensable” means having the right to grant, to the maximum extent possible, whether at the time of the initial grant or subsequently, any and all of the rights conveyed by this License. 1.10. “Modifications” means any of the following: a. any file in Source Code Form that results from an addition to, deletion from, or modification of the contents of Covered Software; or b. any new file in Source Code Form that contains any Covered Software. 1.11. “Patent Claims” of a Contributor means any patent claim(s), including without limitation, method, process, and apparatus claims, in any patent Licensable by such Contributor that would be infringed, but for the grant of the License, by the making, using, selling, offering for sale, having made, import, or transfer of either its Contributions or its Contributor Version. 1.12. “Secondary License” means either the GNU General Public License, Version 2.0, the GNU Lesser General Public License, Version 2.1, the GNU Affero General Public License, Version 3.0, or any later versions of those licenses. 1.13. “Source Code Form” means the form of the work preferred for making modifications. 1.14. “You” (or “Your”) means an individual or a legal entity exercising rights under this License. For legal entities, “You” includes any entity that controls, is controlled by, or is under common control with You. For purposes of this definition, “control” means (a) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (b) ownership of more than fifty percent (50%) of the outstanding shares or beneficial ownership of such entity. License Grants and Conditions 2.1. Grants Each Contributor hereby grants You a world-wide, royalty-free, non-exclusive license: a. under intellectual property rights (other than patent or trademark) Licensable by such Contributor to use, reproduce, make available, modify, display, perform, distribute, and otherwise exploit its Contributions, either on an unmodified basis, with Modifications, or as part of a Larger Work; and b. under Patent Claims of such Contributor to make, use, sell, offer for sale, have made, import, and otherwise transfer either its Contributions or its Contributor Version. 2.2. Effective Date The licenses granted in Section 2.1 with respect to any Contribution become effective for each Contribution on the date the Contributor first distributes such Contribution. 2.3. Limitations on Grant Scope The licenses granted in this Section 2 are the only rights granted under this License. No additional rights or licenses will be implied from the distribution or licensing of Covered Software under this License. Notwithstanding Section 2.1(b) above, no patent license is granted by a Contributor: a. for any code that a Contributor has removed from Covered Software; or b. for infringements caused by: (i) Your and any other third party’s modifications of Covered Software, or (ii) the combination of its Contributions with other software (except as part of its Contributor Version); or c. under Patent Claims infringed by Covered Software in the absence of its Contributions. This License does not grant any rights in the trademarks, service marks, or logos of any Contributor (except as may be necessary to comply with the notice requirements in Section 3.4). 2.4. Subsequent Licenses No Contributor makes additional grants as a result of Your choice to distribute the Covered Software under a subsequent version of this License (see Section 10.2) or under the terms of a Secondary License (if permitted under the terms of Section 3.3). 2.5. Representation Each Contributor represents that the Contributor believes its Contributions are its original creation(s) or it has sufficient rights to grant the rights to its Contributions conveyed by this License. 2.6. Fair Use This License is not intended to limit any rights You have under applicable copyright doctrines of fair use, fair dealing, or other equivalents. 2.7. Conditions Sections 3.1, 3.2, 3.3, and 3.4 are conditions of the licenses granted in Section 2.1. Responsibilities 3.1. Distribution of Source Form All distribution of Covered Software in Source Code Form, including any Modifications that You create or to which You contribute, must be under the terms of this License. You must inform recipients that the Source Code Form of the Covered Software is governed by the terms of this License, and how they can obtain a copy of this License. You may not attempt to alter or restrict the recipients’ rights in the Source Code Form. 3.2. Distribution of Executable Form If You distribute Covered Software in Executable Form then: a. such Covered Software must also be made available in Source Code Form, as described in Section 3.1, and You must inform recipients of the Executable Form how they can obtain a copy of such Source Code Form by reasonable means in a timely manner, at a charge no more than the cost of distribution to the recipient; and b. You may distribute such Executable Form under the terms of this License, or sublicense it under different terms, provided that the license for the Executable Form does not attempt to limit or alter the recipients’ rights in the Source Code Form under this License. 3.3. Distribution of a Larger Work You may create and distribute a Larger Work under terms of Your choice, provided that You also comply with the requirements of this License for the Covered Software. If the Larger Work is a combination of Covered Software with a work governed by one or more Secondary Licenses, and the Covered Software is not Incompatible With Secondary Licenses, this License permits You to additionally distribute such Covered Software under the terms of such Secondary License(s), so that the recipient of the Larger Work may, at their option, further distribute the Covered Software under the terms of either this License or such Secondary License(s). 3.4. Notices You may not remove or alter the substance of any license notices (including copyright notices, patent notices, disclaimers of warranty, or limitations of liability) contained within the Source Code Form of the Covered Software, except that You may alter any license notices to the extent required to remedy known factual inaccuracies. 3.5. Application of Additional Terms You may choose to offer, and to charge a fee for, warranty, support, indemnity or liability obligations to one or more recipients of Covered Software. However, You may do so only on Your own behalf, and not on behalf of any Contributor. You must make it absolutely clear that any such warranty, support, indemnity, or liability obligation is offered by You alone, and You hereby agree to indemnify every Contributor for any liability incurred by such Contributor as a result of warranty, support, indemnity or liability terms You offer. You may include additional disclaimers of warranty and limitations of liability specific to any jurisdiction. Inability to Comply Due to Statute or Regulation If it is impossible for You to comply with any of the terms of this License with respect to some or all of the Covered Software due to statute, judicial order, or regulation then You must: (a) comply with the terms of this License to the maximum extent possible; and (b) describe the limitations and the code they affect. Such description must be placed in a text file included with all distributions of the Covered Software under this License. Except to the extent prohibited by statute or regulation, such description must be sufficiently detailed for a recipient of ordinary skill to be able to understand it. Termination 5.1. The rights granted under this License will terminate automatically if You fail to comply with any of its terms. However, if You become compliant, then the rights granted under this License from a particular Contributor are reinstated (a) provisionally, unless and until such Contributor explicitly and finally terminates Your grants, and (b) on an ongoing basis, if such Contributor fails to notify You of the non-compliance by some reasonable means prior to 60 days after You have come back into compliance. Moreover, Your grants from a particular Contributor are reinstated on an ongoing basis if such Contributor notifies You of the non-compliance by some reasonable means, this is the first time You have received notice of non-compliance with this License from such Contributor, and You become compliant prior to 30 days after Your receipt of the notice. 5.2. If You initiate litigation against any entity by asserting a patent infringement claim (excluding declaratory judgment actions, counter-claims, and cross-claims) alleging that a Contributor Version directly or indirectly infringes any patent, then the rights granted to You by any and all Contributors for the Covered Software under Section 2.1 of this License shall terminate. 5.3. In the event of termination under Sections 5.1 or 5.2 above, all end user license agreements (excluding distributors and resellers) which have been validly granted by You or Your distributors under this License prior to termination shall survive termination. Disclaimer of Warranty Covered Software is provided under this License on an “as is” basis, without warranty of any kind, either expressed, implied, or statutory, including, without limitation, warranties that the Covered Software is free of defects, merchantable, fit for a particular purpose or non-infringing. The entire risk as to the quality and performance of the Covered Software is with You. Should any Covered Software prove defective in any respect, You (not any Contributor) assume the cost of any necessary servicing, repair, or correction. This disclaimer of warranty constitutes an essential part of this License. No use of any Covered Software is authorized under this License except under this disclaimer. Limitation of Liability Under no circumstances and under no legal theory, whether tort (including negligence), contract, or otherwise, shall any Contributor, or anyone who distributes Covered Software as permitted above, be liable to You for any direct, indirect, special, incidental, or consequential damages of any character including, without limitation, damages for lost profits, loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses, even if such party shall have been informed of the possibility of such damages. This limitation of liability shall not apply to liability for death or personal injury resulting from such party’s negligence to the extent applicable law prohibits such limitation. Some jurisdictions do not allow the exclusion or limitation of incidental or consequential damages, so this exclusion and limitation may not apply to You. Litigation Any litigation relating to this License may be brought only in the courts of a jurisdiction where the defendant maintains its principal place of business and such litigation shall be governed by laws of that jurisdiction, without reference to its conflict-of-law provisions. Nothing in this Section shall prevent a party’s ability to bring cross-claims or counter-claims. Miscellaneous This License represents the complete agreement concerning the subject matter hereof. If any provision of this License is held to be unenforceable, such provision shall be reformed only to the extent necessary to make it enforceable. Any law or regulation which provides that the language of a contract shall be construed against the drafter shall not be used to construe this License against a Contributor. Versions of the License 10.1. New Versions Mozilla Foundation is the license steward. Except as provided in Section 10.3, no one other than the license steward has the right to modify or publish new versions of this License. Each version will be given a distinguishing version number. 10.2. Effect of New Versions You may distribute the Covered Software under the terms of the version of the License under which You originally received the Covered Software, or under the terms of any subsequent version published by the license steward. 10.3. Modified Versions If you create software not governed by this License, and you want to create a new license for such software, you may create and use a modified version of this License if you rename the license and remove any references to the name of the license steward (except to note that such modified license differs from this License). 10.4. Distributing Source Code Form that is Incompatible With Secondary Licenses If You choose to distribute Source Code Form that is Incompatible With Secondary Licenses under the terms of this version of the License, the notice described in Exhibit B of this License must be attached. Exhibit A - Source Code Form License Notice This Source Code Form is subject to the terms of the Mozilla Public License, v. 2.0. If a copy of the MPL was not distributed with this file, You can obtain one at http://mozilla.org/MPL/2.0/. If it is not possible or desirable to put the notice in a particular file, then You may include the notice in a location (such as a LICENSE file in a relevant directory) where a recipient would be likely to look for such a notice. You may add additional accurate notices of copyright ownership. Exhibit B - “Incompatible With Secondary Licenses” Notice This Source Code Form is “Incompatible With Secondary Licenses”, as defined by the Mozilla Public License, v. 2.0. downloadjs@1.4.7 (MIT)MIT License Copyright (c) 2016 dandavis Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. escape-html@1.0.3 (MIT)(The MIT License) Copyright (c) 2012-2013 TJ Holowaychuk Copyright (c) 2015 Andreas Lubbe Copyright (c) 2015 Tiancheng “Timothy” Gu Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ‘Software’), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ‘AS IS’, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. events@3.3.0 (MIT)MIT Copyright Joyent, Inc. and other Node contributors. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. fast-safe-stringify@2.1.1 (MIT)The MIT License (MIT) Copyright (c) 2016 David Mark Clements Copyright (c) 2017 David Mark Clements & Matteo Collina Copyright (c) 2018 David Mark Clements, Matteo Collina & Ruben Bridgewater Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. fast-xml-parser@4.3.4 (MIT)MIT License Copyright (c) 2017 Amit Kumar Gupta Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. feelers@1.3.1 (MIT)Copyright (c) 2023-present Camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. feelin@3.1.0 (MIT)The MIT License (MIT) Copyright (c) 2019-present Nico Rehwaldt Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. file-drops@0.5.0 (MIT)The MIT License (MIT) Copyright (c) 2018-present Nico Rehwaldt Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. flatpickr@4.6.13 (MIT)The MIT License (MIT) Copyright (c) 2017 Gregory Petrosyan Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. focus-trap@7.5.4 (MIT)The MIT License (MIT) Copyright (c) 2015-2016 David Clark Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. function-bind@1.1.1 (MIT)Copyright (c) 2013 Raynos. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. get-intrinsic@1.2.0 (MIT)MIT License Copyright (c) 2020 Jordan Harband Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. hammerjs@2.0.8 (MIT)The MIT License (MIT) Copyright (C) 2011-2014 by Jorik Tangelder (Eight Media) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. has@1.0.3 (MIT)Copyright (c) 2013 Thiago de Arruda Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. has-symbols@1.0.3 (MIT)MIT License Copyright (c) 2016 Jordan Harband Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. htm@3.1.1 (Apache-2.0)Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION Definitions. “License” shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. “Licensor” shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. “Legal Entity” shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, “control” means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. “You” (or “Your”) shall mean an individual or Legal Entity exercising permissions granted by this License. “Source” form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. “Object” form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. “Work” shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). “Derivative Works” shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. “Contribution” shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, “submitted” means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as “Not a Contribution.” “Contributor” shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a “NOTICE” text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an “AS IS” BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets “[]” replaced with your own identifying information. (Don’t include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same “printed page” as the copyright notice for easier identification within third-party archives. Copyright 2018 Google Inc. Licensed under the Apache License, Version 2.0 (the “License”); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an “AS IS” BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. ids@1.0.5 (MIT)The MIT License (MIT) Copyright (c) 2014 camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. inferno@5.6.2 (MIT)# MIT License Copyright (c) 2013-2016 Dominic Gannaway Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. inherits@2.0.4 (ISC)The ISC License Copyright (c) Isaac Z. Schlueter Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies. THE SOFTWARE IS PROVIDED “AS IS” AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE. inherits-browser@0.1.0 (ISC)The ISC License Copyright (c) 2022-present Nico Rehwaldt Copyright (c) 2011-2022 Isaac Z. Schlueter Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies. THE SOFTWARE IS PROVIDED “AS IS” AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE. jquery@3.7.1 (MIT)Copyright OpenJS Foundation and other contributors, https://openjsf.org/ Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. jquery-ui@1.13.2 (MIT)Copyright jQuery Foundation and other contributors, https://jquery.org/ This software consists of voluntary contributions made by many individuals. For exact contribution history, see the revision history available at https://github.com/jquery/jquery-ui The following license applies to all parts of this software except as documented below: ==== Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. ==== Copyright and related rights for sample code are waived via CC0. Sample code is defined as all source code contained within the demos directory. CC0: http://creativecommons.org/publicdomain/zero/1.0/ ==== All files located in the node_modules and external directories are externally maintained libraries used by this software which have their own licenses; we recommend you read them, as their terms may differ from the terms above. lang-feel@2.0.0 (MIT)MIT License Copyright (C) 2022-current Nico Rehwaldt https://github.com/nikku Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. lezer-feel@1.2.8 (MIT)MIT License Copyright (C) 2020 by Nico Rehwaldt git_nikku@nixis.de and others Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. luxon@3.4.4 (MIT)Copyright 2019 JS Foundation and other contributors Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. marked@12.0.2 (MIT)# License information Contribution License Agreement If you contribute code to this project, you are implicitly allowing your code to be distributed under the MIT license. You are also implicitly verifying that all code is your original work. </legalese> Marked Copyright (c) 2018+, MarkedJS (https://github.com/markedjs/) Copyright (c) 2011-2018, Christopher Jeffrey (https://github.com/chjj/) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Markdown Copyright © 2004, John Gruber http://daringfireball.net/ All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. Neither the name “Markdown” nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. This software is provided by the copyright holders and contributors “as is” and any express or implied warranties, including, but not limited to, the implied warranties of merchantability and fitness for a particular purpose are disclaimed. In no event shall the copyright owner or contributors be liable for any direct, indirect, incidental, special, exemplary, or consequential damages (including, but not limited to, procurement of substitute goods or services; loss of use, data, or profits; or business interruption) however caused and on any theory of liability, whether in contract, strict liability, or tort (including negligence or otherwise) arising in any way out of the use of this software, even if advised of the possibility of such damage. min-dash@4.2.1 (MIT)The MIT License (MIT) Copyright (c) 2017-present camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. min-dom@3.2.1 (MIT)The MIT License (MIT) Copyright (c) 2014 Nico Rehwaldt Copyright (c) 2015-present camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. mitt@3.0.1 (MIT)MIT License Copyright (c) 2021 Jason Miller Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. moddle@4.1.0 (MIT)The MIT License (MIT) Copyright (c) 2014 camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. moddle-xml@7.5.0 (MIT)The MIT License (MIT) Copyright (c) 2014-present Camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. moment@2.30.1 (MIT)Copyright (c) JS Foundation and other contributors Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. mousetrap@1.6.5 (Apache-2.0 WITH LLVM-exception)Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION Definitions. “License” shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. “Licensor” shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. “Legal Entity” shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, “control” means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. “You” (or “Your”) shall mean an individual or Legal Entity exercising permissions granted by this License. “Source” form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. “Object” form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. “Work” shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). “Derivative Works” shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. “Contribution” shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, “submitted” means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as “Not a Contribution.” “Contributor” shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a “NOTICE” text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an “AS IS” BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS — Exceptions to the Apache 2.0 License —- As an exception, if, as a result of your compiling your source code, portions of this Software are embedded into an Object form of such source code, you may redistribute such embedded portions in such Object form without complying with the conditions of Sections 4(a), 4(b) and 4(d) of the License. In addition, if you combine or link compiled forms of this Software with software that is licensed under the GPLv2 (“Combined Software”) and if a court of competent jurisdiction determines that the patent provision (Section 3), the indemnity provision (Section 9) or other Section of the License conflicts with the conditions of the GPLv2, you may retroactively and prospectively choose to deem waived or otherwise exclude such Section(s) of the License, but only in their entirety and only with respect to the Combined Software. object-inspect@1.12.3 (MIT)MIT License Copyright (c) 2013 James Halliday Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. object-refs@0.4.0 (MIT)The MIT License (MIT) Copyright (c) 2014-present camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. path-intersection@3.0.0 (MIT)The MIT License (MIT) Copyright (c) 2017 camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. preact@10.19.3 (MIT)The MIT License (MIT) Copyright (c) 2015-present Jason Miller Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. q@1.5.1 (MIT)Copyright 2009–2017 Kristopher Michael Kowal. All rights reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. qs@6.11.0 (BSD-3-Clause)BSD 3-Clause License Copyright (c) 2014, Nathan LaFreniere and other contributors All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. saxen@8.1.2 (MIT)The MIT License (MIT) Copyright (c) 2012 Vopilovskii Konstantin Copyright (c) 2017-present Nico Rehwaldt Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. selection-ranges@3.0.3 (MIT)Copyright (c) 2017-present Nico Rehwaldt Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. selection-update@0.1.2 (MIT)The MIT License (MIT) Copyright (c) 2015 Nico Rehwaldt Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. side-channel@1.0.4 (MIT)MIT License Copyright (c) 2019 Jordan Harband Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. style-mod@4.1.0 (MIT)Copyright (C) 2018 by Marijn Haverbeke and others Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. superagent@8.1.2 (MIT)(The MIT License) Copyright (c) 2014-2016 TJ Holowaychuk tj@vision-media.ca Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ‘Software’), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ‘AS IS’, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. tabbable@6.2.0 (MIT)The MIT License (MIT) Copyright (c) 2015 David Clark Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. table-js@9.0.0 (MIT)The MIT License (MIT) Copyright (c) 2017-present camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. tiny-svg@2.2.4 (MIT)The MIT License (MIT) Copyright (c) 2014 Nico Rehwaldt Copyright (c) 2015-present camunda Services GmbH Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. w3c-keyname@2.2.8 (MIT)Copyright (C) 2016 by Marijn Haverbeke and others Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.",
    "url": "/manual/latest/introduction/third-party-libraries/cibseven-bpm-platform-license-book/index.html"
  },
  {
    "id": "manual/latest/introduction/third-party-libraries/index.html",
    "title": "Third-Party Libraries | docs.cibseven.org",
    "content": "This section covers third party libraries and their use in Camunda. It provides license books (see sub pages) that list the third-party dependencies that Camunda distributes along with its code. Our license books include the library name, version, copyright notices, and licenses under which we use the library. By downloading and using CIB seven, you agree to adhere to these licenses. For selected third-party libraries that we consider especially noteworthy, this page describes their license terms and use in the CIB seven artifacts. For legal reference and any other license-related aspects please refer to Licences. Web Applications (Cockpit, Tasklist, Admin) XLTS for AngularJS Starting with versions 7.18.0-alpha2, 7.17.2, 7.16.9, 7.15.15, the Camunda web applications use a set of third-party libraries referred to as XLTS for AngularJS (technical names: angular, angular-animate, angular-cookies, angular-loader, angular-mocks, angular-resource, angular-route, angular-sanitize, angular-touch). XLTS for AngularJS follows a proprietary license called EULA for the downstream recipient of XLTS for AngularJS (short XLTS for AngularJS – EULA) that you can find here. This license imposes restrictions around distributing and reverse-engineering XLTS for AngularJS independently of Camunda artifacts. The license does otherwise not restrict how you can use and distribute the Camunda artifacts that include XLTS for AngularJS. You can find our rationale for using this library in our blog post on ensuring the long-term maintenance of CIB seven.",
    "url": "/manual/latest/introduction/third-party-libraries/index.html"
  },
  {
    "id": "manual/latest/notices/index.html",
    "title": "Security Notices | docs.cibseven.org",
    "content": "On this page, we publishhing security notices after fixes are available. Fixes are available as alpha or minor releases of CIB seven platform. Notices None. Hooray!",
    "url": "/manual/latest/notices/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/custom-extensions/extension-attributes/index.html",
    "title": "Camunda BPMN Extension Attributes | docs.cibseven.org",
    "content": "The following attributes are extension attributes for the camunda namespace http://camunda.org/schema/1.0/bpmn. assignee Description The attribute specifies a human performer of a User Task. Type java.lang.String or org.cibseven.bpm.engine.delegate.Expression Possible Values The name of a performer as java.lang.String or an expression which evaluates to a java.lang.String e.g., ${initiator} Default Value – BPMN 2.0 Elements User Task asyncAfter Description Specifies an asynchronous continuation after an activity, see Asynchronous Continuations for more information. Type java.lang.Boolean Possible Values true, false Default Value false BPMN 2.0 Elements Start Events, End Events, Intermediate Throw Events, Intermediate Catch Events, Task, Service Task, Send Task, User Task, Business Rule Task, Script Task, Receive Task, Manual Task, Embedded Subprocess, Call Activity, Transaction Subprocess, Parallel Gateway, Inclusive Gateway, Exclusive Gateway, Multi Instance Loop Characteristics, Boundary Event, Message Boundary Event, Error Boundary Event, Timer Boundary Event, Escalation Boundary Event, Conditional Boundary Event, Signal Boundary Event, Cancel Boundary Event asyncBefore Description Specifies an asynchronous continuation before an activity, see Asynchronous Continuations for more information. Type java.lang.Boolean Possible Values true, false Default Value false BPMN 2.0 Elements Start Events, End Events, Intermediate Throw Events, Intermediate Catch Events, Task, Service Task, Send Task, User Task, Business Rule Task, Script Task, Receive Task, Manual Task, Embedded Subprocess, Call Activity, Transaction Subprocess, Parallel Gateway, Event Based Gateway, Inclusive Gateway, Exclusive Gateway, Multi Instance Loop Characteristics, Boundary Event, Message Boundary Event, Error Boundary Event, Timer Boundary Event, Escalation Boundary Event, Conditional Boundary Event, Signal Boundary Event, Cancel Boundary Event calledElementBinding Description The attribute specifies which process definition version of the subprocess the call activity calls. If the value is version, the attribute camunda:calledElementVersion is required. If the value is versionTag, the attribute camunda:calledElementVersionTag is required. See Called Element Binding for more information. Type java.lang.String Possible Values latest, deployment, version, versionTag Default Value latest BPMN 2.0 Elements Call Activity calledElementVersion Description The attribute specifies which process definition version of the subprocess the call activity calls if the camunda:calledElementBinding is set to version, see Called Element Binding for more information. Type java.lang.Integer or org.cibseven.bpm.engine.delegate.Expression Possible Values A concrete version of all deployed version numbers of the subprocess to call as java.lang.Integer or an expression which evaluates to a java.lang.Integer e.g., ${versionToCall} Default Value – BPMN 2.0 Elements Call Activity calledElementVersionTag Description The attribute specifies which process definition version tag of the subprocess the call activity calls if the camunda:calledElementBinding is set to versionTag, see Called Element Binding for more information. Type java.lang.String or org.cibseven.bpm.engine.delegate.Expression Possible Values A concrete version tag of all deployed version numbers of the subprocess to call as java.lang.String or an expression which evaluates to a java.lang.String e.g., ${versionTagToCall} Default Value – BPMN 2.0 Elements Call Activity calledElementTenantId Description The attribute specifies the tenant id of the process definition which is to be resolved by a call activity, see Called Element Tenant Id for more information. Type java.lang.String or org.cibseven.bpm.engine.delegate.Expression Possible Values A concrete tenant id or an expression which evaluates to a java.lang.String e.g., ${execution.tenantId} Default Value – BPMN 2.0 Elements Call Activity candidateGroups Description The attribute specifies which group(s) will be candidate for performing the User Task. Type java.lang.String or org.cibseven.bpm.engine.delegate.Expression Possible Values Comma separated list of group ids as java.lang.String or expressions that evaluate to a java.lang.String or a java.util.Collection of java.lang.String, e.g., management or management, ${accountancyGroupId()} Default Value – BPMN 2.0 Elements User Task candidateStarterGroups Description The attribute specifies which group(s) will be able to start the process. Type java.lang.String or org.cibseven.bpm.engine.delegate.Expression Possible Values Comma separated list of group ids as java.lang.String or expressions that evaluate to a java.lang.String or a java.util.Collection of java.lang.String, e.g., management or management, ${accountancyGroupId()} Default Value – BPMN 2.0 Elements Process candidateStarterUsers Description The attribute specifies which user(s) will be able to start the process. Type java.lang.String or org.cibseven.bpm.engine.delegate.Expression Possible Values Comma separated list of user ids as java.lang.String or expressions that evaluate to a java.lang.String or a java.util.Collection of java.lang.String, e.g., kermit, gonzo or ${ldapService.findAllSales()} Default Value – BPMN 2.0 Elements Process candidateUsers Description The attribute specifies which user(s) will be candidate for performing the User Task. Type java.lang.String or org.cibseven.bpm.engine.delegate.Expression Possible Values Comma separated list of user ids as java.lang.String or expressions that evaluate to a java.lang.String or a java.util.Collection of java.lang.String, e.g., kermit, gonzo or ${ldapService.findAllSales()} Default Value – BPMN 2.0 Elements User Task caseBinding Description The attribute specifies which case definition version of the subcase the call activity calls. If the value is version, the attribute camunda:caseVersion is required, see Case Binding for more information. Type java.lang.String Possible Values latest, deployment, version Default Value – BPMN 2.0 Elements Call Activity caseRef Description The attribute references a case definition by its key to call. Type java.lang.String Possible Values – Default Value – BPMN 2.0 Elements Call Activity caseVersion Description The attribute specifies which case definition version of the subcase the call activity calls if the camunda:caseBinding is set to version, see Case Binding for more information. Type java.lang.Integer Possible Values All deployed version numbers of the subprocess to call Default Value – BPMN 2.0 Elements Call Activity caseTenantId Description The attribute specifies the tenant id of the case definition which is to be resolved by a call activity, see Case Tenant Id for more information. Type java.lang.String or org.cibseven.bpm.engine.delegate.Expression Possible Values A concrete tenant id or an expression which evaluates to a java.lang.String e.g., ${execution.tenantId} Default Value – BPMN 2.0 Elements Call Activity class Description The attribute specifies which Java class will be executed at runtime. The stated class must implement a Java delegate interface. Type java.lang.String Possible Values Fully qualified Java class name of a class which implements a Java Delegate interface, e.g., org.cibseven.bpm.MyJavaDelegate Default Value – BPMN 2.0 Elements Service Task, Business Rule Task, Send Task, Message Event Definition of Message Intermediate Throwing Event or Message End Event, camunda:taskListener, camunda:executionListner collection Description The attribute specifies a collection, where an instance will be created for each element, see Multiple Instance for more information. Type java.lang.String or org.cibseven.bpm.engine.delegate.Expression Possible Values The name of a java.util.Collection process variable as java.lang.String or an Expression which evaluates to the name of a collection Default Value – BPMN 2.0 Elements Multi Instance Loop Characteristics of Task, Embedded Subprocess, Call Activity, Transaction Subprocess decisionRef Description The attribute references a decision definition to evalute by its key. Type java.lang.String or org.cibseven.bpm.engine.delegate.Expression Possible Values A String or an expression which evalutes to the key of a decision definition which should be evaluated by this task, e.g., myDecisionDefinitionKey or ${decisionKey} Default Value – BPMN 2.0 Elements Business Rule Task decisionRefBinding Description The attribute specifies which decision definition version the task evaluates. If the value is version, the attribute camunda:decisionRefVersion is required. If the value is versionTag, the attribute camunda:decisionRefVersionTag is required. Type java.lang.String Possible Values latest, deployment, version, versionTag Default Value latest BPMN 2.0 Elements Business Rule Task decisionRefVersion Description The attribute specifies which decision definition version the task evaluates if the camunda:decisionRefBinding is set to version. Type java.lang.Integer or org.cibseven.bpm.engine.delegate.Expression Possible Values A concrete version of all deployed version numbers of the decision to call as java.lang.Integer or an expression which evaluates to a java.lang.Integer e.g., ${versionToCall} Default Value – BPMN 2.0 Elements Business Rule Task decisionRefVersionTag Description The attribute specifies which decision definition version tag the task evaluates if the camunda:decisionRefBinding is set to versionTag. Type java.lang.String or org.cibseven.bpm.engine.delegate.Expression Possible Values A concrete version tag of all deployed version tags of the decision to call as java.lang.String or an expression which evaluates to a java.lang.String e.g., ${versionTagToCall} Default Value – BPMN 2.0 Elements Business Rule Task decisionRefTenantId Description The attribute specifies the tenant id of the decision definition which is to be resolved by a business rule task, see DecisionRef Tenant Id for more information. Type java.lang.String or org.cibseven.bpm.engine.delegate.Expression Possible Values A concrete tenant id or an expression which evaluates to a java.lang.String e.g., ${execution.tenantId} Default Value – BPMN 2.0 Elements Business Rule Task delegateExpression Description The attribute allows specification of an expression which must resolve to an object that implements the corresponding interface (see delegation code). Type org.cibseven.bpm.engine.delegate.Expression Possible Values Expression which evaluates to a Java class implementing a delegation interface, e.g., ${myJavaDelegate} or #{myTaskListener} Default Value – BPMN 2.0 Elements Service Task, Business Rule Task, Send Task, Message Event Definition of Message Intermediate Throwing Event or Message End Event, camunda:taskListener, camunda:executionListner dueDate Description The attribute specifies the initial due date of a User Task when it is created. Type org.cibseven.bpm.engine.delegate.Expression Possible Values An expression which evaluates to a java.util.Date, java.util.String (ISO 8601 formatted) or null, e.g., ${dateVariable} Default Value – BPMN 2.0 Elements User Task elementVariable Description The attribute specifies the process variable which will be set on each created instance, containing an element of the specified collection see Multiple Instance for more information. Type java.lang.String Possible Values The name of a process variable as java.lang.String Default Value – BPMN 2.0 Elements Multi Instance Loop Characteristics of Task, Embedded Subprocess, Call Activity, Transaction Subprocess errorMessage Description The attribute specifies a message to give further information about the error. When an error start event or boudary event catches the error the message will be saved as process variable if `errorMessageVariable` is configured. See Error Events for more information. Type java.lang.String Possible Values The error message asjava.lang.String Default Value – BPMN 2.0 Elements Error errorCodeVariable Description The attribute specifies a process variable that holds the error code and the errorCodevariable will be set if an error has been received by the error start or boundary event, see Error Events for more information. Type java.lang.String Possible Values The name of a process variable as java.lang.String Default Value – BPMN 2.0 Elements Error Events errorMessageVariable Description The attribute specifies a process variable that holds the error message and the errorMessageVariable will be set if an error has been received by the error start or boundary event, see Error Events for more information. Type java.lang.String Possible Values The name of a process variable as java.lang.String Default Value – BPMN 2.0 Elements Error Events escalationCodeVariable Description The attribute specifies a process variable which will be set if an escalation has been received by an escalation start or boundary event, see Escalation Events for more information. Type java.lang.String Possible Values The name of a process variable as java.lang.String Default Value – BPMN 2.0 Elements Escalation Events exclusive Description The attribute specifies that jobs should be executed exclusively. See Exclusive Jobs for more information. Type java.lang.Boolean Possible Values true, false Default Value true BPMN 2.0 Elements Start Events, End Events, Intermediate Throw Events, Intermediate Catch Events, Task, <a href=\"/manual/latest/reference/bpmn20/tasks/service-task/\">Service Task</a>, <a href=\"/manual/latest/reference/bpmn20/tasks/send-task/\">Send Task</a>, <a href=\"/manual/latest/reference/bpmn20/tasks/user-task/\">User Task</a>, <a href=\"/manual/latest/reference/bpmn20/tasks/business-rule-task/\">Business Rule Task</a>, <a href=\"/manual/latest/reference/bpmn20/tasks/script-task/\">Script Task</a>, <a href=\"/manual/latest/reference/bpmn20/tasks/receive-task/\">Receive Task</a>, <a href=\"/manual/latest/reference/bpmn20/tasks/manual-task/\">Manual Task</a>, <a href=\"/manual/latest/reference/bpmn20/subprocesses/embedded-subprocess/\">Embedded Subprocess</a>, <a href=\"/manual/latest/reference/bpmn20/subprocesses/call-activity/\">Call Activity</a>, <a href=\"/manual/latest/reference/bpmn20/subprocesses/transaction-subprocess/\">Transaction Subprocess</a>, <a href=\"/manual/latest/reference/bpmn20/gateways/parallel-gateway/\">Parallel Gateway</a>, <a href=\"/manual/latest/reference/bpmn20/gateways/event-based-gateway/\">Event Based Gateway</a>, <a href=\"/manual/latest/reference/bpmn20/gateways/inclusive-gateway/\">Inclusive Gateway</a>, <a href=\"/manual/latest/reference/bpmn20/gateways/exclusive-gateway/\">Exclusive Gateway</a>, <a href=\"/manual/latest/reference/bpmn20/tasks/task-markers/#multiple-instance\">Multi Instance Loop Characteristics</a>, Boundary Event, <a href=\"/manual/latest/reference/bpmn20/events/message-events/#message-boundary-event\">Message Boundary Event</a>, <a href=\"/manual/latest/reference/bpmn20/events/error-events/#error-boundary-event\">Error Boundary Event</a>, <a href=\"/manual/latest/reference/bpmn20/events/timer-events/#timer-boundary-event\">Timer Boundary Event</a>, <a href=\"/manual/latest/reference/bpmn20/events/escalation-events/#escalation-boundary-event\">Escalation Boundary Event</a>, <a href=\"/manual/latest/reference/bpmn20/events/conditional-events/#conditional-boundary-event\">Conditional Boundary Event</a>, <a href=\"/manual/latest/reference/bpmn20/events/signal-events/#signal-boundary-event\">Signal Boundary Event</a>, <a href=\"/manual/latest/reference/bpmn20/events/cancel-and-compensation-events/#cancel-boundary-event\">Cancel Boundary Event</a> </td> expression Description The attribute defines an expression which will be evaluated at runtime. Type org.cibseven.bpm.engine.delegate.Expression Possible Values Expression, e.g., ${gender == 'male' ? 'Mr.' : 'Mrs.'} or #{printer.printMessage()} Default Value – BPMN 2.0 Elements Service Task, Business Rule Task, Send Task, Message Event Definition of Message Intermediate Throwing Event or Message End Event, camunda:taskListener, camunda:executionListner followUpDate Description The attribute specifies the initial follow-up date of a User Task when it is created. Type org.cibseven.bpm.engine.delegate.Expression Possible Values An expression which evaluates to a java.util.Date, java.util.String (ISO 8601 formatted) or null, e.g., ${dateVariable} Default Value – BPMN 2.0 Elements User Task formHandlerClass Description The attribute specifies the class that will be called during the parsing of the form information of a Start Event or User Task. Type java.lang.String Possible Values Fully qualified Java class name of a class which implements the org.cibseven.bpm.engine.impl.form.handler.StartFormHandler or org.cibseven.bpm.engine.impl.form.handler.TaskFormHandler interface, e.g., org.cibseven.bpm.MyUserTaskFormHandler Default Value – BPMN 2.0 Elements Initial Start Event of a Process, User Task formKey Description The attribute specifies a form resource. See task forms for more information. Type java.lang.String Possible Values A java.lang.String of a form resource which can be evaluated by the Tasklist Default Value – BPMN 2.0 Elements Initial Start Event of a Process, User Task formRef Description The attribute references a Camunda form definition by its key. See task forms for more information. Type java.lang.String or org.cibseven.bpm.engine.delegate.Expression Possible Values A java.lang.String or a org.cibseven.bpm.engine.delegate.Expression which Tasklist can evaluate to display the referenced Camunda Form, e.g., myCamundaFormDefinitionKey or ${formKey}. Default Value – BPMN 2.0 Elements Initial Start Event of a Process, User Task formRefBinding Description The attribute specifies which Camunda form definition version the activity references. If the value is version, the attribute camunda:formRefVersion is required. Type java.lang.String Possible Values latest, deployment, version Default Value latest BPMN 2.0 Elements Initial Start Event of a Process, User Task formRefVersion Description The attribute specifies which Camunda form definition version the activity references if the camunda:formRefBinding is set to version. Type java.lang.Integer or org.cibseven.bpm.engine.delegate.Expression Possible Values A concrete version of all deployed version numbers of the Camunda form definition as java.lang.Integer or an expression which evaluates to a java.lang.Integer e.g., ${versionToReference} Default Value – BPMN 2.0 Elements Initial Start Event of a Process, User Task historyTimeToLive Description The attribute specifies the history time to live (in days) for the process definition. It is used within History cleanup. Type java.lang.Integer or java.lang.String Possible Values Any non-negative integer number or string containing a time in days defined by the ISO-8601 date format. Default Value null - means that process definition history won't ever be removed during history cleanup run BPMN 2.0 Elements Process initiator Description The attribute specifies a process variable in which the user id of the process initiator is set. Type java.lang.String Possible Values A process variable name to save the process initiator Default Value – BPMN 2.0 Elements Start Event of a Process isStartableInTasklist Description The attribute specifies whether the process is startable in Tasklist or not. Type java.lang.Boolean Possible Values true, false Default Value true BPMN 2.0 Elements Process jobPriority Description Specifies the priority a job receives that is created in the context of executing the given process element (e.g., a timer event, or in the case of asyncBefore and asyncAfter). See the user guide on Job Prioritization for details. Type A number in the range of a Java long value or org.cibseven.bpm.engine.delegate.Expression Possible Values An expression must resolve to a valid Java long value. Default Value none BPMN 2.0 Elements Start Events, End Events, Intermediate Throw Events, Intermediate Catch Events, Task, <a href=\"/manual/latest/reference/bpmn20/tasks/service-task/\">Service Task</a>, <a href=\"/manual/latest/reference/bpmn20/tasks/send-task/\">Send Task</a>, <a href=\"/manual/latest/reference/bpmn20/tasks/user-task/\">User Task</a>, <a href=\"/manual/latest/reference/bpmn20/tasks/business-rule-task/\">Business Rule Task</a>, <a href=\"/manual/latest/reference/bpmn20/tasks/script-task/\">Script Task</a>, <a href=\"/manual/latest/reference/bpmn20/tasks/receive-task/\">Receive Task</a>, <a href=\"/manual/latest/reference/bpmn20/tasks/manual-task/\">Manual Task</a>, <a href=\"/manual/latest/reference/bpmn20/subprocesses/embedded-subprocess/\">Embedded Subprocess</a>, <a href=\"/manual/latest/reference/bpmn20/subprocesses/call-activity/\">Call Activity</a>, <a href=\"/manual/latest/reference/bpmn20/subprocesses/transaction-subprocess/\">Transaction Subprocess</a>, <a href=\"/manual/latest/reference/bpmn20/gateways/parallel-gateway/\">Parallel Gateway</a>, <a href=\"/manual/latest/reference/bpmn20/gateways/inclusive-gateway/\">Inclusive Gateway</a>, <a href=\"/manual/latest/reference/bpmn20/gateways/exclusive-gateway/\">Exclusive Gateway</a>, <a href=\"/manual/latest/reference/bpmn20/tasks/task-markers/#multiple-instance\">Multi Instance Loop Characteristics</a>, Process </td> mapDecisionResult Description The attribute references which built-in Decision Result Mapper is used to pass the result of an evaluated decision to a process variable. It should be used in combination with camunda:resultVariable. Type java.lang.String Possible Values singleEntry, singleResult, collectEntries, resultList Default Value resultList BPMN 2.0 Elements Business Rule Task priority Description The attribute specifies the initial priority of a User Task when it is created. Type org.cibseven.bpm.engine.delegate.Expression Possible Values An expression which evaluates to a java.lang.Number or a java.lang.String which represents a number or null, e.g., ${dateVariable} Default Value – BPMN 2.0 Elements User Task taskPriority Description The attribute specifies the initial priority of an External Task when it is created. Type A number in the range of a Java long value or org.cibseven.bpm.engine.delegate.Expression Possible Values An expression must resolve to a valid Java long value. Default Value 0 BPMN 2.0 Elements Service Task, Message End Event, Message Intermediate Throwing Event, Business Rule Task, Send Task, Process resource Description The attribute specifies an external resource. The resource can be part of the deployment or exists in the classpath. To specify the type of resource, a URL scheme like prefix deployment:// resp. classpath:// can be supplied. If the scheme is omitted, it is assumed that the resource exists in the classpath. Type java.lang.String or org.cibseven.bpm.engine.delegate.Expression Possible Values The path to a resource or an expression which returns the path. Optional the path can start with an URL like scheme classpath:// or deployment:// to specify where to find the resource. If omitted the resource is assumed to exists in the classpath. Default Value – BPMN 2.0 Elements Script Task resultVariable Description The attribute specifies the process variable to save the return value of a camunda:expression. Note that when you use camunda:resultVariable in a multi-instance construct, for example in a multi-instance subprocess, the result variable is overwritten every time the task completes, unless the variable is a local variable in the scope of the multi-instance construct. This can lead to seemingly random behavior. This is a known issue. As a workaround, a local variable can be declared by adding an execution listener to the subprocess' start event that initializes the variable as null. Type java.lang.String Possible Values The name of a process variable to save the return value Default Value – BPMN 2.0 Elements Service Task, Business Rule Task, Script Task, Send Task, Message Event Definition of Message Intermediate Throwing Event or Message End Event, versionTag Description The attribute specifies a version tag for the process definition. Type java.lang.String Possible Values Any value that has a meaning as version tag for the process definition. Note: Sorting by versionTag is string based. The version will not be interpreted. As an example, the sorting could return v0.1.0, v0.10.0, v0.2.0. Default Value – BPMN 2.0 Elements Process topic Description The attribute specifies the topic of an external task instance. The task is going to be offered to workers polling for that topic. It is only relevant when camunda:type is set to external. Type java.lang.String or org.cibseven.bpm.engine.delegate.Expression Possible Values Any value that has a meaning as a topic identifier as java.lang.String or an expression which evaluates to a java.lang.String, e.g. ${topicName} Default Value – BPMN 2.0 Elements Service Task, Message End Event, Message Intermediate Throwing Event, Business Rule Task, Send Task type Description The attribute specifies which built-in task implementation to use. Currently an email, a shell service, and an external task exists. Type java.lang.String Possible Values external, mail, shell Default Value – BPMN 2.0 Elements Service Task, Message End Event, Message Intermediate Throwing Event, Business Rule Task, Send Task variableMappingClass Description The attribute specifies which Java class will be executed at runtime to map the input and output variables for a call activity. The stated class must implement the Delegate Variable Mapping interface. Type java.lang.String Possible Values Fully qualified Java class name of a class which implements the Delegate Variable Mapping interface, e.g., org.cibseven.bpm.MyVariableMappingDelegate Default Value – BPMN 2.0 Elements Call Activity variableMappingDelegateExpression Description The attribute allows specification of an expression which must resolve to an object that implements the corresponding interface Delegate Variable Mapping. Type org.cibseven.bpm.engine.delegate.Expression Possible Values Expression which evaluates to a Java class that implements the Delegate Variable Mapping interface, e.g., ${myVariableMapping}. Default Value – BPMN 2.0 Elements Call Activity variableName Description The attribute allows to specify a variable name on which a condition of a conditional event should be evaluated exclusively. Type java.lang.String Possible Values The name of a process variable on which a condition should be evaluated after a change happens. Default Value – BPMN 2.0 Elements Conditional Event variableEvents Description The attribute allows to specify a comma separated list of variable change events. These events specify the variable change events on which a condition of a conditional event should be evaluated exclusively. Type java.lang.String Possible Values A comma separated list of variable change events. Variable change events are: create, update and delete. Default Value – BPMN 2.0 Elements Conditional Event",
    "url": "/manual/latest/reference/bpmn20/custom-extensions/extension-attributes/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/custom-extensions/extension-elements/index.html",
    "title": "Camunda BPMN Extension Elements | docs.cibseven.org",
    "content": "The following attributes are extension attributes for the camunda namespace http://camunda.org/schema/1.0/bpmn. connector Description The configuration of a camunda connector. Attributes – Constraints The camunda:connectorId child element is required and must identify a connector implementation known to the process engine Parent elements Service Task, Business Rule Task, Send Task, Message Event Definition of Message Intermediate Throwing Event or Message End Event, Child elements camunda:inputOutput, camunda:connectorId connectorId Description The unique identifier of the connector type to instantiate. Attributes – Constraints The connector type has to be known to the process engine Parent elements camunda:connector Child elements – constraint Description Metadata of an individual validation constraint for a form field (see Form Field Validation). Attributes name The name of the form field constraint type config The configuration of the form field constraint type Constraints The name attribute must be one of the known validators (required, minlength, maxlength, min, max, readonly or validator) Parent elements camunda:validation Child elements – entry Description A single entry of a map structure. The value can be a constant, expression, script, list or another map. Attributes key The key of the entry in the map. Can be a string or an expression. Constraints The key attribute is required Parent elements camunda:map Child elements camunda:list, camunda:map, camunda:script errorEventDefinition Description Definition of an error event that can be triggered by an expression. This element extends the errorEventDefinition element from the bpmn namespace inheriting all of its attributes: id, errorRef Attributes expression An expression that will trigger the error if it evaluates to true. Constraints The errorRef attribute is required Parent elements Service Task of type external Child elements – executionListener Description Add an execution listener to an event. Attributes event The type of the event for which the listener is called class see camunda:class expression see camunda:expression delegateExpression see camunda:delegateExpression Constraints The event attribute is required (except for transitions) and must be one of the task events: start or end One of the attributes class, expression or delegateExpression is mandatory Parent elements Process, Task, Service Task, Send Task, User Task, Business Rule Task, Script Task, Receive Task, Manual Task, Exclusive Gateway, Sequence Flow, Parallel Gateway, Inclusive Gateway, Event Based Gateway, Start Event, Intermediate Catch Event, Intermediate Throw Event, End Events, Boundary Events, Embedded Subprocess, Call Activity, Event Subprocess, Transaction Subprocess Child elements camunda:field, camunda:script expression Description Defines an expression to inject in delegated classes (see Field Injection). Attributes – Text Content The expression to inject Constraints – Parent elements camunda:field Child elements – failedJobRetryTimeCycle Description Defines the custom retry schedule for a failed job (see Failed Jobs). Attributes – Text Content The retry time cycle value or expression Constraints The configuration follows the ISO 8601 standard for repeating time intervals Parent elements Task, Service Task, Send Task, User Task, Business Rule Task, Script Task, Receive Task, Timer Start Event, Timer Intermediate Catching Event, Timer Boundary Event, Intermediate Signal Throw Event, Embedded Subprocess, Call Activity, Transaction Subprocess, Multi Instance Loop Characteristics Child elements – field Description Defines the value to inject in delegated classes (see Field Injection). Attributes name The name of the field expression The value of the field as expression stringValue The value of the field as String Constraints Only one attribute of stringValue and expression or one of the child elements string and expression can be used Parent elements Service Task, Business Rule Task, Send Task, Message Event Definition of Message Intermediate Throwing Event or Message End Event, camunda:taskListener, camunda:executionListner Child elements camunda:expression, camunda:string formData Description Metadata to define fields of a form, which are used to generate task forms (see Generated Task Forms). Attributes – Constraints – Parent elements Start Event, User Task Child elements camunda:formField formField Description Metadata to define a single form field (see Generated Task Forms). Attributes id The id of the form field, corresponding to the name of a process variable label The label to be displayed next to the form field type The type of the form field datePattern The pattern of a date type form field defaultValue The value to be used as a default (pre-selection) for the field Constraints The attribute id may not be empty The attribute type can be one of the known form field types (string, long, boolean, date or enum) or a custom one The attribute datePattern can only be used if the type attribute is set to date The child element camunda:properties is only allowed once The child element camunda:validation is only allowed once The child elements camunda:values can only be used if the type attribute is set to enum Parent elements camunda:formData Child elements camunda:properties, camunda:validation, camunda:value formProperty Description Metadata to define a form field (Deprecated, use camunda:formData). Attributes id The key used to submit the property through the API name The display label of the property type The type of the property required True if the form field is required (default: false) readable True if the form field is readable and will be displayed (default: true) writeable True if the form field is writeable (default: true) variable Specifies the process variable on which the variable is mapped expression Specifies an expression that maps the property, e.g., ${street.address} datePattern The pattern of a date type form field default The default value or expression of the property Constraints The id attribute is required The attribute type can be one of the known types (string, long, boolean, date or enum) or a custom one The attribute datePattern can only be used if the type attribute is set to date The child elements camunda:values can only be used if the type attribute is set to enum Parent elements Start Event, User Task Child elements camunda:value in Description The element specifies variables which should be passed to the subprocess, see passing variables for more information. Attributes source A name of a process variable to be passed in sourceExpression An expression to be evaluated and passed in variables Can be set to all to pass all process variables in target Name of the process variable inside the subprocess instance local Can be set to true to only pass local variables of the execution that executes the call activity. businessKey Set the business key of the subprocess process instance Constraints Only one of the attributes source, sourceExpression, variables or businessKey can be used The attribute target is required if the source or sourceExpression attribute is used Parent elements Call Activity, Signal Events (in Intermediate and End Throwing Events) Child elements – inputParameter Description An single input mapping for the activity. If the element has no child element, the text content of this element is mapped into the activity. The text content can be a constant string value or an expression. If no child element or text content exists, the variable inside the activity is set to the special value null. Attributes name The name of the variable inside the activity. Constraints The name attribute is required. The element can have one child element, a constant string or an expression as text content. Parent elements camunda:inputOutput Child elements camunda:list, camunda:map, camunda:script inputOutput Description The element describes an input/output mapping for the activity. Attributes – Constraints – Parent elements All Tasks, All Events (except Start and Boundary Events), Call Activity, Embedded Subprocess, Transaction Subprocess, camunda:connector Child elements camunda:inputParameter, camunda:outputParameter list Description A list structure. If the list contains multiple values, they should be added as text content of child elements. Which child elements are used is arbitrary, e.g.,: <camunda:list> <camunda:value>one</camunda:value> <camunda:value>two</camunda:value> <camunda:value>three</camunda:value> </camunda:list> A camunda:script element can also be used as a list element. The return value of the script is added to the list. Furthermore, lists can contain nested lists and maps. Attributes – Constraints Multiple values have to be encapsulated in child elements. Parent elements camunda:inputParameter, camunda:outputParameter, camunda:list, camunda:entry Child elements Any child element, camunda:list, camunda:map map Description A map structure. The entries can be constants, expressions, scripts, nested maps and lists. Attributes – Constraints – Parent elements camunda:inputParameter, camunda:outputParameter, camunda:list, camunda:entry Child elements camunda:entry out Description The element specifies variables which should be passed back from the subprocess, see passing variables for more information. Attributes source A name of a process variable to be passed back sourceExpression An expression to be evaluated and passed back variables Can be set to all to pass all subprocess variables back target Name of the process variable inside the subprocess instance local Can be set to true to pass variables from the called case/process instance to local variables of the execution executing the call activity. Constraints Only one of the attributes source, sourceExpression or variables can be used The attribute target is required if the source or sourceExpression attribute is used Parent elements Call Activity Child elements – outputParameter Description An single output mapping for the activity. If the element has no child element, the text content of this element is mapped out of the activity. The text content can be a constant string value or an expression. If no child element or text content exists, the variable outside of the activity is set to the special value null. Attributes name The name of the variable outside of the activity. Constraints The name attribute is required. The element can have one child element, a constant string or an expression as text content. Parent elements camunda:inputOutput Child elements camunda:list, camunda:map, camunda:script potentialStarter Description Defines which users or groups can start the process. Attributes – Constraints – Parent elements Process Child elements resourceAssignmentExpression properties Description A key value list of properties which be can be interpreted freely. Attributes – Constraints – Parent elements Base Element, camunda:formField Child elements camunda:property property Description A key value pair which can be interpreted freely. Attributes id The id of the form field property name The name of the property value The value of the property Constraints If the property belongs to a camunda:formField extension element, only the attributes id and value are used. If the parent camunda:properties element is directly added as an extension element, for example by the Camunda Modeler, only the attributes name and value are used. Parent elements camunda:properties Child elements – script Description A script element. The script is executed and the return value is used as mapping value. Attributes scriptFormat The format identifier, normally the language of the script source code resource equivalent to camunda:resource Constraints The scriptFormat attribute is required If the resource attribute is used, no source code text content is allowed Parent elements camunda:inputParameter, camunda:outputParameter, camunda:entry, camunda:list, camunda:executionListener, camunda:taskListener Child elements – string Description Defines a String value to inject in delegated classes (see Field Injection). Attributes – Text Content The String value to inject Constraints – Parent elements camunda:field Child elements – taskListener Description Adds a task listener to a task event. Attributes event The type of the event for which the listener is called class see camunda:class expression see camunda:expression delegateExpression see camunda:delegateExpression id The id of the task listener in the parent scope, only required when event is set to timeout Constraints The event attribute is required and must be one of the task events: create, assignment, update, complete, delete or timeout One of the attributes class, expression or delegateExpression is mandatory If the attribute event is set to timeout, the attribute id and exactly one child element of type timerEventDefinition are mandatory Parent elements User Task Child elements camunda:field, camunda:script, timerEventDefinition validation Description Metadata to define a list of validation constraints for form fields (see Form Field Validation). Attributes – Constraints – Parent elements camunda:formField Child elements camunda:constraint value Description Possible values of a form field with the type enum. Attributes id The id of the value name The name of the value Constraints – Parent elements camunda:formField, camunda:formProperty Child elements –",
    "url": "/manual/latest/reference/bpmn20/custom-extensions/extension-elements/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/custom-extensions/index.html",
    "title": "Extension Reference | docs.cibseven.org",
    "content": "Camunda extends BPMN with custom Extension Elements and Attributes.",
    "url": "/manual/latest/reference/bpmn20/custom-extensions/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/events/cancel-and-compensation-events/index.html",
    "title": "Cancel and Compensation Events | docs.cibseven.org",
    "content": "Cancel Events Cancel End Event The cancel end event can only be used in combination with a transaction subprocess. When the cancel end event is reached, a cancel event is thrown which must be caught by a cancel boundary event. The cancel boundary event then cancels the transaction and triggers compensation. Cancel Boundary Event An attached intermediate catching cancel event on the boundary of a transaction subprocess, or, for short, a cancel boundary event, is triggered when a transaction is canceled. When the cancel boundary event is triggered, it first interrupts all active executions in the current scope. Next, it starts compensation of all active compensation boundary events in the scope of the transaction. Compensation is performed synchronously, i.e., the boundary event waits before compensation is completed before leaving the transaction. When compensation is completed, the transaction subprocess is left using the sequence flow(s) running out of the cancel boundary event. Note: Only a single cancel boundary event is allowed for a transaction subprocess. Note: If the transaction subprocess hosts nested subprocesses, compensation is only triggered for subprocesses that have completed successfully. Note: In case a cancel boundary event is placed on a transaction subprocess with multi instance characteristics, if one instance triggers cancellation, the boundary event cancels all instances. A cancel boundary event is defined as a typical boundary event: <boundaryEvent id=\"boundary\" attachedToRef=\"transaction\" > <cancelEventDefinition /> </boundaryEvent> Since the cancel boundary event is always interrupting, the cancelActivity attribute is not required. Compensation Events Intermediate Throwing Compensation Event An intermediate throwing compensation event can be used to trigger compensation. Triggering compensation: Compensation can either be triggered for a designated activity or for the scope that hosts the compensation event. Compensation is performed through execution of the compensation handler associated with an activity. When compensation is thrown for an activity, the associated compensation handler is executed the same amount of times the activity completed successfully. If compensation is thrown for the current scope, all activities within the current scope are compensated, which includes activities on concurrent branches. Compensation is triggered hierarchically: if an activity to be compensated is a subprocess, compensation is triggered for all activities contained within the subprocess. If the subprocess has nested activities, compensation is thrown recursively. However, compensation is not propagated to the “upper levels” of the process: if compensation is triggered within a subprocess, it is not propagated to activities outside of the subprocess scope. The BPMN specification states that compensation is triggered for activities at “the same level of subprocess”. Compensation is consumed by compensation event subprocess: if an activity to be compensated is a subprocess and the subprocess contains an event subprocess triggered by a compensation start event, compensation triggers the event subprocess instead of trigger the activities contained within the subprocess. Compensation is performed in reverse order of execution. This means that whichever activity completed last is compensated first, etc. The intermediate throwing compensation event can be used to compensate transaction subprocesses which completed successfully. Note: If compensation is thrown within a scope which contains a subprocess and the subprocess contains activities with compensation handlers, compensation is only propagated to the subprocess if it has completed successfully when compensation is thrown. If some of the activities nested inside the subprocess have completed and have attached compensation handlers, the compensation handlers are not executed if the subprocess containing these activities is not completed yet. Consider the following example: In this process we have two concurrent executions, one executing the embedded subprocess and one executing the “charge credit card” activity. Lets assume both executions are started and the first concurrent execution is waiting for a user to complete the “review bookings” task. The second execution performs the “charge credit card” activity and an error is thrown, which causes the “cancel reservations” event to trigger compensation. At this point the parallel subprocess is not yet completed which means that the compensation event is not propagated to the subprocess and thus the “cancel hotel reservation” compensation handler is not executed. If the user task (and thus the embedded subprocess) completes before the “cancel reservations” is performed, compensation is propagated to the embedded subprocess. Note: When compensation is thrown for a multi instance activity, the associated compensation handler is only executed when all instances of this activity have ended. That means, the multi instance activity must be ended before it can be compensated. Process variables: When compensating an embedded subprocess, the execution used for executing the compensation handlers has access to the local process variables of the subprocess in the state they were in when the subprocess completed execution. To achieve this, a snapshot of the process variables associated with the scope execution (execution created for executing the subprocess) is taken. From this, a couple of implications follow: The compensation handler does not have access to variables added to concurrent executions created inside the subprocess scope. Process variables associated with executions higher up in the hierarchy, e.g., process variables associated with the process instance execution, are not contained in the snapshot: the compensation handler has access to these process variables in the state they are in when compensation is thrown. A variable snapshot is only taken for embedded subprocesses, not for other activities. Current limitations: waitForCompletion=\"false\" is currently unsupported. When compensation is triggered using the intermediate throwing compensation event, the event is only left after compensation completed successfully. Compensation itself is currently performed by concurrent executions. The concurrent executions are started in reverse order to which the compensated activities completed. Future versions of Camunda Automation Platform 7 might include an option to perform compensation sequentially. Compensation is not propagated to sub process instances spawned by call activities. A compensation intermediate event is defined as an intermediate throwing event. The specific type sub-element in this case is a compensateEventDefinition element. <intermediateThrowEvent id=\"throwCompensation\"> <compensateEventDefinition /> </intermediateThrowEvent> Additionally, the optional argument activityRef can be used to trigger compensation of a specific scope / activity: <intermediateThrowEvent id=\"throwCompensation\"> <compensateEventDefinition activityRef=\"bookHotel\" /> </intermediateThrowEvent> Compensation End Event A compensation end event triggers compensation and the current path of execution is ended. It has the same behavior and limitations as a compensation intermediate throwing event. <endEvent id=\"throwCompensation\"> <compensateEventDefinition /> </endEvent> Camunda Extensions Attributes camunda:asyncBefore, camunda:asyncAfter, camunda:exclusive, camunda:jobPriority Extension Elements camunda:inputOutput Constraints – Compensation Boundary Event An attached intermediate catching compensation on the boundary of an activity, or, for short, a compensation boundary event, can be used to attach a compensation handler to an activity or an embedded subprocess. The compensation boundary event must reference a single compensation handler using a directed association. A compensation boundary event has a different activation policy than other boundary events. Other boundary events, such as the signal boundary event are activated when the activity they are attached to is started. When the activity is left, they are deactivated and the corresponding event subscription is canceled. The compensation boundary event is different. The compensation boundary is activated when the activity it is attached to completes successfully. At this point, the corresponding subscription to compensation events is created. The subscription is removed either when a compensation event is triggered or when the corresponding process instance ends. This leads to the following points: When compensation is triggered, the compensation handler associated with the compensation boundary event is invoked the same amount of times that the activity it is attached to completed successfully. If a compensation boundary event is attached to an activity with multiple instance characteristics, a compensation event subscription is created for each instance. If a compensation boundary event is attached to an activity which is contained inside a loop, a compensation event subscription is created for each time the activity is executed. If the process instance ends, the subscriptions to compensation events are canceled. A compensation boundary event is defined as a typical boundary event: <boundaryEvent id=\"compensateBookHotelEvt\" attachedToRef=\"bookHotel\" > <compensateEventDefinition /> </boundaryEvent> <association associationDirection=\"One\" id=\"a1\" sourceRef=\"compensateBookHotelEvt\" targetRef=\"undoBookHotel\" /> <serviceTask id=\"undoBookHotel\" isForCompensation=\"true\" camunda:class=\"...\" /> As the compensation boundary event is activated after the activity has completed successfully, the cancelActivity attribute is not supported. Compensation Start Event A compensation start event can only be used to trigger an Event Sub-Process - it cannot be used to start a process instance. This kind of event subprocess is called compensation event subprocess. When deploying a process definition with a compensation event subprocess, the following considerations apply: The compensation event subprocess is only supported for embedded subprocess and not at process-level, caused by the current limitation that compensation is not propagated to sub process instances spawned by call activities. There can be only one compensation event subprocess at the same level of subprocess. A subprocess with a compensation event subprocess and an attached compensation boundary event is not supported. Note that the compensation event subprocess and the compensation boundary event have a similar intent, so only one of them should be chosen. A compensation event subprocess can be used as a compensation handler for the embedded subprocess. Similar to a compensation boundary event attached to a subprocess, a compensation event subprocess will only be invoked by a thrown compensation event, if the subprocess completed successfully before. In this case, the compensation event subprocess will be invoked the same amount of times that the subprocess was completed. Contrary to a compensation boundary event attached to a subprocess, a compensation event subprocess consumes a thrown compensation event. That means, activities contained in the subprocess are not compensated by default. Instead, the compensation event subprocess can recursively trigger compensation for activities contained in its parent. The above process contains an embedded subprocess with a compensation event subprocess, triggered by a compensation start event. Note that this compensation handler deviates from default compensation in that it triggers compensation activities in an specific order independent from the order of execution; it also contains an additional activity adding process logic that cannot be derived from the body of the subprocess itself. The XML representation of a compensation start event is the normal start event declaration with a compensateEventDefinition child-element: <subProcess id=\"compensationEventSubprocess\" triggeredByEvent=\"true\"> <startEvent id=\"compensationStart\" > <compensateEventDefinition /> </startEvent> <!-- ... --> </subProcess> Additional Resources Transaction subprocess Compensation Events in the BPMN 2.0 Modeling Reference",
    "url": "/manual/latest/reference/bpmn20/events/cancel-and-compensation-events/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/events/conditional-events/index.html",
    "title": "Conditional Events | docs.cibseven.org",
    "content": "The conditional event defines an event which is triggered if a given condition is evaluated to true. It can be used as start event of an event sub process, as intermediate event and boundary event. The start and boundary event can be interrupting and non interrupting. In Camunda, conditional events are triggered with the help of process variables. See the Trigger Conditional Events section for details. In the following BPMN model, all supported conditional events are used. As you can see, an intermediate conditional event is like a wait until the condition is satisfied. In this example, if the processor becomes available and the condition is, for example, ${processorAvailable == true}, the condition will be satisfied and the execution process continues to the next activity. If the condition of the conditional boundary event, which checks if the application was changed, is satisfied, then the corresponding user task will be interrupted. During the entire execution of the process instance, the application can be canceled. If the condition of the conditional start event is satisfied, the execution of the process instance will be interrupted by the event sub process. This will cancel the current processing of the application. Condition To specify when a conditional event should be triggered, a condition element must be specified as a sub-element of conditionalEventDefinition. <conditionalEventDefinition> <condition type=\"tFormalExpression\">${var1 == 1}</condition> </conditionalEventDefinition> The specified condition can be an EL expression and has access to the process instance variables. For information about EL expressions, see the Expression Language section. A condition is evaluated every time a variable changes, see the Trigger Conditional Events section for details. To prevent the continuous evaluation of a condition, the evaluation can be restricted to specific variable changes. For that, the Camunda extension attributes camunda:variableName and camunda:variableEvents can be used. By default, condition evaluation is triggered by any kind of variable change, i.e., create/update/delete of any variable. variableName can be used to restrict that to changes of a specific variable. variableEvents can be used to restrict the type of change. It is possible to specify more than one variable change event as a comma separated list. The attributes can be used in combination. The conditionalEventDefinition can, for example, look like this: <conditionalEventDefinition camunda:variableName=\"var1\" camunda:variableEvents=\"create, update\"> <condition type=\"tFormalExpression\">${var1 == 1}</condition> </conditionalEventDefinition> The condition above is only evaluated if the variable var1 is created or updated. The attributes are especially useful on non interrupting events, since these events can be triggered more than once! Conditional Boundary Event A conditional boundary event acts like an observer which is triggered if a specific condition is satisfied. There is a difference between an interrupting and a non interrupting conditional event. The interrupting event is the default. The non-interrupting event leads to the original activity not being interrupted, the instance remains active. Instead, an additional path of execution is created, taking the outgoing transition of the event. A non interrupting conditional event can be triggered more than once as long as the activity it is attached to is active. In the XML representation for non interrupting conditional events, the cancelActivity attribute is set to false: <boundaryEvent id=\"conditionalEvent\" attachedToRef=\"taskWithCondition\" cancelActivity=\"false\"> <conditionalEventDefinition> <condition type=\"tFormalExpression\">${var1 == 1}</condition> </conditionalEventDefinition> </boundaryEvent> Intermediate Conditional Catch Event An intermediate conditional event is like a wait until the condition is true. When the execution arrives at the catching event activity, the condition is evaluated for the first time. If the condition is satisfied, the execution process continues to the next activity. If the condition is not satisfied, the execution stays in this activity until the condition is satisfied. An intermediate conditional event is defined as an intermediate catching event. The specific sub-element type in this case is a conditionalEventDefinition element. <intermediateCatchEvent id=\"conditionalEvent\"> <conditionalEventDefinition> <condition type=\"tFormalExpression\">${var1 == 1}</condition> </conditionalEventDefinition> </intermediateCatchEvent> Conditional Start Event A conditional start event can be used to start a process by evaluating some condition. One process can have one or more conditional start events. If more than one conditions are fulfilled the respective number of processes will be triggered. When deploying a process definition with conditional start events, the following considerations apply: The condition of the conditional start event must be unique across a given process definition, i.e., a process definition must not have multiple conditional start events with the same condition. The engine throws an exception upon deployment of a process definition in case two or more conditional start events contain the same condition. Process versioning: Upon deployment of a new version of a process definition, the conditional subscriptions of the previous version are cancelled. This is also the case for conditional events that are not present in the new version. When starting a process instance, a conditional start event can be triggered using the following method on the RuntimeService: List<ProcessInstance> instances = runtimeService .createConditionEvaluation() .setVariable(\"temperature\", 24) .evaluateStartConditions(); // or List<ProcessInstance> instances = runtimeService .createConditionEvaluation() .setVariables(variableMap) .evaluateStartConditions(); The provided variables are used to evaluate the conditions. Also they are passed as variables to the newly created process instances. The XML representation of a conditional start event is the normal start event declaration with a conditionalEventDefinition child element. Optional: Adding variableName attribute to conditionalEventDefinition allows to specify a variable name on which a condition of a conditional event should be evaluated exclusively. <startEvent id=\"conditionalStartEvent\"> <conditionalEventDefinition camunda:variableName=\"temperature\"> <condition type=\"tFormalExpression\">${temperature > 20}</condition> </conditionalEventDefinition> </startEvent> Conditional Start Event for Event Sub Process Similar to conditional boundary events, conditional start events for event sub process can be interrupting and non interrupting. Note: An Event Sub-Process must have a single start event. The XML representation of a conditional start event is the normal start event declaration with a conditionalEventDefinition child-element: <subProcess id=\"EventSubProcess\" triggeredByEvent=\"true\"> <startEvent id=\"conditionalStartEvent\"> <conditionalEventDefinition> <condition type=\"tFormalExpression\">${var1 == 1}</condition> </conditionalEventDefinition> </startEvent> </subProcess> Trigger Conditional Events Triggering on Scope Instantiation When a BPMN scope is instantiated, the event conditions which are available in this scope are evaluated. This behavior is called triggering on scope instantiation. Consider the following process model: When a process instance is started, i.e., the process definition scope is instantiated, the condition of the sub process is evaluated before the none start event is executed. If fulfilled, it triggers immediately and the none start event never executes. The same applies to activities with conditional boundary events and intermediate conditional events. Triggering via Variable API Besides the triggering on scope instantiation, conditional events can also be triggered when a process variable changes. That is the case if a variable is created, updated or deleted. Set Variable From Outside Variables can be changed from the outside with the help of the variable API. See the following example how to set a variable on the variable scope of the process instance: //set variable on process instance runtimeService.setVariable(processInstance.getId(), \"variable\", 1); This statement triggers the evaluation of all applicable conditional events. For details, see the sections on Top-Down Evaluation and Scoped Evaluation. Set Variable From Delegation Code Variables can not only be set from outside, but also also from within a process instance via delegation code. For example: public class SetVariableDelegate implements JavaDelegate { @Override public void execute(DelegateExecution execution) throws Exception { execution.setVariable(\"variable\", 1); } } When set from delegation code, variable changes do not trigger conditional events immediately, to not interfere with the remaining code execution. Instead, the changes are recorded and collectively dispatched at the end of a phase of the activity instance lifecycle. In the following picture the different activity instance phases are displayed. Starting corresponds to the starting phase of the activity instance. At this time the input mappings and execution start listeners are called. Execute corresponds to the executing phase of the activity instance. Ending corresponds to the ending phase of the activity instance. At this time the output mappings and execution end listeners are called. For example, let us assume a variable is set in a start execution listener of an activity. Conditional events are only triggered after all start listeners have been executed and the activity instance is ready to enter the Execute phase. Top-Down Evaluation A variable change causes condition evaluation and event triggering in a top-down fashion. That means the evaluation starts at the the conditional events of the BPMN scope in which the variable was changed. It then step by step descends into the instances of nested BPMN scopes (e.g., embedded sub processes). This is done until a conditional event is triggered that interrupts the current scope instance (thereby cancelling all children) or until there are no more deeper nested scopes. For example see the following BPMN process model: If a variable is set in the context of the sub process instance, then the conditional boundary event of the sub process is evaluated first. If the condition is satisfied, then the execution is interrupted, otherwise the conditional boundary event of UserTask B is evaluated and triggered, if the condition is satisfied. Scoped Evaluation Variable changes in the context of a scope instance can only trigger the conditional events to which the variable is visible, but do not interfere with unrelated scope instances. That means if a variable changes, only those conditional events are evaluated that listen in the context of that scope instance or its children. See the following BPMN process model: If we have started the process above and UserTask B and UserTask A are active, then the activity instance hierarchy is: ProcessInstance UserTask A SubProcess UserTask B If a variable is set in the context of the SubProcess instance, then only the conditional boundary event of UserTask B is evaluated. The boundary event of UserTask A cannot trigger as the variable is not visible in its context. The user guide section on variable scopes and variable visibility provides details on the general concept. Camunda Extensions Attributes camunda:variableName, camunda:variableEvents, Extension Elements – Constraints – Additional Resources Conditional Events in the BPMN 2.0 Modeling Reference",
    "url": "/manual/latest/reference/bpmn20/events/conditional-events/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/events/error-events/index.html",
    "title": "Error Events | docs.cibseven.org",
    "content": "Error events are events which are triggered by a defined error. Business Errors vs. Technical Errors A BPMN error is meant for business errors - which are different than technical exceptions. So, this is different than Java exceptions - which are, by default, handled in their own way. You might also want to check out the basics of Threading and Transactions in the User Guide first. Defining an Error An error event definition references an error element. The following is an example of an error end event, referencing an error declaration: <definitions> <error id=\"myError\" errorCode=\"ERROR-OCCURED\" name=\"ERROR-OCCURED\"/> <!-- ... --> <process> <!-- ... --> <endEvent id=\"myErrorEndEvent\"> <errorEventDefinition errorRef=\"myError\" /> </endEvent> </process> </definitions> You can trigger this error event either with a throwing error event within your process definition or from Delegation Code, see the Throwing BPMN Errors from Delegation Code section of the User Guide for more information. Another possibility to define an error is setting of the type (class name) of any Java Exception as error code. Example: <definitions> <error id=\"myException\" errorCode=\"com.company.MyBusinessException\" name=\"myBusinessException\"/> <!-- ... --> <process> <!-- ... --> <endEvent id=\"myErrorEndEvent\"> <errorEventDefinition errorRef=\"myException\" /> </endEvent> </process> </definitions> The exception type should only be used for business exceptions and not for technical exceptions in the process. An error event handler references the same error element to declare that it catches the error. It is also possible to define an error message with the camunda:errorMessage extension for an error element to give further information about the error. The referencing error event definition must specify camunda:errorMessageVariable to receive the error message. The error message can also contain expressions. <definitions> <error id=\"myError\" errorCode=\"ERROR-OCCURED\" name=\"ERROR-OCCURED\" camunda:errorMessage=\"Something went wrong: ${errorCause}\" /> <!-- ... --> <process> <!-- ... --> <endEvent id=\"myErrorEndEvent\"> <errorEventDefinition errorRef=\"myError\" camunda:errorMessageVariable=\"err\"/> </endEvent> </process> </definitions> When the error thrown by the error end event is catched a process variable with the name err will be created that holds the evaluated message. For External Tasks, it is also possible to define error events by using a camunda:errorEventDefinition as shown in the following example. It additionally requires an expression that must evaluate to true in order for the BPMN error to be thrown. For further details on how to use those error events, consult the External Tasks Guide. <serviceTask id=\"validateAddressTask\" name=\"Validate Address\" camunda:type=\"external\" camunda:topic=\"AddressValidation\" > <extensionElements> <camunda:errorEventDefinition id=\"addressErrorDefinition\" errorRef=\"addressError\" expression=\"${externalTask.getErrorDetails().contains('address error found')}\" /> </extensionElements> </serviceTask> Error Start Event An error start event can only be used to trigger an Event Sub-Process - it cannot be used to start a process instance. The error start event is always interrupting. Three optional attributes can be added to the error start event: errorRef, camunda:errorCodeVariable and camunda:errorMessageVariable: <definitions> <error id=\"myException\" errorCode=\"com.company.MyBusinessException\" name=\"myBusinessException\"/> ... <process> ... <subProcess id=\"SubProcess_1\" triggeredByEvent=\"true\">> <startEvent id=\"myErrorStartEvent\"> <errorEventDefinition errorRef=\"myException\" camunda:errorCodeVariable=\"myErrorVariable\" camunda:errorMessageVariable=\"myErrorMessageVariable\" /> </startEvent> ... </subProcess> ... </process> </definitions> If errorRef is omitted, the subprocess will start for every error event that occurs. The camunda:errorCodeVariable will contain the error code that was specified with the error. The camunda:errorMessageVariable will contain the error message that was specified with the error. camunda:errorCodeVariable and camunda:errorMessageVariable can be retrieved like any other process variable, but only if the attribute was set. Error End Event When process execution arrives at an error end event, the current path of execution is ended and an error is thrown. This error can be caught by a matching intermediate error boundary event. In case no matching error boundary event is found, the execution semantics defaults to the none end event semantics. Camunda Extensions Error Event Definition Attributes camunda:asyncBefore, camunda:asyncAfter, camunda:errorCodeVariable, camunda:errorMessageVariable, camunda:exclusive, camunda:jobPriority Extension Elements camunda:inputOutput Constraints – Error Definition Attributes camunda:errorMessage Extension Elements – Constraints – Error Boundary Event An intermediate catching error event on the boundary of an activity, or error boundary event for short, catches errors that are thrown within the scope of the activity on which it is defined. Defining a error boundary event makes most sense on an embedded subprocess, or a call activity, as a subprocess creates a scope for all activities inside the subprocess. Errors are thrown by error end events. Such an error will propagate its parent scopes upwards until a scope is found on which a error boundary event is defined that matches the error event definition. When an error event is caught, the activity on which the boundary event is defined is destroyed, also destroying all current executions therein (e.g., concurrent activities, nested subprocesses, etc.). Process execution continues following the outgoing sequence flow of the boundary event. A error boundary event is defined as a typical boundary event. As with the other error events, the errorRef references an error defined outside of the process element: <definitions> <error id=\"myError\" errorCode=\"ERROR-OCCURED\" name=\"name of error\"/> <!-- ... --> <process> <!-- ... --> <subProcess id=\"mySubProcess\"> <!-- ... --> </subProcess> <boundaryEvent id=\"catchError\" attachedToRef=\"mySubProcess\"> <errorEventDefinition errorRef=\"myError\" camunda:errorCodeVariable=\"myErrorVariable\" camunda:errorMessageVariable=\"myErrorMessageVariable\" /> </boundaryEvent> </process> </definitions> The errorCode is used to match the errors that are caught: If errorRef is omitted, the error boundary event will catch any error event, regardless of the errorCode of the error. In case an errorRef is provided and it references an existing error, the boundary event will only catch errors with the defined error code. If the errorCodeVariable is set, the error code can be retrieved using this variable. If the errorMessageVariable is set, the error message can be retrieved using this variable. Unhandled BPMN Error It can happen that no catching boundary event was defined for an error event. The default behaviour in this case is to log information and end the current execution. This behaviour can be changed with enableExceptionsAfterUnhandledBpmnError property set to true (via the process engine configuration or the deployment descriptor) and Process Engine Exception will be thrown if unhandled BPMN Error occurs. Catch and Re-Throw Pattern An error can be handled by the error start event in the event sub process and the same error can be thrown from the event sub process to handle the error on the higher level scope (in the example below, the error thrown from the Event Subprocess is handled by the error boundary event in the Subprocess). Additional Resources Error Events in the BPMN 2.0 Modeling Reference Incidents in the User Guide",
    "url": "/manual/latest/reference/bpmn20/events/error-events/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/events/escalation-events/index.html",
    "title": "Escalation Events | docs.cibseven.org",
    "content": "Escalation events are events which reference a named escalation. They are mostly used to communicate from a subprocess to an upper process. Unlike an error, an escalation event is non critical and execution continues at the location of throwing. Defining Escalation An escalation event definition is declared by using the escalationEventDefinition element. The attribute escalationRef references an escalation element declared as a child element of the definitions root element. The following is an excerpt of a process in which an escalation event is declared and referenced by an escalation intermediate throw event. <definitions> <escalation id=\"lateShipment\" escalationCode=\"ORDER-LATE-SHIPMENT\" /> <!-- ... --> <process> <!-- ... --> <intermediateThrowEvent id=\"throwEscalation\" name=\"late shipment\"> <escalationEventDefinition escalationRef=\"lateShipment\" /> </intermediateThrowEvent> <!-- ... --> </process> </definitions> Catching Escalation Events Escalation Start Event An escalation start event can only be used to trigger an event sub-process - it cannot be used to start a process instance. An event sub-process with an escalation start event is triggered by an escalation event that occurs in the same scope or in a lower scope (e.g., sub-process or call activity). When the sub-process is triggered by an escalation event from a call activity, then the defined output variables of the call activity are passed to the sub-process. Two optional attributes can be added to the escalation start event, escalationRef and escalationCodeVariable: <subprocess triggeredByEvent=\"true\"> <startEvent id=\"catchEscalation\" isInterrupting=\"false\"> <escalationEventDefinition camunda:escalationCodeVariable=\"code\"/> </startEvent> <!-- ... --> </subprocess> If escalationRef is omitted or escalationCode of referenced escalation is omitted, the event sub-process is triggered by any escalation event, regardless of the escalation code of the escalation. In case an escalationRef is set, the event sub-process is only triggered by escalation events with the defined escalation code. If escalationCodeVariable is set, the escalation code of the occurred escalation event can be retrieved using this variable. Current Limitations The escalation code of the start event must be unique across the event sub-processes of the same scope. If a start event has no escalationRef or escalationCode of referenced escalation then another event sub-process with an escalation start event is not supported. Camunda Extensions The following extensions are supported for escalationEventDefinition. Attributes camunda:escalationCodeVariable Extension Elements – Constraints – Escalation Boundary Event An intermediate catching escalation event on the boundary of an activity, or escalation boundary event for short, catches escalations that are thrown within the scope of the activity on which it is defined. An escalation boundary event can only attached on an embedded sub-process or a call activity, since an escalation can only be thrown by an escalation intermediate throw event or an escalation end event. When the boundary event is triggered by an escalation event from a call activity, then the defined output variables of the call activity are passed to the scope of the boundary event. Two optional attributes can be added to the escalation boundary event, escalationRef and escalationCodeVariable, see Escalation Start Event. <boundaryEvent id=\"catchEscalation\" name=\"late shipment\" attachedToRef=\"productProcurement\"> <escalationEventDefinition escalationRef=\"lateShipment\" cancelActivity=\"false\" /> </boundaryEvent> Current Limitations The escalation code of the boundary event must be unique across the boundary events of the attached activity. If a boundary event has no escalationRef or escalationCode of referenced escalation then another escalation boundary event is not supported. Camunda Extensions The following extensions are supported for escalationEventDefinition. Attributes camunda:escalationCodeVariable Extension Elements – Constraints – Throwing Escalation Events Escalation Intermediate Throw Event When process execution arrives at an escalation intermediate throw event, a named escalation is thrown. This escalation can be caught by an escalation boundary event or an event sub-process with an escalation start event which has the same or none escalation code. Like an error event, an escalation event is propagated to upper scopes (e.g., from sub-process or call activity) till it is caught. In case no boundary event or event sub-process caught the event, the execution just continues with normal flow. If the escalation is propagated to an upper scope via call activity then the defined output variables of the call activity are passed to the upper scope. <intermediateThrowEvent id=\"throwEscalation\" name=\"order shipped\"> <escalationEventDefinition escalationRef=\"orderShipped\" /> </intermediateThrowEvent> Escalation End Event When process execution arrives at an escalation end event, the current path of execution is ended and a named escalation is thrown. It has the same behavior as an escalation intermediate throw event. <endEvent id=\"throwEscalation\" name=\"late shipment\"> <escalationEventDefinition escalationRef=\"lateShipment\" /> </endEvent>",
    "url": "/manual/latest/reference/bpmn20/events/escalation-events/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/events/index.html",
    "title": "Events | docs.cibseven.org",
    "content": "BPMN defines different Event types. The following are supported by Camunda.",
    "url": "/manual/latest/reference/bpmn20/events/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/events/link-events/index.html",
    "title": "Link Events | docs.cibseven.org",
    "content": "Link events are a special case - it has no special execution semantics but serves as a “GoTo” to another point in the same process model (to be precise: in the same sub process). Hence you can use two matching links as an alternative to a sequence flow as shown in the following example. Note that you might have the same event source (throwing intermediate link event with the same event definition name) multiple times, but the event target (catching intermediate link event) has to be unique according to the BPMN 2.0 specification. Link Event Definition The name of the link is set by a LinkEventDefinition within the XML. Please note that this should always correspond to the name of the intermediate event, otherwise this gets really confusing to everybody looking at the diagram (however, the engine just gives a warning as it is valid BPMN 2.0). <process id=\"someProcess\"> <!-- ... --> <intermediateThrowEvent id=\"IntermediateThrowEvent_1\" name=\"LinkA\"> <linkEventDefinition id=\"LinkEventDefinition_1\" name=\"LinkA\"/> </intermediateThrowEvent> <intermediateCatchEvent id=\"IntermediateCatchEvent_1\" name=\"LinkA\"> <linkEventDefinition id=\"LinkEventDefinition_2\" name=\"LinkA\"/> </intermediateCatchEvent> <!-- ... --> </process> Camunda Extensions Attributes camunda:asyncBefore, camunda:asyncAfter, camunda:exclusive, camunda:jobPriority Extension Elements camunda:inputOutput Constraints –",
    "url": "/manual/latest/reference/bpmn20/events/link-events/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/events/message-events/index.html",
    "title": "Message Events | docs.cibseven.org",
    "content": "Message events are events which reference a named message. A message has a name and a payload. Unlike a signal, a message event is always directed at a single recipient. Defining a Message A message event definition is declared by using the messageEventDefinition element. The attribute messageRef references a message element declared as a child element of the definitions root element. The following is an excerpt of a process in which two message events are declared and referenced by a start event and an intermediate catching message event. Example <definitions id=\"definitions\" xmlns=\"http://www.omg.org/spec/BPMN/20100524/MODEL\" xmlns:camunda=\"http://activiti.org/bpmn\" targetNamespace=\"Examples\" xmlns:tns=\"Examples\"> <message id=\"newInvoice\" name=\"newInvoiceMessage\" /> <message id=\"payment\" name=\"paymentMessage\" /> <process id=\"invoiceProcess\"> <startEvent id=\"messageStart\" > <messageEventDefinition messageRef=\"newInvoice\" /> </startEvent> ... <intermediateCatchEvent id=\"paymentEvt\" > <messageEventDefinition messageRef=\"payment\" /> </intermediateCatchEvent> ... </process> </definitions> Expressions You can use expressions for the name in the message event definition (except for the message start event). The name is then resolved as soon as a process reaches the scope of the message. For example when the process instances reaches a Message Intermediate Catching Event, then the expression within the name is resolved. By using expressions within the message name, you can influence the message name dynamically based on process variables. An example could look as follows: <message id=\"newInvoice\" name=\"newInvoiceMessage-${execution.processBusinessKey}\" /> Note: It is not allowed to use expressions in the message name of a start event of the process definition. So using an expression in the message definition and then referencing this definition in a message start event of the process entry point will cause an error. However, it is allowed to use expressions in the message start event of a subprocess. Therefore, using an expression in the message definition and then referencing this definition in the message start event within a subprocess will work just fine. Camunda Extensions Attributes camunda:asyncBefore, camunda:asyncAfter, camunda:exclusive, camunda:jobPriority Extension Elements camunda:inputOutput Constraints – Message Api As an embeddable process engine, the CIB seven engine is not concerned with the receiving part of the message. This would be environment dependent and entails platform-specific activities such as connecting to a JMS (Java Messaging Service) Queue/Topic or processing a Webservice or REST request. The reception of messages is therefore something you have to implement as part of the application or infrastructure into which the process engine is embedded. After you have received a message, you can choose whether you employ the engine’s built-in correlation or explicitly deliver the message to start a new process instance or trigger a waiting execution. Using the Runtime Service’s Correlation Methods The engine offers a basic correlation mechanism that will either signal an execution waiting for a specific message or instantiate a process with a matching message start event. The RuntimeService provides a fluent message correlation API: The result of the correlation is an object of type MessageCorrelationResult. It contains the type of the correlation, which is either execution or processDefinition. The first type is set if the message was correlated to an intermediate message catch event. The second is set if the message was correlated to a start event. If the type is set to execution, then the result contains an Execution object which can be accessed via the result.getExecution() method. If the type is set to processDefinition, the result contains a ProcessInstance object which was created through the start event, which is accessible via the result.getProcessInstance() method. // correlate the message MessageCorrelationResult result = runtimeService.createMessageCorrelation(\"messageName\") .processInstanceBusinessKey(\"AB-123\") .setVariable(\"payment_type\", \"creditCard\") .correlateWithResult(); You can also explicitly query for the subscription and trigger it: ProcessInstance pi = runtimeService.startProcessInstanceByKey(\"processWaitingInReceiveTask\"); EventSubscription subscription = runtimeService.createEventSubscriptionQuery() .processInstanceId(pi.getId()).eventType(\"message\").singleResult(); runtimeService.messageEventReceived(subscription.getEventName(), subscription.getExecutionId()); The messageName identifies the message as defined in the message name attribute in the process definition xml. Correlation is successful if a single matching entity exists among the following: Process Definition: A process definition matches if it can be started by a message named messageName. Execution (Process Instance): An execution matches if it is waiting for a message named messageName (if provided) and its process instance matches the given businessKey and correlationKeys (if provided). The correlationKeys map is matched against the process instance variables. If messageName is not provided, any execution that matches the other criteria matches the overall correlation. This can be useful when the sending party only knows a dynamic correlation key but not the message name as defined in the process model. Alternatively, it is possible to correlate a message to multiple matched executions and to a process definition that can be instantiated by this message in one go. To do so, you can correlate a message by using the message correlation builder as follows: List<MessageCorrelationResult> results = runtimeService .createMessageCorrelation(\"aMessageName\") .correlateAllWithResult(); The result will be a list of MessageCorrelationResult objects. Each result corresponds to a correlation. It is possible to retrieve the process variables on message correlation. By specifying the boolean parameter shouldDeserializeValues, you decide whether the variables’ values to be serialized or not. Please see the example below: MessageCorrelationResultWithVariables result = runtimeService .createMessageCorrelation(\"aMessageName\") .setVariable(\"name\", \"value\") .correlateWithResultAndVariables(shouldDeserializeValues); VariableMap processVariables = result.getVariables(); Additionally, message correlation builder provides the possibility to correlate the message by local execution variables. List<MessageCorrelationResult> results = runtimeService .createMessageCorrelation(\"aMessageName\") .localVariableEquals(\"localVarName\", \"localVarValue\")) .correlateAllWithResult(); In this case the matching execution will be selected based on variables existing in it’s scope (ignoring all parent scopes). In case of successful correlation, the correlated or newly created process instance is updated with the variables from the processVariables map. Explicitly Triggering a Message Alternatively, you can explicitly deliver a message to start a process instance or trigger a waiting execution. If the message should trigger the starting of a new process instance then you can use the correlation API: ProcessInstance startedProcessInstance = runtimeService .createMessageCorrelation(\"messageName\") .processInstanceBusinessKey(\"businessKey\") .setVariable(\"name\", \"value\") .correlateStartMessage(); // or MessageCorrelationResultWithVariables result = runtimeService .createMessageCorrelation(\"aMessageName\") .processInstanceBusinessKey(\"businessKey\") .startMessageOnly() .setVariable(\"name\", \"value\") .correlateWithResultAndVariables(shouldDeserializeValues); ProcessInstance startedProcessInstance = result.getProcessInstance(); VariableMap processVariables = result.getVariables(); Or you can use one of the following methods offered by the runtime service: ProcessInstance startProcessInstanceByMessage(String messageName); ProcessInstance startProcessInstanceByMessage(String messageName, Map<String, Object> processVariables); ProcessInstance startProcessInstanceByMessage(String messageName, String businessKey, Map<String, Object> processVariables); These methods allow starting a process instance using the referenced message. If the message needs to be received by an existing process instance, you first have to correlate the message to a specific process instance (see the next section) and then trigger continuation of the waiting execution. The runtime service offers the following methods to trigger an execution based on a message event subscription: void messageEventReceived(String messageName, String executionId); void messageEventReceived(String messageName, String executionId, HashMap<String, Object> processVariables); For an asynchronous correlation to existing process instances, you can use a Batch operation. Querying for Message Event Subscriptions The engine supports message start events and intermediate message events. In case of a message start event, the message event subscription is associated with a particular process definition. Such message subscriptions can be queried using a ProcessDefinitionQuery: ProcessDefinition processDefinition = repositoryService.createProcessDefinitionQuery() .messageEventSubscription(\"newCallCenterBooking\") .singleResult(); As there can only be one process definition for a specific message subscription, the query always returns zero or one results. If a process definition is updated, only the newest version of the process definition has a subscription to the message event. In case of an intermediate catch message event, the message event subscription is associated with a particular execution. Such message event subscriptions can be queried using an ExecutionQuery: Execution execution = runtimeService.createExecutionQuery() .messageEventSubscriptionName(\"paymentReceived\") .processVariableValueEquals(\"orderId\", message.getOrderId()) .singleResult(); Such queries are called correlation queries and usually require knowledge about the processes (in this case, there is a maximum of one process instance for a given orderId). Message Start Event A message start event can be used to start a process instance using a named message. This effectively allows us to select the right start event from a set of alternative start events using the message name. When deploying a process definition with one or more message start events, the following considerations apply: The name of the message start event must be unique across a given process definition, i.e., a process definition must not have multiple message start events with the same name. The engine throws an exception upon deployment of a process definition in case two or more message start events reference the same message or if two or more message start events reference messages with the same message name. The name of the message start event must be unique across all deployed process definitions. The engine throws an exception upon deployment of a process definition in case one or more message start events reference a message with the same name as a message start event already deployed by a different process definition. Process versioning: Upon deployment of a new version of a process definition, the message subscriptions of the previous version are canceled. This is also the case for message events that are not present in the new version. When starting a process instance, a message start event can be triggered using the following methods on the RuntimeService: ProcessInstance startProcessInstanceByMessage(String messageName); ProcessInstance startProcessInstanceByMessage(String messageName, Map<String, Object> processVariables); ProcessInstance startProcessInstanceByMessage(String messageName, String businessKey, Map<String, Object> processVariables); The messageName is the name given in the name attribute of the message element referenced by the messageRef attribute of the messageEventDefinition. The following considerations apply when starting a process instance: Message start events are only supported in top-level processes. Message start events are not supported in embedded sub processes. If a process definition has multiple message start events, runtimeService.startProcessInstanceByMessage(...) allows selection of the appropriate start event. If a process definition has multiple message start events and a single none start event, runtimeService.startProcessInstanceByKey(...) and runtimeService.startProcessInstanceById(...) start a process instance using the none start event. If a process definition has multiple message start events and no none start event, runtimeService.startProcessInstanceByKey(...) and runtimeService.startProcessInstanceById(...) throw an exception. If a process definition has a single message start event, runtimeService.startProcessInstanceByKey(...) and runtimeService.startProcessInstanceById(...) start a new process instance using the message start event. If a process is started from a call activity, message start event(s) are only supported if in addition to the message start event(s), the process has a single none start event the process has a single message start event and no other start events. The XML representation of a message start event is the normal start event declaration with a messageEventDefinition child-element: <definitions id=\"definitions\" xmlns=\"http://www.omg.org/spec/BPMN/20100524/MODEL\" xmlns:camunda=\"http://activiti.org/bpmn\" targetNamespace=\"Examples\" xmlns:tns=\"Examples\"> <message id=\"newInvoice\" name=\"newInvoiceMessage\" /> <process id=\"invoiceProcess\"> <startEvent id=\"messageStart\" > <messageEventDefinition messageRef=\"tns:newInvoice\" /> </startEvent> ... </process> </definitions> A process can be started using one of two different messages, this is useful if the process needs alternative ways to react to different start events but eventually continues in a uniform way. Message Intermediate Catching Event When a token arrives at the message intermediate catching event it will wait there until a message with the proper name arrives. As already described, the message must be handed into the engine via the appropriate API calls. The following example shows different message events in a process model: <intermediateCatchEvent id=\"message\"> <messageEventDefinition messageRef=\"newCustomerMessage\" /> </intermediateCatchEvent> Instead of the message intermediate catching event you might want to think about a Receive Task instead, which can serve similar purposes but is able to be used in combination with boundary events. In combination with the message intermediate catching event you might want to use an Event-based Gateway. Message Boundary Event Boundary events are catching events that are attached to an activity. This means that while the activity is running, the message boundary event is listening for named message. When this is caught, two things might happen, depending on the configuration of the boundary event: Interrupting boundary event: The activity is interrupted and the sequence flow going out of the event is followed. Non-interrupting boundary event: One token stays in the activity and an additional token is created which follows the sequence flow going out of the event. Message Intermediate Throwing Event A Message Intermediate Throwing event sends a message to an external service. This event has the same behavior as a Service Task. <intermediateThrowEvent id=\"message\"> <messageEventDefinition camunda:class=\"org.cibseven.bpm.MyMessageServiceDelegate\" /> </intermediateThrowEvent> Camunda Extensions for messageEventDefinition Attributes camunda:class, camunda:delegateExpression, camunda:expression, camunda:resultVariable, camunda:topic, camunda:type, camunda:taskPriority Extension Elements camunda:field, camunda:connector Constraints One of the attributes camunda:class, camunda:delegateExpression, camunda:type or camunda:expression is mandatory The attribute camunda:resultVariable can only be used in combination with the camunda:expression attribute The attribute camunda:type can only be set to external. The attribute camunda:topic can only be used when the camunda:type attribute is set to external. The attribute camunda:taskPriority can only be used when the camunda:type attribute is set to external. Message End Event When process execution arrives at a Message End Event, the current path of execution is ended and a message is sent. The Message End Event has the same behavior as a Service Task. <endEvent id=\"end\"> <messageEventDefinition camunda:class=\"org.cibseven.bpm.MyMessageServiceDelegate\" /> </endEvent> Camunda Extensions for messageEventDefinition Attributes camunda:class, camunda:delegateExpression, camunda:expression, camunda:resultVariable, camunda:topic, camunda:type, camunda:taskPriority Extension Elements camunda:field, camunda:connector Constraints One of the attributes camunda:class, camunda:delegateExpression, camunda:type or camunda:expression is mandatory The attribute camunda:resultVariable can only be used in combination with the camunda:expression attribute The attribute camunda:type can only be set to external. The attribute camunda:topic can only be used when the camunda:type attribute is set to external. The attribute camunda:taskPriority can only be used when the camunda:type attribute is set to external.",
    "url": "/manual/latest/reference/bpmn20/events/message-events/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/events/none-events/index.html",
    "title": "None Events | docs.cibseven.org",
    "content": "None events are unspecified events, also called ‘blank’ events. For instance, a ’none’ start event technically means that the trigger for starting the process instance is unspecified. This means that the engine cannot anticipate when the process instance must be started. The none start event is used when the process instance is started through the API by calling one of the startProcessInstanceBy... methods. ProcessInstance processInstance = runtimeService.startProcessInstanceByKey('invoice'); Note: a subprocess must always have a none start event. None End Event A ’none’ end event means that the result thrown when the event is reached is unspecified. As such, the engine will not do anything besides ending the current path of execution. The XML representation of a none end event is the normal end event declaration, without any sub-element (other end event types all have a sub-element declaring the type). <endEvent id=\"end\" name=\"my end event\" /> Intermediate None Event (throwing) The following process diagram shows a simple example of an intermediate none event, which is often used to indicate some state achieved in the process. This can be a good hook to monitor some KPI’s, basically by adding an execution listener <intermediateThrowEvent id=\"noneEvent\"> <extensionElements> <camunda:executionListener class=\"org.cibseven.bpm.engine.test.bpmn.event.IntermediateNoneEventTest$MyExecutionListener\" event=\"start\" /> </extensionElements> </intermediateThrowEvent> You can add some own code to the execution listener to maybe send some event to your BAM tool or DWH. The engine itself doesn’t do anything in the event, it just passes through it. Camunda Extensions Attributes camunda:asyncBefore, camunda:asyncAfter, camunda:exclusive, camunda:jobPriority Extension Elements camunda:failedJobRetryTimeCycle, camunda:inputOutput Constraints The camunda:exclusive attribute is only evaluated if the attribute camunda:asyncBefore or camunda:asyncAfter is set to true",
    "url": "/manual/latest/reference/bpmn20/events/none-events/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/events/signal-events/index.html",
    "title": "Signal Events | docs.cibseven.org",
    "content": "Signal events are events which reference a named signal. A signal is an event of global scope (broadcast semantics) and is delivered to all active handlers. The following is an example of two separate processes communicating using signals. The first process is started if an insurance policy is updated or changed. After the changes have been reviewed by a human participant, a signal event is thrown, signaling that a policy has changed: This event can now be caught by all process instances which are interested. The following is an example of a process subscribing to the event. Note: It is important to understand that a signal event is broadcast to all active handlers. In the example given above this means that all instances of the process catching the signal would receive the event. Signal Event Definition A signal event definition is declared using the signalEventDefinition element. The attribute signalRef references a signal element declared as a child element of the definitions root element. The following is an excerpt of a process in which a signal event is thrown and caught by intermediate events. The signalEventDefinitions reference the ‘global’ signal element. <definitions> <!-- declaration of the signal --> <signal id=\"alertSignal\" name=\"alert\" /> <process id=\"catchSignal\"> <intermediateThrowEvent id=\"throwSignalEvent\" name=\"Alert\"> <!-- signal event definition --> <signalEventDefinition signalRef=\"alertSignal\" /> </intermediateThrowEvent> <!-- ... --> <intermediateCatchEvent id=\"catchSignalEvent\" name=\"On Alert\"> <!-- signal event definition --> <signalEventDefinition signalRef=\"alertSignal\" /> </intermediateCatchEvent> <!-- ... --> </process> </definitions> Note: Contrary to other events, such error events, a signal is not consumed if it is caught. If you have two active signal boundary events catching the same signal event, both boundary events are triggered, even if they are part of different process instances. Expressions You can use expressions for the name in the signal event definition. The name is then resolved as soon as a process reaches the scope of the signal. For example when the process instances reaches a Signal Intermediate Catching Event, then the expression within the name is resolved. By using expressions within the signal name you can influence the signal name dynamically based on process variables. This could come in handy when for example there is the need to interrupt parallel branches. An example could look like follows: <signal id=\"alertSignal\" name=\"alert-${execution.processBusinessKey}\" /> Signal Api Triggering (Throwing) Signals A signal can either be thrown by a process instance using a BPMN construct or programmatically using Java API. The RuntimeService provides a fluent API to throw a signal programmatically: // broadcast signal runtimeService .createSignalEvent(\"signalName\") .setVariables(variables) .send(); // deliver a signal to a single execution runtimeService .createSignalEvent(\"signalName\") .executionId(executionId) .setVariables(variables) .send(); Additionally, you can use one of the following methods offered by the RuntimeService: RuntimeService.signalEventReceived(String signalName); RuntimeService.signalEventReceived(String signalName, String executionId); If an execution id is specified then the signal is only delivered to the specific execution. Otherwise, the signal is thrown globally to all subscribed handlers (broadcast semantics). Note: The signal event does not perform any kind of correlation to a specific process instance. On the contrary, it is broadcast to all process instances. If you need to exclusively deliver a signal to a specific process instance, do not use the throwing signal event. Instead, perform the correlation manually using the appropriate query mechanisms and deliver the signal to a specific execution programmatically. Querying for Signal Event Subscriptions It is possible to query for all executions which have subscribed to a specific signal event: List<Execution> executions = runtimeService.createExecutionQuery() .signalEventSubscriptionName(\"alert\") .list(); You could then use the signal API to deliver the signal to these executions. Catching Signal Events Signal Start Event A signal start event can be used to start a process instance using a named signal. When deploying a process definition with one or more signal start events, the following considerations apply: The name of the signal start event must be unique across a given process definition, i.e., a process definition must not have multiple signal start events with the same name. The engine throws an exception upon deployment of a process definition in case two or more signal start events reference the same signal or if two or more signal start events reference signals with the same signal name. Contrary to message start events, the name of the signal start event does not have to be unique across all deployed process definitions. Process versioning: Upon deployment of a new version of a process definition, the signal subscriptions of the previous version are canceled. This is also the case for signal events that are not present in the new version. A process instance of a process definition with one or more signal start events will be started, when a signal with the proper name is thrown. The signal can either be thrown by a process instance (i.e., on intermediate throwing signal event or signal end event) or using the following methods on the RuntimeService: void signalEventReceived(String signalName); void signalEventReceived(String signalName, Map<String, Object> processVariables); Note: A thrown signal can start multiple process instances when multiple process definitions have a signal start event with the same signal name. The XML representation of a signal start event is the normal start event declaration with a signalEventDefinition child-element: <startEvent id=\"signalStart\" > <signalEventDefinition signalRef=\"alertSignal\" /> </startEvent> Signal Intermediate Catching Event When a token arrives at the signal intermediate catching event, it will wait there until a signal with the proper name arrives. <intermediateCatchEvent id=\"signal\"> <signalEventDefinition signalRef=\"newCustomerSignal\" /> </intermediateCatchEvent> Camunda Extensions The following extensions are supported for the Signal Intermediate Catching Event: Attributes – Extension Elements camunda:inputOutput Constraints – Signal Boundary Event When an execution arrives in the activity to which the signal boundary event is attached, the signal boundary event catches signals with the proper name. Note: Contrary to other events, such as the error boundary event, a signal boundary event does not only catch signal events thrown from the scope it is attached to. A signal event has a global scope (broadcast semantics), meaning that the signal can be thrown from any place, even from a different process instance. <boundaryEvent id=\"boundary\" attachedToRef=\"task\" cancelActivity=\"true\"> <signalEventDefinition signalRef=\"alertSignal\"/> </boundaryEvent> Throwing Signal Events Signal Intermediate Throwing Event A signal intermediate throwing event throws a signal event for a defined signal. The signal is broadcast to all active handlers (i.e., all catching signal events). Signals can be published synchronously or asynchronously. In the default configuration, the signal is delivered synchronously. This means that the throwing process instance waits until the signal is delivered to all catching process instances. The catching process instances are also notified in the same transaction as the throwing process instance, which means that if one of the notified instances produces a technical error (throws an exception), all involved instances fail. A signal can also be delivered asynchronously. In that case it is determined which handlers are active at the time the throwing signal event is reached. For each active handler, an asynchronous notification message (Job) is stored and delivered by the JobExecutor. A signal intermediate event is defined as an intermediate throwing event. In this case, the specific type sub-element is a signalEventDefinition element. <intermediateThrowEvent id=\"signal\"> <signalEventDefinition signalRef=\"newCustomerSignal\" /> </intermediateThrowEvent> An asynchronous signal event would look like this: <intermediateThrowEvent id=\"signal\"> <signalEventDefinition signalRef=\"newCustomerSignal\" camunda:asyncBefore=\"true\" /> </intermediateThrowEvent> Signal End Event A signal end event throws a signal event for a defined signal and the current path of execution is ended. It has the same behavior as a signal intermediate throwing event. <endEvent id=\"signal\"> <signalEventDefinition signalRef=\"newCustomerSignal\" /> </endEvent> Passing Variables It is possible to pass process variables from the signal-throwing process instance, to all of the signal-catching process instances. The data is copied into a signal-catching process instance when it is started with a Signal Start Event, or before it leaves the wait-state in a Signal Intermediate Catching Event. <signalEventDefinition signalRef=\"newCustomerSignal\"> <extensionElements> <camunda:in source=\"throwingVariableName\" target=\"catchingVariableName\" /> </extensionElements> </signalEventDefinition> The variables declared in the “camunda:in” elements are set in the highest possible variable scope at the signal-catching process instance. It is also possible to use expressions and modify the data before it is passed on to the signal-catching process instances. <signalEventDefinition signalRef=\"newCustomerSignal\"> <extensionElements> <camunda:in sourceExpression=\"${X + 5}\" target=\"Y\" /> </extensionElements> </signalEventDefinition> The Y process variable at the signal-catching process instances will have the value of (X + 5), where X is a process variable of the signal-throwing process instance. Moreover, it can be declared that all of the process variable of the signal-throwing process instance be passed to the signal-catching processes. <signalEventDefinition signalRef=\"newCustomerSignal\"> <extensionElements> <camunda:in variables=\"all\" /> </extensionElements> </signalEventDefinition> By setting local=“true”, only the local variables of the execution executing the Throwing Signal Event will be passed to the signal-catching process instances. These are the variables that can be declared as input parameters. <signalEventDefinition signalRef=\"newCustomerSignal\"> <extensionElements> <camunda:in variables=\"all\" local=\"true\" /> </extensionElements> </signalEventDefinition> It is possible to use multiple of the above-mentioned options at once. For example (below), it can be declared that only the local variables are passed, a higher-scope variable, and an expression including the same, higher-scope variable. <signalEventDefinition signalRef=\"newCustomerSignal\"> <extensionElements> <camunda:in variables=\"all\" local=\"true\" /> <camunda:in source=\"X\" target=\"Y\" /> <camunda:in sourceExpression=\"${X + 5}\" target=\"Z\" /> </extensionElements> </signalEventDefinition> Passing a Business Key In addition to passing process variables to the signal-catching process instances, it is also possible to pass a Business Key. However, this Business Key passing can only be applied to process instances that use a Signal Start Event. <signalEventDefinition signalRef=\"newCustomerSignal\"> <extensionElements> <camunda:in businessKey=\"${execution.processBusinessKey}\" /> </extensionElements> </signalEventDefinition> The business key “camunda:in” element can be used in combination with the process variable passing “camunda:in” elements. Camunda Extensions The following extensions are supported for the Signal Intermediate and End Throwing Events: Attributes – Extension Elements camunda:in, camunda:failedJobRetryTimeCycle, camunda:inputOutput Constraints – Additional Resources Signal Events in the BPMN 2.0 Modeling Reference",
    "url": "/manual/latest/reference/bpmn20/events/signal-events/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/events/start-events/index.html",
    "title": "Start Events | docs.cibseven.org",
    "content": "Start events define where a Process or Sub Process starts. The process engine supports different types of start events: Blank Timer Message Signal Conditional The engine requires at least one start event to instantiate a process. There can be a maximum of one blank or timer start event per process definition. There can be multiple message or signal start events. Asynchronous Instantiation A start event may be declared as asynchronous with camunda:asyncBefore=\"true\" <startEvent id=\"startEvent\" camunda:asyncBefore=\"true\" /> This will ensure that the process engine creates a process instance when the process is instantiated, but the execution of the initial activities is not done synchronously. Instead, a job is created and asynchronously processed by the job executor. See the Asynchronous Continuations section of the User Guide for some background information. Camunda Extensions Attributes camunda:asyncBefore, camunda:asyncAfter, camunda:exclusive, camunda:formHandlerClass, camunda:formKey, camunda:formRef, camunda:formRefBinding, camunda:formRefVersion, camunda:initiator, camunda:jobPriority Extension Elements camunda:failedJobRetryTimeCycle, camunda:formData, camunda:formProperty, Constraints The camunda:exclusive attribute is only evaluated if the attribute camunda:asyncBefore or camunda:asyncAfter is set to true The attributes camunda:asyncBefore and camunda:initiator are only available for start events of a Process Only one camunda:formData extension element is allowed The attributes camunda:formHandlerClass and camunda:formKey are only available for the intital start event of a Process",
    "url": "/manual/latest/reference/bpmn20/events/start-events/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/events/terminate-event/index.html",
    "title": "Terminate Events | docs.cibseven.org",
    "content": "A terminate event ends the complete scope it is raised in and all contained inner scopes. It is useful if you have a parallel token flow in a process and you want to consume all tokens available in the same scope immediately. A terminate event on process instance level terminates the complete instance. On subprocess level the current scope and all contained processes instances will be terminated. Terminate Event Definition A terminate event is modeled as an end event with an additional definition element to mark the termination: <process id=\"someProcess\"> <!-- ... --> <endEvent id=\"EndEvent_2\" name=\"Tweet rejected\"> <terminateEventDefinition id=\"TerminateEventDefinition_1\"/> <endEvent> <!-- ... --> </process> Camunda Extensions Attributes camunda:asyncBefore, camunda:asyncAfter, camunda:exclusive, camunda:jobPriority Extension Elements camunda:inputOutput Constraints – Additional Resources Terminate Events in the BPMN 2.0 Modeling Reference",
    "url": "/manual/latest/reference/bpmn20/events/terminate-event/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/events/timer-events/index.html",
    "title": "Timer Events | docs.cibseven.org",
    "content": "Timer events are events which are triggered by a defined timer. They can be used as start event, intermediate event or boundary event. Boundary events can be interrupting or not. Configuration Timers are only fired when the Job Executor is enabled. Defining a Timer Timers are configured using an ISO 8601 time format. A timer definition must have exactly one of the following elements. Time Date This format specifies a fixed time and date in adhering to the ISO 8601 format, when the trigger will be fired. Example: <timerEventDefinition> <timeDate>2011-03-11T12:13:14Z</timeDate> </timerEventDefinition> Time Duration To specify how long the timer should run before it is fired, a timeDuration can be specified as a sub-element of timerEventDefinition. It is possible to define the duration in two different ISO 8601 Durations formats: PnYnMnDTnHnMnS PnW Example (interval lasting 10 days): <timerEventDefinition> <timeDuration>P10D</timeDuration> </timerEventDefinition> Time Cycle Specifies repeating intervals, which can be useful for starting process periodically, or for sending multiple reminders for overdue user tasks. A time cycle element can be in two formats. One option is the format of recurring time duration, as specified by the ISO 8601 Repeating Intervals standard. Example (3 repeating intervals, each lasting 10 hours): <timerEventDefinition> <timeCycle>R3/PT10H</timeCycle> </timerEventDefinition> Additionally, you can specify a time cycle using cron expressions, the example below shows a trigger firing every 5 minutes, starting at full hour: 0 0/5 * * * ? Please see the CronTrigger Tutorial for additional information about using cron expressions. Note: The first symbol denotes seconds, not minutes as in normal Unix cron. The recurring time duration option is better suited for handling relative timers, which are calculated in respect to some particular point in time (e.g., the time when a user task was started), while cron expressions can handle absolute timers - which is particularly useful for timer start events. Modify a Time Cycle A timer’s repeat cycle can be controlled via the REST API or by calling the ManagementService. By setting the due date of a timer, it is possible to change the point in time when a timer is executed. managementService.setJobDuedate(String jobId, Date newDuedate) Changes to one timer instance do not automatically affect subsequent timer instances. For example, a certain recurring timer produces a timer event every 30 minutes. If the due date of one timer event is changed (e.g. +15minutes), it would be executed 45 minutes after the previous timer. However, the following timer would follow the old pattern and would execute 15 minutes after the changed timer. If the desired outcome is to calculate the due dates of all subsequent timers based on the changes made, then it is possible to pass a cascade flag (when using the REST API) or use the following Java API method: managementService.setJobDuedate(String jobId, Date newDuedate, boolean cascade) Expressions You can use expressions for the timer event definitions. By doing so you can influence the timer definition based on process variables. The process variables must contain the ISO 8601 (or cron for cycle type) string for the appropriate timer type. <boundaryEvent id=\"escalationTimer\" cancelActivity=\"true\" attachedToRef=\"firstLineSupport\"> <timerEventDefinition> <timeDuration>${duration}</timeDuration> </timerEventDefinition> </boundaryEvent> Re-evaluate a time cycle A timer’s repeat cycle can be updated if the defined expression is changed. This is achieved by re-evaluation of the expression next time when a timer is fired. So the new cycle will be effective from the next scheduled timer. Let’s observe a scenario with the following timer defined where myBean.getCycle()=\"R3/PT2H\": <startEvent id=\"theStart\"> <timerEventDefinition> <timeCycle>#{myBean.getCycle()}</timeCycle> </timerEventDefinition> </startEvent> Let’s assume the timer is meant to fire at 1 p.m., 3 p.m., and 5 p.m. At 4 p.m., after the timer has fired two times, we adjust the bean to return myBean.getCycle()=\"R2/PT30M\". In effect, the timer will still be triggered at 5 p.m. (as initially scheduled and calculated by the previous cycle). Afterward, it will fire at 5:30 p.m. and 6 p.m. (based on the new cycle). The feature is disabled by default. To enable it, set the reevaluateTimeCycleWhenDue property to true in the process engine configuration. Heads-up! To enforce an immediate re-evaluation of a time cycle, follow the steps: Change the expression of the time cycle (e.g., Adjust the Spring bean that resolves the cycle). Update the current timer job due date: via Java API: ManagementService#setJobDuedate via REST API: Job/operation/setJobDuedate via Cockpit: Navigate to the Job view of the currently running process instance and select “Change due date for this Job” button. After this job is executed, the next jobs will be created with adjusted time cycle. Handling of Timezones The configuration 2022-03-11T12:13:14 does not specify a time zone. At runtime, such a date is interpreted in the local time zone of the JVM executing the process. This can be problematic in various cases, such as when running multiple CIB seven nodes in different time zones or when you cannot assume the time zone the platform runs in. Furthermore, there can be glitches with respect to daylight saving time (DST). If in doubt, specify the time in UTC (e.g., 2022-03-11T12:13:14Z) or with a UTC-relative offset (e.g., 2022-03-11T12:13:14+01). CIB seven Extensions Attributes camunda:asyncBefore, camunda:asyncAfter, camunda:exclusive, camunda:jobPriority Extension Elements camunda:failedJobRetryTimeCycle, camunda:inputOutput Constraints – Timer Start Event A timer start event is used to create process instance at a given time. It can be used both for processes which should start only once and for processes that should start in specific time intervals. Note: A subprocess cannot have a timer start event. Note: A timer start event is scheduled as soon as process is deployed. There is no need to call startProcessInstanceBy..., although calling start process methods is not restricted and will cause one more start of the process at the time of the startProcessInstanceBy... invocation. The XML representation of a timer start event is the normal start event declaration, with a timer definition sub-element. The following example process will start 4 times, in 5 minute intervals, starting on 11th of March 2022, at 12:13 (UTC +01, 24 hour clock system): <startEvent id=\"theStart\"> <timerEventDefinition> <timeCycle>R4/2022-03-11T12:13+01/PT5M</timeCycle> </timerEventDefinition> </startEvent> and this process will start once, on a selected date, at Greenwich time: <startEvent id=\"theStart\"> <timerEventDefinition> <timeDate>2022-03-11T12:13:14Z</timeDate> </timerEventDefinition> </startEvent> Timer Intermediate Catching Event A timer intermediate event acts as a stopwatch. When an execution arrives in catching event activity, a timer is started. When the timer fires (e.g., after a specified interval), the sequence flow going out of the timer intermediate event is followed. A timer intermediate event is defined as an intermediate catching event. The specific type sub-element in this case is a timerEventDefinition element. <intermediateCatchEvent id=\"timer\"> <timerEventDefinition> <timeDuration>PT5M</timeDuration> </timerEventDefinition> </intermediateCatchEvent> Timer Boundary Event A timer boundary event acts as a stopwatch and as an alarm clock. When an execution arrives in the activity to which the boundary event is attached, a timer is started. When the timer fires (e.g., after a specified interval), the activity is interrupted and the sequence flow going out of the timer boundary event are followed. There is the difference between an interrupting and a non interrupting timer event. The interrupting event is the default. The non-interrupting event leads to the original activity not being interrupted, the activity stays there. Instead, an additional execution is created and sent over the outgoing transition of the event. In the XML representation, the cancelActivity attribute is set to false: <boundaryEvent id=\"escalationTimer\" cancelActivity=\"false\" /> <timerEventDefinition> <timeDuration>PT4H</timeDuration> </timerEventDefinition> </boundaryEvent>",
    "url": "/manual/latest/reference/bpmn20/events/timer-events/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/gateways/event-based-gateway/index.html",
    "title": "Event-based Gateway | docs.cibseven.org",
    "content": "The event-based Gateway allows you to make a decision based on events. Each outgoing sequence flow of the gateway needs to be connected to an intermediate catching event. When process execution reaches an event-based Gateway, the gateway acts like a wait state: execution is suspended. In addition, an event subscription is created for each outgoing sequence flow. Note that the sequence flows running out of an event-based Gateway are different than ordinary sequence flows. These sequence flows are never actually “executed”. On the contrary, they allow the process engine to determine which events an execution arriving at an event-based Gateway needs to subscribe to. The following restrictions apply: An event-based Gateway must have two or more outgoing sequence flows. An event-based Gateway may only be followed by elements of the type intermediateCatchEvent. (Receive Tasks after an event-based Gateway are not supported by the engine yet.) An intermediateCatchEvent connected to an event-based Gateway must have a single incoming sequence flow. The following process is an example of a process with an event-based Gateway. When the execution arrives at the event-based Gateway, process execution is suspended. Additionally, the process instance subscribes to the alert signal event and creates a timer which fires after 10 minutes. This effectively causes the process engine to wait for ten minutes for a signal event. If the signal event occurs within 10 minutes, the timer is canceled and execution continues after the signal. If the signal is not fired, execution continues after the timer and the signal subscription is canceled. The corresponding xml looks like this: <definitions> <signal id=\"alertSignal\" name=\"alert\" /> <process id=\"catchSignal\"> <startEvent id=\"start\" /> <sequenceFlow sourceRef=\"start\" targetRef=\"gw1\" /> <eventBasedGateway id=\"gw1\" /> <sequenceFlow sourceRef=\"gw1\" targetRef=\"signalEvent\" /> <sequenceFlow sourceRef=\"gw1\" targetRef=\"timerEvent\" /> <intermediateCatchEvent id=\"signalEvent\" name=\"Alert\"> <signalEventDefinition signalRef=\"alertSignal\" /> </intermediateCatchEvent> <intermediateCatchEvent id=\"timerEvent\" name=\"Alert\"> <timerEventDefinition> <timeDuration>PT10M</timeDuration> </timerEventDefinition> </intermediateCatchEvent> <sequenceFlow sourceRef=\"timerEvent\" targetRef=\"exGw1\" /> <sequenceFlow sourceRef=\"signalEvent\" targetRef=\"task\" /> <userTask id=\"task\" name=\"Handle alert\"/> <exclusiveGateway id=\"exGw1\" /> <sequenceFlow sourceRef=\"task\" targetRef=\"exGw1\" /> <sequenceFlow sourceRef=\"exGw1\" targetRef=\"end\" /> <endEvent id=\"end\" /> </process> </definitions> Camunda Extensions Attributes camunda:asyncBefore, camunda:exclusive, camunda:jobPriority Extension Elements camunda:failedJobRetryTimeCycle, camunda:executionListener Constraints The camunda:exclusive attribute is only evaluated if the attribute camunda:asyncBefore is set to true Additional Resources Event-based Gateways in the BPMN 2.0 Modeling Reference",
    "url": "/manual/latest/reference/bpmn20/gateways/event-based-gateway/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/gateways/exclusive-gateway/index.html",
    "title": "Data-based Exclusive Gateway (XOR) | docs.cibseven.org",
    "content": "An exclusive gateway (also called the XOR gateway or, in more technical terms, the exclusive data-based gateway), is used to model a decision in the process. When the execution arrives at this gateway, all outgoing sequence flows are evaluated in the order in which they have been defined. The sequence flow which condition evaluates to ’true’ (or which doesn’t have a condition set, conceptually having a ’true’ value defined on the sequence flow) is selected for continuing the process. Note that only one sequence flow is selected when using the exclusive gateway. In case multiple sequence flow have a condition that evaluates to ’true’, the first one defined in the XML is exclusively selected for continuing the process. If no sequence flow can be selected (no condition evaluates to ’true’) this will result in a runtime exception, unless you have a default flow defined. One default flow can be set on the gateway itself in case no other condition matches - like an ’else’ in programming languages. Note that a gateway without an icon inside it defaults to an exclusive gateway, even if we recommend to use the X within the gateway if your BPMN tool gives you that option. The XML representation of an exclusive gateway is straightforward: one line defining the gateway and condition expressions defined on the outgoing sequence flow. The default flow (optional) is set as attribute on the gateway itself. Note that the name of the flow (used in the diagram, meant for the human being) might be different than the formal expression (used in the engine). <exclusiveGateway id=\"exclusiveGw\" name=\"Exclusive Gateway\" default=\"flow4\" /> <sequenceFlow id=\"flow2\" sourceRef=\"exclusiveGw\" targetRef=\"theTask1\" name=\"${x==1}\"> <conditionExpression xsi:type=\"tFormalExpression\">${x == 1}</conditionExpression> </sequenceFlow> <sequenceFlow id=\"flow3\" sourceRef=\"exclusiveGw\" targetRef=\"theTask2\" name=\"${x==2}\"> <conditionExpression xsi:type=\"tFormalExpression\">${x == 2}</conditionExpression> </sequenceFlow> <sequenceFlow id=\"flow4\" sourceRef=\"exclusiveGw\" targetRef=\"theTask3\" name=\"else\"> </sequenceFlow> Camunda Extensions Attributes camunda:asyncBefore, camunda:asyncAfter, camunda:exclusive, camunda:jobPriority Extension Elements camunda:failedJobRetryTimeCycle, camunda:executionListener Constraints The camunda:exclusive attribute is only evaluated if the attribute camunda:asyncBefore or camunda:asyncAfter is set to true Additional Resources Conditional and Default Sequence Flows Exclusive Gateways in the BPMN 2.0 Modeling Reference",
    "url": "/manual/latest/reference/bpmn20/gateways/exclusive-gateway/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/gateways/inclusive-gateway/index.html",
    "title": "Inclusive Gateway | docs.cibseven.org",
    "content": "The Inclusive Gateway can be seen as a combination of an exclusive and a parallel gateway. Like an exclusive gateway, you can define conditions on outgoing sequence flows and the inclusive gateway will evaluate them. However, the main difference is that the inclusive gateway can receive more than one sequence flow, like a parallel gateway. The functionality of the inclusive gateway is based on the incoming and outgoing sequence flows: fork: all outgoing sequence flow conditions are evaluated and for the sequence flow conditions that evaluate to ’true’, the flows are followed in parallel, creating one concurrent execution for each sequence flow. join: all concurrent executions arriving at the inclusive gateway wait at the gateway until an execution has arrived for each of the incoming sequence flows that have a process token. This is an important difference to the parallel gateway. So in other words, the inclusive gateway will only wait for the incoming sequence flows that are executed. After the join, the process continues past the joining inclusive gateway. Note that an inclusive gateway can have both fork and join behavior, if there are multiple incoming and outgoing sequence flows for the same inclusive gateway. In that case, the gateway will first join all incoming sequence flows that have a process token, before splitting into multiple concurrent paths of executions for the outgoing sequence flows that have a condition that evaluates to ’true'. Defining an inclusive gateway needs one line of XML: <inclusiveGateway id=\"myInclusiveGateway\" /> The actual behavior (fork, join or both) is defined by the sequence flows connected to the inclusive gateway. For example, the model above comes down to the following XML: <startEvent id=\"theStart\" /> <sequenceFlow id=\"flow1\" sourceRef=\"theStart\" targetRef=\"fork\" /> <inclusiveGateway id=\"fork\" /> <sequenceFlow sourceRef=\"fork\" targetRef=\"receivePayment\" > <conditionExpression xsi:type=\"tFormalExpression\">${paymentReceived == false}</conditionExpression> </sequenceFlow> <sequenceFlow sourceRef=\"fork\" targetRef=\"shipOrder\" > <conditionExpression xsi:type=\"tFormalExpression\">${shipOrder == true}</conditionExpression> </sequenceFlow> <userTask id=\"receivePayment\" name=\"Receive Payment\" /> <sequenceFlow sourceRef=\"receivePayment\" targetRef=\"join\" /> <userTask id=\"shipOrder\" name=\"Ship Order\" /> <sequenceFlow sourceRef=\"shipOrder\" targetRef=\"join\" /> <inclusiveGateway id=\"join\" /> <sequenceFlow sourceRef=\"join\" targetRef=\"archiveOrder\" /> <userTask id=\"archiveOrder\" name=\"Archive Order\" /> <sequenceFlow sourceRef=\"archiveOrder\" targetRef=\"theEnd\" /> <endEvent id=\"theEnd\" /> In the above example, after the process is started, two tasks are created if the process variables paymentReceived == false and shipOrder == true. In case only one of these conditions evaluates to true, only one task will be created. If no condition evaluates to true, an exception is thrown. This can be prevented by specifying a default outgoing sequence flow. In the following example one task will be created, the ship order task: HashMap<String, Object> variableMap = new HashMap<String, Object>(); variableMap.put(\"receivedPayment\", true); variableMap.put(\"shipOrder\", true); ProcessInstance pi = runtimeService.startProcessInstanceByKey(\"forkJoin\"); TaskQuery query = taskService.createTaskQuery() .processInstanceId(pi.getId()) .orderByTaskName() .asc(); List<Task> tasks = query.list(); assertEquals(1, tasks.size()); Task task = tasks.get(0); assertEquals(\"Ship Order\", task.getName()); When this task is completed, the second inclusive gateway joins the two executions and, since there is only one outgoing sequence flow, no concurrent paths of execution are created and only the Archive Order task is active. Note that an inclusive gateway does not need to be ‘balanced’ (i.e., a matching number of incoming/outgoing sequence flows for corresponding inclusive gateways). An inclusive gateway will simply wait for all incoming sequence flows and create a concurrent path of execution for each outgoing sequence flow, not influenced by other constructs in the process model. Camunda-specific behavior Note that in Camunda’s implementation of the inclusive gateway, the following holds: If the join waits for a token, but that token takes a different turn in the process so that it can no longer reach the join (e.g. because of a boundary event interrupting the flow), then the join will not trigger. The join will trigger when: it received a number of tokens greater or equal to the number of incoming sequence flows. The tokens do not necessarily need to reach the gateway through different sequence flows. it received a number of tokens smaller than the number of incoming sequence flows and there are no more tokens that can arrive at the gateway. The following examples show under which conditions an inclusive gateway will trigger a join: In the following scenario, Parallel Gateway 1 creates three execution tokens, but only two sequence flows join in the inclusive gateway. In this scenario, the inclusive gateway will trigger even with only two tokens since the tokens from Task 1 and Task 2 were joined in a single token by Parallel Gateway 2. In this scenario, Parallel Gateway 1 creates two execution tokens, and three sequence flows join in the inclusive gateway. In this scenario, the inclusive gateway will trigger with three tokens since Parallel Gateway 2 splits the single token from Task 1 into two separate tokens for Task 3 and Task 4. In the diagram below, the parallel gateway creates two execution tokens. The first execution token will wait at User Task 1, and the second will reach the Inclusive Gateway. The Inclusive Gateway will trigger immediately for the first token, and a second time, for the second token, as both tokens arrive on the same sequence flow. As a result, there will be two instances of User Task 2 that will need to be completed. In the last scenario, the parallel gateway creates two execution tokens. The first execution token will wait at User Task 1, and the second will reach the Inclusive Gateway 2 and wait for the gateway to trigger. However, the Inclusive Gateway 2 will not trigger a join until User Task 1 is completed and the second token arrives at the gateway. As a result, the Inclusive Gateway 2 will trigger only once instead of two times. According to the BPMN 2.0 specification, since both tokens pass the same sequence flow (true), the inclusive gateway should trigger twice. Finally, due to this behavior, only one instance of User Task 2 will need to be completed instead of the expected two. In cases like this one, it is recommended to use an Exclusive Gateway instead of the Inclusive Gateway 1. Camunda Extensions Attributes camunda:asyncBefore, camunda:asyncAfter, camunda:exclusive, camunda:jobPriority Extension Elements camunda:failedJobRetryTimeCycle, camunda:executionListener Constraints The camunda:exclusive attribute is only evaluated if the attribute camunda:asyncBefore or camunda:asyncAfter is set to true Additional Resources Inclusive Gateways in the BPMN 2.0 Modeling Reference Conditional and Default Sequence Flows",
    "url": "/manual/latest/reference/bpmn20/gateways/inclusive-gateway/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/gateways/index.html",
    "title": "Gateways | docs.cibseven.org",
    "content": "Gateways control token flow in a process. They allow modeling decisions based on data and events as well as fork / join concurrency.",
    "url": "/manual/latest/reference/bpmn20/gateways/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/gateways/parallel-gateway/index.html",
    "title": "Parallel Gateway | docs.cibseven.org",
    "content": "Gateways can also be used to model concurrency in a process. The most straightforward gateway to introduce concurrency in a process model is the Parallel Gateway, which allows forking into multiple paths of execution or joining multiple incoming paths of execution. The functionality of the parallel gateway is based on the incoming and outgoing sequence flow(s): fork: all outgoing sequence flows are followed in parallel, creating one concurrent execution for each sequence flow. join: all concurrent executions arriving at the parallel gateway wait at the gateway until an execution has arrived for each of the incoming sequence flows. Then the process continues past the joining gateway. Limitation Note that in Camunda’s implementation of the parallel gateway, the gateway triggers as soon as the following holds: The number of arrived tokens is equal to the number of incoming sequence flows. It is not required that a token arrives on every incoming flow. Note that a parallel gateway can have both fork and join behaviors, if there are multiple incoming and outgoing sequence flows for the same parallel gateway. In that case, the gateway will first join all incoming sequence flows, before splitting into multiple concurrent paths of executions. An important difference with other gateway types is that the parallel gateway does not evaluate conditions. If conditions are defined on the sequence flow connected with the parallel gateway, they are simply ignored. Defining a parallel gateway needs one line of XML: <parallelGateway id=\"myParallelGateway\" /> The actual behavior (fork, join or both), is defined by the sequence flow connected to the parallel gateway. For example, the model above comes down to the following XML: <startEvent id=\"theStart\" /> <sequenceFlow id=\"flow1\" sourceRef=\"theStart\" targetRef=\"fork\" /> <parallelGateway id=\"fork\" /> <sequenceFlow sourceRef=\"fork\" targetRef=\"receivePayment\" /> <sequenceFlow sourceRef=\"fork\" targetRef=\"shipOrder\" /> <userTask id=\"receivePayment\" name=\"Receive Payment\" /> <sequenceFlow sourceRef=\"receivePayment\" targetRef=\"join\" /> <userTask id=\"shipOrder\" name=\"Ship Order\" /> <sequenceFlow sourceRef=\"shipOrder\" targetRef=\"join\" /> <parallelGateway id=\"join\" /> <sequenceFlow sourceRef=\"join\" targetRef=\"archiveOrder\" /> <userTask id=\"archiveOrder\" name=\"Archive Order\" /> <sequenceFlow sourceRef=\"archiveOrder\" targetRef=\"theEnd\" /> <endEvent id=\"theEnd\" /> In the above example, after the process is started, two tasks are created: ProcessInstance pi = runtimeService.startProcessInstanceByKey(\"forkJoin\"); TaskQuery query = taskService.createTaskQuery() .processInstanceId(pi.getId()) .orderByTaskName() .asc(); List<Task> tasks = query.list(); assertEquals(2, tasks.size()); Task task1 = tasks.get(0); assertEquals(\"Receive Payment\", task1.getName()); Task task2 = tasks.get(1); assertEquals(\"Ship Order\", task2.getName()); When these two tasks are completed, the second parallel gateway joins the two executions and, as there is only one outgoing sequence flow, no concurrent paths of execution are created and only the Archive Order task is active. Note that a parallel gateway does not need to be ‘balanced’ (i.e., a matching number of incoming/outgoing sequence flows for corresponding parallel gateways). A parallel gateway will simply wait for all incoming sequence flows and create a concurrent path of execution for each outgoing sequence flow, not influenced by other constructs in the process model. So, the following process is legal in BPMN 2.0: Camunda Extensions Attributes camunda:asyncBefore, camunda:asyncAfter, camunda:exclusive, camunda:jobPriority Extension Elements camunda:failedJobRetryTimeCycle, camunda:executionListener Constraints The camunda:exclusive attribute is only evaluated if the attribute camunda:asyncBefore or camunda:asyncAfter is set to true Additional Resources Parallel Gateways in the BPMN 2.0 Modeling Reference",
    "url": "/manual/latest/reference/bpmn20/gateways/parallel-gateway/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/gateways/sequence-flow/index.html",
    "title": "Conditional and Default Sequence Flows | docs.cibseven.org",
    "content": "A sequence flow is the connector between two elements of a process. After an element is visited during process execution, all outgoing sequence flows are followed. This means that the default nature of BPMN 2.0 is to be parallel: two outgoing sequence flows will create two separate, parallel paths of execution. Camunda Extensions Attributes – Extension Elements camunda:executionListener Constraints – Conditional Sequence Flow A sequence flow can have a condition defined on it. When a BPMN 2.0 activity is left, the default behavior is to evaluate the conditions on the outgoing sequence flows. When a condition evaluates to ’true’, that outgoing sequence flow is selected. When multiple sequence flows are selected that way, multiple executions will be generated and the process is continued in a parallel way. Note: This is different for gateways. Gateways will handle sequence flows with conditions in specific ways, depending on the gateway type. A conditional sequence flow is represented in XML as a regular sequence flow, containing a conditionExpression sub-element. Note that at the moment only tFormalExpressions are supported. Omitting the xsi:type=\"\" definition will simply default to this type of expression. <sequenceFlow id=\"flow\" sourceRef=\"theStart\" targetRef=\"theTask\"> <conditionExpression xsi:type=\"tFormalExpression\"> <![CDATA[${order.price > 100 && order.price < 250}]]> </conditionExpression> </sequenceFlow> Currently, conditionalExpressions can be used with UEL and scripts. The expression or script used should resolve to a boolean value, otherwise an exception is thrown while evaluating the condition. The example below references data of a process variable, in the typical JavaBean style through getters. <conditionExpression xsi:type=\"tFormalExpression\"> <![CDATA[${order.price > 100 && order.price < 250}]]> </conditionExpression> This example invokes a method that resolves to a boolean value. <conditionExpression xsi:type=\"tFormalExpression\"> <![CDATA[${order.isStandardOrder()}]]> </conditionExpression> In this example a simple groovy script is used to evaluate a process variable status. <conditionExpression xsi:type=\"tFormalExpression\" language=\"groovy\"> <![CDATA[status == 'complete']]> </conditionExpression> Similar to a script task, an external script resource can also be specified (see the documentation on script source for more information). <conditionExpression xsi:type=\"tFormalExpression\" language=\"groovy\" camunda:resource=\"org/cibseven/bpm/exampe/condition.groovy\" /> Extensions for conditionExpression Attributes camunda:resource Extension Elements – Constraints – Default Sequence Flow All BPMN 2.0 tasks and gateways can have a default sequence flow. This sequence flow is only selected as the outgoing sequence flow for that activity if none of the other sequence flows could be selected. Conditions on a default sequence flow are always ignored. A default sequence flow for a certain activity is defined by the default attribute on that activity. The following example shows an exclusive gateway with a default sequence flow. Only when x is neither 1 nor 2 it will be selected as outgoing sequence flow for the gateway. Note the ‘slash’ marker at the beginning of the default sequence flow. The corresponding XML snippet shows how flow4 is configured as a default sequence flow. <exclusiveGateway id=\"exclusiveGw\" name=\"Exclusive Gateway\" default=\"flow4\" /> <sequenceFlow id=\"flow2\" sourceRef=\"exclusiveGw\" targetRef=\"theTask1\" name=\"${x==1}\"> <conditionExpression xsi:type=\"tFormalExpression\">${x == 1}</conditionExpression> </sequenceFlow> <sequenceFlow id=\"flow3\" sourceRef=\"exclusiveGw\" targetRef=\"theTask2\" name=\"${x==2}\"> <conditionExpression xsi:type=\"tFormalExpression\">${x == 2}</conditionExpression> </sequenceFlow> <sequenceFlow id=\"flow4\" sourceRef=\"exclusiveGw\" targetRef=\"theTask3\" name=\"else\"> </sequenceFlow>",
    "url": "/manual/latest/reference/bpmn20/gateways/sequence-flow/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/index.html",
    "title": "BPMN 2.0 Implementation Reference | docs.cibseven.org",
    "content": "This page gives you an overview of the BPMN 2.0 elements and the current coverage of the process engine. BPMN - Business Process Model and Notation If you are unfamiliar with BPMN 2.0, you might want to check out the BPMN Tutorial first. Coverage The elements marked in orange are supported. Symbols Participants Pool Lane Subprocesses Subprocess Call Activity Event Subprocess Transaction Tasks Service Task User Task Script Task Business Rule Task Manual Task Receive Task Undefined Task Send Task Receive Task (instantiated) Gateways XOR OR AND Event Complex Data Data Object Data Store Artifacts Text Annotation Group Events In BPMN there are start events, intermediate events and end events. These three event types can be catching events or throwing events. Intermediate events can be used as boundary events on tasks, in which case they can be interrupting or non-interrupting. This gives you a lot of flexibility to use events in your processes. Understanding BPMN Events To help understand the principle behavior of events in BPMN, we recommend to check the Events: Basic Concepts chapter of the BPMN Modeling Reference. Type Start Intermediate End Normal Event Subprocess Event Subprocess non-interrupt catch boundary boundary non-interrupt throw None Message Timer Conditional Link Signal Error Escalation Termination Compensation Cancel Multiple Multiple Parallel",
    "url": "/manual/latest/reference/bpmn20/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/subprocesses/call-activity/index.html",
    "title": "Call Activity | docs.cibseven.org",
    "content": "BPMN 2.0 makes a distinction between an embedded subprocess and a call activity. From a conceptual point of view, both will call a subprocess when process execution arrives at the activity. The difference is that the call activity references a process that is external to the process definition, whereas the subprocess is embedded within the original process definition. The main use case for the call activity is to have a reusable process definition that can be called from multiple other process definitions. Although not yet part of the BPMN specification, it is also possible to call a CMMN case definition. When process execution arrives at the call activity, a new process instance is created, which is used to execute the subprocess, potentially creating parallel child executions as within a regular process. The main process instance waits until the subprocess is completely ended, and continues the original process afterwards. A call activity is visualized the same way as a collapsed embedded subprocess, however with a thick border. Depending on the modeling tool, a call activity can also be expanded, but the default visualization is the collapsed representation. A call activity is a regular activity that requires a calledElement which references a process definition by its key. In practice, this means that the id of the process is used in the calledElement: <callActivity id=\"callCheckCreditProcess\" name=\"Check credit\" calledElement=\"checkCreditProcess\" /> Note that the process definition of the subprocess is resolved at runtime. This means that the subprocess can be deployed independently from the calling process, if needed. CalledElement Binding In a call activity the calledElement attribute contains the process definition key as reference to the subprocess. This means that the latest process definition version of the subprocess is always called. To call another version of the subprocess it is possible to define the attributes calledElementBinding, calledElementVersion, and calledElementVersionTag in the call activity. These attributes are optional. CalledElementBinding has four different values: latest: always call the latest process definition version (which is also the default behaviour if the attribute isn’t defined) deployment: if called process definition is part of the same deployment as the calling process definition, use the version from deployment version: call a fixed version of the process definition, in this case calledElementVersion is required. The version number can either be specified in the BPMN XML or returned by an expression (see custom extensions) versionTag: call a fixed version tag of the process definition, in this case calledElementVersionTag is required. The version tag can either be specified in the BPMN XML or returned by an expression (see custom extensions) <callActivity id=\"callSubProcess\" calledElement=\"checkCreditProcess\" camunda:calledElementBinding=\"latest|deployment|version\" camunda:calledElementVersion=\"17\"> </callActivity> or <callActivity id=\"callSubProcess\" calledElement=\"checkCreditProcess\" camunda:calledElementBinding=\"versionTag\" camunda:calledElementVersionTag=\"ver-tag-1.0.1\"> </callActivity> CalledElement Tenant Id When the call activity resolves the process definition to be called it must take multi tenancy into account. Default Tenant Resolution By default, the tenant id of the calling process definition is used to resolve the called process definition. That is, if the calling process definition has no tenant id, then the call activity resolves a process definition using the provided key, binding and without a tenant id (tenant id = null). If the calling process definition has a tenant id, a process definition with the provided key and the same tenant id is resolved. Note that the tenant id of the calling process instance is not taken into account in the default behavior. Explicit Tenant Resolution In some situations it may be useful to override this default behavior and specify the tenant id explicitly. The camunda:calledElementTenantId attribute allows to explicitly specify a tenant id: <callActivity id=\"callSubProcess\" calledElement=\"checkCreditProcess\" camunda:calledElementTenantId=\"TENANT_1\"> </callActivity> If the tenant id is not known at design time, an expression can be used as well: <callActivity id=\"callSubProcess\" calledElement=\"checkCreditProcess\" camunda:calledElementTenantId=\"${ myBean.calculateTenantId(variable) }\"> </callActivity> An expression also allows using the tenant id of the calling process instance instead of the calling process definition: <callActivity id=\"callSubProcess\" calledElement=\"checkCreditProcess\" camunda:calledElementTenantId=\"${ execution.tenantId }\"> </callActivity> Passing Variables You can pass process variables to the subprocess and vice versa. The data is copied into the subprocess when it is started and copied back into the main process when it ends. <callActivity id=\"callSubProcess\" calledElement=\"checkCreditProcess\" > <extensionElements> <camunda:in source=\"someVariableInMainProcess\" target=\"nameOfVariableInSubProcess\" /> <camunda:out source=\"someVariableInSubProcss\" target=\"nameOfVariableInMainProcess\" /> </extensionElements> </callActivity> By default, variables declared in out elements are set in the highest possible variable scope. Furthermore, you can configure the call activity so that all process variables are passed to the subprocess and vice versa. The process variables have the same name in the main process as in the subprocess. <callActivity id=\"callSubProcess\" calledElement=\"checkCreditProcess\" > <extensionElements> <camunda:in variables=\"all\" /> <camunda:out variables=\"all\" /> </extensionElements> </callActivity> It is possible to use expressions here as well: <callActivity id=\"callSubProcess\" calledElement=\"checkCreditProcess\" > <extensionElements> <camunda:in sourceExpression=\"${x+5}\" target=\"y\" /> <camunda:out sourceExpression=\"${y+5}\" target=\"z\" /> </extensionElements> </callActivity> So in the end z = y+5 = x+5+5 holds. Source expressions are evaluated in the context of the called process instance. That means, in cases where calling and called process definitions belong to different process applications, context like Java classes, Spring or CDI beans is resolved from the process application the called process definition belongs to. Variable Output on BPMN Error Event When a BPMN error event from a called process instance is caught in the calling process instance, the output variable mappings are executed as well. Depending on the BPMN models, this requires output parameters to tolerate null values for variables that do not exist in the called instance when the error is propagated. Combination with Input/Output parameters Call activities can be combined with Input/Output parameters as well. This allows for an even more flexible mapping of variables into the called process. In order to only map variables that are declared in the inputOutput mapping, the attribute local can be used. Consider the following XML: <callActivity id=\"callSubProcess\" calledElement=\"checkCreditProcess\" > <extensionElements> <!-- Input/Output parameters --> <camunda:inputOutput> <camunda:inputParameter name=\"var1\"> <camunda:script scriptFormat=\"groovy\"> <![CDATA[ sum = a + b + c ]]> </camunda:script> </camunda:inputParameter> <camunda:inputParameter name=\"var2\"></camunda:inputParameter> </camunda:inputOutput> <!-- Mapping to called instance --> <camunda:in variables=\"all\" local=\"true\" /> </extensionElements> </callActivity> Setting local=\"true\" means that all local variables of the execution executing the call activity are mapped into the called process instance. These are exactly the variables that are declared as input parameters. The same can be done with output parameters: <callActivity id=\"callSubProcess\" calledElement=\"checkCreditProcess\" > <extensionElements> <!-- Input/Output parameters --> <camunda:inputOutput> <camunda:outputParameter name=\"var1\"> <camunda:script scriptFormat=\"groovy\"> <![CDATA[ sum = a + b + c ]]> </camunda:script> </camunda:outputParameter> <camunda:outputParameter name=\"var2\"></camunda:outputParameter> </camunda:inputOutput> <!-- Mapping from called instance --> <camunda:out variables=\"all\" local=\"true\" /> </extensionElements> </callActivity> When the called process instance ends, due to local=\"true\" in the camunda:out parameter all variables are mapped to local variables of the execution executing the call activity. These variables can be mapped to process instance variables by using an output mapping. Any variable that is not declared by a camunda:outputParameter element will not be available anymore after the call activity ends. Delegation of Variable Mapping The mapping of input and output variables can also be delegated. This means the passing of input or/and output variables can be done in Java code. For this the Delegate Variable Mapping interface must be implemented. There are two possible ways to use delegation for variable mapping. Delegate Variable Mapping via Reference The first one is to set the Camunda extension property variableMappingClass and reference the implementation of the DelegateVariableMapping interface via the whole class name. <process id=\"callSimpleSubProcess\"> <startEvent id=\"theStart\" /> <sequenceFlow id=\"flow1\" sourceRef=\"theStart\" targetRef=\"callSubProcess\" /> <callActivity id=\"callSubProcess\" calledElement=\"simpleSubProcess\" camunda:variableMappingClass=\"org.cibseven.bpm.example.bpm.callactivity.DelegatedVarMapping\"/> <sequenceFlow id=\"flow3\" sourceRef=\"callSubProcess\" targetRef=\"taskAfterSubProcess\" /> <userTask id=\"taskAfterSubProcess\" name=\"Task after subprocess\" /> <sequenceFlow id=\"flow4\" sourceRef=\"taskAfterSubProcess\" targetRef=\"theEnd\" /> <endEvent id=\"theEnd\" /> </process> Delegate Variable Mapping via Expression The second one is to set the Camunda extension property variableMappingDelegateExpression with an expression. This allows to specify an expression that resolves to an object implementing the DelegateVariableMapping interface. <process id=\"callSimpleSubProcess\"> <startEvent id=\"theStart\" /> <sequenceFlow id=\"flow1\" sourceRef=\"theStart\" targetRef=\"callSubProcess\" /> <callActivity id=\"callSubProcess\" calledElement=\"simpleSubProcess\" camunda:variableMappingDelegateExpression=\"${expr}\"/> <sequenceFlow id=\"flow3\" sourceRef=\"callSubProcess\" targetRef=\"taskAfterSubProcess\" /> <userTask id=\"taskAfterSubProcess\" name=\"Task after subprocess\" /> <sequenceFlow id=\"flow4\" sourceRef=\"taskAfterSubProcess\" targetRef=\"theEnd\" /> <endEvent id=\"theEnd\" /> </process> See Delegate Variable Mapping for further information of implementing the interface. Passing Business Key You can pass the business key to the subprocess. The data is copied into the subprocess when it is started. You can not give back the business key to the parent process because the business key is not changeable. <callActivity id=\"callSubProcess\" calledElement=\"checkCreditProcess\" > <extensionElements> <camunda:in businessKey=\"#{execution.processBusinessKey}\" /> </extensionElements> </callActivity> Example The following process diagram shows a simple handling of an order. Since, for example, the billing could be common to many other processes, it is modeled as a call activity. The XML looks as follows: <startEvent id=\"theStart\" /> <sequenceFlow id=\"flow1\" sourceRef=\"theStart\" targetRef=\"shipping\" /> <callActivity id=\"shipping\" name=\"Shipping\" calledElement=\"shippingProcess\" /> <sequenceFlow id=\"flow2\" sourceRef=\"shipping\" targetRef=\"billing\" /> <callActivity id=\"billing\" name=\"Billing\" calledElement=\"billingProcess\" /> <sequenceFlow id=\"flow3\" sourceRef=\"billing\" targetRef=\"end\" /> <endEvent id=\"end\" /> There is nothing special about the process definition of the subprocess. It could also be used without being called from another process. Create a Case Instance A call activity can also be used to create a new CMMN case instance as a subordinate of the corresponding process instance. The call activity completes as soon as the created case instance reaches the state COMPLETED for the first time. In contrast to calling a BPMN process, the attribute caseRef instead of the attribute calledElement must be used to reference a case definition by its key. This means that the latest case definition version is always called. Case Binding To call another version of a case definition it is possible to define the attributes caseBinding and caseVersion in the call activity. Both attributes are optional. CaseBinding has three different values: latest: always call the latest case definition version (which is also the default behaviour if the attribute isn’t defined) deployment: if called case definition is part of the same deployment as the calling process definition, use the version from deployment version: call a fixed version of the case definition, in this case caseVersion is required <callActivity id=\"callSubProcess\" camunda:caseRef=\"checkCreditCase\" camunda:caseBinding=\"latest|deployment|version\" camunda:caseVersion=\"17\"> </callActivity> Case Tenant Id The call activity must take multi tenancy into account when resolving the case definition to be called. The default behavior is the same as when resolving BPMN Process Definitions (i.e., the tenant id of the calling process definition is used to resolve the called case definition.) In order to override the default behavior, the tenant id for resolving the called case definition can be specified explicitly using the camunda:caseTenantId attribute: <callActivity id=\"callSubProcess\" camunda:caseRef=\"checkCreditCase\" camunda:caseTenantId=\"TENANT_1\"> </callActivity> If the tenant id is not known at design time, an expression can be used as well: <callActivity id=\"callSubProcess\" camunda:caseRef=\"checkCreditCase\" camunda:caseTenantId=\"${ myBean.calculateTenantId(variable) }\"> </callActivity> An expression also allows using the tenant id of the calling process instance instead of the calling process definition: <callActivity id=\"callSubProcess\" camunda:caseRef=\"checkCreditCase\" camunda:caseTenantId=\"${ execution.tenantId }\"> </callActivity> Camunda Extensions Attributes camunda:asyncBefore, camunda:asyncAfter, camunda:calledElementBinding, camunda:calledElementVersion, camunda:calledElementVersionTag, camunda:calledElementTenantId, camunda:caseBinding, camunda:caseRef, camunda:caseVersion, camunda:caseTenantId, camunda:exclusive, camunda:jobPriority, camunda:variableMappingClass, camunda:variableMappingDelegateExpression Extension Elements camunda:in, camunda:out, camunda:inputOutput, camunda:failedJobRetryTimeCycle Constraints The camunda:exclusive attribute is only evaluated if the attribute camunda:asyncBefore or camunda:asyncAfter is set to true The attribute camunda:calledElementVersion should only be set if the attribute camunda:calledElementBinding equals version The attribute calledElement cannot be used in combination with the attribute camunda:caseRef and vice versa. The attribute camunda:caseVersion should only be set if the attribute camunda:caseBinding equals version Additional Resources Call Activity in the BPMN 2.0 Modeling Reference",
    "url": "/manual/latest/reference/bpmn20/subprocesses/call-activity/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/subprocesses/embedded-subprocess/index.html",
    "title": "Embedded Subprocess | docs.cibseven.org",
    "content": "A subprocess is an activity that contains other activities, gateways, events, etc., which itself forms a process that is part of a bigger process. A subprocess is completely defined inside a parent process (that’s why it’s often called an embedded Subprocess). Subprocesses have two major use cases: Subprocesses allow hierarchical modeling. Many modeling tools allow that subprocesses can be collapsed, hiding all the details of the subprocess and displaying a high-level, end-to-end overview of the business process. A subprocess creates a new scope for events. Events that are thrown during execution of the subprocess can be caught by a boundary event on the boundary of the subprocess, thus creating a scope for that event, limited to the subprocess. Using a subprocess does impose some constraints: A subprocess can only have one none start event, no other start event types are allowed. A subprocess must have at least one end event. Note that the BPMN 2.0 specification allows to omit the start and end events in a subprocess, but the current engine implementation does not support this. Sequence flows can not cross subprocess boundaries. A subprocess is visualized as a typical activity, i.e., a rounded rectangle. In case the subprocess is collapsed, only the name and a plus-sign are displayed, giving a high-level overview of the process: In case the subprocess is expanded, the steps of the subprocess are displayed within the subprocess boundaries: One of the main reasons to use a subprocess is to define a scope for an event. The following process model shows this: If we are spontaneously invited to dinner, we will cancel our cooking process. However, if we are already eating, we will not react to an invitation anymore. In more technical terms, the scope of the message event is the subprocess, so the message can only be received while the subprocess is active. A subprocess is defined by the subprocess element. All activities, gateways, events, etc. that are part of the subprocess need to be enclosed within this element. <startEvent id=\"outerStartEvent\" /> <!-- ... other elements ... --> <subProcess id=\"subProcess\"> <startEvent id=\"subProcessStart\" /> <!-- ... other subprocess elements ... --> <endEvent id=\"subProcessEnd\" /> </subProcess> Camunda Extensions Attributes camunda:asyncBefore, camunda:asyncAfter, camunda:exclusive, camunda:jobPriority Extension Elements camunda:failedJobRetryTimeCycle, camunda:inputOutput Constraints The camunda:exclusive attribute is only evaluated if the attribute camunda:asyncBefore or camunda:asyncAfter is set to true Additional Resources Subprocesses in the BPMN 2.0 Modeling Reference",
    "url": "/manual/latest/reference/bpmn20/subprocesses/embedded-subprocess/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/subprocesses/event-subprocess/index.html",
    "title": "Event Subprocess | docs.cibseven.org",
    "content": "The event subprocess is a subprocess that is triggered by an event. An event subprocess can be added at the process level or at any subprocess level. The event used to trigger an event subprocess is configured using a start event. Therefore, none start events are not supported for event subprocesses. An event subprocess might be triggered using events like message events, error events, signal events, timer events, or compensation events. The subscription to the start event is created when the scope (process instance or subprocess) hosting the event subprocess is created. The subscription is removed when the scope is ended. An event subprocess may be interrupting or non-interrupting. An interrupting subprocess cancels any executions in the current scope. A non-interrupting event subprocess spawns a new concurrent execution. While an interrupting event subprocess can only be triggered once for each activation of the scope hosting it, a non-interrupting event subprocess can be triggered multiple times. Whether the subprocess is interrupting or non-interrupting is configured using the start event which triggers the event subprocess. An event subprocess may not have any incoming or outgoing sequence flows. As an event subprocess is triggered by an event, an incoming sequence flow makes no sense. When an event subprocess is ended, either the current scope is ended (in case of an interrupting event subprocess), or the concurrent execution spawned for the non-interrupting subprocess is ended. The event subprocess is visualized as an embedded subprocess with a dotted outline. It is represented using XML in the same way as an embedded subprocess. Additionally, the attribute triggeredByEvent must have the value true: <subProcess id=\"eventSubProcess\" triggeredByEvent=\"true\"> <!-- ... --> </subProcess> Event subprocesses triggered using an Error Start Event, Signal Start Event, Compensation Start Event, Timer Start Event and Message Start Event are supported. Example The following is an example of an event subprocess triggered using an Error Start Event. The event subprocess is located at the “process level”, i.e., is scoped to the process instance: This is what the event subprocess looks like in XML: <subProcess id=\"eventSubProcess\" triggeredByEvent=\"true\"> <startEvent id=\"catchError\"> <errorEventDefinition errorRef=\"error\" /> </startEvent> <sequenceFlow id=\"flow2\" sourceRef=\"catchError\" targetRef=\"taskAfterErrorCatch\" /> <userTask id=\"taskAfterErrorCatch\" name=\"Provide additional data\" /> </subProcess> As already stated, an event subprocess can also be added to an embedded subprocess. If it is added to an embedded subprocess, it becomes an alternative to a boundary event. Consider the two following process diagrams. In both cases the embedded subprocess throws an error event. Both times the error is caught and handled using a user task. as opposed to: In both cases the same tasks are executed. However, there are differences between both modeling options: The embedded subprocess is executed using the same execution which executed the scope it is hosted in. This means that an embedded subprocess has access to the variables local to it’s scope. When using a boundary event, the execution created for executing the embedded subprocess is deleted by the sequence flow leaving the boundary event. This means that the variables created by the embedded subprocess are not available anymore. When using an event subprocess, the event is completely handled by the subprocess it is added to. When using a boundary event, the event is handled by the parent process. These two differences can help you decide whether a boundary event or an embedded subprocess is better suited for solving a particular process modeling / implementation problem. Camunda Extensions Attributes camunda:asyncBefore, camunda:asyncAfter, camunda:exclusive, camunda:jobPriority Extension Elements camunda:failedJobRetryTimeCycle, camunda:inputOutput Constraints The camunda:exclusive attribute is only evaluated if the attribute camunda:asyncBefore or camunda:asyncAfter is set to true Additional Resources Event subprocess in the BPMN 2.0 Modeling Reference",
    "url": "/manual/latest/reference/bpmn20/subprocesses/event-subprocess/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/subprocesses/index.html",
    "title": "Subprocess | docs.cibseven.org",
    "content": "A subprocess in Camunda allows modeling based on reusability and grouping. Below are the different types of subprocesses supported by Camunda.",
    "url": "/manual/latest/reference/bpmn20/subprocesses/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/subprocesses/transaction-subprocess/index.html",
    "title": "Transaction Subprocess | docs.cibseven.org",
    "content": "A transaction subprocess is an embedded subprocess which can be used to group multiple activities to a transaction. A transaction is a logical unit of work which allows grouping of a set of individual activities, so that they either succeed or fail collectively. A transaction can have three possible outcomes: A transaction is successful if it is neither canceled nor terminated by a hazard. If a transaction subprocess is successful, it is left using the outgoing sequenceflow(s). A successful transaction might be compensated if a compensation event is thrown later in the process. Note: just as “ordinary” embedded subprocesses, a transaction subprocess may be compensated after successful completion using an intermediate throwing compensation event. A transaction is canceled if an execution reaches the cancel end event. In that case, all executions are terminated and removed. A single remaining execution is then set to the cancel boundary event, which triggers compensation. After compensation is completed, the transaction subprocess is left, using the outgoing sequence flow(s) of the cancel boundary event. A transaction is ended by a hazard if an error event is thrown which is not caught within the scope of the transaction subprocess. (This also applies if the error is caught on the boundary of the transaction subprocess.) In this case, compensation is not performed. The following diagram illustrates the three different outcomes: A transaction subprocess is represented in xml using the transaction element: <transaction id=\"myTransaction\" > <!-- ... --> </transaction> Relation to ACID Transactions It is important not to confuse the BPMN transaction subprocess with technical (ACID) transactions. The BPMN transaction subprocess is not a way to scope technical transactions. To understand transaction management in CIB seven, read the Transactions in Processes section of the User Guide. A BPMN transaction differs from a technical transaction in the following ways: While an ACID transaction is typically short lived, a BPMN transaction may take hours, days or even months to complete. (Consider a case where one of the activities grouped by a transaction is a usertask; typically, people have longer response times than applications. Or, in another situation, a BPMN transaction might wait for some business event to occur, like the fact that a particular order has been fulfilled.) Such operations usually take considerably longer to complete than updating a record in a database or storing a message using a transactional queue. Because it is impossible to scope a technical transaction to the duration of a business activity, a BPMN transaction typically spans multiple ACID transactions. Since a BPMN transaction spans multiple ACID transactions, we lose ACID properties. Consider the example given above. Let’s assume the “book hotel” and the “charge credit card” operations are performed in separate ACID transactions. Let’s also assume that the “book hotel” activity is successful. Now we have an intermediate inconsistent state because we have performed a hotel booking but have not yet charged the credit card. Now, in an ACID transaction, we would also perform different operations sequentially and therefore also have an intermediate inconsistent state. What is different here is that the inconsistent state is visible outside of the scope of the transaction. For example, if the reservations are made using an external booking service, other parties using the same booking service might already see that the hotel is booked. This means that when implementing business transactions, we completely lose the isolation property (granted, we usually also relax isolation when working with ACID transactions to allow for higher levels of concurrency, but there we have fine grained control and intermediate inconsistencies are only present for very short periods of time). A BPMN business transaction can also not be rolled back in the traditional sense. As it spans multiple ACID transactions, some of these ACID transactions might already be committed at the time the BPMN transaction is canceled. At that point they cannot be rolled back anymore. Since BPMN transactions are long-running in nature, the lack of isolation and a rollback mechanism needs to be dealt with differently. In practice there is usually no better solution than to deal with these problems in a domain specific way: The rollback is performed using compensation. If a cancel event is thrown in the scope of a transaction, the effects of all activities that executed successfully and have a compensation handler are compensated. The lack of isolation is also often dealt with by using domain specific solutions. For instance, in the example above, a hotel room might appear to be booked to a second customer before we have actually made sure that the first customer can pay for it. Since this might be undesirable from a business perspective, a booking service might have chosen to allow for a certain amount of overbooking. In addition, since the transaction can be aborted in case of a hazard, the booking service has to deal with the situation where a hotel room is booked but payment is never attempted (since the transaction was aborted). In that case, the booking service might choose a strategy where a hotel room is reserved for a maximum period of time and, if payment is not received by then, the booking is canceled. To sum it up: while ACID transactions offer a generic solution to such problems (rollback, isolation levels and heuristic outcomes), we need to find domain specific solutions to these problems when implementing business transactions. Current Limitations The BPMN specification requires that the process engine reacts to events issued by the underlying transaction protocol and, in case a transaction is canceled, if a cancel event occurs, in the underlying protocol. As an embeddable engine, the CIB seven engine currently does not support this. (For some ramifications of this, see the paragraph on consistency below.) Consistency on top of ACID transactions and optimistic concurrency: A BPMN transaction guarantees consistency in the sense that either all activities compete successfully, or, if some activity cannot be performed, the effects of all other successful activities are compensated. So either way, we end up in a consistent state. However, it is important to recognize that in CIB seven, the consistency model for BPMN transactions is superposed on top of the consistency model for process execution. The CIB seven engine executes processes in a transactional way. Concurrency is addressed using optimistic locking. In the engine BPMN error, cancel and compensation events are built on top of the same ACID transactions and optimistic locking. For example, a cancel end event can only trigger compensation if it is actually reached. It is not reached if some undeclared exception is thrown by a service task before. The effects of a compensation handler can not be committed if some other participant in the underlying ACID transaction sets the transaction to the state rollback-only. Also, when two concurrent executions reach a cancel end event, compensation might be triggered twice and fail with an optimistic locking exception. All of this is to say that when implementing BPMN transactions in the core engine, the same set of rules apply as when implementing “ordinary” processes and subprocesses. So, to effectively guarantee consistency, it is important to implement processes in a way that takes the optimistic, transactional execution model into consideration. For further information, see the documentation on optimistic locking. Camunda Extensions Attributes camunda:asyncBefore, camunda:asyncAfter, camunda:exclusive, camunda:jobPriority Extension Elements camunda:failedJobRetryTimeCycle, camunda:inputOutput Constraints The camunda:exclusive attribute is only evaluated if the attribute camunda:asyncBefore or camunda:asyncAfter is set to true Additional Resources Transactions in Processes",
    "url": "/manual/latest/reference/bpmn20/subprocesses/transaction-subprocess/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/tasks/business-rule-task/index.html",
    "title": "Business Rule Task | docs.cibseven.org",
    "content": "A Business Rule Task is used to synchronously execute one or more rules. It is also possible to call Java code or providing a work item for an external worker to complete asynchronously or invoking a logic which is implemented in form of webservices. Using Camunda DMN Engine You can use the Camunda DMN engine integration to evaluate a DMN decision. You have to specify the decision key to evaluate as the camunda:decisionRef attribute. Additionally, the camunda:decisionRefBinding specifies which version of the decision should be evaluated. Valid values are: deployment, which evaluates the decision version which was deployed with the process version, latest which will always evaluate the latest decision version, version which allows you to specify a specific version to execute with the camunda:decisionRefVersion attribute, and versionTag which allows you to specify a specific version tag to execute with the camunda:decisionRefVersionTag attribute. <businessRuleTask id=\"businessRuleTask\" camunda:decisionRef=\"myDecision\" camunda:decisionRefBinding=\"version\" camunda:decisionRefVersion=\"12\" /> The camunda:decisionRefBinding attribute defaults to latest. <businessRuleTask id=\"businessRuleTask\" camunda:decisionRef=\"myDecision\" /> The attributes camunda:decisionRef, camunda:decisionRefVersion, and camunda:decisionRefVersionTag can be specified as an expression which will be evaluated on execution of the task. <businessRuleTask id=\"businessRuleTask\" camunda:decisionRef=\"${decisionKey}\" camunda:decisionRefBinding=\"version\" camunda:decisionRefVersion=\"${decisionVersion}\" /> The output of the decision, also called decision result, is not saved as process variable automatically. It has to pass into a process variable by using a predefined or a custom mapping of the decision result. In case of a predefined mapping, the camunda:mapDecisionResult attribute references the mapper to use. The result of the mapping is saved in the variable which is specified by the camunda:resultVariable attribute. If no predefined mapper is set then the resultList mapper is used by default. <businessRuleTask id=\"businessRuleTask\" camunda:decisionRef=\"myDecision\" camunda:mapDecisionResult=\"singleEntry\" camunda:resultVariable=\"result\" /> See the User Guide for details about the mapping. Name of the Result Variable The result variable should not have the name decisionResult, as the decision result itself is saved in a variable with this name. Otherwise, an exception is thrown while saving the result variable. DecisionRef Tenant Id When the Business Rule Task resolves the decision definition to be evaluated it must take multi tenancy into account. Default Tenant Resolution By default, the tenant id of the calling process definition is used to evaluate the decision definition. That is, if the calling process definition has no tenant id, then the Business Rule Task evaluates a decision definition using the provided key, binding and without a tenant id (tenant id = null). If the calling process definition has a tenant id, a decision definition with the provided key and the same tenant id is evaluated. Note that the tenant id of the calling process instance is not taken into account in the default behavior. Explicit Tenant Resolution In some situations it may be useful to override this default behavior and specify the tenant id explicitly. The camunda:decisionRefTenantId attribute allows to explicitly specify a tenant id: <businessRuleTask id=\"businessRuleTask\" decisionRef=\"myDecision\" camunda:decisionRefTenantId=\"TENANT_1\"> </businessRuleTask> If the tenant id is not known at design time, an expression can be used as well: <businessRuleTask id=\"businessRuleTask\" decisionRef=\"myDecision\" camunda:decisionRefTenantId=\"${ myBean.calculateTenantId(variable) }\"> </businessRuleTask> An expression also allows using the tenant id of the calling process instance instead of the calling process definition: <businessRuleTask id=\"businessRuleTask\" decisionRef=\"myDecision\" camunda:decisionRefTenantId=\"${ execution.tenantId }\"> </businessRuleTask> Using a Custom Rule Engine You can integrate with other rule engines. To do so, you have to plug in your implementation of the rule task the same way as in a Service Task. <businessRuleTask id=\"businessRuleTask\" camunda:delegateExpression=\"${MyRuleServiceDelegate}\" /> Using Delegate Code Alternatively, a Business Rule Task can be implemented using Java Delegation just as a Service Task. For more information on this please see the Service Tasks documentation. Implementing as an External Task In addition to the above, a Business Rule Task can be implemented via the External Task mechanism where an external system polls the process engine for work to do. See the section on Service Tasks for more information about how to configure an external task. Camunda Extensions Attributes camunda:asyncBefore, camunda:asyncAfter, camunda:class, camunda:decisionRef, camunda:decisionRefBinding, camunda:decisionRefTenantId, camunda:decisionRefVersion, camunda:decisionRefVersionTag, camunda:delegateExpression, camunda:exclusive, camunda:expression, camunda:jobPriority, camunda:mapDecisionResult, camunda:resultVariable, camunda:topic, camunda:type, camunda:taskPriority Extension Elements camunda:failedJobRetryTimeCycle, camunda:field, camunda:connector, camunda:inputOutput Constraints One of the attributes camunda:class, camunda:delegateExpression, camunda:decisionRef, camunda:type or camunda:expression is mandatory The attribute camunda:resultVariable can only be used in combination with the camunda:decisionRef or camunda:expression attribute The camunda:exclusive attribute is only evaluated if the attribute camunda:asyncBefore or camunda:asyncAfter is set to true The attribute camunda:topic can only be used when the camunda:type attribute is set to external. The attribute camunda:taskPriority can only be used when the camunda:type attribute is set to external. Additional Resources Decisions Service Tasks Tasks in the BPMN 2.0 Modeling Reference Demo using Drools on the Business Rule Task",
    "url": "/manual/latest/reference/bpmn20/tasks/business-rule-task/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/tasks/index.html",
    "title": "Tasks | docs.cibseven.org",
    "content": "Tasks allow modeling the actual work being performed in the process. Different types of tasks are supported.",
    "url": "/manual/latest/reference/bpmn20/tasks/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/tasks/manual-task/index.html",
    "title": "Manual Task | docs.cibseven.org",
    "content": "A Manual Task defines a task that is external to the BPM engine. It is used to model work that is done by somebody who the engine does not need to know of and that has no known system or UI interface. For the engine, a manual task is handled as a pass-through activity, automatically continuing the process when the process execution arrives at it. <manualTask id=\"myManualTask\" name=\"Manual Task\" /> Camunda Extensions Attributes camunda:asyncBefore, camunda:asyncAfter, camunda:exclusive, camunda:jobPriority Extension Elements camunda:failedJobRetryTimeCycle, camunda:inputOutput Constraints The camunda:exclusive attribute is only evaluated if the attribute camunda:asyncBefore or camunda:asyncAfter is set to true",
    "url": "/manual/latest/reference/bpmn20/tasks/manual-task/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/tasks/receive-task/index.html",
    "title": "Receive Task | docs.cibseven.org",
    "content": "A Receive Task is a simple task that waits for the arrival of a certain message. When the process execution arrives at a Receive Task, the process state is committed to the persistence storage. This means that the process will stay in this wait state until a specific message is received by the engine, which triggers continuation of the process beyond the Receive Task. A Receive Task with a message reference can be triggered like an ordinary event: <definitions ...> <message id=\"newInvoice\" name=\"newInvoiceMessage\"/> <process ...> <receiveTask id=\"waitState\" name=\"wait\" messageRef=\"newInvoice\"> ... You can then either correlate the message: // correlate the message runtimeService.createMessageCorrelation(subscription.getEventName()) .processInstanceBusinessKey(\"AB-123\") .correlate(); Or explicitly query for the subscription and trigger it: ProcessInstance pi = runtimeService.startProcessInstanceByKey(\"processWaitingInReceiveTask\"); EventSubscription subscription = runtimeService.createEventSubscriptionQuery() .processInstanceId(pi.getId()).eventType(\"message\").singleResult(); runtimeService.messageEventReceived(subscription.getEventName(), subscription.getExecutionId()); Correlation of a parallel multi instance isn’t possible because the subscription can’t be identified unambiguously. To continue a process instance that is currently waiting at a Receive Task without a message reference, the runtimeService.signal(executionId) can be called, using the id of the execution that arrived in the Receive Task. <receiveTask id=\"waitState\" name=\"wait\" /> The following code snippet shows how this works in practice: ProcessInstance pi = runtimeService.startProcessInstanceByKey(\"receiveTask\"); Execution execution = runtimeService.createExecutionQuery() .processInstanceId(pi.getId()).activityId(\"waitState\").singleResult(); runtimeService.signal(execution.getId()); Camunda Extensions Attributes camunda:asyncBefore, camunda:asyncAfter, camunda:exclusive, camunda:jobPriority Extension Elements camunda:failedJobRetryTimeCycle, camunda:inputOutput Constraints The camunda:exclusive attribute is only evaluated if the attribute camunda:asyncBefore or camunda:asyncAfter is set to true Additional Resources Tasks in the BPMN 2.0 Modeling Reference Message Receive Events Trigger a subscription via REST",
    "url": "/manual/latest/reference/bpmn20/tasks/receive-task/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/tasks/script-task/index.html",
    "title": "Script Task | docs.cibseven.org",
    "content": "A Script Task is an automated activity. When a process execution arrives at the Script Task, the corresponding script is executed. A Script Task is defined by specifying the script and the scriptFormat. <scriptTask id=\"theScriptTask\" name=\"Execute script\" scriptFormat=\"groovy\"> <script> sum = 0 for ( i in inputArray ) { sum += i } </script> </scriptTask> The value of the scriptFormat attribute must be a name that is compatible with JSR-223 (Scripting for the Java Platform). If you want to use a (JSR-223 compatible) scripting engine, you need to to add the corresponding jar to the classpath and use the appropriate name. The script source code has to be added as the text content of the script child element. Alternatively, the source code can be specified as an expression or external resource. For more information on the possible ways of providing the script source code please see the corresponding section of the User Guide. For general information about scripting in the process engine, please see the Scripting section of the User Guide. Supported Script Languages CIB seven should work with most of the JSR-223 compatible script engine implementations. We test integration for Groovy, JavaScript, JRuby and Jython. See the Third Party Dependencies section of the User Guide for more details. Variables in Scripts All process variables that are accessible through the execution that arrives in the Script Task can be used within the script. In the example below, the script variable inputArray is in fact a process variable (an array of integers). <script> sum = 0 for ( i in inputArray ) { sum += i } </script> It’s also possible to set process variables in a script. Variables can be set by using the setVariable(...) methods provided by the VariableScope interface: <script> sum = 0 for ( i in inputArray ) { sum += i } execution.setVariable(\"sum\", sum); </script> Enabling auto-storing of Script Variables By setting the property autoStoreScriptVariables to true in the process engine configuration, the process engine will automatically store all global script variables as process variables. To use this feature, you have to set autoStoreScriptVariables to true in the process engine configuration prefix all script variables that should not be stored as script variables using the def keyword: def sum = 0. In this case the variable sum will not be stored as process variable. Groovy-Support only The configuration flag autoStoreScriptVariables is only supported for Groovy Script Tasks. If enabled for other script languages, it is not guaranteed which variables will be exported by the script engine. For example, Ruby will not export any of the script variables at all. Note: the following names are reserved and cannot be used as variable names: out, out:print, lang:import, context, elcontext. Script Results The return value of a Script Task can be assigned to a previously existing or to a new process variable by specifying the process variable name as a literal value for the camunda:resultVariable attribute of a Script Task definition. Any existing value for a specific process variable will be overwritten by the result value of the script execution. When a result variable name is not specified, the script result value gets ignored. <scriptTask id=\"theScriptTask\" name=\"Execute script\" scriptFormat=\"juel\" camunda:resultVariable=\"myVar\"> <script>#{echo}</script> </scriptTask> In the above example, the result of the script execution (the value of the resolved expression #{echo}) is set to the process variable named myVar after the script completes. Result variables and multi-instance Note that when you use camunda:resultVariable in a multi-instance construct, for example in a multi-instance subprocess, the result variable is overwritten every time the task completes, which may appear as random behavior. See camunda:resultVariable for details. Camunda Extensions Attributes camunda:asyncBefore, camunda:asyncAfter, camunda:exclusive, camunda:jobPriority, camunda:resultVariable, camunda:resource Extension Elements camunda:failedJobRetryTimeCycle, camunda:inputOutput Constraints The camunda:exclusive attribute is only evaluated if the attribute camunda:asyncBefore or camunda:asyncAfter is set to true",
    "url": "/manual/latest/reference/bpmn20/tasks/script-task/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/tasks/send-task/index.html",
    "title": "Send Task | docs.cibseven.org",
    "content": "A Send Task is used to send a message. In Camunda this is done by calling Java code. The Send Task has the same behavior as a Service Task. <sendTask id=\"sendTask\" camunda:class=\"org.cibseven.bpm.MySendTaskDelegate\" /> Camunda Extensions Attributes camunda:asyncBefore, camunda:asyncAfter, camunda:class, camunda:delegateExpression, camunda:exclusive, camunda:expression, camunda:jobPriority, camunda:resultVariable, camunda:topic, camunda:type, camunda:taskPriority Extension Elements camunda:failedJobRetryTimeCycle, camunda:field, camunda:connector, camunda:inputOutput Constraints One of the attributes camunda:class, camunda:delegateExpression, camunda:type or camunda:expression is mandatory The attribute camunda:resultVariable can only be used in combination with the camunda:expression attribute The camunda:exclusive attribute is only evaluated if the attribute camunda:asyncBefore or camunda:asyncAfter is set to true The attribute camunda:topic can only be used when the camunda:type attribute is set to external. The attribute camunda:taskPriority can only be used when the camunda:type attribute is set to external.",
    "url": "/manual/latest/reference/bpmn20/tasks/send-task/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/tasks/service-task/index.html",
    "title": "Service Task | docs.cibseven.org",
    "content": "A Service Task is used to invoke services. In Camunda this is done by calling Java code or providing a work item for an external worker to complete asynchronously or invoking a logic which is implemented in form of webservices. Calling Java Code There are four ways of declaring how to invoke Java logic: Specifying a class that implements a JavaDelegate or ActivityBehavior Evaluating an expression that resolves to a delegation object Invoking a method expression Evaluating a value expression To specify a class that is called during process execution, the fully qualified classname needs to be provided by the camunda:class attribute. <serviceTask id=\"javaService\" name=\"My Java Service Task\" camunda:class=\"org.cibseven.bpm.MyJavaDelegate\" /> Please refer to the Java Delegate section of the User Guide for details on how to implement a Java Delegate. It is also possible to use an expression that resolves to an object. This object must follow the same rules as objects that are created when the camunda:class attribute is used. <serviceTask id=\"beanService\" name=\"My Bean Service Task\" camunda:delegateExpression=\"${myDelegateBean}\" /> Or an expression which calls a method or resolves to a value. <serviceTask id=\"expressionService\" name=\"My Expression Service Task\" camunda:expression=\"${myBean.doWork()}\" /> For more information about expression language as delegation code, please see the corresponding section of the User Guide. It is also possible to invoke logic which is implemented in form of webservices. camunda:connector is an extension that allows calling REST/SOAP APIs directly from the workflow. For more information about using connectors, please see the corresponding section of the User Guide Generic Java Delegates & Field Injection You can easily write generic Java Delegate classes which can be configured later on via the BPMN 2.0 XML in the Service Task. Please refer to the Field Injection section of the User Guide for details. Service Task Results The return value of a service execution (for a Service Task exclusively using expressions) can be assigned to an already existing or to a new process variable by specifying the process variable name as a literal value for the camunda:resultVariable attribute of a Service Task definition. Any existing value for a specific process variable will be overwritten by the result value of the service execution. When not specifying a result variable name, the service execution result value is ignored. <serviceTask id=\"aMethodExpressionServiceTask\" camunda:expression=\"#{myService.doSomething()}\" camunda:resultVariable=\"myVar\" /> In the example above, the result of the service execution (the return value of the doSomething() method invocation on object myService) is set to the process variable named myVar after the service execution completes. Result variables and multi-instance Note that when you use camunda:resultVariable in a multi-instance construct, for example in a multi-instance subprocess, the result variable is overwritten every time the task completes, which may appear as random behavior. See camunda:resultVariable for details. External Tasks In contrast to calling Java code, where the process engine synchronously invokes Java logic, it is possible to implement a Service Task outside of the process engine’s boundaries in the form of an external task. When a Service Task is declared external, the process engine offers a work item to workers that independently poll the engine for work to do. This decouples the implementation of tasks from the process engine and allows to cross system and technology boundaries. See the user guide on external tasks for details on the concept and the relevant API. To declare a Service Task to be handled externally, the attribute camunda:type can be set to external and the attribute camunda:topic specifies the external task’s topic. For example, the following XML snippet defines an external Service Task with topic ShipmentProcessing: <serviceTask id=\"anExternalServiceTask\" camunda:type=\"external\" camunda:topic=\"ShipmentProcessing\" /> Camunda Extensions Attributes camunda:asyncBefore, camunda:asyncAfter, camunda:class, camunda:delegateExpression, camunda:exclusive, camunda:expression, camunda:jobPriority, camunda:resultVariable, camunda:topic, camunda:type, camunda:taskPriority Extension Elements camunda:errorEventDefinition, camunda:failedJobRetryTimeCycle, camunda:field, camunda:connector, camunda:inputOutput Constraints One of the attributes camunda:class, camunda:delegateExpression, camunda:type or camunda:expression is mandatory The attribute camunda:resultVariable can only be used in combination with the camunda:expression attribute The camunda:exclusive attribute is only evaluated if the attribute camunda:asyncBefore or camunda:asyncAfter is set to true The attribute camunda:topic can only be used when the camunda:type attribute is set to external. The attribute camunda:taskPriority can only be used when the camunda:type attribute is set to external. The element camunda:errorEventDefinition can only be used as a child of serviceTask when the camunda:type attribute is set to external. Additional Resources Tasks in the BPMN Modeling Reference section How to call a Webservice from BPMN. Please note that this article is outdated. However, it is still valid regarding how you would call a Web Service using the process engine.",
    "url": "/manual/latest/reference/bpmn20/tasks/service-task/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/tasks/task-markers/index.html",
    "title": "Task Markers | docs.cibseven.org",
    "content": "In addition to the various types of tasks, we can mark tasks as loops, multiple instances or compensations. Markers can be combined with task types. Multiple Instance A multi-instance activity is a way of defining repetition for a certain step in a business process. In programming concepts, a multi-instance matches the for each construct: it allows execution of a certain step or even a complete subprocess for each item in a given collection, sequentially or in parallel. A multi-instance is a regular activity that has extra properties defined (so-called multi-instance characteristics) which will cause the activity to be executed multiple times at runtime. Following activities can become multi-instance activities: Service Task Send Task User Task Business Rule Task Script Task Receive Task Manual Task (Embedded) Sub-Process Call Activity Transaction Subprocess A Gateway or Event can not become multi-instance. If an activity is multi-instance, this is indicated by three short lines at the bottom of the activity. Three vertical lines indicate that the instances will be executed in parallel, while three horizontal lines indicate sequential execution. As required by the specification, each parent execution of the created executions for each instance will have the following variables: nrOfInstances: the total number of instances nrOfActiveInstances: the number of currently active, i.e., not yet finished, instances. For a sequential multi-instance, this will always be 1 nrOfCompletedInstances: the number of already completed instances These values can be retrieved by calling the execution.getVariable(x) method. Additionally, each of the created executions will have an execution-local variable (i.e., not visible for the other executions and not stored on process instance level) : loopCounter: indicates the index in the for each loop of that particular instance To make an activity multi-instance, the activity xml element must have a multiInstanceLoopCharacteristics child element. <multiInstanceLoopCharacteristics isSequential=\"false|true\"> ... </multiInstanceLoopCharacteristics> The isSequential attribute indicates if the instances of that activity are executed sequentially or in parallel. The number of instances are calculated once, when entering the activity. There are a few ways of configuring this. One way is directly specifying a number by using the loopCardinality child element. <multiInstanceLoopCharacteristics isSequential=\"false|true\"> <loopCardinality>5</loopCardinality> </multiInstanceLoopCharacteristics> Expressions that resolve to a positive number are also possible: <multiInstanceLoopCharacteristics isSequential=\"false|true\"> <loopCardinality>${nrOfOrders-nrOfCancellations}</loopCardinality> </multiInstanceLoopCharacteristics> Another way to define the number of instances is to specify the name of a process variable which is a collection using the loopDataInputRef child element. For each item in the collection, an instance will be created. Optionally, it is possible to set that specific item of the collection for the instance using the inputDataItem child element. This is shown in the following XML example: <userTask id=\"miTasks\" name=\"My Task ${loopCounter}\" camunda:assignee=\"${assignee}\"> <multiInstanceLoopCharacteristics isSequential=\"false\"> <loopDataInputRef>assigneeList</loopDataInputRef> <inputDataItem name=\"assignee\" /> </multiInstanceLoopCharacteristics> </userTask> Suppose the variable assigneeList contains the values [kermit, gonzo, foziee]. In the snippet above, three user tasks will be created in parallel. Each of the executions will have a process variable named assignee containing one value of the collection, which is used to assign the user task in this example. The downside of the loopDataInputRef and inputDataItem is that 1) the names are pretty hard to remember and 2) due to the BPMN 2.0 schema restrictions they can’t contain expressions. We solve this by offering the collection and elementVariable attributes on the multiInstanceCharacteristics: <userTask id=\"miTasks\" name=\"My Task\" camunda:assignee=\"${assignee}\"> <multiInstanceLoopCharacteristics isSequential=\"true\" camunda:collection=\"${myService.resolveUsersForTask()}\" camunda:elementVariable=\"assignee\" > </multiInstanceLoopCharacteristics> </userTask> A multi-instance activity ends when all instances are finished. However, it is possible to specify an expression that is evaluated every time one instance ends. When this expression evaluates to true, all remaining instances are destroyed and the multi-instance activity ends, continuing the process. Such an expression must be defined in the completionCondition child element. <userTask id=\"miTasks\" name=\"My Task\" camunda:assignee=\"${assignee}\"> <multiInstanceLoopCharacteristics isSequential=\"false\" camunda:collection=\"assigneeList\" camunda:elementVariable=\"assignee\" > <completionCondition>${nrOfCompletedInstances/nrOfInstances >= 0.6 }</completionCondition> </multiInstanceLoopCharacteristics> </userTask> In this example, parallel instances will be created for each element of the assigneeList collection. However, when 60% of the tasks are completed, the other tasks are deleted and the process continues. Camunda Extensions Attributes camunda:collection, camunda:elementVariable, camunda:asyncBefore, camunda:asyncAfter, camunda:exclusive, camunda:jobPriority Extension Elements – Constraints The camunda:exclusive attribute is only evaluated if the attribute camunda:asyncBefore or camunda:asyncAfter is set to true Boundary Events and Multi-Instance Since a multi-instance is a regular activity, it is possible to define a boundary event on its boundary. In case of an interrupting boundary event, when the event is caught, all instances that are still active will be destroyed. For example, take the following multi-instance subprocess: Here all instances of the subprocess will be destroyed when the timer fires, regardless of how many instances there are or which inner activities are currently not completed yet. Loops The loop marker is not natively supported yet by the engine. For Multiple Instance, the number of repetitions is known in advance - which makes it a bad candidate for loops anyway, as it defines a completion condition that may already be sufficient in some cases. To get around this limitation, the solution is to explicitly model the loop in your BPMN process: Be assured that we have the loop marker in our backlog to be added to the engine. JSON Collections with Multi-Instance Collections JSON Arrays created with Camunda SPIN can be used as a collection for multi-instance activities. Consider the following JavaScript example that initializes execution variable collection: var collection = S('{ \"collection\" : [\"System 1\", \"System 3\"] }'); execution.setVariable(\"collection\", collection); This script can be injected in the model in several ways, e.g. using [Script task] (/manual/latest/reference/bpmn20/tasks/script-task/). We can now use collection variable in multi-instance activity’s camunda:collection extension element. <multiInstanceLoopCharacteristics camunda:collection=\"${collection.prop('collection').elements()}\" camunda:elementVariable=\"collectionElem\" /> This uses the SPIN’s JSON .prop() and .elements() to return the JSON array. Set the multi-instance activity’s elementVariable to a variable name that will contain the array item. To access the value of the element, you can use .value() in your element variable. Compensation If an activity is used for compensating the effects of another activity, it can be declared to be a compensation handler. Compensation handlers are not contained in the regular flow and are only executed when a compensation event is thrown. Notice the compensation handler icon in the bottom center area of the “cancel hotel reservation” service task. Compensation handlers may not have incoming or outgoing sequence flows. A compensation handler must be associated with a compensation boundary event using a directed association. To declare an activity to be a compensation handler, we need to set the attribute isForCompensation to true: <serviceTask id=\"undoBookHotel\" isForCompensation=\"true\" camunda:class=\"...\" /> Additional Resources Tasks in the BPMN 2.0 Modeling Reference Transaction Subprocess",
    "url": "/manual/latest/reference/bpmn20/tasks/task-markers/index.html"
  },
  {
    "id": "manual/latest/reference/bpmn20/tasks/user-task/index.html",
    "title": "User Task | docs.cibseven.org",
    "content": "A User Task is used to model work that needs to be done by a human actor. When the process execution arrives at such a User Task, a new task is created in the task list of the user(s) or group(s) assigned to that task. A User Task is defined in XML as follows. The id attribute is required, while the name attribute is optional. <userTask id=\"theTask\" name=\"Important task\" /> Description A User Task can also have a description. In fact, any BPMN 2.0 element can have a description. A description is defined by adding the documentation element. <userTask id=\"theTask\" name=\"Schedule meeting\" > <documentation> Schedule an engineering meeting for next week with the new hire. </documentation> The description text can be retrieved from the task in the standard Java way: task.getDescription(); Properties Due Date Each task has a field indicating the due date of that task. The Query API can be used to query for tasks that are due on, before or after a certain date. There is an activity extension which allows you to specify an expression in your task-definition to set the initial due date of a task when it is created. The expression should always resolve to a java.util.Date, java.util.String (ISO8601 formatted) or null. When using ISO8601 formatted Strings, you may either specify an exact point in time or a time period relative to the time the task is created. For example, you could use a date that was entered in a previous form in the process or calculated in a previous Service Task. <userTask id=\"theTask\" name=\"Important task\" camunda:dueDate=\"${dateVariable}\"/> The due date of a task can also be altered using the TaskService or in TaskListeners using the passed DelegateTask. Follow Up Date Each task has a field indicating the follow up date of that task. The Query API can be used to query for tasks that need to be followed up on, before or after a certain date. There is an activity extension which allows you to specify an expression in your task-definition to set the initial follow up date of a task when it is created. The expression should always resolve to a java.util.Date, java.util.String (ISO8601 formatted) or null. When using ISO8601 formatted Strings, you may either specify an exact point in time or a time period relative to the time the task is created. For example, you could use a date that was entered in a previous form in the process or calculated in a previous Service Task. <userTask id=\"theTask\" name=\"Important task\" camunda:followUpDate=\"${dateVariable}\"/> User Assignment A User Task can be directly assigned to a single user, a list of users or a list of groups. Assignment using BPMN Resource Assignments BPMN defines some native assignment concepts which can be used in camunda. As a more powerful alternative, Camunda also defines a set of custom extension elements (see below). Human Performer This is done by defining a humanPerformer sub element. Such a humanPerformer definition needs a resourceAssignmentExpression that actually defines the user. Currently, only formalExpressions are supported. <process ... > ... <userTask id='theTask' name='important task' > <humanPerformer> <resourceAssignmentExpression> <formalExpression>kermit</formalExpression> </resourceAssignmentExpression> </humanPerformer> </userTask> Only one user can be assigned to the task as a human performer. In the engine terminology, this user is called the assignee. Tasks that have an assignee are not visible in the task lists of other users and can be found in the so-called personal task list of the assignee instead. Tasks directly assigned to users can be retrieved through the TaskService as follows: List<Task> tasks = taskService.createTaskQuery().taskAssignee(\"kermit\").list(); Potential Owner Tasks can also be put in the so-called candidate task list of people. In that case, the potentialOwner construct must be used. The usage is similar to the humanPerformer construct. Please note that for each element in the formal expression it is required to specifically define if it is a user or a group (the engine cannot guess this). <process ... > ... <userTask id='theTask' name='important task' > <potentialOwner> <resourceAssignmentExpression> <formalExpression>user(kermit), group(management)</formalExpression> </resourceAssignmentExpression> </potentialOwner> </userTask> Tasks defined with the potential owner construct can be retrieved as follows (or a similar TaskQuery, such as for tasks which have an assignee, can be used): List<Task> tasks = taskService.createTaskQuery().taskCandidateUser(\"kermit\"); This will retrieve all tasks where kermit is a candidate user, i.e., the formal expression contains the user kermit. This will also retrieve all tasks that are assigned to a group of which kermit is a member (e.g., group(management), if kermit is a member of that group and the identity component is used). The groups of a user are resolved at runtime and these can be managed through the IdentityService. If no specifics are given whether the given text string is a user or a group, the engine defaults to group. So the following two alternatives lead to the same result: <formalExpression>accountancy</formalExpression> <formalExpression>group(accountancy)</formalExpression> User Assignment using Camunda Extensions It is clear that user and group assignments are quite cumbersome for use cases where the assignment is more complicated. To avoid these complexities, custom extensions on the User Task are possible. Assignee The assignee attribute: this custom extension allows direct assignment of a User Task to a given user. <userTask id=\"theTask\" name=\"my task\" camunda:assignee=\"kermit\" /> This is exactly the same as using a humanPerformer construct as defined above. Candidate Users The candidateUsers attribute: this custom extension allows you to make a user a candidate for a task. <userTask id=\"theTask\" name=\"my task\" camunda:candidateUsers=\"kermit, gonzo\" /> This is exactly the same as using a potentialOwner construct as defined above. Note that it is not required to use the user(kermit) declaration as is the case with the potential owner construct, since this attribute can only be used for users. Candidate Groups The candidateGroups attribute: this custom extension allows you to make a group a candidate for a task. <userTask id=\"theTask\" name=\"my task\" camunda:candidateGroups=\"management, accountancy\" /> This is exactly the same as using a potentialOwner construct as defined above. Note that it is not required to use the group(management) declaration as is the case with the potential owner construct, since this attribute can only be used for groups. Combining Candidate Users and Groups candidateUsers and candidateGroups can both be defined for the same User Task. Assignment based on Data and Service Logic In the above examples, constant values such as kermit or management are used. But what if the exact name of an assignee or a candidate group is not known at design time? And what if the assignee is not a constant value but depends on data such as “The person who started the process”? Maybe the assigment logic is also more complex and needs to access an external data source such as LDAP to implement a lookup such as “The manager of the employee who started the process”. Such things can be implemented using assignment expressions or task listeners. Assignment Expressions Assignment expressions allow accessing process variables or calling out to beans and services. Using Process Variables Process variables are useful for assignments based on data which has been collected or calculated up front. The following example shows how to assign a User Task to the person who started the process: <startEvent id=\"startEvent\" camunda:initiator=\"starter\" /> ... <userTask id=\"task\" name=\"Clarify Invoice\" camunda:assignee=\"${ starter }\"/> ... First, the camunda:initiator extension is used to bind the user id of the person who started (“initiated”) the process to the variable starter. Then the expression ${ starter } retrieves that value and uses it as assignee for the task. It is possible to use all process variables visible from the User Task in the expression. Invoking a Service / Bean When using Spring or CDI, it is possible to delegate to a bean or service implementation. This way it is possible to call out to complex assignment logic without modeling it as an explicit service task in the process which would then produce a variable used in the assignment. In the following example, the assignee will be set by calling the findManagerOfEmployee() on the ldapService Spring/CDI bean. The emp parameter that is passed is a process variable. <userTask id=\"task\" name=\"My Task\" camunda:assignee=\"${ldapService.findManagerForEmployee(emp)}\"/> This also works in a similar way for candidate users and groups: <userTask id=\"task\" name=\"My Task\" camunda:candidateUsers=\"${ldapService.findAllSales()}\"/> Note that this will only work if the return type of the invoked methods is String or Collection<String> (for candidate users and groups): public class FakeLdapService { public String findManagerForEmployee(String employee) { return \"Kermit The Frog\"; } public List<String> findAllSales() { return Arrays.asList(\"kermit\", \"gonzo\", \"fozzie\"); } } Assignments in Listeners It is also possible to use task listeners for handling assignments. The following example demonstrates a task listener on the create event: <userTask id=\"task1\" name=\"My task\" > <extensionElements> <camunda:taskListener event=\"create\" class=\"org.cibseven.bpm.MyAssignmentHandler\" /> </extensionElements> </userTask> The DelegateTask that is passed to the TaskListener implementation allows you to set the assignee and candidate-users/groups: public class MyAssignmentHandler implements TaskListener { public void notify(DelegateTask delegateTask) { // Execute custom identity lookups here // and then for example call following methods: delegateTask.setAssignee(\"kermit\"); delegateTask.addCandidateUser(\"fozzie\"); delegateTask.addCandidateGroup(\"management\"); ... } } Note Assigning a task, or setting any other property through a TaskListener, will not result in an assignment or update event unless a TaskService method is used to perform these actions. This is intentional, in order to avoid creating event loops. Assignments and Identity Service Although the CIB seven engine provides an identity management component, which is exposed through the IdentityService, it does not check whether a provided user is known by the identity component. This allows integration of the engine with existing identity management solutions when it is embedded into an application. However, note that you can use the identity service in a service / bean or listener to query your user repository if this is useful to you. You can query for users with the help of the identity service. See the following example: ProcessEngine processEngine = delegateTask.getProcessEngine(); IdentityService identityService = processEngine.getIdentityService(); List<User> managementUsers = identityService.createUserQuery() .memberOfGroup(\"management\") .list(); User kermit = identityService.createUserQuery() .userFirstName(\"kermit\") .singleResult(); Reporting Bpmn Error See the documentation for Error Boundary Events. To report a business error during user task operation, use TaskService#handleBpmnError. It can be invoked only when the task is active. The #handleBpmnError method requires a mandatory argument: errorCode. The error code identifies a predefined error. If the given errorCode does not exist or there is no boundary event defined, the current activity instance simply ends and the error is not handled. See the following example: Task task = taskService.createTaskQuery().taskName(\"Perform check\").singleResult(); // ... business error appears taskService.handleBpmnError( task.getId(), \"bpmn-error-543\", // errorCode \"Thrown BPMN Error during...\", // errorMessage variables); A BPMN error with the error code bpmn-error-543 is propagated. If a boundary event with this error code exists, the BPMN error will be caught and handled. The error message and variables are optional. They can provide additional information for the error. The variables will be passed to the execution if the BPMN error is caught. Reporting Bpmn Escalation See the documentation for Catching Escalation Events. Reporting an escalation during user task execution can be achieved via TaskService#handleEscalation. The user task should be active to do so. The escalationCode is compulsory to invoke the escalation, this code identifies a predefined escalation. If the given escalationCode does not exist an Process Engine Exception will be thrown. See the following example: taskService.handleEscalation( taskId, \"escalation-432\", // escalationCode variables); Here an escalation is propagated with escalation code escalation-432. If a boundary event with this escalation code exists, the escalation will be caught and handled. The variables are optional. They will be passed to the execution if the escalation is caught. Completion Complete is part of the task lifecycle operation along with create, set candidate, assign, etc. (allow available via Java API). Complete a task by passing variables, optionally the process variables can be retrieved:: taskService.complete(taskId, variables); // or complete and retrieve the process variables VariableMap processVariables = taskService .completeWithVariablesInReturn(taskId, variables, shouldDeserializeValues); Forms It is possible to provide information to render a User Task form by using the camunda:formKey attribute: <userTask id=\"someTask\" camunda:formKey=\"someForm.html\"> ... </userTask> The form key is a symbolic value which can be set in the BPMN XML file by using the extension attribute formKey and retrieved at runtime using the process engine API. If the User Task form is displayed inside the Camunda Tasklist, the format of the formKey must follow special rules. See the corresponding section in the user guide for details. In custom applications, the value of the form key attribute can be interpreted freely. Based on the specific UI technology used, it can reference the name of an HTML file, a JSF / Facelets template, a Vaadin / GWT view, … Retrieving the Form Key using the Form Service. String formKey = formService.getTaskFormData(someTaskId).getFormKey(); Retrieving the Form using the Task Service When performing a task query, it is possible to retrieve the form key as well. This is most useful if the form keys need to be retrieved for a complete list of tasks: List<Task> tasks = TaskService.createTaskQuery() .assignee(\"jonny\") .initializeFormKeys() // must be invoked .list(); for(Task task : tasks) { String formKey = task.getFormKey(); } Note that it is required to call the .initializeFormKeys() method on the TaskQuery object to make sure the form keys are initialized. Form submission When a form is submitted, it is possible to fetch the process variables in return: VariableMap processVariables = formService .submitTaskFormWithVariablesInReturn(taskId, properties, shouldDeserializeValues); // or avoid unnecessary variable access formService.submitTaskForm(taskId, properties); Camunda Extensions Attributes camunda:assignee, camunda:asyncBefore, camunda:asyncAfter, camunda:candidateGroups, camunda:candidateUsers, camunda:dueDate, camunda:exclusive, camunda:formHandlerClass, camunda:formKey, camunda:formRef, camunda:formRefBinding, camunda:formRefVersion, camunda:jobPriority, camunda:priority Extension Elements camunda:formData, camunda:formProperty, camunda:taskListener, camunda:failedJobRetryTimeCycle, camunda:inputOutput Constraints The attribute camunda:assignee cannot be used simultaneously with the humanPerformer element Only one camunda:formData extension element is allowed The camunda:exclusive attribute is only evaluated if the attribute camunda:asyncBefore or camunda:asyncAfter is set to true",
    "url": "/manual/latest/reference/bpmn20/tasks/user-task/index.html"
  },
  {
    "id": "manual/latest/reference/cmmn11/api/classic-vs-fluent/index.html",
    "title": "Classic vs Fluent API | docs.cibseven.org",
    "content": "To interact with case instances and executions, the process engine offers the case service. It can be retrieved by processEngine.getCaseService(). The CaseService offers two API variants. One is in the following referred to as the classic API, since it is very similar to the API offered by the RuntimeService for BPMN processes. The fluent API follows a different concept in that it allows composition of case service commands by method chaining. Classic and Fluent API by Example As an example, the CaseService offers two classic methods to manually start a task: caseService.manuallyStartCaseExecution(caseExecutionId); Map<String, Object> variables = new HashMap<String, Object>(); variables.put(\"aVariableToSet\", \"aValueToSet\"); caseService.manuallyStartCaseExecution(caseExecutionId, variables); The same can be expressed using the fluent API as follows: caseService .withCaseExecution(caseExecutionId) .manualStart(); Map<String, Object> variables = new HashMap<String, Object>(); variables.put(\"aVariableToSet\", \"aValueToSet\"); caseService .withCaseExecution(caseExecutionId) .setVariables(variables) .manualStart(); In this way, the fluent API is another, fluently readable way of expressing the same functionality. On top, the fluent API, due to its flexibility, allows expression of very specific interactions that the classic API does not offer. For example, the following snippet manually starts a case execution, sets variables and removes another variable in one command (and therefore transaction): Map<String, Object> variables = new HashMap<String, Object>(); variables.put(\"aVariableToSet\", \"aValueToSet\"); caseService .withCaseExecution(caseExecutionId) .setVariables(variables) .removeVariable(\"aVariableToRemove\") .manualStart(); Entry Points to the Fluent API The fluent API can be used to work with case definitions and case executions. The entry points are as follows: caseService.withCaseDefinition(caseDefinitionId): Offers interactions on the case definition that has the provided id, such as creating a new case instance. caseService.withCaseDefinitionByKey(caseDefinitionKey): Offers interactions on the case definition that has the latest version of those that have the provided key. caseService.withCaseExecution(caseExecutionId): Offers interactions on case executions, such as starting and completing tasks.",
    "url": "/manual/latest/reference/cmmn11/api/classic-vs-fluent/index.html"
  },
  {
    "id": "manual/latest/reference/cmmn11/concepts/entry-exit-criteria/index.html",
    "title": "Entry and Exit Criteria | docs.cibseven.org",
    "content": "Transitions in a CMMN case can happen in two ways: Either by external interaction or by events occurring and conditions being fulfilled. The former refers to any explicit interaction with a case that is triggered from the outside. For example, a human worker completing a human task would be such an interaction. Completing a task means that the corresponding plan item is completed, depending on the actual case model, the case instance may complete. Similar changes in the state of a case instance may be driven by events occurring or conditions getting fulfilled. For example, it is possible to define that when one plan item completes, another is enabled. Similarly, a plan item can terminate when an event triggers. When specifying plan items, this concept is referred to as entry criteria and exit criteria. These criteria are always defined for individual plan items, not for plan item definitions. For example, the following case model fragment defines an entry criterion for the plan item PlanItem_HumanTask_1: <definitions> <case id=\"case\" name=\"Case\"> <casePlanModel id=\"CasePlanModel_1\"> <planItem id=\"PlanItem_HumanTask_1\" definitionRef=\"HumanTask_1\"> <entryCriterion sentryRef=\"Sentry_1\" /> </planItem> <planItem id=\"PlanItem_HumanTask_2\" definitionRef=\"HumanTask_1\"/> <sentry id=\"Sentry_1\"> <planItemOnPart sourceRef=\"PlanItem_HumanTask_2\"> <standardEvent>complete</standardEvent> </planItemOnPart> </sentry> <humanTask id=\"HumanTask_1\" camunda:assignee=\"kermit\" /> </casePlanModel> </case> </defintions> Similarly, PlanItem_HumanTask_1 with an exit criterion looks as follows: <planItem id=\"PlanItem_HumanTask_1\" definitionRef=\"HumanTask_1\"> <exitCriterion sentryRef=\"Sentry_1\" /> </planItem> The conditions and events behind entry and exit criteria can be expressed by so-called sentries. Refer to the Sentry section on how sentries work and what kind of conditions can be expressed by them. When any entry criterion is met, the plan item it is defined for performs the state transition from AVAILABLE to ENABLED. While the plan item is not in state AVAILABLE, entry criteria are not relevant. Any exit criteria can only be met when the corresponding plan item is in the ACTIVE state. When any exit criterion is met, a plan item performs a state transition from ACTIVE to state TERMINATED. The details of plan item states and transitions are provided in the Plan Item Lifecycles section.",
    "url": "/manual/latest/reference/cmmn11/concepts/entry-exit-criteria/index.html"
  },
  {
    "id": "manual/latest/reference/cmmn11/concepts/index.html",
    "title": "CMMN Concepts | docs.cibseven.org",
    "content": "This section introduces the concepts behind CMMN. Understanding these concepts is important when designing and implementing Cases with CMMN.",
    "url": "/manual/latest/reference/cmmn11/concepts/index.html"
  },
  {
    "id": "manual/latest/reference/cmmn11/concepts/lifecycle/index.html",
    "title": "Plan Item Lifecycles | docs.cibseven.org",
    "content": "CMMN case instances and plan items go through a lifecycle of states during their execution. Depending on their state, different actions may be carried out to interact with them. Moreover, state transitions may automatically trigger changes in other plan items. The concrete lifecycle of a plan item depends on its plan item definition. The following descriptions cover the CMMN lifecycles as supported by the CIB seven engine. This is a subset of states and transitions that the CMMN standard defines. Any state or transition that is currently not supported is marked in grey. The descriptions in this section are general for the constructs they describe. Considerations that are specific for individual plan item definitions can be found in the respective sections of this guide. Lifecycles By Example To understand the role lifecycles play for CMMN execution, consider the following case: This case contains two human tasks Task A and Task B that are connected by a sentry. The sentry expresses that Task B can be enacted when Task A finishes. This is formally specified by lifecycles. In our example, the following steps might take place: A user instantiates the case by caseService.createCaseInstanceByKey(\"case\");. A new case instance is created in state ACTIVE. Two instances for each human task are automatically created, both in state AVAILABLE. Task A does not have a condition to start, so it immediately reaches state ENABLED. Note that the steps 1 to 3 all happens synchronously with the caseService invocation from step 1. The case is now in the following state: 4. A user manually starts Task A by calling `caseService.manuallyStartCaseExecution(taskAExecutionId);`. As a consequence, Task A reaches state `ACTIVE` and a task instance is added to the assignee's task list. Note that starting a task is only allowed if that task is in state `ENABLED`. Thus, trying to manually start Task B here by `caseService.manuallyStartCaseExecution(taskBExecutionId);` would fail. The state is now: 5. The assignee completes the task instance by calling `taskService.complete(taskId);`. Task A reaches the state `COMPLETED`. 6. Task A's state transition triggers Task B's sentry. In consequence, Task B becomes `ENABLED`. This happens synchronously in the invocation from step 5. Accordingly, the case's new state is: 7. Similar to Task A, a user may now use the `CaseService` and `TaskService` to start Task B, complete the corresponding task instance, and complete Task B. Ultimately, Task B reaches the state `COMPLETED`. 8. With both tasks in state `COMPLETED`, the case instance automatically reaches the state `COMPLETED` as well. The state has case has reached the following state: 9. A user may close the case instance by invoking `caseService.closeCaseInstance(caseInstanceId);`. The case instance reaches the state `CLOSED`. Notice how the lifecycle states define the overall state of the case and restrict the interactions that are possible. For example, the tasks A and B can only be worked on when in state ACTIVE. Before, they go through states AVAILABLE and ENABLED, which represent that conditions for working on the task are not yet met, for example that the task was not manually started or that a sentry is not fulfilled yet. This formal lifecycle model is exposed via the CaseService API in Camunda. Not only is it possible to trigger state transitions as in the code examples above. By making a case instance or case execution query, the current lifecycles state of a plan items are exposed. For example, the following code gets the state of the plan item for Task A: CaseExecution caseExecution = caseService.createCaseExecutionQuery().activityId(\"taskA\").singleResult(); caseExecution.isAvailable(); caseExecution.isActive(); caseExecution.isCompleted(); ... Note that a CaseExecution object corresponds to a plan item, here the plan item for Task A. Case Instance Lifecycle Case instance refers to an instance of the case plan model. More specific, it is an instance of the single top-level stage in a case definition. The lifecycle of a case instance is the following: States: State Description active The state active is the initial state when a case is instantiated via the CaseService API. Subsequently, all plan items defined in the case plan model are created and enter the state available. completed The transition complete automatically triggers when all plan items contained in the case plan model are completed, terminated, or disabled. With automatic completion enabled, only required plan items have to reach theses states. Furthermore, it is possible to manually complete a case instance via the CaseService API if it has no active tasks or stages and all required plan items are either completed, terminated, or disabled. terminated The transition terminate automatically triggers when the case instance's exit criteria are fulfilled. Furthermore, it is possible to manually terminate an active case instance via the CaseService API. closed A case instance can be manually closed at any time via the CaseService API. This removes the case instance from the runtime database. Task/Stage Lifecycle The lifecycle of a task or stage plan item is the following: States: State Description available A task/stage becomes available as soon as the stage it is contained in becomes active. enabled A task or stage becomes enabled as soon as any of its entry criteria is fulfilled. If this is given when a the task/stage becomes available, it immediately becomes enabled or, depending on its manual activation rule, active. disabled A task or stage can be disabled by using the CaseService API. While an enabled task prevents the containing stage from completion, disabling contained tasks is one way of making a stage completable. Similarly, a disabled task/stage can be re-enabled using the CaseService API. active When a task or stage becomes active, its actual work is performed. For a stage, all contained plan items are instantiated. For a task, its actual work is issued, e.g., for a human task, a task instance is created and needs to be worked on by a user. In order for a task or stage to become active, at least one entry criterion has to be fulfilled. Activation can either be performed manually by a human worker using the CaseService API if the manualActivation rule is specified or automatically if not manualActivation rule is specified. completed The complete transition triggers for a task when its actual work is done. For a stage, this transition triggers when all contained tasks/stages are either completed, terminated, or disabled. With automatic completion enabled, only required plan items have to reach theses states. A task/stage in state completed is removed from the runtime database. terminated The exit transition triggers when the task's/stage's exit criteria are met or when the parent (Case instance or a stage) is terminated. Furthermore, it is possible to manually terminate an active stage/task via the CaseService API. A task/stage in state terminated is removed from the runtime database. Milestone Lifecycle The lifecycle of a milestone plan item is the following: States State Description available A milestone becomes available as soon as the stage it is contained in becomes active. completed The transition occur automatically triggers when all entry criteria of the milestone are fulfilled. terminated It is possible to manually terminate an available milestone via the CaseService API. A task/stage in state terminated is removed from the runtime database.",
    "url": "/manual/latest/reference/cmmn11/concepts/lifecycle/index.html"
  },
  {
    "id": "manual/latest/reference/cmmn11/concepts/plan-items/index.html",
    "title": "Plan Items and Item Definitions | docs.cibseven.org",
    "content": "CMMN differentiates between plan items and plan item definitions. While plan items represent actual units of work that are enacted as part of the case, plan item definitions serve as the blueprint for how a plan item has to be enacted. This concept simplifies reuse of plan item definitions and furthermore enables dynamic planning so that additional items can be generated from a definition at runtime. As an example, consider the following fragment of a case definition: <definitions> <case id=\"case\" name=\"Case\"> <casePlanModel id=\"CasePlanModel_1\"> <planItem id=\"PlanItem_HumanTask_1\" definitionRef=\"HumanTask_1\" /> <planItem id=\"PlanItem_HumanTask_2\" definitionRef=\"HumanTask_1\" /> <humanTask id=\"HumanTask_1\" camunda:assignee=\"kermit\" /> </casePlanModel> </case> </defintions> This model contains one plan item definition, namely the humanTask element. This definition is referenced by two plan items, PlanItem_HumanTask_1 and PlanItem_HumanTask_2. When a new case of this model is created, there will be two human task instances, one for each plan item. The plan item definition is the single point at which the human task is configured. Thus, the assignee specification by the attribute camunda:assignee=\"kermit\" is valid for both plan items. Accordingly, a case plan model that contains plan item definitions but no plan items will appear as a case with no tasks at runtime. Apart from reuse of configuration, plan item definitions can be instantiated at runtime, typically referred to as planning. Planning allows users to create plan items of a well-defined set of plan item definitions dynamically as needed. Note that planning is currently not supported by the CIB seven engine. This reference describes, if not otherwise noted, the plan item definitions supported by the CIB seven engine. Whenever there is a consideration of runtime state, it is assumed that a plan item referencing that definition exists.",
    "url": "/manual/latest/reference/cmmn11/concepts/plan-items/index.html"
  },
  {
    "id": "manual/latest/reference/cmmn11/custom-extensions/camunda-attributes/index.html",
    "title": "Extension Attributes | docs.cibseven.org",
    "content": "The following attributes are extension attributes for the camunda namespace http://camunda.org/schema/1.0/cmmn. assignee Description This attribute specifies a performer of a Human Task. Type java.lang.String or org.cibseven.bpm.engine.delegate.Expression Possible Values The name of a performer as java.lang.String or an expression which evaluates to a java.lang.String e.g., ${perfomer} Default Value – CMMN 1.1 Elements Human Task candidateGroups Description This attribute specifies which group(s) will be candidate for performing the Human Task. Type java.lang.String or org.cibseven.bpm.engine.delegate.Expression Possible Values Comma separated list of group ids as java.lang.String or expressions that evaluate to a java.lang.String or a java.util.Collection of java.lang.String, e.g., management or management, ${accountancyGroupId()} Default Value – CMMN 1.1 Elements Human Task candidateUsers Description This attribute specifies which user(s) will be candidate for performing the Human Task. Type java.lang.String or org.cibseven.bpm.engine.delegate.Expression Possible Values Comma separated list of user ids as java.lang.String or expressions that evaluate to a java.lang.String or a java.util.Collection of java.lang.String, e.g., kermit, gonzo or ${ldapService.findAllSales()} Default Value – CMMN 1.1 Elements Human Task caseBinding Description This attribute specifies which case definition version should be called inside the case task. Type java.lang.String Possible Values latest, deployment, version Constraints If the value is set to version the attribute camunda:caseVersion is required, see Case Binding for more information. Default Value – CMMN 1.1 Elements Case Task caseTenantId Description The attribute specifies the tenant id of the case definition which is to be resolved by a case task, see Case Tenant Id for more information. Type java.lang.String or org.cibseven.bpm.engine.delegate.Expression Possible Values A concrete tenant id or an expression which evaluates to a java.lang.String e.g., ${caseExecution.tenantId} Default Value – CMMN 1.1 Elements Case Task caseVersion Description This attribute explicitly defines which case definition version should be called inside the case task. Type java.lang.Integer or org.cibseven.bpm.engine.delegate.Expression Possible Values All deployed version numbers of the case definition to call or an expression which evaluates to a java.lang.Integer Default Value – CMMN 1.1 Elements Case Task class Description The attribute specifies which Java class will be executed at runtime. The stated class must implement a Java delegate interface. Type java.lang.String Possible Values Fully qualified Java class name of a class which implements a Java Delegate interface, e.g., org.cibseven.bpm.MyJavaDelegate Default Value – CMMN 1.1 Elements camunda:variableListener, camunda:caseExecutionListener decisionBinding Description This attribute specifies which decision definition version should be evaluated inside the decision task. Type java.lang.String Possible Values latest, deployment, version Constraints If the value is set to version the attribute camunda:decisionVersion is required. Default Value latest CMMN 1.1 Elements Decision Task decisionTenantId Description The attribute specifies the tenant id of the decision definition which is to be evaluated by a decision task, see Decision Tenant Id for more information. Type java.lang.String or org.cibseven.bpm.engine.delegate.Expression Possible Values A concrete tenant id or an expression which evaluates to a java.lang.String e.g., ${caseExecution.tenantId} Default Value – CMMN 1.1 Elements Decision Task decisionVersion Description This attribute explicitly defines which decision definition version should be called inside the decision task. Type java.lang.Integer or org.cibseven.bpm.engine.delegate.Expression Possible Values All deployed version numbers of the decision definition to call or an expression which evaluates to a java.lang.Integer Default Value – CMMN 1.1 Elements Decision Task delegateExpression Description The attribute allows specification of an expression which must resolve to an object that implements the corresponding interface (see delegation code). Type org.cibseven.bpm.engine.delegate.Expression Possible Values Expression which evaluates to a Java class implementing a delegation interface, e.g., ${myVariableListener}. Default Value – CMMN 1.1 Elements camunda:variableListener, camunda:caseExecutionListener dueDate Description This attribute specifies the initial due date of a Human Task when it is created. Type org.cibseven.bpm.engine.delegate.Expression Possible Values An expression which evaluates to a java.util.Date, java.util.String (ISO 8601 formatted) or null, e.g., ${dueDate} Default Value – CMMN 1.1 Elements Human Task expression Description The attribute defines an expression which will be evaluated at runtime. Type org.cibseven.bpm.engine.delegate.Expression Possible Values Expression, e.g., ${gender == 'male' ? 'Mr.' : 'Mrs.'} or #{printer.printMessage()} Default Value – CMMN 1.1 Elements camunda:variableListener, camunda:caseExecutionListener formKey Description This attribute specifies a form resource. See task forms for more information. Type java.lang.String Possible Values A java.lang.String of a form resource which can be evaluated by the Tasklist Default Value – CMMN 1.1 Elements Human Task historyTimeToLive Description The attribute specifies the history time to live (in days) for the case definition. It is used within History cleanup. Type java.lang.Integer or java.lang.String Possible Values Any non-negative integer number or string containing a time in days defined by the ISO-8601 date format. Default Value null - means that case definition history won't ever be removed during history cleanup run CMMN 1.1 Elements Case mapDecisionResult Description The attribute references which built-in Decision Result Mapper is used to pass the result of an evaluated decision to a case variable. It should be used in combination with camunda:resultVariable. Type java.lang.String Possible Values singleEntry, singleResult, collectEntries, resultList Default Value resultList CMMN 1.1 Elements Decision Task priority Description This attribute specifies the initial priority of a Human Task when it is created. Type org.cibseven.bpm.engine.delegate.Expression Possible Values An expression which evaluates to a java.lang.Number or a java.lang.String which represents a number or null, e.g., ${priority} Default Value – CMMN 1.1 Elements Human Task processBinding Description This attribute specifies which process definition version should be called inside the process task. Type java.lang.String Possible Values latest, deployment, version Constraints If the value is set to version the attribute camunda:processVersion is required, see Process Binding for more information. Default Value – CMMN 1.1 Elements Process Task processTenantId Description The attribute specifies the tenant id of the process definition which is to be resolved by a process task, see Process Tenant Id for more information. Type java.lang.String or org.cibseven.bpm.engine.delegate.Expression Possible Values A concrete tenant id or an expression which evaluates to a java.lang.String e.g., ${caseExecution.tenantId} Default Value – CMMN 1.1 Elements Process Task processVersion Description This attribute explicitly defines which process definition version should be called inside the process task. Type java.lang.Integer or org.cibseven.bpm.engine.delegate.Expression Possible Values All deployed version numbers of the process definition to call or an expression which evaluates to a java.lang.Integer Default Value – CMMN 1.1 Elements Process Task repeatOnStandardEvent Description The attribute specifies a transition in which the repetition rule of a stage or task is evaluated. Note that this attribute is omitted when the stage or task to repeat has at least one entry criterion. Type java.lang.String Possible Values create, enable, disable, reenable, manualStart, start, complete, exit Default Value complete CMMN 1.1 Elements Repetition Rule resource Description The attribute specifies an external resource. The resource can be part of the deployment or exists in the classpath. To specify the type of resource, a URL scheme like prefix deployment:// resp. classpath:// can be supplied. If the scheme is omitted, it is assumed that the resource exists in the classpath. Type java.lang.String or org.cibseven.bpm.engine.delegate.Expression Possible Values The path to a resource or an expression which returns the path. Optional the path can start with an URL like scheme classpath:// or deployment:// to specify where to find the resource. If omitted the resource is assumed to exists in the classpath. Default Value – CMMN 1.1 Elements camunda:variableListener, camunda:caseExecutionListener resultVariable Description The attribute specifies the case variable in which the returned decision result is saved. It can be used in combination with camunda:mapDecisionResult to define a decision result mapping. Type java.lang.String Possible Values The name of a case variable to save the return value Default Value – CMMN 1.1 Elements Decision Task variableName Description The variable name that is attached to element camunda:variableOnPart for which the sentry listens. Sentry is evaluated when the variable event transition occurs. Type java.lang.String Camunda extension element camunda:variableOnPart",
    "url": "/manual/latest/reference/cmmn11/custom-extensions/camunda-attributes/index.html"
  },
  {
    "id": "manual/latest/reference/cmmn11/custom-extensions/camunda-elements/index.html",
    "title": "Extension Elements | docs.cibseven.org",
    "content": "The following elements are extension elements for the camunda namespace http://camunda.org/schema/1.0/cmmn. caseExecutionListener Description Add an execution listener to an event in the lifecycle of a case item. Attributes event The type of the lifecycle event for which the listener is called class see camunda:class expression see camunda:expression delegateExpression see camunda:delegateExpression Constraints The event attribute is required and must be one of the lifecycle events that are valid for the plan item it is defined on. For regular tasks, these are: create, enable, disable, reenable, start, manualStart, complete, reactivate, terminate, exitparentTerminate, suspend, resume, parentSuspend, parentSuspend, close, occur One of the attributes class, expression or delegateExpression is mandatory Parent elements Case, Human Task, Process Task, Case Task, Stage, Milestone, Child elements camunda:field, camunda:script expression Description Defines an expression to inject in delegated classes (see Field Injection). Attributes – Text Content The expression to inject Constraints – Parent elements camunda:field Child elements – field Description Defines the value to inject in delegated classes (see Field Injection). Attributes name The name of the field expression The value of the field as expression stringValue The value of the field as String Constraints Only one attribute of stringValue and expression or one of the child elements string and expression can be used Parent elements camunda:variableListener, camunda:caseExecutionListener Child elements camunda:expression, camunda:string in Description This element specifies variables which should be passed to the sub instance (process instance or case instance), see passing variables to called process or passing variables to called case for more information. Attributes source A name of a variable to be passed in sourceExpression An expression to be evaluated and passed in variables Can be set to all to pass all variables in target Name of the variable inside the sub instance local Can be set to true to only pass local variables of the case execution that executes this case/process task instance. businessKey Set the business key of the sub instance Constraints Only one of the attributes source, sourceExpression, variables or businessKey can be used The attribute target is required if the source or sourceExpression attribute is used Parent elements Process Task, Case Task Child elements – out Description This element specifies variables which should be passed back from the sub instance (process instance or case instance), see passing variables to called process or passing variables to called case for more information. Attributes source A name of a variable to be passed back sourceExpression An expression to be evaluated and passed back variables Can be set to all to pass all sub instance variables back target Name of the variable inside the calling case instance Constraints Only one of the attributes source, sourceExpression or variables can be used The attribute target is required if the source or sourceExpression attribute is used Parent elements Process Task, Case Task Child elements – script Description A script element. The script is executed and the return value is used as mapping value. Attributes scriptFormat The format identifier, normally the language of the script source code resource equivalent to camunda:resource Constraints The scriptFormat attribute is required If the resource attribute is used, no source code text content is allowed Parent elements camunda:variableListener, camunda:caseExecutionListener Child elements – string Description Defines a String value to inject in delegated classes (see Field Injection). Attributes – Text Content The String value to inject Constraints – Parent elements camunda:field Child elements – taskListener Description Add a task listener to a task event. Attributes event The type of the event for which the listener is called class see camunda:class expression see camunda:expression delegateExpression see camunda:delegateExpression Constraints The event attribute is required and must be one of the task events: create, assignment, complete or delete One of the attributes class, expression or delegateExpression is mandatory Parent elements Human Task Child elements camunda:field, camunda:script variableListener Description Adds custom code to listen to variable events such as the creation, update or deletion of a variable. A listener defined on a model scope (like the case plan model, a human task, etc.) is notified for all variable events that occur in this scope or any of its subordinate scopes. Attributes event The type of the event for which the listener is called class see camunda:class expression see camunda:expression delegateExpression see camunda:delegateExpression Constraints Valid values for the event attribute are create, update and delete. This attribute is optional and if left out, the listener is notified for all kinds of events. Either one of the attributes class, expression or delegateExpression, or a camunda:script child element is mandatory. Parent elements Case Plan Model, Stage, Human Task, Process Task, Case Task Child elements camunda:field, camunda:script variableOnPart Description Add variableOnPart to sentry. see variableOnPart. Attributes variableName see camunda:variableName Constraints variableEvent element and variableName attribute are mandatory fields when the variableOnPart is defined in a sentry. Parent element Sentries Child element camunda:variableEvent variableEvent Description Add variableEvent to a VariableOnPart. A sentry is evaluated when the variableEvent transition occurs. Value Valid values are create,update or delete Parent element VariableOnPart",
    "url": "/manual/latest/reference/cmmn11/custom-extensions/camunda-elements/index.html"
  },
  {
    "id": "manual/latest/reference/cmmn11/custom-extensions/index.html",
    "title": "Extension Reference | docs.cibseven.org",
    "content": "Camunda extends CMMN with custom Extension Elements and Attributes defined in the http://camunda.org/schema/1.0/cmmn namespace.",
    "url": "/manual/latest/reference/cmmn11/custom-extensions/index.html"
  },
  {
    "id": "manual/latest/reference/cmmn11/grouping-tasks/index.html",
    "title": "Grouping Tasks | docs.cibseven.org",
    "content": "Multiple tasks can be grouped together using a Stage.",
    "url": "/manual/latest/reference/cmmn11/grouping-tasks/index.html"
  },
  {
    "id": "manual/latest/reference/cmmn11/grouping-tasks/stage/index.html",
    "title": "Stage | docs.cibseven.org",
    "content": "A stage can contain other plan items like a human task, a process task, a case task or another stage. Stages may be considered ’episodes’ of a case. However, stages are not necessarily planned sequentially but can also be active in parallel. If a stage is collapsed, only its name and a plus sign are displayed: If a stage is expanded, its plan items are displayed within its boundaries: A stage is defined in XML as follows: <stage id=\"checkCredit\"> <!-- plan items --> <planItem id=\"PI_checkSolvency\" definitionRef=\"checkSolvency\" /> <planItem id=\"PI_calculateCredit\" definitionRef=\"calculateCredit\" /> <planItem id=\"PI_calculateHousekeepingBill\" definitionRef=\"calculateHousekeepingBill\" /> </stage> Furthermore, a case always refers to one stage as its case plan model. The case plan model defines the outermost stage of the case. This outermost stage also contains all plan item definitions that are used in the case. <case> <casePlanModel> <!-- plan items --> <planItem id=\"PI_checkCredit\" definitionRef=\"checkCredit\" /> <!-- plan item definitions --> <humanTask id=\"checkSolvency\" name=\"Check Solvency\" /> <humanTask id=\"calculateCredit\" name=\"Calculate Credit\" /> <humanTask id=\"calculateHousekeepingBill\" name=\"Calculate Hausekeeping Bill\" /> <stage id=\"checkCredit\"> <!-- plan items --> <planItem id=\"PI_checkSolvency\" definitionRef=\"checkSolvency\" /> <planItem id=\"PI_calculateCredit\" definitionRef=\"calculateCredit\" /> <planItem id=\"PI_calculateHousekeepingBill\" definitionRef=\"calculateHousekeepingBill\" /> </stage> </casePlanModel> </case> Note: The listed plan item definitions inside the casePlanModel are referenced by plan items in the case plan model itself (i.e., stage), as well as by plan items in nested stages. Plan item definitions must not be contained by any other stage than the case plan model. A stage in state ENABLED can be started manually using the CaseService as follows: caseService.manuallyStartCaseExecution(\"aCaseExecutionId\"); When the stage becomes ACTIVE, the contained plan items are instantiated and reach the state AVAILABLE. A stage in this state always contains at least one stage or task instance in the state AVAILABLE, ENABLED, or ACTIVE. In other words, a stage completes automatically if a user has no option to do further work on its contained plan items. This means that if a contained plan item completes or is disabled, the stage is notified about that state transition and checks if it is able to complete. A stage instance can only complete if there are no contained plan items in the state ACTIVE, and all are either in state DISABLED or COMPLETED. In case the check succeeds, the stage instance completes. Camunda Extensions Extension Elements camunda:caseExecutionListener, camunda:variableListener",
    "url": "/manual/latest/reference/cmmn11/grouping-tasks/stage/index.html"
  },
  {
    "id": "manual/latest/reference/cmmn11/index.html",
    "title": "CMMN 1.1 Implementation Reference | docs.cibseven.org",
    "content": "This page provides an overview of the CMMN 1.1 elements and the current coverage of the process engine. The CMMN editor is disabled in recent versions of Camunda Modeler but can be enabled with a feature flag. For more context and information on how to enable this feature flag in Camunda Modeler, please see this forum post. Coverage The elements marked in orange are supported. Definitions Grouping Tasks Event-Triggered Elements CaseFileItem Markers Type Marker Planning Table Entry Criterion Exit Criterion AutoComplete Manual Activation Required Repetition Case Plan Model Stage Task Milestone EventListener CaseFileItem PlanFragment",
    "url": "/manual/latest/reference/cmmn11/index.html"
  },
  {
    "id": "manual/latest/reference/cmmn11/markers/auto-complete/index.html",
    "title": "Auto Complete | docs.cibseven.org",
    "content": "Can be used with: Stage, CasePlanModel The attribute autoComplete controls the completion of a stage instance. The following table describes the completion criteria of a stage instance based on the autoComplete property. autoComplete = true: There are no children in the ACTIVE state, and all required (see Required Rule) children are COMPLETED, DISABLED or TERMINATED. autoComplete = false: There are no children in the ACTIVE state, and all children are COMPLETED, DISABLED or TERMINATED, or on manual completion using CaseService#completeCaseExecution, all required (see Required Rule) children are COMPLETED, DISABLED or TERMINATED. For a CasePlanModel the property autoComplete can be set as follows: <case id=\"case\"> <casePlanModel id=\"CasePlanModel_1\" autoComplete=\"true\"> ... </casePlanModel> </case> For a Stage, the following XML can be used: <case id=\"case\"> <casePlanModel id=\"CasePlanModel_1\" autoComplete=\"true\"> <planItem id=\"PI_Stage_1\" definitionRef=\"Stage_1\" /> <stage id=\"Stage_1\" autoComplete=\"true\"/> </casePlanModel> </case>",
    "url": "/manual/latest/reference/cmmn11/markers/auto-complete/index.html"
  },
  {
    "id": "manual/latest/reference/cmmn11/markers/index.html",
    "title": "Markers | docs.cibseven.org",
    "content": "Markers allow control over behavioral aspects of plan items such as their lifecycle, if they are required or the number of repetitions.",
    "url": "/manual/latest/reference/cmmn11/markers/index.html"
  },
  {
    "id": "manual/latest/reference/cmmn11/markers/manual-activation-rule/index.html",
    "title": "Manual Activation Rule | docs.cibseven.org",
    "content": "Can be used with: Task, Stage Whether the actual work of a task or stage can be performed depends on its entry criteria. Given that an entry criterion is fulfilled, there are two ways to activate a task: By manual activation By automatic activation Automatic activation is the default behavior in which it is not required that a user manually activates a task. In camunda, manual activation can be done by using the CaseService API with caseService.manuallyStartCaseExecution(caseExecutionId). By specifying a manual activation rule, it is possible to omit this step or make it depend on case variable payload. With manual activation, a user can decide to activate a task or instead disable it. A task that is automatically activated must be carried out. In XML, a manual activation rule can be specified for an individual plan item or for a plan item definition. For a plan item it looks as follows: <planItem id=\"PlanItem_HumanTask_1\" definitionRef=\"HumanTask_1\"> <itemControl> <manualActivationRule> <condition>${true}</condition> </manualActivationRule> </itemControl> </planItem> <humanTask id=\"HumanTask_1\"> </humanTask> The specified expression ${true} evaluates to the boolean value true and means that the plan item should become active in only through the human intervention. For a plan item definition, the following XML can be used: <planItem id=\"PlanItem_HumanTask_1\" definitionRef=\"HumanTask_1\"/> <humanTask id=\"HumanTask_1\"> <defaultControl> <manualActivationRule> <condition>${true}</condition> </manualActivationRule> </defaultControl> </humanTask> The rule specified in the humanTask element is valid for all plan items that reference it, here PlanItem_HumanTask_1. Tricky Specification Automatic activation is the default behavior. Thus, by specifying the element manualActivationRule you can express exceptions from that default for cases in which a task does need a manual activation. As with any expression, you can use case variables to determine the result of a manual activation rule. The following snippet expresses that manual activation is required when a variable var has a value greater than 100: <manualActivationRule> <condition>${var > 100}</condition> </manualActivationRule> In terms of the task/stage lifecycle, manual activation corresponds to the transition from AVAILABLE to ENABLED when an entry criterion occurs, and from ENABLED to ACTIVE when the task is manually activated. In contrast, automatic activation corresponds to the direct transition from AVAILABLE to ACTIVE that fires immediately when an entry criterion occurs.",
    "url": "/manual/latest/reference/cmmn11/markers/manual-activation-rule/index.html"
  },
  {
    "id": "manual/latest/reference/cmmn11/markers/repetition-rule/index.html",
    "title": "Repetition Rule | docs.cibseven.org",
    "content": "Can be used with: Task, Stage, Milestone Under which conditions a plan item is repeatable can be specified by a repetition rule. In XML, a repetition rule can be specified for an individual plan item or for a plan item definition. For a plan item it looks as follows: <planItem id=\"PlanItem_HumanTask\" definitionRef=\"HumanTask\"> <itemControl> <repetitionRule> <condition><![CDATA[${var < 100}]]></condition> </repetitionRule> </itemControl> </planItem> <humanTask id=\"HumanTask\" /> For a plan item definition, the following XML can be used: <planItem id=\"PlanItem_HumanTask\" definitionRef=\"HumanTask\"/> <humanTask id=\"HumanTask_1\"> <defaultControl> <repetitionRule> <condition><![CDATA[${var < 100}]]></condition> </repetitionRule> </defaultControl> </humanTask> The rule specified in the humanTask element is valid for all plan items that reference it, here PlanItem_HumanTask_1. The behavior of the repetition relies on the presence of entry criteria. If there is no entry criterion defined, then the repetition rule is evaluated by default in the transition into the COMPLETED state. Otherwise the repetition rule is only evaluated, when an entry criterion is satisfied and the plan item instance transitions away from the state AVAILABLE into the next state. Repetition on completion To repeat a task or stage when it gets completed a repetition rule must be defined and the task or stage must not have any entry criteria. Whenever a task or stage instance transitions into the COMPLETED state, the repetition rule is evaluated and if it evaluates to true a new instance of the task or stage is created. The new instance transitions into the AVAILABLE state. Heads Up! It is not advisable to define a repetition rule without entry criteria on a milestone. Since a milestone without entry criteria gets fulfilled upon its instantiation, this would lead to an infinite loop. Consider the following excerpt of a CMMN case definition: The corresponding XML representation could look like this: <definitions> <case id=\"case\" name=\"Case\"> <casePlanModel id=\"CasePlanModel_1\"> <planItem id=\"PlanItem_HumanTask_A\" name=\"A\" definitionRef=\"HumanTask\" /> <humanTask id=\"HumanTask\"> <defaultControl> <repetitionRule> <condition><![CDATA[${score < 50}]]></condition> </repetitionRule> </defaultControl> </humanTask> </casePlanModel> </case> </defintions> This case contains a human task A. Task A has a repetition rule indicating that the task is repeatable as long as the variable score is less than 50. In our example, the following steps might take place: A user instantiates the case and sets the variable score to the value 10. An instance A for the human task is created. The instance A transitions into state ENABLED. A user manually starts task A and the instance reaches the state ACTIVE. A user completes task A. During the transition into state COMPLETED, the repetition rule is evaluated. As a consequence that the variable score is less than 50, a new instance A' of the corresponding task is created. The new instance moves into state ENABLED. Once again, a user manually starts and completes task A’. Since the variable score is still less than 50, the repetition rule evaluates to true when A’ transitions into state COMPLETED. As a result, a new instance A’’ is created. A user changes the value of the variable score to 55. A user manually starts and completes task A’’ and the instance reaches the state COMPLETED. Since the variable score has been set to 55 the repetition rule evaluates to false and a new instance is not created. From now on, no more repetitions of A can occur. The transition in which the repetition rule is evaluated can be changed by a Camunda extension attribute named camunda:repeatOnStandardEvent. For a task it looks as follows: <definitions> <case id=\"case\" name=\"Case\"> <casePlanModel id=\"CasePlanModel_1\"> <planItem id=\"PlanItem_HumanTask_A\" name=\"A\" definitionRef=\"HumanTask\" /> <humanTask id=\"HumanTask\"> <defaultControl> <repetitionRule camunda:repeatOnStandardEvent=\"disable\"> <condition><![CDATA[${score < 50}]]></condition> </repetitionRule> </defaultControl> </humanTask> </casePlanModel> </case> </defintions> This means that the repetition rule is evaluated in the transition disable. So, whenever an instance of the defined human task gets disabled, the repetition rule is evaluated and if this rule evaluates to true, a new instance is created. As a consequence, the repetition rule is not evaluated when an instance transitions in state COMPLETED anymore. Repetition triggered by entry criteria A trigger for a repetition of a milestone, stage or task is a satisfied sentry, that is referenced as entry criterion. Whenever an entry criterion is satisfied, the repetition rule is evaluated and if it evaluates to true, a new instance of the milestone, stage or task is created. The new instance transitions into the AVAILABLE state. The previous instance, in case of a milestone instance, transitions in state COMPLETED and, in case of a stage or task instance, into the ACTIVE or ENABLED state (depending on the manual activation rule) because the entry criterion is satisfied. Consider the following excerpt of a CMMN case definition, where the repetition of the tasks depends on the occurrence of an entry criterion: The corresponding XML representation could look like this: <definitions> <case id=\"case\" name=\"Case\"> <casePlanModel id=\"CasePlanModel_1\"> <planItem id=\"PlanItem_HumanTask_B\" name=\"B\" definitionRef=\"HumanTask\"> <entryCriterion sentryRef=\"Sentry_1\" /> </planItem> <planItem id=\"PlanItem_HumanTask_A\" name=\"A\" definitionRef=\"HumanTask\"> <entryCriterion sentryRef=\"Sentry_2\" /> </planItem> <sentry id=\"Sentry_1\"> ... </sentry> <sentry id=\"Sentry_2\"> <planItemOnPart sourceRef=\"PlanItem_HumanTask_B\"> <standardEvent>complete</standardEvent> </planItemOnPart> </sentry> <humanTask id=\"HumanTask\"> <defaultControl> <repetitionRule> <condition><![CDATA[${score < 50}]]></condition> </repetitionRule> </defaultControl> </humanTask> </casePlanModel> </case> </defintions> This case contains two human tasks A and B that are connected by a sentry. Task B gets ENABLED if any conditions are fulfilled and task A gets ENABLED if an instance of B completes. Furthermore both tasks are repeatable as long as the variable score is less than 50. In our example, the following steps might take place: A user instantiates the case and sets the variable score to the value 10. Two instances for each human task are automatically created and both transition in state AVAILABLE. When the entry criterion (Sentry_1) of instance B is satisfied, the task B reaches the state ENABLED. During the transition to the state ENABLED, the repetition rule is evaluated. As a consequence that the variable score is less than 50, a new instance B’ of the corresponding task is created. The instance B’ moves into state AVAILABLE. A user manually starts and completes task B and the instance reaches the state COMPLETED. The completion of instance B satisfies the entry criterion (Sentry_2) of A. In consequence, task A becomes ENABLED and a new instance A’ is created, because the evaluation of the repetition rule during the transition returns true. A user changes the value of the variable score to 55. The entry criterion (Sentry_1) of instance B’ is satisfied (once again). The instance B’ reaches the state ENABLED. As a consequence that the variable score has been set to 55, the repetition rule evaluates to false. So, a new instance is not created. A user manually starts and completes task B’ and the instance reaches the state COMPLETED. The completion of instance B’ satisfies the entry criterion (Sentry_2) of A’. So that A’ becomes ENABLED and a new instance of the corresponding task is not created, because the repetition rule evaluates to false. From now on, no more repetitions of A or B can occur. Camunda Extensions Attributes camunda:repeatOnStandardEvent Note The attribute camunda:repeatOnStandardEvent is ignored when a milestone, stage or task has at least one entry criterion.",
    "url": "/manual/latest/reference/cmmn11/markers/repetition-rule/index.html"
  },
  {
    "id": "manual/latest/reference/cmmn11/markers/required-rule/index.html",
    "title": "Required Rule | docs.cibseven.org",
    "content": "Can be used with: Task, Stage and Milestone A plan item may be required, meaning that it has to reach an end-like state before the containing stage can complete. Whether a plan item is required can be specified by a required rule. This rule is evaluated when the milestone, stage or task is instantiated and transitions to the state AVAILABLE, and its result value of type boolean is maintained throughout the remainder of the case instance. If this rule evaluates to true, the plan item’s parent stage instance must not transition to COMPLETED state unless the plan item is in the COMPLETED, TERMINATED or DISABLED state. For example, a task that has not yet been worked on, i.e., is in state ENABLED, prevents its containing stage to complete. If the rule is not present, then it is considered to be false. <planItem id=\"PlanItem_HumanTask_1\" definitionRef=\"HumanTask_1\"> <itemControl> <requiredRule> <condition>${true}</condition> </requiredRule> </itemControl> </planItem> <humanTask id=\"HumanTask_1\"> </humanTask> The specified expression ${true} evaluates to the boolean value true and means that the plan item is required. For a plan item definition, the following XML can be used: <planItem id=\"PlanItem_HumanTask_1\" definitionRef=\"HumanTask_1\"/> <humanTask id=\"HumanTask_1\"> <defaultControl> <requiredRule> <condition>${true}</condition> </requiredRule> </defaultControl> </humanTask> The rule specified in the humanTask element is valid and individually evaluated for all plan items that reference it, here PlanItem_HumanTask_1. As with any expression, you can use case variables to determine the result of a required rule. The following snippet expresses that the plan item is required when a variable var has a value greater than 100: <requiredRule> <condition>${var > 100}</condition> </requiredRule>",
    "url": "/manual/latest/reference/cmmn11/markers/required-rule/index.html"
  },
  {
    "id": "manual/latest/reference/cmmn11/migration/10-to-11/index.html",
    "title": "1.0 to 1.1 | docs.cibseven.org",
    "content": "In order to update existing CMMN 1.0 XMLs to valid CMMN 1.1 the following adjustments must be done. The namespace must be updated as follows: Affected Elements Definitions CMMN 1.0 <definitions xmlns=\"http://www.omg.org/spec/CMMN/20131201/MODEL\"> CMMN 1.1 <definitions xmlns=\"http://www.omg.org/spec/CMMN/20151109/MODEL\"> The <body/> element from expressions must be removed: Affected Elements Condition CMMN 1.0 <condition> <body>${any-expression}<body> </condition> CMMN 1.1 <condition>${any-expression}</condition> This is relevant for all elements containing a condition like `IfPart`, `ManualActivationRule` and `RequiredRule` The attributes entryCriteriaRefs and exitCriteriaRefs are dropped, so that the following adjustments must be done: Affected Elements PlanItem, CasePlanModel CMMN 1.0 <planItem id=\"A_PLAN_ITEM_ID\" entryCriteriaRefs=\"Sentry_1 Sentry_2\" exitCriteriaRefs=\"Sentry_3 Sentry4\" /> CMMN 1.1 <planItem id=\"A_PLAN_ITEM_ID\"> <entryCriterion sentryRef=\"Sentry_1\" /> <entryCriterion sentryRef=\"Sentry_2\" /> <exitCriterion sentryRef=\"Sentry_3\" /> <exitCriterion sentryRef=\"Sentry_4\" /> </planItem> The attribute description is not available anymore. Instead of the description attribute use the <documentation/> element: Affected Elements Any CMMN element CMMN 1.0 <planItem id=\"A_PLAN_ITEM_ID\" description=\"This is a description of the plan item...\" /> CMMN 1.1 <planItem id=\"A_PLAN_ITEM_ID\"> <documentation> This is a description of the plan item... </documentation> </planItem>",
    "url": "/manual/latest/reference/cmmn11/migration/10-to-11/index.html"
  },
  {
    "id": "manual/latest/reference/cmmn11/migration/index.html",
    "title": "Migration between Specification Versions | docs.cibseven.org",
    "content": "The following sections describe the necessary steps to migrate CMMN models from a given specification version to the next specification version.",
    "url": "/manual/latest/reference/cmmn11/migration/index.html"
  },
  {
    "id": "manual/latest/reference/cmmn11/milestone/index.html",
    "title": "Milestones | docs.cibseven.org",
    "content": "A milestone is used to represent achievable targets within the case. It is not associated with any work but rather marks that certain conditions have been reached within the case. As a milestone is a regular plan item definition, a milestone’s completion may be used as entry criteria for other tasks and stages. This way, a milestone can be used to bring logical stages within a case into order. In XML, a milestone is defined as follows: <milestone id=\"theMilestone\" name=\"A Milestone\"/> When referenced in a case plan, a milestone gets completed as soon as its entry criteria are fulfilled. This requires no human interaction. A more complete example of a milestone depending on the completion of a human task is the following: <definitions> <case id=\"case\" name=\"Case\"> <casePlanModel id=\"CasePlanModel_1\"> <planItem id=\"PlanItem_HumanTask\" definitionRef=\"HumanTask_1\"/> <planItem id=\"PlanItem_Milestone\" definitionRef=\"Milestone_1\"> <entryCriterion sentryRef=\"Sentry_1\" /> </planItem> <sentry id=\"Sentry_1\"> <planItemOnPart sourceRef=\"PlanItem_HumanTask\"> <standardEvent>complete</standardEvent> </planItemOnPart> </sentry> <humanTask id=\"HumanTask_1\" /> <milestone id=\"Milestone_1\" name=\"A Milestone\" /> </casePlanModel> </case> </defintions> In this case, the milestone will complete as soon as as the human task completes. A milestone cannot have exit criteria. Always define Milestones with Entry Criteria A milestone without entry criteria is fulfilled as soon as the stage it is contained in becomes active. For example, a milestone item that is defined on the case definition level is completed as soon as the case is instantiated. It is therefore advisable to define at least one entry criterion for a milestone plan item. Checking Milestones In order to check whether a milestone has occurred, the history service can be used. The following checks the state of a milestone instance: HistoricCaseActivityInstance milestoneInstance = historyService .createHistoricCaseActivityInstanceQuery() .caseInstanceId(\"aCaseInstanceId\") .caseActivityId(\"theMilestone\") .singleResult(); milestoneInstance.isCompleted(); // true if milestone occurred Camunda Extensions Extension Elements camunda:caseExecutionListener",
    "url": "/manual/latest/reference/cmmn11/milestone/index.html"
  },
  {
    "id": "manual/latest/reference/cmmn11/sentry/index.html",
    "title": "Sentries | docs.cibseven.org",
    "content": "A sentry captures the occurrence of a certain event occurring or a condition being fulfilled within a case. Sentries are used as entry and exit criteria. Note that the black and white diamonds represent the criteria. A sentry itself has no graphical representation. In XML, a sentry can be specified as follows: <planItem id=\"PlanItem_HumanTask_1\" definitionRef=\"HumanTask_1\"/> <planItem id=\"PlanItem_HumanTask_2\" definitionRef=\"HumanTask_1\"> <entryCriterion sentryRef=\"Sentry_1\" /> </planItem> <sentry id=\"Sentry_1\"> <planItemOnPart sourceRef=\"PlanItem_HumanTask_1\"> <standardEvent>complete</standardEvent> </planItemOnPart> <ifPart> <condition>${myVar > 100}</condition> </ifPart> </sentry> <humanTask id=\"HumanTask_1\"/> The above example defines a sentry that is fulfilled when the plan item PlanItem_HumanTask_1 performs the state transition complete (note the planItemOnPart element) and a variable named myVar has a value greater than 100 (note the ifPart element). Furthermore, it serves as an entry criterion for the plan item PlanItem_HumanTask_2 that becomes ENABLED as soon as the sentry is fulfilled (note the entryCriterion child element of the element PlanItem_HumanTask_2). As conditions or event triggers, sentries may define the following elements: OnPart: A trigger that occurs when a certain transition in the lifecycle of a plan item or a case file item is performed. IfPart: A condition that is checked when all OnParts are fulfilled. This condition is defined on case data. OnPart OnParts are defined on lifecycle transitions for plan items or case file items. As the CIB seven engine does not currently support case file items, it is only possible to use plan item OnParts. A sentry with an OnPart can be defined as follows: <sentry id=\"Sentry_1\"> <planItemOnPart sourceRef=\"PlanItem_1\"> <standardEvent>complete</standardEvent> </planItemOnPart> </sentry> A planItemOnPart must always reference a plan item by the attribute sourceRef. This plan item must be contained by the same stage the sentry is defined in. The child element standardEvent can the identifier of any lifecycle transition from that plan item’s lifecycle and that is supported by the CIB seven engine. Note that different plan item definitions define different lifecycles. For details on valid lifecycle transitions, see the Lifecycles section. As an alternative to sourceRef, the CMMN specification allows to define an attribute sentryRef responsible for referencing another sentry such that the onPart is fulfilled when the plan item that sentry references performs the exit state transition. This attribute is currently not supported by the CIB seven engine. Note that it is possible to have any number of OnParts which allows to combine multiple events. All OnParts must be fulfilled for a sentry to occur, i.e., specifying multiple OnParts is a conjunction of multiple events. An OnPart is fulfilled as soon as the element it is defined on performs the specified lifecycle transition. It is irrelevant whether this element performs any other subsequent lifecycle transitions. IfPart An IfPart defines an additional condition that is checked when all OnParts of the sentry are fulfilled. Only if the IfPart evaluates to true, the sentry is fulfilled. In Camunda, a sentry with an IfPart looks as follows: <sentry id=\"Sentry_1\"> <ifPart> <condition>${myVar > 100}</condition> </ifPart> </sentry> A sentry can have at most one IfPart and that IfPart can have at most one condition element. In the condition element, expression language must be used. In such an expression, case variables can be accessed by their name. The above example defines a condition that evaluates to true if there is a variable named myVar and that variable’s value is greater than 100. In addition to variable names, the identifier caseExecution can be used to access the execution object for the stage that the sentry is defined in. The below example explicitly accesses a local variable of that execution: <sentry id=\"Sentry_1\"> <ifPart> <condition>${caseExecution.getVariableLocal(\"myVar\") > 100}</condition> </ifPart> </sentry> The CMMN specification allows to reference a case file item by the sentry attribute contextRef. This attribute is not supported by the CIB seven engine and therefore ignored. The engine evaluates IfParts at every lifecycle transition of a plan item contained in the sentry’s stage. That means, if an IfPart is not satisfied immediately when all OnParts have occurred, the sentry may still occur at any later lifecycle transition. Camunda Extensions VariableOnPart VariableOnParts are defined on lifecycle transitions of a variable. Sentry with VariableOnPart is evaluated when the variable undergoes a transition (create or delete or update). A sentry can have more than one variableOnPart and can have at most one variable event each. In Camunda, a sentry with a variableOnPart looks as follows <sentry id=\"Sentry_1\"> <extensionElements> <camunda:variableOnPart variableName = \"variable_1\"> <camunda:variableEvent>create</camunda:variableEvent> </camunda:variableOnPart> </extensionElements> </sentry> In the above example, sentry is evaluated when the create event on the variable variable_1 occurs. VariableOnPart Evaluation Variable event that occurs in the scope of the execution triggers the sentry with variableOnParts in the following conditions: variableName and variableEvent defined in the variableOnPart of the sentry matches the occurred variable event and the associated variable name. There exists no variable of the same name in the ancestory path of the sentry between the execution scope of the sentry and the execution scope of the variable event occurrence (the scope of the variable definition) Consider the below example in which there are two human tasks. HumanTask1 is defined inside the case model and the HumanTask_2 is defined inside the stage. Each human task is attached with a entry criterion sentry and both the sentries are evaluated when the update event for the variable foo occurs. Scenario 1: When a variable foo is set and updated in the scope of the case model, then both the sentries are evaluated and results in the transition of HumanTask1 and HumanTask_2 from available state to enabled state. Scenario 2: When there exists two variables of the same name foo, one defined in the scope of the case model and the other defined in the scope of stage. Then, sentries are triggered based on the scope of the update event. When the variable foo is updated in the scope of the case model, then only the HumanTask1 gets enabled. When the variable foo is updated in the scope of the stage, then only the HumanTask_2 gets enabled. Combining OnParts, IfParts and VariableOnParts Sentries allow a flexible definition of event occurrences and data-based conditions to be fulfilled. The following rules apply for combining OnParts, IfParts and VariableOnParts. A valid sentry must have at least one of the sentry parts (OnPart or IfPart or VariableOnPart). A sentry without OnParts is fulfilled when the IfPart evaluates to true and all the VariableOnParts have occurred. A sentry without an IfPart is fulfilled when all OnParts and all the VariableOnParts have occurred. A sentry without variableOnPart is fullfilled when all the OnParts and IfPart are fulfilled.",
    "url": "/manual/latest/reference/cmmn11/sentry/index.html"
  },
  {
    "id": "manual/latest/reference/cmmn11/tasks/case-task/index.html",
    "title": "Case Task | docs.cibseven.org",
    "content": "A case task can be used to call another CMMN case. A case task is a regular task that requires a caseRef attribute that references a case definition by its key. Such a case task can be defined as follows: <caseTask id=\"checkCreditCase\" name=\"Check credit\" caseRef=\"checkCreditCase\" /> The referenced case definition is resolved at runtime. This means that the referenced case can be deployed independently from the calling case, if needed. A case task in state ENABLED can be started manually using the CaseService as follows: caseService.manuallyStartCaseExecution(\"aCaseExecutionId\"); When the case task instance becomes ACTIVE, a new case instance will be launched. In the above example a new case instance of the case checkCreditCase will be created. If a case task is blocking (the attribute isBlocking is set to true), the case task remains ACTIVE until the case instance associated with the case task is completed. When the called case instance reaches the state COMPLETED for the first time, the corresponding case task completes automatically. It is not possible to complete a blocking case task manually. In case of a non-blocking (the attribute isBlocking is set to false) task, the case task does not wait for the case instance to complete, and completes immediately upon its activation and after calling its associated case. Note: The default value for the attribute isBlocking is true. To define a non-blocking case task the attribute isBlocking must be set to false as follows: <caseTask id=\"checkCreditCase\" name=\"Check credit\" caseRef=\"checkCreditCase\" isBlocking=\"false\" /> Transactional Behavior The activation of the case task as well as the creation and execution of the case instance are performed in the same transaction. Case Binding By default, the case task always creates a new case instance of the latest case definition with the specified key. To specify a different version of a case, it is possible to define a binding with the Camunda custom attribute caseBinding. The following values are allowed for the attribute caseBinding: latest: use the latest case definition version (which is also the default behavior if the attribute is not defined) deployment: use the case definition version that is part of the calling case definition’s deployment (note: this requires that a case with the specified key is deployed along with the calling case definition) version: use a fixed version of the case definition, in this case the attribute caseVersion is required The following is an example of a case task that calls the checkCreditCase case with version 3. <caseTask id=\"checkCreditCase\" caseRef=\"checkCreditCase\" camunda:caseBinding=\"latest|deployment|version\" camunda:caseVersion=\"3\"> </caseTask> Note: It is also possible to use an expression for the attribute caseVersion that must resolve to an integer at runtime. Case Tenant Id When the case task resolves the case definition to be called it must take into account multi tenancy. Default Tenant Resolution By default, the tenant id of the calling case definition is used to resolve the called case definition. That is, if the calling case definition has no tenant id, then the case task resolves a case definition using the provided key, binding and without a tenant id (tenant id = null). If the calling case definition has a tenant id, a case definition with the provided key and the same tenant id is resolved. Note that the tenant id of the calling case instance is not taken into account in the default behavior. Explicit Tenant Resolution In some situations it may be useful to override this default behavior and specify the tenant id explicitly. The camunda:caseTenantId attribute allows to explicitly specify a tenant id: <caseTask id=\"checkCreditCase\" caseRef=\"checkCreditCase\" camunda:caseTenantId=\"TENANT_1\"> </casetask> If the tenant id is not known at design time, an expression can be used as well: <caseTask id=\"checkCreditCase\" caseRef=\"checkCreditCase\" camunda:caseTenantId=\"${ myBean.calculateTenantId(variable) }\"> </caseTask> An expression also allows using the tenant id of the calling case instance instead of the calling case definition: <caseTask id=\"checkCreditCase\" caseRef=\"checkCreditCase\" camunda:caseTenantId=\"${ caseExecution.tenantId }\"> </caseTask> Exchange Variables The Camunda custom extensions elements in and out allow to exchange variables between the case task (in a case instance) and the case instance that it creates: in elements of a case task map variables of the calling case to input variables of the launched case instance and out mappings of a case task map output variables of the called case instance to variables of the calling case, e.g.,: <caseTask id=\"checkCreditCase\" name=\"Check credit\" caseRef=\"checkCreditCase\"> <extensionElements> <camunda:in source=\"aCaseVariable\" target=\"aSubCaseVariable\" /> <camunda:out source=\"aSubCaseVariable\" target=\"anotherCaseVariable\" /> </extensionElements> </caseTask> In the above example, the value of the input variable aCaseVariable is passed to the newly created case instance. Inside the case instance, the value of the input variable aCaseVariable is available as aSubCaseVariable. After successful completion of the called case instance, the value of the output variable aSubCaseVariable is passed back to the calling case task where it can be accessed by the name anotherCaseVariable. In addition, it is also possible to use expressions: <caseTask id=\"checkCreditCase\" name=\"Check credit\" caseRef=\"checkCreditCase\"> <extensionElements> <camunda:in sourceExpression=\"${x+5}\" target=\"y\" /> <camunda:out sourceExpression=\"${y+5}\" target=\"z\" /> </extensionElements> </caseTask> Assuming y is not updated by the called case instance, the following holds after the case task completes: z = y+5 = x+5+5. Source expressions are evaluated in the context of the called case instance. That means, in cases where calling and called case definitions belong to different process applications, context like Java classes, Spring or CDI beans are resolved from the process application the called case definition belongs to. Furthermore, the case task can be configured to pass all variables to the called case instance, and to pass all variables of the case instance back to the associated case task: <caseTask id=\"checkCreditCase\" name=\"Check credit\" caseRef=\"checkCreditCase\"> <extensionElements> <camunda:in variables=\"all\" /> <camunda:out variables=\"all\" /> </extensionElements> </caseTask> Note: The variables keeps their names. It is possible, at runtime, to decide which variables are mapped into the called case instance. This can be declared with the local attribute on the camunda:in element as follows: <caseTask id=\"checkCreditCase\" name=\"Check credit\" caseRef=\"checkCreditCase\"> <extensionElements> <camunda:in variables=\"all\" local=\"true\" /> </extensionElements> </caseTask> With this setting, only local variables are going to be mapped. These can be set via the CaseService before starting the case instance. Consider the following code to manually start a case task: caseService .withCaseExecution(caseTaskExecutionId) .setVariable(\"var1\", \"abc\") .setVariableLocal(\"var2\", \"def\") .manualStart(); With local=\"true\" for the in mapping, only var2 is mapped into the called case instance. Pass Business Key In addition to exchanging variables, it is possible to pass a business key to the called case instance as well. Since a business key is immutable, this is one way mapping. It is not possible to have output mapping for a business key. The following example shows how the business key of the calling case instance can be passed to the called case instance. In this case, the calling case instance and the called case instance end up with the same business key. <caseTask id=\"checkCreditCase\" name=\"Check credit\" caseRef=\"checkCreditCase\"> <extensionElements> <camunda:in businessKey=\"#{caseExecution.caseBusinessKey}\" /> </extensionElements> </caseTask> If the business key of the called case instance should be different from the business key of the calling case instance, it is possible to use an expression that, for example, references a variable: <caseTask id=\"checkCreditCase\" name=\"Check credit\" caseRef=\"checkCreditCase\"> <extensionElements> <camunda:in businessKey=\"#{customerId}\" /> </extensionElements> </caseTask> Camunda Extensions Attributes camunda:caseBinding, camunda:caseTenantId, camunda:caseVersion Extension Elements camunda:in, camunda:out, camunda:caseExecutionListener, camunda:variableListener Constraints The attribute camunda:caseVersion should only be set if the attribute camunda:caseBinding equals version",
    "url": "/manual/latest/reference/cmmn11/tasks/case-task/index.html"
  },
  {
    "id": "manual/latest/reference/cmmn11/tasks/decision-task/index.html",
    "title": "Decision Task | docs.cibseven.org",
    "content": "A decision task can be used to invoke a DMN 1.3 decision from a case. A decision task is a regular task that requires a decisionRef attribute that references a decision definition by its key. Such a decision task can be defined as follows: <decisionTask id=\"checkCreditDecision\" name=\"Check credit\" decisionRef=\"checkCreditDecision\" /> Instead of the decisionRef attribute it is also possible to use an expression which must evaluate to a key of a decision definition at runtime. <decisionTask id=\"checkCreditDecision\" name=\"Check credit\"> <decisionRefExpression>${resolveToCheckCreditDecision}</decisionRefExpression> </decisionTask> One of the attributes decisionRef or decisionRefExpression must be present. The referenced decision definition is resolved at runtime. This means that the referenced decision can be deployed independently from the calling case, if needed. A decision task in state ENABLED can be started manually using the CaseService as follows: caseService.manuallyStartCaseExecution(\"aCaseExecutionId\"); When the decision task instance becomes ACTIVE, the referenced decision is evaluated synchronously. As a consequence, the decision task is always executed as blocking, because the engine does not distinguish between a blocking and a non-blocking decision task. Transactional Behavior The activation of the decision task as well as the evaluation of the decision are performed in the same transaction. Decision Binding By default, the decision task always evaluates the latest decision definition with the specified key. To specify a different version of a decision, it is possible to define a binding with the Camunda custom attribute decisionBinding. The following values are allowed for the attribute decisionBinding: latest: use the latest decision definition version (which is also the default behavior if the attribute is not defined) deployment: use the decision definition version that is part of the calling case definition’s deployment (note: this requires that a decision with the specified key is deployed along with the calling case definition) version: use a fixed version of the decision definition, in this case the attribute decisionVersion is required The following is an example of a decision task that calls the checkCreditDecision decision with version 3. <decisionTask id=\"checkCreditDecision\" decisionRef=\"checkCreditDecision\" camunda:decisionBinding=\"version\" camunda:decisionVersion=\"3\"> </decisionTask> Note: It is also possible to use an expression for the attribute decisionVersion that must resolve to an integer at runtime. Decision Tenant Id When the decision task resolves the decision definition to be evaluated it must take into account multi tenancy. Default Tenant Resolution By default, the tenant id of the calling case definition is used to evaluate the decision definition. That is, if the calling case definition has no tenant id, then the decision task evaluate a decision definition using the provided key, binding and without a tenant id (tenant id = null). If the calling case definition has a tenant id, a decision definition with the provided key and the same tenant id is evaluated. Note that the tenant id of the calling case instance is not taken into account in the default behavior. Explicit Tenant Resolution In some situations it may be useful to override this default behavior and specify the tenant id explicitly. The camunda:decisionTenantId attribute allows to explicitly specify a tenant id: <decisionTask id=\"checkCreditDecision\" decisionRef=\"checkCreditDecision\" camunda:decisionTenantId=\"TENANT_1\"> </decisionTask> If the tenant id is not known at design time, an expression can be used as well: <decisionTask id=\"checkCreditDecision\" decisionRef=\"checkCreditDecision\" camunda:decisionTenantId=\"${ myBean.calculateTenantId(variable) }\"> </decisionTask> An expression also allows using the tenant id of the calling case instance instead of the calling case definition: <decisionTask id=\"checkCreditDecision\" decisionRef=\"checkCreditDecision\" camunda:decisionTenantId=\"${ caseExecution.tenantId }\"> </decisionTask> Decision Result The output of the decision, also called decision result, is not saved as case variable automatically. It has to pass into a case variable by using a predefined or a custom mapping of the decision result. In case of a predefined mapping, the camunda:mapDecisionResult attribute references the mapper to use. The result of the mapping is saved in the variable which is specified by the camunda:resultVariable attribute. If no predefined mapper is set then the resultList mapper is used by default. The following example calls the latest version of the checkCreditDecision and maps the singleEntry of the decision result into the case variable result. The mapper singleEntry assumes that the decision result only contains one entry or none at all. <decisionTask id=\"checkCreditDecision\" decisionRef=\"checkCreditDecision\" camunda:mapDecisionResult=\"singleEntry\" camunda:resultVariable=\"result\" /> See the User Guide for details about the mapping. Name of the Result Variable The result variable should not have the name decisionResult since the decision result itself is saved in a variable with this name. Otherwise an exception is thrown while saving the result variable. Limitations of the Decision Task To evaluate a referenced decision, the integration of the Camunda DMN engine is used. As a result, only DMN 1.3 decisions can be evaluated with a decision task. There is no option to integrate with other rule engines. Camunda Extensions Attributes camunda:decisionBinding, camunda:decisionTenantId, camunda:decisionVersion, camunda:mapDecisionResult, camunda:resultVariable Extension Elements camunda:caseExecutionListener, camunda:variableListener Constraints The attribute camunda:decisionVersion should only be set if the attribute camunda:decisionBinding equals version",
    "url": "/manual/latest/reference/cmmn11/tasks/decision-task/index.html"
  },
  {
    "id": "manual/latest/reference/cmmn11/tasks/human-task/index.html",
    "title": "Human Task | docs.cibseven.org",
    "content": "A human task is used to model work that needs to be done by a human actor. A human task is defined in XML as follows: <humanTask id=\"theHumanTask\" name=\"A Human Task\" /> A human task in state ENABLED can be started manually using the CaseService as follows: caseService.manuallyStartCaseExecution(\"aCaseExecutionId\"); When the human task becomes ACTIVE, a new task is created in the task list of the user(s) or group(s) assigned to that task. If the work associated with the human task is done, it is possible to complete the human task manually using the CaseService as follows: caseService.completeCaseExecution(\"aCaseExecutionId\"); This completes the created task as well. Instead of using the CaseService it is also possible to use the TaskService to complete a human task: taskService.complete(\"aTaskId\"); Properties In that case the associated human task is completed as well. Description A human task can have a description. In fact, any CMMN 1.1 element can have a description. A description is defined by adding the description attribute. <humanTask id=\"theTask\" name=\"Schedule meeting\" description=\"Schedule an engineering meeting for next week with the new hire\" /> The description text can be retrieved from the task in the standard Java way: task.getDescription(); Due Date Each task has a field indicating the due date of that task. The Query API can be used to query for tasks that are due on, before or after a certain date. There is an extension attribute that allows to specify an expression in a task definition to set the initial due date of a task when it is created. The expression should always resolve to a java.util.Date, java.util.String (ISO8601 formatted) or null. When using ISO8601 formatted Strings, you may either specify an exact point in time or a time period relative to the time the task is created. <humanTask id=\"theTask\" name=\"Important task\" camunda:dueDate=\"${dateVariable}\"/> The due date of a task can also be altered using the task service or in task listeners using the passed delegate task. Follow Up Date Each task has a field indicating the follow up date of that task. The Query API can be used to query for tasks that need to be followed up on, before or after a certain date. There is an extension attribute that allows you to specify an expression in a task definition to set the initial follow up date of a task when it is created. The expression should always resolve to a java.util.Date, java.util.String (ISO8601 formatted) or null. When using ISO8601 formatted Strings, you may either specify an exact point in time or a time period relative to the time the task is created. <humanTask id=\"theTask\" name=\"Important task\" camunda:followUpDate=\"${dateVariable}\"/> User Assignment A human task can be directly assigned to a single user, a list of users or a list of groups. Assignment using CMMN Case Role CMMN defines some native assignment concepts which can be used in Camunda. As a more powerful alternative, Camunda also defines a set of custom extension elements (see below). The CMMN concept of performerRef can be used to assign a task to a single user. The performerRef attribute references an existing role. Such a role definition needs a name that defines the user. <case ... > ... <humanTask id=\"theTask\" name='important task' perfomerRef=\"aCaseRole\" /> <caseRoles id=\"aCaseRole\" name=\"kermit\" /> </case> Only one user can be assigned to the task as a performer. This user is called the assignee. Tasks that have an assignee are not visible in the task lists of other users and can only be found in the personal task list of the assignee. Tasks directly assigned to users can be retrieved through the task service as follows: List<Task> tasks = taskService.createTaskQuery().taskAssignee(\"kermit\").list(); User Assignment using Camunda Extensions When strictly following the CMMN standard, user and group assignments can be quite cumbersome for use cases where the assignment is more complicated. To avoid these complexities, custom extensions on the human task element can be set. The CMMN Human task supports the same assignment extensions and concepts as the BPMN User Task. You can read up on these extensions in the BPMN User Task Section. Same as for the BPMN User task, assignment based on data and service logic is supported for the CMMN Human Task as well. Forms It is possible to provide information to render a human task form by using the camunda:formKey attribute: <humanTask id=\"someTask\" camunda:formKey=\"someForm.html\"> ... </humanTask> The form key is a symbolic value which can be set in the CMMN XML file by using the extension attribute formKey and retrieved at runtime using the process engine API. If the user task form is displayed inside the Camunda Tasklist, the format of the formKey must follow special rules. See the corresponding section in the user guide for details. In custom applications, the value of the form key can be chosen freely. In a custom application the value of the form key attribute can be interpreted freely. Based on the specific UI technology used, it can reference the name of an HTML file, a JSF / Facelets template, a Vaadin / GWT view, … Retrieving the form key using the form service. String formKey = formService.getTaskFormData(someTaskId).getFormKey(); Retrieving the form using the task service When performing a task query, it is possible to retrieve the form key as well. This is most useful if the form keys need to be retrieved for a complete list of tasks: List<Task> tasks = TaskService.createTaskQuery() .assignee(\"jonny\") .initializeFormKeys() // must be invoked .list(); for(Task task : tasks) { String formKey = task.getFormKey(); } Note that it is required to call the .initializeFormKeys() method on the TaskQuery object to make sure the form keys are initialized. Camunda Extensions Attributes camunda:assignee, camunda:candidateGroups, camunda:candidateUsers, camunda:dueDate, camunda:formKey, camunda:priority Extension Elements camunda:in, camunda:out, camunda:caseExecutionListener, camunda:taskListener, camunda:variableListener Constraints The attribute camunda:assignee cannot be used simultaneously with the perfomerRef attribute on a human task element.",
    "url": "/manual/latest/reference/cmmn11/tasks/human-task/index.html"
  },
  {
    "id": "manual/latest/reference/cmmn11/tasks/index.html",
    "title": "Tasks | docs.cibseven.org",
    "content": "Tasks signify that some kind of work is being performed. CMMN provides different types of Tasks. The following are supported by Camunda:",
    "url": "/manual/latest/reference/cmmn11/tasks/index.html"
  },
  {
    "id": "manual/latest/reference/cmmn11/tasks/process-task/index.html",
    "title": "Process Task | docs.cibseven.org",
    "content": "A process task can be used to invoke a BPMN 2.0 process from a case. A process task is a regular task that requires an attribute processRef which references a process definition by its key. Such a process task can be defined as follows: <processTask id=\"checkCreditProcess\" name=\"Check credit\" processRef=\"checkCreditProcess\" /> The referenced process definition is resolved at runtime. This means that the process can be deployed independently from the calling case, if needed. A process task in state ENABLED can be started manually using the CaseService as follows: caseService.manuallyStartCaseExecution(\"aCaseExecutionId\"); When the process task instance becomes ACTIVE, a new process instance is launched. In the above example a new process instance of the process checkCreditProcess is created. If a process task is blocking (i.e., the attribute isBlocking is set to true), the process task remains ACTIVE until the process instance associated with the process task is completed. After a successful completion of the called process instance, the corresponding process task completes automatically. It is not possible to complete a blocking process task manually. In case of a non-blocking (the attribute isBlocking is set to false) task, the process task is not waiting for the process instance to complete and completes immediately after its activation and calling its associated process. Note: The default value for the attribute isBlocking is true. To define a non-blocking process task the attribute isBlocking must be set to false as follows: <processTask id=\"checkCreditProcess\" name=\"Check credit\" processRef=\"checkCreditProcess\" isBlocking=\"false\" /> Transactional Behavior The activation of the process task as well as the creation and execution of the process instance are performed in the same transaction. The transaction is executed until a wait state or an asynchronous continuation is reached inside the called process instance (for further details read the Transactions in Processes section of the user guide). To launch a process instance asynchronously it is possible to declare the process’ start event as asynchronous with the XML attribute asyncBefore=\"true\" (see Asynchronous Instantiation). Process Binding By default, the process task creates a new process instance of the latest process definition with the specified key. To specify a different version of a process, it is possible to define a binding with the Camunda custom attribute processBinding. The following values are allowed for the attribute processBinding: latest: use the latest process definition version (which is also the default behavior if the attribute is not defined) deployment: use the process definition version that is part of the calling case definition’s deployment (note: this requires that a process with the specified key is deployed along with the case definition) version: use a fixed version of the process definition, in this case the attribute processVersion is required The following is an example of a process task that calls the checkCreditProcess process with version 3. <processTask id=\"checkCreditProcess\" processRef=\"checkCreditProcess\" camunda:processBinding=\"version\" camunda:processVersion=\"3\"> </processTask> Note: It is also possible to use an expression for the attribute processVersion that must resolve to an integer when the task is executed. Process Tenant Id When the process task resolves the process definition to be called it must take into account multi tenancy. Default Tenant Resolution By default, the tenant id of the calling case definition is used to resolve the called process definition. That is, if the calling case definition has no tenant id, then the process task resolves a process definition using the provided key, binding and without a tenant id (tenant id = null). If the calling case definition has a tenant id, a process definition with the provided key and the same tenant id is resolved. Note that the tenant id of the calling case instance is not taken into account in the default behavior. Explicit Tenant Resolution In some situations it may be useful to override this default behavior and specify the tenant id explicitly. The camunda:processTenantId attribute allows to explicitly specify a tenant id: <processTask id=\"checkCreditProcess\" processRef=\"checkCreditProcess\" camunda:processTenantId=\"TENANT_1\"> </processTask> If the tenant id is not known at design time, an expression can be used as well: <processTask id=\"checkCreditProcess\" processRef=\"checkCreditProcess\" camunda:processTenantId=\"${ myBean.calculateTenantId(variable) }\"> </processTask> An expression also allows using the tenant id of the calling case instance instead of the calling case definition: <processTask id=\"checkCreditProcess\" processRef=\"checkCreditProcess\" camunda:processTenantId=\"${ caseExecution.tenantId }\"> </processTask> Exchange Variables The Camunda custom extensions elements in and out allow to exchange variables between the process task (in a case instance) and the process instance that it creates: in elements of a process task map case variables to input variables of the launched process instance and out mappings of a process task map output variables of the process instance to case variables, e.g.,: <processTask id=\"checkCreditProcess\" name=\"Check credit\" processRef=\"checkCreditProcess\"> <extensionElements> <camunda:in source=\"aCaseVariable\" target=\"aProcessVariable\" /> <camunda:out source=\"aProcessVariable\" target=\"anotherCaseVariable\" /> </extensionElements> </processTask> In the above example, the value of the input variable aCaseVariable is passed to the newly created process instance. Inside the process instance, the value of the input variable aCaseVariable is available as aProcessVariable. After successful completion of the called process instance, the value of the output variable aProcessVariable is passed back to the calling process task where it can be accessed by the name anotherCaseVariable. In addition, it is possible to use expressions: <processTask id=\"checkCreditProcess\" name=\"Check credit\" processRef=\"checkCreditProcess\"> <extensionElements> <camunda:in sourceExpression=\"${x+5}\" target=\"y\" /> <camunda:out sourceExpression=\"${y+5}\" target=\"z\" /> </extensionElements> </processTask> Assuming y is not updated by the process instance, the following holds after the process task completes: z = y+5 = x+5+5. Source expressions are evaluated in the context of the called process instance. That means, in cases where calling and called case/process definitions belong to different process applications, context like Java classes, Spring or CDI beans are resolved from the process application the called process definition belongs to. Furthermore, the process task can be configured to pass all variables to the called process instance and to pass all variables of the process instance back to the associated process task: <processTask id=\"checkCreditProcess\" name=\"Check credit\" processRef=\"checkCreditProcess\"> <extensionElements> <camunda:in variables=\"all\" /> <camunda:out variables=\"all\" /> </extensionElements> </processTask> Note: The variables keep their names. It is possible to decide at runtime which variables are mapped into the called process instance. This can be declared with the local attribute on the camunda:in element as follows: <processTask id=\"checkCreditProcess\" name=\"Check credit\" processRef=\"checkCreditProcess\"> <extensionElements> <camunda:in variables=\"all\" local=\"true\"/> </extensionElements> </processTask> With this setting, only local variables are going to be mapped. These can be set via the CaseService before starting the process instance. Consider the following code to manually start a process task: caseService .withCaseExecution(processTaskExecutionId) .setVariable(\"var1\", \"abc\") .setVariableLocal(\"var2\", \"def\") .manualStart(); With local=\"true\" for the in mapping, only var2 is mapped into the called process instance. Pass a Business Key In addition to exchanging variables, it is possible to pass a business key to the called process instance. Since a business key is immutable, this is one way mapping. It is not possible to have output mapping for a business key. The following example shows how the business key of the calling case instance can be passed to the called process instance. In this case, the calling case instance and the called process instance end up with the same business key. <processTask id=\"checkCreditProcess\" name=\"Check credit\" processRef=\"checkCreditProcess\"> <extensionElements> <camunda:in businessKey=\"#{caseExecution.caseBusinessKey}\" /> </extensionElements> </processTask> If the business key of the called process instance should be different than the business key of the calling case instance, it is possible to use an expression that, for example, references a variable: <processTask id=\"checkCreditProcess\" name=\"Check credit\" processRef=\"checkCreditProcess\"> <extensionElements> <camunda:in businessKey=\"#{customerId}\" /> </extensionElements> </processTask> Camunda Extensions Attributes camunda:processBinding, camunda:processTenantId, camunda:processVersion Extension Elements camunda:in, camunda:out, camunda:caseExecutionListener, camunda:variableListener Constraints The attribute camunda:processVersion should only be set if the attribute camunda:processBinding is equal to version",
    "url": "/manual/latest/reference/cmmn11/tasks/process-task/index.html"
  },
  {
    "id": "manual/latest/reference/connect/extending-connect/index.html",
    "title": "Extending Connect | docs.cibseven.org",
    "content": "Configuring Connectors The connectors available to Connect may not always suit your needs. Sometimes, it is necessary to provide configuration. To configure a connector detected by Spin, the SPI org.cibseven.connect.spi.ConnectorConfigurator can be implemented. A configurator specifies which classes it can configure. Connect discovers a configurator by employing Java’s service loader mechanism and will then provide it with all connectors that match the specified class (or are a subclass thereof). The concrete configuration options depend on the actual connector. For example, the HTTP based connector can modify the Apache HTTP client that the connector uses. To provide a custom configurator, you have to Provide a custom implementation of org.cibseven.connect.spi.ConnectorConfigurator Add the configurator’s fully qualified classname to a file named META-INF/services/org.cibseven.connect.spi.ConnectorConfigurator Ensure that the artifact containing the configurator is reachable from Connect’s classloader Custom Connector A connector is an implementation of the interface org.cibseven.connect.spi.Connector. An implementation of this interface can be registered by implementing the SPI org.cibseven.connect.spi.ConnectorProvider. Connect uses the Java platform’s service loader mechanism to lookup provider implementations at runtime. To provide a custom connector, you have to Provide a custom implementation of org.cibseven.connect.spi.Connector Provide a custom implementation of org.cibseven.connect.spi.ConnectorProvider Add the provider’s fully qualified classname to a file named META-INF/services/org.cibseven.connect.spi.ConnectorProvider Ensure that the artifact containing the provider is reachable from Connect’s classloader If you now call org.cibseven.connect.Connectors.getAvailableConnectors(), then the custom connector is returned along with the built-in connectors. Furthermore, org.cibseven.connect.Connectors.getConnector(String connectorId) can be used to explicity retrieve the connector by a specific provider.",
    "url": "/manual/latest/reference/connect/extending-connect/index.html"
  },
  {
    "id": "manual/latest/reference/connect/http-connector/index.html",
    "title": "HTTP Connector | docs.cibseven.org",
    "content": "In Camunda Connect a Connectors class exists which automatically detects every connector in the classpath. It can be used to get the HTTP connector instance by its connector ID, which is http-connector. HttpConnector http = Connectors.getConnector(HttpConnector.ID); Configure Apache HTTP Client Camunda Connect HTTP client uses the Apache HTTP client to make HTTP requests. Accordingly, it supports the same configuration options. Default Configuration By default, the HTTP client uses Apache’s default configuration and respects the system properties that are supported by HTTP client. Custom Configuration If you want to reconfigure the client going beyond the default configuration options, e.g. you want to configure another connection manager, the easiest way is to register a new connector configurator. package org.cibseven.connect.example; import org.apache.http.impl.client.CloseableHttpClient; import org.apache.http.impl.client.HttpClients; import org.cibseven.connect.httpclient.impl.AbstractHttpConnector; import org.cibseven.connect.spi.ConnectorConfigurator; public class HttpConnectorConfigurator implements ConnectorConfigurator<HttpConnector> { public Class<HttpConnector> getConnectorClass() { return HttpConnector.class; } public void configure(HttpConnector connector) { CloseableHttpClient client = HttpClients.custom() .setMaxConnPerRoute(10) .setMaxConnTotal(200) .build(); ((AbstractHttpConnector) connector).setHttpClient(client); } } To enable auto detection of your new configurator please add a file called org.cibseven.connect.spi.ConnectorConfigurator to your resources/META-INF/services directory with class name as content. For more information see the extending Connect section. org.cibseven.connect.example.HttpConnectorConfigurator Requests Create a Simple HTTP Request The HTTP connector can be used to create a new request, set a HTTP method, URL, content type and payload. A simple GET request: http.createRequest() .get() .url(\"http://camunda.org\") .execute(); A POST request with a content type and payload set: http.createRequest() .post() .url(\"http://camunda.org\") .contentType(\"text/plain\") .payload(\"Hello World!\") .execute(); The HTTP methods PUT, DELETE, PATCH, HEAD, OPTIONS, TRACE are also available. Adding HTTP Headers to a Request To add own headers to the HTTP request the method header is available. HttpResponse response = http.createRequest() .get() .header(\"Accept\", \"application/json\") .url(\"http://camunda.org\") .execute(); Enabling HTTP Response Error Handling By default, the HTTP connector does not seamlessly handle 4XX and 5XX related response errors during HTTP call. To activate the handling of these errors without additional scripting, set the throw-http-error property to TRUE via the configOption method. Once enabled, the client will throw an exception in case of http response errors (status code 400-599). HttpResponse response = http.createRequest() .get() .configOption(\"throw-http-error\", \"TRUE\") .url(\"http://camunda.org\") .execute(); Using the Generic API Besides the configuration methods also a generic API exists to set parameters of a request. The following parameters are available: Parameter Description method Sets the HTTP method of the request url Sets the URL of the request headers Contains a map of the configured HTTP headers of the request payload Sets the payload of the request This can be used as follows: HttpRequest request = http.createRequest(); request.setRequestParameter(\"method\", \"GET\"); request.setRequestParameter(\"url\", \"http://camunda.org\"); request.setRequestParameter(\"payload\", \"hello world!\"); Response A response contains the status code, response headers and body. Integer statusCode = response.getStatusCode(); String contentTypeHeader = response.getHeader(\"Content-Type\"); String body = response.getResponse(); After the response was processed it should be closed. response.close() Using the Generic API Besides the response methods a generic API is provided to gather the response parameters. The following parameters are available: Parameter Description statusCode Contains the status code of the response headers Contains a map with the HTTP headers of the response response Contains the response body This can be used as follows: response.getResponseParameter(\"statusCode\"); response.getResponseParameter(\"headers\"); response.getResponseParameter(\"response\");",
    "url": "/manual/latest/reference/connect/http-connector/index.html"
  },
  {
    "id": "manual/latest/reference/connect/index.html",
    "title": "CIB seven Connector Reference | docs.cibseven.org",
    "content": "CIB seven Connect provides a simple API for connecting HTTP services and other things. It aims at two usage scenarios: usage in a generic system such as the CIB seven process engine and standalone usage via API. Connectors CIB seven Connect provides a HTTP and a SOAP HTTP connector. If you want to add an own connector to Connect please have a look at the extending Connect section. This section also describes the usage of a ConnectorConfigurator to configure the connector instances. During the request invocation of a connector an interceptor chain is passed. The user can add own interceptors to this chain. The interceptor is called for every request of this connector. connector.addRequestInterceptor(interceptor).createRequest(); Maven Coordinates Connect can be used in any Java-based application by adding the following maven dependency to your pom.xml file: CIB seven BOM If you use other CIB seven projects please import the CIB seven BOM to ensure correct versions for every CIB seven project. <dependencyManagement> <dependencies> <dependency> <groupId>org.cibseven.connect</groupId> <artifactId>cibseven-connect-bom</artifactId> <scope>import</scope> <type>pom</type> <version>${version.cibseven}</version> </dependency> </dependencies> </dependencyManagement> <dependencies> <dependency> <groupId>org.cibseven.connect</groupId> <artifactId>cibseven-connect-core</artifactId> </dependency> <dependency> <groupId>org.cibseven.connect</groupId> <artifactId>cibseven-connect-connectors-all</artifactId> </dependency> </dependencies> CIB seven Connect is published to maven central. Process engine plugin If you are using Connect in the CIB seven process engine, you also need the cibseven-engine-plugin-connect dependency. For more information, refer to the Connectors guide. Logging CIB seven Connect uses cibseven-commons-logging which itself uses SLF4J as a logging backend. To enable logging a SLF4J implementation has to be part of your classpath. For example slf4j-simple, log4j12 or logback-classic. To also enable logging for the Apache HTTP client you can use a SLF4J bridge like jcl-over-slf4j as the Apache HTTP Client doesn’t support SLF4J.",
    "url": "/manual/latest/reference/connect/index.html"
  },
  {
    "id": "manual/latest/reference/connect/soap-connector/index.html",
    "title": "SOAP Connector | docs.cibseven.org",
    "content": "In Camunda Connect a Connectors class exists which automatically detects every connector in the classpath. It can be used to get the SOAP connector instance by its connector ID, which is soap-http-connector. SoapHttpConnector soap = Connectors.getConnector(SoapHttpConnector.ID); The SOAP connector extends the Camunda Connect HTTP connector which uses the Apache HTTP client in the default implementation. To read about default and custom client configuration, please see the corresponding section in the HTTP connector docs. Request Creating a Request The SOAP HTTP connector can be used to create a new request, set a URL, content type and payload. connector.createRequest() .url(\"http://camunda.org/soap\") .soapAction(\"doIt\") .contentType(\"application/soap+xml\") .payload(soap_envelope) .execute(); Adding HTTP Headers to a Request To add own headers to the HTTP request the method header is available. connector.createRequest() .url(\"http://camunda.org/soap\") .soapAction(\"doIt\") .contentType(\"application/soap+xml\") .header(\"Accept\", \"application/xml\") .payload(soap_envelope) .execute(); Using the Generic API Besides the configuration methods also a generic API exists to set parameters of a request. The following parameters are available: Parameter Description method Sets the HTTP method of the request url Sets the URL of the request headers Contains a map of the configured HTTP headers of the request payload Sets the payload of the request This can be used as follows: HttpRequest request = http.createRequest(); request.setRequestParameter(\"method\", \"GET\"); request.setRequestParameter(\"url\", \"http://camunda.org\"); request.setRequestParameter(\"payload\", \"hello world!\"); Response A response contains the status code, response headers and body. Integer statusCode = response.getStatusCode(); String contentTypeHeader = response.getHeader(\"Content-Type\"); String body = response.getResponse(); After the response was processed it should be closed. response.close() Using the Generic API Besides the response methods a generic API is provided to gather the response parameters. The following parameters are available: Parameter Description statusCode Contains the status code of the response headers Contains a map with the HTTP headers of the response response Contains the response body This can be used as follows: response.getResponseParameter(\"statusCode\"); response.getResponseParameter(\"headers\"); response.getResponseParameter(\"response\");",
    "url": "/manual/latest/reference/connect/soap-connector/index.html"
  },
  {
    "id": "manual/latest/reference/deployment-descriptors/descriptors/bpm-platform-xml/index.html",
    "title": "bpm-platform.xml | docs.cibseven.org",
    "content": "The bpm-platform.xml file is part of the CIB seven distribution and can be used for configuration of process engines and the job executor. It is used to configure CIB seven in the following distributions: Apache Tomcat Wildfly The bpm-platform.xml file is not used in the CIB seven distribution for Wildfly. There, the configuration is added to the central application server configuration file (standalone.xml or domain.xml). The XML schema is the same (i.e., the same elements and properties can be used). See the The CIB seven Wildfly Subsystem section of the User Guide for more details. Xml Schema Namespace The namespace for the bpm-platform.xml file is http://www.camunda.org/schema/1.0/BpmPlatform. The XSD file can be found in the cibseven-engine.jar file. Example <?xml version=\"1.0\" encoding=\"UTF-8\"?> <bpm-platform xmlns=\"http://www.camunda.org/schema/1.0/BpmPlatform\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.camunda.org/schema/1.0/BpmPlatform http://www.camunda.org/schema/1.0/BpmPlatform \"> <job-executor> <job-acquisition name=\"default\" /> </job-executor> <process-engine name=\"default\"> <job-acquisition>default</job-acquisition> <configuration>org.cibseven.bpm.engine.impl.cfg.JtaProcessEngineConfiguration</configuration> <datasource>jdbc/ProcessEngine</datasource> <properties> <property name=\"history\">full</property> <property name=\"databaseSchemaUpdate\">true</property> <property name=\"transactionManagerJndiName\">java:appserver/TransactionManager</property> <property name=\"authorizationEnabled\">true</property> </properties> </process-engine> </bpm-platform> Syntax Reference Tag name Parent tag name Required? Description <bpm-platform> None. true Root element of the bpm-platform.xml file. <job-executor> <bpm-platform> true See job-executor Reference <process-engine> <bpm-platform> false See process-engine Reference Configure Location of the bpm-platform.xml File You can configure the location of the bpm-platform.xml, so the file can be stored externally to allow an easy update path of cibseven-bpm-platform.ear. This negates the work of unpacking / repackaging the ear when you need to change the configuration. This feature is available for: Apache Tomcat It is not available for the Wildfly subsystem implementation, because the subsystem implementation uses the JBoss specific standalone.xml to configure the platform. To specify the location, you have to provide an absolute path or an http/https url pointing to the bpm-platform.xml file, e.g., /home/cibseven/.cibseven/bpm-platform.xml or http://example.org/bpm-platform.xml. During startup of the cibseven-bpm-platform, it tries to discover the location of the bpm-platform.xml file from the following sources, in the listed order: JNDI entry is available at java:/comp/env/bpm-platform-xml Environment variable BPM_PLATFORM_XML is set System property bpm.platform.xml is set, e.g., when starting the server JVM it is appended as -Dbpm.platform.xml on the command line META-INF/bpm-platform.xml exists on the classpath (For Tomcat only): checks if there is a bpm-platform.xml inside the folder specified by ${CATALINA_BASE} || ${CATALINA_HOME} + /conf/ The discovery stops when one of the above mentioned sources is found or, in case none is found, it falls back to the bpm-platform.xml on the classpath, respectively ${CATALINA_BASE} || ${CATALINA_HOME} + /conf/ for Tomcat. We ship a default bpm-platform.xml file inside the cibseven-bpm-platform.ear, except when you use the Tomcat or Wildfly version of the platform. Using System Properties To externalize environment specific parts of the configuration, it is possible to reference system properties using Ant-style expressions (i.e., ${PROPERTY_KEY}). Expression resolution is supported within the property elements only. System properties may be set via command line (-Doption) or in an implementation specific manner (Apache Tomcat’s catalina.properties for example). Complex operations are not supported, but you may combine more than one expression in a single property element (e.g., ${ldap.host}:${ldap.port}). Example <!-- ... --> <plugin> <class>org.cibseven.bpm.engine.impl.plugin.AdministratorAuthorizationPlugin</class> <properties> <property name=\"administratorUserName\">${camunda.administratorUserName}</property> </properties> </plugin> <!-- ... -->",
    "url": "/manual/latest/reference/deployment-descriptors/descriptors/bpm-platform-xml/index.html"
  },
  {
    "id": "manual/latest/reference/deployment-descriptors/descriptors/processes-xml/index.html",
    "title": "processes.xml | docs.cibseven.org",
    "content": "The processes.xml file is deployed as part of a process application and is used for configuration of the deployment of BPMN 2.0 resource files. Additionally, it can be used to configure process engines which are started / stopped with the deployment of the application. See the processes.xml section of the User Guide for more details.. Xml Schema Namespace The namespace for the processes.xml file is http://www.camunda.org/schema/1.0/ProcessApplication. The XSD file can be found in the camunda-engine.jar file. Empty processes.xml The processes.xml may be left blank (can be empty). In this case, default values are used. See the Empty processes.xml section of the User Guide for more details. Example <process-application xmlns=\"http://www.camunda.org/schema/1.0/ProcessApplication\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <process-archive name=\"loan-approval\"> <process-engine>default</process-engine> <properties> <property name=\"isDeleteUponUndeploy\">false</property> <property name=\"isScanForProcessDefinitions\">true</property> </properties> </process-archive> </process-application> Syntax Reference Tag name Parent tag name Required? Description <process-application> None. true Root element of the processes.xml file. <process-engine> <process-application> false See process-engine Reference <process-archive> <process-application> false See process-archive Reference",
    "url": "/manual/latest/reference/deployment-descriptors/descriptors/processes-xml/index.html"
  },
  {
    "id": "manual/latest/reference/deployment-descriptors/index.html",
    "title": "Deployment Descriptor Reference | docs.cibseven.org",
    "content": "This guide is a syntax reference for the files mentioned below. The User Guide explains when and how to use the deployment descriptors. The deployment descriptors are XML configuration files which allow configuration of CIB seven and declaratively specify the BPMN 2.0 deployments to the process engine.",
    "url": "/manual/latest/reference/deployment-descriptors/index.html"
  },
  {
    "id": "manual/latest/reference/deployment-descriptors/tags/index.html",
    "title": "Tags | docs.cibseven.org",
    "content": "Overview of the individual tags used in the deployment descriptors:",
    "url": "/manual/latest/reference/deployment-descriptors/tags/index.html"
  },
  {
    "id": "manual/latest/reference/deployment-descriptors/tags/job-executor/index.html",
    "title": "Job Executor Configuration | docs.cibseven.org",
    "content": "The job executor tag is used to configure the job executor and can be placed in the bpm-platform.xml file. Example The following example shows a job executor XML snippet: <job-executor> <job-acquisition name=\"default\"> <properties> <property name=\"maxJobsPerAcquisition\">5</property> <property name=\"waitTimeInMillis\">8000</property> <property name=\"lockTimeInMillis\">400000</property> </properties> </job-acquisition> <properties> <!-- Note: the following properties only take effect in a Tomcat environment --> <property name=\"queueSize\">3</property> <property name=\"corePoolSize\">5</property> <property name=\"maxPoolSize\">10</property> <property name=\"keepAliveTime\">0</property> </properties> </job-executor> Syntax Reference Tag name Parent tag name Required? Description <job-executor> <bpm-platform> true Container element for the configuration of a job executor. Attributes: None. Text Content: None. <job-acquisition> <job-executor> true Specifies a job acquisition thread. Attributes: name: Defines the name of the job acquisition thread. Text Content: None. <job-executor-class> <job-acquisition> false Specifies the fully qualified classname of the job executor. Attributes: None. Text Content: None. Example: <job-executor-class>org.cibseven.bpm.example.MyJobExecutor</job-executor-class> <properties> <job-acquisition> or <job-executor> false Container element for providing a set of thread configuration properties. Attributes: None. Text Content: None. <property> <properties> false Set value for job acquisition configuration property. Attributes: name: The name of the property. Text Content: The value of the property to be set. Job-Executor Configuration Properties The following is a list with the available job acquisition thread configuration properties, along with some explanations. The properties can be used in the <property name=\"foo\">bar</property> tag, where foo is the name of the property and bar is the value of the property. Limitation: These properties only take effect in a Tomcat environment. Property name Type Description queueSize Integer Sets the size of the queue which is used for holding tasks to be executed. Default Value: 3 corePoolSize Integer Sets the size of the core pool in the thread pool. This number of threads will always be present and wait to execute tasks. Default Value: 3 maxPoolSize Integer Sets the maximum number of threads that can be present in the thread pool. Default Value: 10 keepAliveTime Long Specify the time in milliseconds threads will be kept alive when there are no tasks present before threads are terminated until the core pool size is reached. Default Value: 0 Job-Acquisition Configuration Properties The following is a list with the available job acquisition thread configuration properties, along with some explanations. The properties can be used in the <property name=\"foo\">bar</property> tag, where foo is the name of the property and bar is the value of the property. Property name Type Description maxJobsPerAcquisition Integer Sets the maximal number of jobs to be acquired at once. Default Value: 3 lockTimeInMillis Integer Specifies the time in milliseconds an acquired job is locked for execution. During that time, no other job executor can acquire the job. Default Value: 300000 waitTimeInMillis Integer Specifies the wait time of the job acquisition thread in milliseconds in case there are less jobs available for execution than requested during acquisition. If this is repeatedly the case, the wait time is increased exponentially by the factor waitIncreaseFactor. The wait time is capped by maxWait. Default Value: 5000 maxWait Long Specifies the maximum wait time of the job acquisition thread in milliseconds in case there are less jobs available for execution than requested during acquisition. Default Value: 60000 backoffTimeInMillis Integer Specifies the wait time of the job acquisition thread in milliseconds in case jobs were acquired but could not be locked. This condition indicates that there are other job acquisition threads acquiring jobs in parallel. If this is repeatedly the case, the backoff time is increased exponentially by the factor waitIncreaseFactor. The time is capped by maxBackoff. With every increase in backoff time, the number of jobs acquired increases by waitIncreaseFactor as well. Default Value: 0 maxBackoff Long Specifies the maximum wait time of the job acquisition thread in milliseconds in case jobs were acquired but could not be locked. Default Value: 0 backoffDecreaseThreshold Integer Specifies the number of successful job acquisition cycles without a job locking failure before the backoff time is decreased again. In that case, the backoff time is reduced by waitIncreaseFactor. Default Value: 100 waitIncreaseFactor Float Specifies the factor by which wait and backoff time are increased in case their activation conditions are repeatedly met. Default Value: 2",
    "url": "/manual/latest/reference/deployment-descriptors/tags/job-executor/index.html"
  },
  {
    "id": "manual/latest/reference/deployment-descriptors/tags/process-archive/index.html",
    "title": "Process Archive Configuration | docs.cibseven.org",
    "content": "The process archive tag allows configuration of a process engine deployment and can be used in the processes.xml file. See the processes.xml section of the User Guide for more details. Example The following example shows a process-archive XML snippet: <process-archive name=\"loan-approval\"> <process-engine>my-engine</process-engine> <resource>bpmn/invoice.bpmn</resource> <resource>bpmn/order-resource.bpmn</resource> <properties> <property name=\"isDeleteUponUndeploy\">false</property> <property name=\"isScanForProcessDefinitions\">true</property> <property name=\"additionalResourceSuffixes\">groovy,py</property> </properties> </process-archive> Syntax Reference Tag name Parent tag name Required? Description <process-archive> <process-application> true Container element for the configuration of a process archive (deployment). Attributes: name: Allows you to define the name of the process archive. The name will be used for the process engine deployment. tenantId: Allows you to define the tenant-id of the process archive. If a tenant-id is set then all containing resources will be deployed for the given tenant-id. See the User Guide for details about Multi-Tenancy. Text Content: None. <process-engine> <process-archive> false Specifies the name of the process engine to which the deployment is performed. If the element is not provided, the default process engine is used. Attributes: None. Text Content: The name of the process engine to which the deployment should be performed. <resource> <process-archive> false Can be used to explicitly list the paths to resources that are part of this deployment. These can be process or case definitions but also additional files like script files. Attributes: None. Text Content: The path to the resource that is part of this deployment. The resource is loaded with the classloader of the process application and therefore must be relative to the process application classloader root(s). <properties> <process-engine>, <plugin> false Container element for providing a set of process archive configuration properties. Attributes: None. Text Content: None. <property> <properties> false Set value for process archive configuration property Attributes: name: The name of the property. Text Content: The value of the property to be set. Configuration Properties The following is a list of all supported configuration properties. Property name Type Description isDeleteUponUndeploy boolean If true, the process engine deployment will be deleted (cascade = true) when the process application is undeployed. Default value: false. isScanForProcessDefinitions boolean If true, the process application will be scanned for deployable resources (.bpmn20.xml, .bpmn, .cmmn11.xml, .cmmn, .dmn11.xml or .dmn files). Resources matching the additionalResourceSuffixes parameter are also included in the scan. Scanning is performed recursively based on the filesystem directory to which the resource root resolves (see property resourceRootPath). This may not cover the entire classpath. For example, scanning for resources in a WAR file does not consider processes of a JAR that is contained within that WAR. Default value: true. isResumePreviousVersions boolean If true, previous versions of the deployment are automatically resumed. See the Process Application Deployment section of the User Guide for more details. Default value: true. resumePreviousBy string The mode to resume previous deployments of the process application. See the Process Application Deployment section of the User Guide for more details. Default value: process-definition-key Options: process-definition-key,deployment-name isDeployChangedOnly boolean If true, only resources that have changed become part of the deployment. This check is performed against previous deployments of the same name. Every resource contained in the process archive is compared to the most recent resource of the same name that is part of one of the previous deployments. Activating this setting does not automatically resume previous versions of the deployment. Default value: false. Note: It is not advised to use this setting when process elements are bound against resources of the same deployment. A binding is required when resources like a process definition from a call activity or an external script are referenced (see the BPMN implementation reference). For example, if a call activity uses the binding deployment and a certain process definition key, whether the process can be resolved depends on if it was deployed. Thus, it is recommended to use the binding latest or version when activating this setting. resourceRootPath string The resource root of the process archive. This property is used when scanning for process definitions (if isScanForProcessDefinitions is set to true). The path is interpreted as local to the root of the classpath. By default or if the prefix classpath: is used, the path is interpreted as relative to the root of the classloader. Example: path/to/my/processes or classpath:path/to/my/processes) relative to the parent folder of the process archive's deployment descriptor file (processes.xml). If the prefix pa: is used, the path is interpreted as relative to the deployment descriptor defining the process archive. Consider the situation of a process application packaged as a WAR file: The deployment structure could look like this: |-- My-Application.war |-- WEB-INF |-- lib/ |-- Sales-Processes.jar |-- META-INF/processes.xml (1) |-- opps/openOpportunity.bpmn |-- leads/openLead.bpmn |-- Invoice-Processes.jar |-- META-INF/processes.xml (2) If the process archive(s) defined in (1) uses a path prefixed with pa:, like for instance pa:opps/, only the opps/-folder of sales-processes.jar is scanned. More precisely, a \"pa-local path\", is resolved relative to the the parent directory of the META-INF-directory containing the defining processes.xml file. This implies that when using a pa-local path in (1), no processes from (2) are visible. additionalResourceSuffixes comma-seperated list Specifies a list of additional suffixes which are considered as deployment resource if the isScanForProcessDefinitions property is set to true. It can be used to deploy additional resources beside process and case definitions, for example to add a script to the deployment and reference it as an external source (see the documentation about script source for more information). To specify multiple suffixes, a comma is used as seperator, i.e., py,groovy,rb.",
    "url": "/manual/latest/reference/deployment-descriptors/tags/process-archive/index.html"
  },
  {
    "id": "manual/latest/reference/deployment-descriptors/tags/process-engine/index.html",
    "title": "Process Engine Configuration | docs.cibseven.org",
    "content": "The process engine configuration can be placed in both processes.xml and the bpm-platform.xml files. If the process engine is configured in either or both of those files, it will be bootstrapped by the CIB seven infrastructure and be made available through BpmPlatform.getProcessEngineService().getProcessEngine(\"name of process engine\"). Example The following example shows an XML snippet which can be placed in both processes.xml and/or bpm-platform.xml. <process-engine name=\"default\"> <job-acquisition>default</job-acquisition> <configuration>org.cibseven.bpm.engine.impl.cfg.StandaloneProcessEngineConfiguration</configuration> <datasource>java:jdbc/ProcessEngine</datasource> <properties> <property name=\"history\">full</property> <property name=\"databaseSchemaUpdate\">true</property> <property name=\"authorizationEnabled\">true</property> </properties> </process-engine> Syntax Reference Tag name Parent tag name Required? Description <process-engine> <process-application> or <bpm-platform> true Container element for the configuration of a process engine. Attributes: name: allows you to define the name of the process engine (Required). Text Content: None. <job-acquisition> <process-engine> true Assign the process engine to a job acquisition. Attributes: None. Text Content: The name of the job acquisition to be used for this process engine. Job acquisitions are configured in the bpm-platform.xml file. Example: <job-acquisition>default</job-acquisition> <configuration> <process-engine> false Provide the name of the process engine configuration class. Attributes: None. Text Content: The fully qualified classname of the Process Engine Configuration class to be used for this process engine. The class must be a subclass of ProcessEngineConfigurationImpl \". Default Value: StandaloneProcessEngineConfiguration Example: <configuration> my.custom.ProcessEngineConfiguration </configuration> <datasource> <process-engine> false Provide the JDBC name of the datasource to use for the process engine. Attributes: None. Text Content: JDBC name of the datasource to use for this process engine. Default Value: null. Example: <datasource>java:jdbc/ProcessEngine</datasource> <properties> <process-engine>, <plugin> false Container element for providing a set of process engine configuration (or plugin) properties. Attributes: None. Text Content: None. <property> <properties> false Set value for process engine configuration property or of a process engine plugin. Attributes: name: The name of the property to be set (Required). The process engine configuration (or plugin) class must provide a setter method setXXX() for the property name. Text Content: The value of the property to be set. Property values are converted into String, Integer or Boolean values, depending on the type of the setter in the process engine configuration (or plugin) class. Example: true <plugins> <process-engine> false Container element for providing a set of process engine plugin configurations. Attributes: None. Text Content: None. <plugin> <plugins> false Container element for providing an individual process engine plugin configuration. Attributes: None. Text Content: None. <class> <plugin> false Sets the classname of a process engine plugin. Attributes: None. Text Content: The fully qualified classname of a process engine plugin. Must be an implementation of ProcessEnginePlugin Configuration Properties The following is a list with the most commonly used process engine configuration properties, along with some explanations. The properties can be used in the <property name=\"foo\">bar</property> tag, where foo is the name of the property and bar is the value of the property. Property name Type Description authorizationEnabled Boolean Activates authorization checks. autoStoreScriptVariables Boolean Controls whether all global script variables should be automatically stored as process variables or not. Default value is false. Values: true, false (Boolean). cmmnEnabled Boolean When set to false, the following behavior changes: The automated schema maintenance (creating and dropping tables, see property databaseSchemaUpdate) does not cover the tables required for CMMN execution. CMMN resources are not deployed as case definitions to the engine. Tasks from CMMN cases are not returned by the task query. Default value is true. Values: true, false (Boolean). databaseSchemaUpdate String Sets the value for process engine database schema creation. Values: false, create-drop, true. databaseTablePrefix String Specifies a prefix for any table name included in SQL statements made by the process engine. Can be used to point the engine to a specific schema by setting the value to MY_SCHEMA. or tables with a naming pattern by setting the value to MY_TABLE_PREFIX_PATTERN_. defaultNumberOfRetries Integer Specifies how many times a job will be executed before an incident is raised. Default value: 3 defaultUserPermissionNameForTask String Set the default permisson to work on a task. Allowed values are UPDATE or TASK_WORK. Default value: UPDATE. disabledPermissions List Define a list of Permissions' names. These permissions will be not taken into account whenever authorization check is performed. dmnEnabled Boolean When set to false, the following behavior changes: The automated schema maintenance (creating and dropping tables, see property databaseSchemaUpdate) does not cover the tables required for DMN execution. DMN resources are not deployed as decision definitions or decision requirements definitions to the engine. Default value is true. Values: true, false (Boolean). enableExceptionsAfterUnhandledBpmnError Boolean If set to true, Process Engine Exception is thrown when unhandled BPMN Error occurs. Default value: false Values: true, false (Boolean). enableExpressionsInAdhocQueries Boolean If set to true, expressions can be used when creating and executing adhoc queries. For details, see the section on security considerations for custom code in the user guide. Default value is false. Values: true, false (Boolean). enableExpressionsInStoredQueries Boolean If set to true, expressions can be used when creating and executing stored queries. For details, see the section on security considerations for custom code in the user guide. Default value is true. Values: true, false (Boolean). enableFetchProcessDefinitionDescription Boolean If set to false, Bpmn Model Instance is not fetched and cached whenever a process definition query is performed and thus the returned process definition does not contain the description. Default value is true. Values: true, false (Boolean). enableXxeProcessing Boolean If set to true, enables XML eXternal Entity (XXE) Processing. When disabled, it provides protection against XXE Processing attacks. Default value is false. Values: true, false (Boolean). enableScriptCompilation Boolean Controls whether the process engine should attempt to compile script sources and cache the compilation result or not. Default value is true. Values: true, false (Boolean). forceCloseMybatisConnectionPool Boolean Controls whether a Mybatis-managed database connection pool is force closed when the process engine is closed. Closing the pool closes all active and idle database connections. Values: true (default), false. failedJobRetryTimeCycle String Sets how often a job is retried after a fail and how long the engine should wait until it tries to execute a job again. See the user guide for more details on this setting. ensureJobDueDateNotNull Boolean Ensures that each job has it's DueDate property set. If the Job DueDate property hasn't been explicitly set, the current time is added. Default value is false. Values: true, false (Boolean). enableHistoricInstancePermissions Boolean If the value of this flag is set to true, Historic Instance Permissions are enabled. Default value is false. Values: true, false (Boolean). enforceSpecificVariablePermission Boolean If the value of this flag is set to true, the default permissions to see/read variables are: READ_INSTANCE_VARIABLE, READ_HISTORY_VARIABLE, and READ_TASK_VARIABLE on Process Definition resource, and READ_VARIABLE on Task resource READ_VARIABLE on Historic Task resource Default value is false. Values: true, false (Boolean). history String Sets the level of the process engine history. Values: none, activity, audit, full. enableDefaultDbHistoryEventHandler Boolean If the value of this flag is true, an instance of the default DbHistoryEventHandler class is included in the collection of History Events Handlers. This flag should be used in conjunction with the customHistoryEventHandlers List property when defining custom History Event Handlers. The default value is true. Values: true, false (Boolean). historyRemovalTimeStrategy String Controls if and when the removal time of an historic instance is set. The default value is end. Please also see the historyCleanupStrategy configuration parameter. Values: start, end, none (String). hostname String Sets the name of the host on which the Process Engine will run. The hostname property is also used as the Metrics Reporter identifier. A custom hostname can be generated by providing an implementation of the HostnameProvider interface and and setting the engine property hostnameProvider to an instance of that class. jdbcDriver String Sets the fully qualified classname of the JDBC driver to use. This is usually used if the process engine is NOT configured using a <datasource> (see above) but using the built-in mybatis connection pool instead. jdbcPassword String Sets the password of the JDBC connection. This is usually used if the process engine is NOT configured using a <datasource> (see above) but using the built-in mybatis connection pool instead. jdbcUrl String Sets the JDBC url for the database connection. This is usually used if the process engine is NOT configured using a <datasource> (see above) but using the built-in mybatis connection pool instead. jdbcUsername String Sets the username of the JDBC connection. This is usually used if the process engine is NOT configured using a <datasource> (see above) but using the built-in mybatis connection pool instead. skipIsolationLevelCheck Boolean If the value of this flag is set to false, a ProcessEngineException will be thrown if the transaction isolation level set for the database is different from the recommended one. If set to true, no exception will be thrown but a warning message will be logged. The default value is false. Note: The recommended transaction isolation level that ensures the correct behaviour of the engine is READ_COMMITTED. Values: true, false (Boolean). jdbcBatchProcessing Boolean Controls if the engine executes the jdbc statements as Batch or not. Default is true, but this has to be disabled for some databases. See the user guide for further details. jobExecutorAcquireByDueDate Boolean Controls whether the job executor acquires the next jobs to execute ordered by due date. Default value is false. See the user guide for more details on this setting. Values: true, false (Boolean). jobExecutorAcquireByPriority Boolean Controls whether the job executor acquires the next jobs to execute ordered by job priority. Default value is false. See the user guide for more details on this setting. Values: true, false (Boolean). jobExecutorActivate Boolean Controls whether the process engine starts with an active job executor or not. For a shared process engine configuration, the default value is true. For an embedded process engine configuration, the default value is false. See the user guide for more details on this setting. Values: true, false (Boolean). jobExecutorDeploymentAware Boolean Controls whether the job executor is deployment aware or not. Values: true, false (Boolean). jobExecutorPreferTimerJobs Boolean Controls whether the job executor prefers due timer jobs over other job types. Default value is false. See the user guide for more details on this setting. Values: true, false (Boolean). jobExecutorPriorityRangeMin Long When set, the job executor will only acquire jobs that have a priority equal to or higher than the specified threshold. You can combine this property with jobExecutorPriorityRangeMax to specify a job priority range for the job executor. Note, that you can configure the priority of batch jobs and history cleanup jobs via the batchJobPriority and historyCleanupJobPriority properties. Both default to 0. Default value: -263 (Long.MIN_VALUE) jobExecutorPriorityRangeMax Long When set, the job executor will only acquire jobs that have a priority equal to or lower than the specified threshold. You can combine this property with jobExecutorPriorityRangeMin to specify a job priority range for the job executor. Note, that you can configure the priority of batch jobs and history cleanup jobs via the batchJobPriority and historyCleanupJobPriority properties. Both default to 0. Default value: 263-1 (Long.MAX_VALUE) jobExecutorAcquireExclusiveOverProcessHierarchies Boolean When set to false, the job executor's acquisition & execution of jobs related to subprocesses will not be exclusive. When set to true, the acquisition & execution of the aforementioned jobs will be performed exclusively. See the user guide for more details. Default value: false Values: true, false (Boolean). skipHistoryOptimisticLockingExceptions Boolean Controls if the engine will throw OptimisticLockingExceptions on UPDATE or DELETE operations for historical data or not. The default is true. To preserve the previous behavior (≤ 7.9), the flag must be set to false. Values: true, false (Boolean). standaloneTasksEnabled Boolean When set to false, the following behavior changes: Standalone tasks can no longer be created via API. Standalone tasks are not returned by the TaskQuery. Default value is true. Values: true, false (Boolean). tenantCheckEnabled Boolean Controls whether the process engine performs tenant checks to ensure that an authenticated user can only access data that belongs to one of his tenants. Default value is true. See the user guide for more details. Values: true, false (Boolean). batchJobsPerSeed Integer Sets the number of batch execution jobs created per batch seed job invocation. See the user guide for more information on batch execution. Default value: 100 invocationsPerBatchJob Integer Sets the number of invocations a single batch execution job executes. See the user guide for more information on batch execution. Default value: 1 invocationsPerBatchJobByBatchType Map Defines the invocations per batch job for each individual batch type. Unless specified in this map, the value of 'invocationsPerBatchJob' is used for batch operations. Read more in the User Guide. batchPollTime Integer Sets the poll interval of the batch monitor job to check for batch completion in seconds. See the user guide for more information on batch execution. Default value: 30 batchJobPriority Integer Sets the default batch job priority. See the user guide for more information on job prioritization. Default value: 0 deploymentLockUsed Boolean Sets if the process engine must acquire an exclusive lock when creating a deployment. Default value: true compositeIncidentHandlersEnabled Boolean Sets if the incidents can be handled by multiple handlers for the same incident type. Default value is false. Values: true, false (Boolean). deploymentSynchronized Boolean Sets if processing of the deployment must be synchronized. When true several deployments will be processed sequentially on one process engine node. When false, they may be processed in parallel, though depending of value of deploymentLockUsed they may still be synchronized using database pessimistic lock. Default value: true javaSerializationFormatEnabled Boolean Sets if Java serialization format can be used, when setting variables by their serialized representation. Default value: false deserializationTypeValidationEnabled Boolean Sets if validation of types should be performed before JSON and XML deserialization. See Security Instructions for further information. Default value: false deserializationAllowedPackages String Sets the allowed package names of types that are analyzed before JSON and XML deserialization if deserializationTypeValidationEnabled is set to true. With the default validator, this can be a comma-separated list of allowed package names. Only the defined packages and their sub-packages will be allowed in conjunction with the deserializationAllowedClasses. Also, the default validator always allows types within the package \"java.lang\" and all sub-packages. See Security Instructions for further information. Default value: null deserializationAllowedClasses String Sets the allowed class names of types that are analyzed before JSON and XML deserialization if deserializationTypeValidationEnabled is set to true. With the default validator, this can be a comma-separated list of class names. Only the defined class names will be allowed in conjunction with the deserializationAllowedPackages. Also, the default validator always allows the following types: java.util.ArrayList, java.util.Arrays$ArrayList, java.util.HashMap, java.util.HashSet, java.util.LinkedHashMap, java.util.LinkedHashSet, java.util.LinkedList, java.util.Properties, java.util.TreeMap, java.util.TreeSet. See Security Instructions for further information. Default value: null enablePasswordPolicy Boolean Set to true, to enable a password policy for users that are managed by the engine. If a custom password policy is configured, it will be enabled. Otherwise the built-in password policy is activated. enableCmdExceptionLogging Boolean Set to false, to disable logging of unhandled exceptions that occur during command execution. The default setting for this flag is true. Note: There might be duplicate log entries for command exceptions (e.g. when a job fails). enableReducedJobExceptionLogging Boolean Set to true, to suppress logging of exceptions that occur during the execution of a job that has retries left. If the job does not have any retries left an exception will still be logged. webappsAuthenticationLoggingEnabled Boolean Set to true to enable authentication logging in the Camunda web apps (Cockpit, Tasklist, and Admin). When enabled, the Camunda web apps will produce log statements in the application log for each user initiated log in and log out event. The name of the logger is org.cibseven.bpm.webapp. queryMaxResultsLimit Integer When defining a limit of maximum results, an authenticated user cannot perform a query with an unbounded number of results or a paginated query that exceeds the limit. Read more about it in the User Guide. Note: To gain the full feature set of the Webapps, and not suffer any UX degradation due to unavailable data, the queryMaxResultsLimit must be set to 2000. If you use Optimize it is recommended to set the value to 10 000, so the import of the data to Optimize works out of the box. The default value is 231-1. dmnFeelEnableLegacyBehavior Boolean Set to true to restore the legacy FEEL configuration of the DMN Engine. This will result in the usage of the old, Java-based FEEL Engine, as well as the usage of JUEL in DMN input expressions, output entries and literal expressions. When set to false, the new, Scala-based FEEL Engine is used, and FEEL is used as the default language for DMN input expressions, input and output entries, and literal expressions. Default value: false dmnFeelCustomFunctionProviders List Define a list of instances of FeelCustomFunctionProvider. Read more about it in the User Guide. dmnReturnBlankTableOutputAsNull Boolean Controls whether blank DMN table outputs are swallowed or returned as null. Default value: false skipOutputMappingOnCanceledActivities Boolean For activities that were canceled (e.g. due to throwing and catching an error) this flag controls if the engine should still perform output mapping. When set to true, output mapping will not be done for any activity that was canceled. This might be helpful when it is not certain which variables will be available when the activity is canceled (e.g. when an external task does not return an expected variable). This flag is often used together with camunda:errorEventDefinition extension elements on external service tasks. Default value: false configureScriptEngineHostAccess Boolean Specifies whether host language resources like classes and their methods are accessible or not. GraalVM JavaScript: If enabled, polyglot.js.allowHostAccess and polyglot.js.allowHostClassLookup are set to true. Note: These flags might not be available in every version of GraalVM JavaScript. Default value is true. Values: true, false (Boolean). enableScriptEngineLoadExternalResources Boolean Specifies whether external resources can be loaded from file system or not. GraalVM JavaScript: If enabled, polyglot.js.allowIO is set to true. Note: This flag might not be available in every version of GraalVM JavaScript. Default value is false. Values: true, false (Boolean). enableScriptEngineNashornCompatibility Boolean Specifies whether Nashorn compatibility mode is enabled or not. GraalVM JavaScript: If enabled, polyglot.js.nashorn-compat is set to true. Note: This flag might not be available in every version of GraalVM JavaScript. Default value is false. Values: true, false (Boolean). disableExceptionCode Boolean Disables the entire exception error code feature. No exception error codes are assigned. Default value is false. Values: true, false (Boolean). disableBuiltinExceptionCodeProvider Boolean Disables the default implementation of ExceptionCodeProvider which allows overriding the reserved exception codes. Default value is false. Values: true, false (Boolean). customExceptionCodeProvider ExceptionCodeProvider Allows registering a custom implementation of the exception code provider allowing to provide custom exception codes. Default value is null. Read more in the User Guide. implicitVariableUpdateDetectionEnabled Boolean Enables detection of implicit updates to process variables of type object. Default value is true. Values: true, false (Boolean). logEntriesPerSyncOperationLimit long Controls how many user operation log entries are produced for a synchronous API call. 1: Regardless of the amount of affected entities, only one operation log entry is generated containing a summary of the operation affecting multiple entities. -1: Disables any limits for user operation logs for synchronous APIs. Unlimited amounts of operation log entries are written. 1<x≤Long.MAX_VALUE Setting a value greater than 1 will instruct the process engine to complete only API calls that involve no more messages than the configured limit. If the limit is exceeded, the API call fails, and a ProcessEngineException is thrown. For successful API calls, the engine produces one operation log entry per affected entity, meaning the number of new operation log entries from one API call can never exceed logEntriesPerSyncOperationLimit. Default value is 1L. More information about security aspects of this configuration can be found in the security guide. Currently supported operations: Correlate message Values:-1, 1≤x≤Long.MAX_VALUE (long). History cleanup configuration parameters historyCleanupStrategy String Controls which History cleanup strategy is used. The default value is removalTimeBased. Please also see the historyRemovalTimeStrategy configuration parameter. Values: removalTimeBased, endTimeBased. historyCleanupDefaultNumberOfRetries Integer Specifies how often a cleanup job will be executed before an incident is raised. This property overrides the global defaultNumberOfRetries property which has a default value of 3. historyCleanupBatchWindowStartTime String History cleanup batch window start time in the format HH:mmZ (Z is for RFC 822 time zone) or HH:mm. E.g., 20:00+0100 or 20:00. In case of null, no batch window is considered to be configured and history cleanup can only be called manually. historyCleanupBatchWindowEndTime String History cleanup batch window end time in the format HH:mmZ (Z is for RFC 822 time zone) or HH:mm. E.g., 23:00-0300 or 23:00. In case batchWindowEndTime exceeds batchWindowStartTime it is considered to be on the same date (e.g., cleanup runs each day between 20:00 and 23:00). Otherwise it is considered to be on the next calendar day (e.g., cleanup starts each day at 20:00 and finishes the next day at 01:00). Default value is 00:00. mondayHistoryCleanupBatchWindowStartTime String History cleanup batch window start time for Mondays. Requires the same format as historyCleanupBatchWindowStartTime. In case it is not configured, batch window configured with historyCleanupBatchWindowStartTime and historyCleanupBatchWindowEndTime will be used for this day of week. mondayHistoryCleanupBatchWindowEndTime String History cleanup batch window end time for Mondays. Requires the same format and follows the same logic as historyCleanupBatchWindowEndTime. tuesdayHistoryCleanupBatchWindowStartTime String Similar to mondayHistoryCleanupBatchWindowStartTime, but for Tuesdays. tuesdayHistoryCleanupBatchWindowEndTime String Similar to mondayHistoryCleanupBatchWindowEndTime, but for Tuesdays. wednesdayHistoryCleanupBatchWindowStartTime String Similar to mondayHistoryCleanupBatchWindowStartTime, but for Wednesdays. wednesdayHistoryCleanupBatchWindowEndTime String Similar to mondayHistoryCleanupBatchWindowEndTime, but for Wednesdays. thursdayHistoryCleanupBatchWindowStartTime String Similar to mondayHistoryCleanupBatchWindowStartTime, but for Thursdays. thursdayHistoryCleanupBatchWindowEndTime String Similar to mondayHistoryCleanupBatchWindowEndTime, but for Thursdays. fridayHistoryCleanupBatchWindowStartTime String Similar to mondayHistoryCleanupBatchWindowStartTime, but for Fridays. fridayHistoryCleanupBatchWindowEndTime String Similar to mondayHistoryCleanupBatchWindowEndTime, but for Fridays. saturdayHistoryCleanupBatchWindowStartTime String Similar to mondayHistoryCleanupBatchWindowStartTime, but for Saturdays. saturdayHistoryCleanupBatchWindowEndTime String Similar to mondayHistoryCleanupBatchWindowEndTime, but for Saturdays. sundayHistoryCleanupBatchWindowStartTime String Similar to mondayHistoryCleanupBatchWindowStartTime, but for Sundays. sundayHistoryCleanupBatchWindowEndTime String Similar to mondayHistoryCleanupBatchWindowEndTime, but for Sundays. historyCleanupBatchSize Integer Defines the amount of top-level objects (e.g., historic process instances) to be removed at once. Default and maximum value is 500. historyCleanupBatchThreshold Integer Defines the minimum amount of top-level objects required for data to be removed. Default value is 10. Hint: if the value is too small and the process engine continues to be used during history cleanup, it can happen that real SQL delete statements are called very frequently for small amounts of data. Note: This property cannot be used in conjunction with historyCleanupStrategy set to removalTimeBased. historyCleanupDegreeOfParallelism Integer Defines the level of parallelism for history cleanup. Default value is 1 (no parallelism). Maximum allowed value is 8. historyCleanupMetricsEnabled Boolean Activates metrics for history cleanup. Default value is true. Note that history cleanup metrics are collected only when general metrics collection is not disabled. historyCleanupEnabled Boolean Configures whether the engine participates in history cleanup or not. The default value is true. For more details, please see Cleanup Execution Participation per Node in the User Guide. historyTimeToLive String Defines history time to live for process definitions and decision definitions if no other value is defined. The history time to live defines the number of days using a time specified by the ISO-8601 date format. The function only accepts the notation to define a number of days. enforceHistoryTimeToLive Boolean Feature flag that prevents the deployment or redeployment of any model resource (BPMN, DMN, CMMN) that contains a historyTimeToLive of null by throwing a ProcessEngineException. Default value: true. batchOperationHistoryTimeToLive String Defines history time to live for historic batch operations. The history time to live defines the number of days using a time specified by the ISO-8601 date format. The function only accepts the notation to define a number of days. batchOperationsForHistoryCleanup Map Defines history time to live for each specific historic batch operation. The history time to live defines the number of days using a time specified by the ISO-8601 date format. The function only accepts the notation to define a number of days. historyCleanupJobLogTimeToLive String Defines history time to live for history job log entries produced by history cleanup jobs. This works with the removalTimeBased history cleanup strategy. The history time to live defines the number of days using a time specified by the ISO-8601 date format. The function only accepts the notation to define a number of days. taskMetricsTimeToLive String Defines time to live for task metrics entries produced by user task assignments. The history time to live defines the number of days using a time specified by the ISO-8601 date format. The function only accepts the notation to define a number of days. Login parameters loginMaxAttempts Integer Defines the maximum number of attempts a user can try to login before this user is locked. Default value: 10 loginDelayMaxTime Integer Defines the maximum amount of time (in seconds) for which a user must wait until they are able to try to login again. Default value: 60 seconds loginDelayFactor Integer Defines the factor by which the delay is calculated after an unsuccessful login attempt. Default value: 2 loginDelayBase Integer Defines the base by which the delay is calculated after an unsuccessful login attempt. Default value: 3 Resource whitelist pattern parameters generalResourceWhitelistPattern String Defines acceptable values for the User, Group and Tenant IDs. Can be defined by using the standard Java Regular Expression syntax. Default value: [a-zA-Z0-9]+|camunda-admin userResourceWhitelistPattern String Defines acceptable values for the User IDs. Can be defined by using the standard Java Regular Expression syntax. Default value: a custom general whitelist pattern or the default [a-zA-Z0-9]+|camunda-admin (if nothing is defined) groupResourceWhitelistPattern String Defines acceptable values for the Group IDs. Can be defined by using the standard Java Regular Expression syntax. Default value: a custom general whitelist pattern or the default [a-zA-Z0-9]+|camunda-admin (if nothing is defined) tenantResourceWhitelistPattern String Defines acceptable values for the Tenant IDs. Can be defined by using the standard Java Regular Expression syntax. Default value: a custom general whitelist pattern or the default [a-zA-Z0-9]+|camunda-admin (if nothing is defined) Logging context parameters These parameters define the keys at which the specified data can be retrieved from the Mapped Diagnostic Context (MDC). See Logging for details. The specified data will only be put into the MDC if a key is defined. All parameters can be set to null or the empty String in order to disable their logging in the MDC. loggingContextActivityId String Defines the key for the current activity id. Default value: activityId loggingContextActivityName String Defines the key for the current activity name. Default value: activityName loggingContextApplicationName String Defines the key for the current process application name. Default value: applicationName loggingContextBusinessKey String Defines the key for the current business key. Default value: null (disabled by default since a lookup into the database might be necessary in case the business key needs to be fetched from the process instance) loggingContextProcessDefinitionId String Defines the key for the current process definition id. Default value: processDefinitionId loggingContextProcessDefinitionKey String Defines the key for the current process definition key. Default value: null (disabled by default since a lookup into the database might be necessary in case the process definition key needs to be fetched from the process instance) loggingContextProcessInstanceId String Defines the key for the current process instance id. Default value: processInstanceId loggingContextTenantId String Defines the key for the current tenant id. Default value: tenantId loggingContextEngineName String Defines the key for the current process engine name. Default value: engineName External Properties Any properties set by the user that match the configured Logging context parameters will be preserved after the processing of the engine. Logging level parameters These parameters define the log level for the specified log entries. logLevelBpmnStackTrace String Defines the log level for the bpmn stack traces. Default value: DEBUG. Possible values are: ERROR, WARN, INFO, DEBUG, TRACE.",
    "url": "/manual/latest/reference/deployment-descriptors/tags/process-engine/index.html"
  },
  {
    "id": "manual/latest/reference/dmn/custom-extensions/camunda-attributes/index.html",
    "title": "Extension Attributes | docs.cibseven.org",
    "content": "The following attributes are extension attributes for the camunda namespace http://camunda.org/schema/1.0/dmn. historyTimeToLive Description The attribute specifies the history time to live (in days) for the decision definition. It is used within History cleanup. Type java.lang.Integer or java.lang.String Possible Values Any non-negative integer number or string containing a time in days defined by the ISO-8601 date format. Default Value null - means that decision definition history won't ever be removed during history cleanup run DMN 1.3 Elements Decision inputVariable Description This attribute specifies the variable name which can be used to access the result of the input expression in an input entry expression. Type java.lang.String Possible Values The name of the variable as java.lang.String. Default Value cellInput DMN 1.3 Elements Input versionTag Description The attribute specifies a version tag for the decision definition. Type java.lang.String Possible Values Any value that has a meaning as version tag for the decision definition. Note: Sorting by versionTag is string based. The version will not be interpreted. As an example, the sorting could return v0.1.0, v0.10.0, v0.2.0. Default Value – DMN 1.3 Elements Decision",
    "url": "/manual/latest/reference/dmn/custom-extensions/camunda-attributes/index.html"
  },
  {
    "id": "manual/latest/reference/dmn/custom-extensions/index.html",
    "title": "Extension Reference | docs.cibseven.org",
    "content": "Camunda extends DMN with custom Extension Elements and Attributes defined in the http://camunda.org/schema/1.0/dmn namespace.",
    "url": "/manual/latest/reference/dmn/custom-extensions/index.html"
  },
  {
    "id": "manual/latest/reference/dmn/custom-extensions/reference/dmn11/custom-extensions/camunda-attributes/index.html",
    "title": "/manual/latest/reference/dmn/custom-extensions/camunda-attributes/",
    "content": "No content available",
    "url": "/manual/latest/reference/dmn/custom-extensions/reference/dmn11/custom-extensions/camunda-attributes/index.html"
  },
  {
    "id": "manual/latest/reference/dmn/decision-literal-expression/index.html",
    "title": "DMN Decision Literal Expression | docs.cibseven.org",
    "content": "A decision literal expression represents decision logic which can be depicted as an expression in DMN 1.3. It consists of a literal expression and a variable. A decision literal expression is represented by a literalExpression element inside a decision XML element. <definitions xmlns=\"https://www.omg.org/spec/DMN/20191111/MODEL/\" id=\"definitions\" name=\"definitions\" namespace=\"http://camunda.org/schema/1.0/dmn\"> <decision id=\"season\" name=\"Season\"> <variable name=\"season\" typeRef=\"string\" /> <literalExpression> <text>calendar.getSeason(date)</text> </literalExpression> </decision> </definitions> Decision Name The name describes the decision for which the literal expression provides the decision logic. It is set as the name attribute on the decision element. <decision id=\"season\" name=\"Season\"> <!-- ... --> </decision> Decision Id The id is the technical identifier of the decision. It is set in the id attribute on the decision element. Each decision should have an unique id when it is deployed to CIB seven. The engine uses the id as the decision key of the deployed DecisionDefinition. <decision id=\"season\" name=\"Season\"> <!-- ... --> </decision> Literal Expression The literal expression specifies how the value of the decision is generated. It is an expression which will be evaluated by the DMN engine. It can be used to do a complex calculation, to invoke a bean which provides decision logic, or to combine the output values of required decisions. The expression is set inside a text element that is a child of the literalExpression XML element. <literalExpression> <text>calendar.getSeason(date)</text> </literalExpression> Literal Expression Language The expression language of the literal expression can be specified by the expressionLanguage attribute on the literalExpression XML element. The supported expression languages are listed in the User Guide. <literalExpression expressionLanguage=\"groovy\"> <text>calendar.getSeason(date)</text> </literalExpression> If no expression language is set then the global expression language is used which is set on the definitions XML element. <definitions id=\"definitions\" name=\"definitions\" xmlns=\"https://www.omg.org/spec/DMN/20191111/MODEL/\" expressionLanguage=\"groovy\" namespace=\"http://camunda.org/schema/1.0/dmn\"> <!-- ... --> </definitions> In case no global expression language is set, the default expression language is used instead. The default expression language for literal expressions is JUEL. Please refer to the User Guide to read more about expression languages. Variable A decision literal expression must have a variable which specifies the name and the type of the decision result. A variable is represented by a variable element inside a decision XML element. <decision id=\"season\" name=\"Season\"> <variable name=\"season\" /> </decision> Variable Name The name of the variable is used to reference the value of the literal expression in the decision result. It is specified by the name attribute on the variable XML element. <variable name=\"season\" /> Variable Type Definition The type of the decision result can be specified by the typeRef attribute on the variable XML element. After the expression is evaluated by the DMN engine it converts the result to the specified type. The supported types are listed in the User Guide. <variable name=\"season\" typeRef=\"string\" /> Note that the type is not required but recommended since it provides a type safety of the expression result.",
    "url": "/manual/latest/reference/dmn/decision-literal-expression/index.html"
  },
  {
    "id": "manual/latest/reference/dmn/decision-table/hit-policy/index.html",
    "title": "DMN Hit Policy | docs.cibseven.org",
    "content": "A decision table has a hit policy that specifies what the results of the evaluation of a decision table consist of. The hit policy is set in the hitPolicy attribute on the decisionTable XML element. If no hit policy is set, then the default hit policy UNIQUE is used. <definitions xmlns=\"https://www.omg.org/spec/DMN/20191111/MODEL/\" id=\"definitions\" name=\"definitions\" namespace=\"http://camunda.org/schema/1.0/dmn\"> <decision id=\"dish\" name=\"Dish\"> <decisionTable id=\"decisionTable\" hitPolicy=\"RULE ORDER\"> <!-- .. --> </decisionTable> </decision> </definitions> The following hit policies are supported by the Camunda DMN engine: Hit Policy XML representation Unique UNIQUE Any ANY First FIRST Rule order RULE ORDER Collect COLLECT The Role of a Hit Policy A hit policy specifies how many rules of a decision table can be satisfied and which of the satisfied rules are included in the decision table result. The hit policies Unique, Any and First will always return a maximum of one satisfied rule. The hit policies Rule Order and Collect can return multiple satisfied rules. Unique Hit Policy Only a single rule can be satisfied or no rule at all. The decision table result contains the output entries of the satisfied rule. If more than one rule is satisfied, the Unique hit policy is violated. See the following decision table. Depending on the current season the dish should be chosen. Only one dish can be chosen, since only one season can exist at the same time. Any Hit Policy Multiple rules can be satisfied. However, all satisfied rules must generate the same output. The decision table result contains only the output of one of the satisfied rules. If multiple rules are satisfied which generate different outputs, the hit policy is violated. See the following example: This is a decision table for the leave application. If the applier has no vacation days left or is currently in the probation period, the application will be refused. Otherwise the application is applied. First Hit Policy Multiple rules can be satisfied. The decision table result contains only the output of the first satisfied rule. See the above decistion table for advertisement. Regarding the current age of the user, which advertisement should be shown is decided. For example, the user is 19 years old. All the rules will match, but since the hit policy is set to first only, the advertisement for Cars is used. Rule Order Hit Policy Multiple rules can be satisfied. The decision table result contains the output of all satisfied rules in the order of the rules in the decision table. Again, see the advertisement example with the rule order policy. Say we have a user at the age of 19 again. All rules are satisfied so all outputs are given, ordered by the rule ordering. It can perhaps be used to indicate the priority of the displayed advertisements. Collect Hit Policy Multiple rules can be satisfied. The decision table result contains the output of all satisfied rules in an arbitrary order as a list. With this hit policy, the output list has no ordering. So the advertisement will be arbitrary if, for example, the age is 19. Additionally, an aggregator can be specified for the Collect hit policy. If an aggregator is specified, the decision table result will only contain a single output entry. The aggregator will generate the output entry from all satisfied rules. Note if the Collect hit policy is used with an aggregator, the decision table can only have one output. The aggregator is set as the aggregation attribute of the decisionTable XML element. <decisionTable id=\"decisionTable\" hitPolicy=\"COLLECT\" aggregation=\"SUM\"> <!-- .. --> </decisionTable> Aggregators for Collect Hit Policy In the visual representation of the decision table an aggregator can be selected in addition to the COLLECT hit policy. The following aggregators are supported by the Camunda DMN engine: Visual representation XML representation Result of the aggregation Collect (Sum) SUM the sum of all output values Collect (Min) MIN the smallest value of all output values Collect (Max) MAX the largest value of all output values Collect (Count) COUNT the number of output values SUM aggregator The SUM aggregator sums up all outputs from the satisfied rules. The showed decision table can be used to sum up the salary bonus for an employee. For example, the employee has been working in the company for 3.5 years. So the first, second and third rule will match and the result of the decision table is 600, since the output is summed up. MIN aggregator The MIN aggregator can be used to return the smallest output value of all satisfied rules. See the following example of a car insurance. After years without a car crash the insurance fee will be reduced. For example, if the input for the decision table is 3.5 years, the result will be 98.83, since the first three rules match but the third rule has the minimal output. MAX aggregator The MAX aggregator can be used to return the largest output value of all satisfied rules. This decision table represents the decision for the amount of pocket money for a child. Depending of the age, the amount grows. For example, an input of 9 will satisfy the first and second rules. The output of the second rule is larger then the output of the first rule, so the output will be 5. A child at the age of 9 will get 5 as pocket money. COUNT aggregator The COUNT aggregator can be use to return the count of satisfied rules. For example, see the salary bonus decision table again, this time with the COUNT aggregator. With an input of 4, the first three rules will be satisfied. Therefore, the result from the decision table will be 3, which means that after 4 years the result of the decision table is 3 salary bonuses.",
    "url": "/manual/latest/reference/dmn/decision-table/hit-policy/index.html"
  },
  {
    "id": "manual/latest/reference/dmn/decision-table/index.html",
    "title": "DMN Decision Table | docs.cibseven.org",
    "content": "A decision table represents decision logic which can be depicted as a table in DMN 1.3. It consists of inputs, outputs and rules. A decision table is represented by a decisionTable element inside a decision XML element. <definitions xmlns=\"https://www.omg.org/spec/DMN/20191111/MODEL/\" id=\"definitions\" name=\"definitions\" namespace=\"http://camunda.org/schema/1.0/dmn\"> <decision id=\"dish\" name=\"Dish\"> <decisionTable id=\"decisionTable\"> <!-- ... --> </decisionTable> </decision> </definitions> Decision Name The name describes the decision for which the decision table provides the decision logic. It is set as the name attribute on the decision element. It can be changed via the Properties Panel after selecting the respective “Decision” in the Decision Requirements Diagram view. <decision id=\"dish\" name=\"Dish\"> <decisionTable id=\"decisionTable\"> <!-- ... --> </decisionTable> </decision> Decision Id The id is the technical identifier of the decision. It is set in the id attribute on the decision element. Just as the name, the id can be changed via the Properties Panel after selecting the respective “Decision” in the Decision Requirements Diagram view. Each decision should have an unique id when it is deployed to CIB seven. The engine uses the id as the decision key of the deployed DecisionDefinition. <decision id=\"dish\" name=\"Dish\"> <decisionTable id=\"decisionTable\"> <!-- ... --> </decisionTable> </decision>",
    "url": "/manual/latest/reference/dmn/decision-table/index.html"
  },
  {
    "id": "manual/latest/reference/dmn/decision-table/input/index.html",
    "title": "DMN Decision Table Input | docs.cibseven.org",
    "content": "A decision table can have one or more inputs, also called input clauses. An input clause defines the id, label, expression and type of a decision table input. An input can be edited by double-clicking on the respective colum header in the decision table. An input clause is represented by an input element inside a decisionTable XML element. <definitions xmlns=\"https://www.omg.org/spec/DMN/20191111/MODEL/\" id=\"definitions\" name=\"definitions\" namespace=\"http://camunda.org/schema/1.0/dmn\"> <decision id=\"dish\" name=\"Dish\"> <decisionTable id=\"decisionTable\"> <input id=\"input1\" label=\"Season\"> <inputExpression id=\"inputExpression1\" typeRef=\"string\"> <text>season</text> </inputExpression> </input> <!-- ... --> </decisionTable> </decision> </definitions> Input Id The input id is a unique identifier of the decision table input. It is used by CIB seven to reference the input in the history of evaluated decisions. Therefore, it is required by the Camunda DMN engine. It is set as the id attribute of the input XML element. <input id=\"input1\" label=\"Season\"> <inputExpression id=\"inputExpression1\" typeRef=\"string\"> <text>season</text> </inputExpression> </input> Input Label An input label is a short description of the input. It is set on the input XML element in the label attribute. Note that the label is not required but recommended, since it helps to understand the decision. <input id=\"input1\" label=\"Season\"> <inputExpression id=\"inputExpression1\" typeRef=\"string\"> <text>season</text> </inputExpression> </input> Input Expression An input expression specifies how the value of the input clause is generated. It is an expression which will be evaluated by the DMN engine. It is usually simple and references a variable which is available during the evaluation. The expression is set inside a text element that is a child of the inputExpression XML element. <input id=\"input1\" label=\"Season\"> <inputExpression id=\"inputExpression1\" typeRef=\"string\"> <text>season</text> </inputExpression> </input> Input Type Definition The type of the input clause can be specified by the typeRef attribute on the inputExpression XML element. After the input expression is evaluated by the DMN engine, it converts the result to the specified type. The supported types are listed in the User Guide. <input id=\"input1\" label=\"Season\"> <inputExpression id=\"inputExpression1\" typeRef=\"string\"> <text>season</text> </inputExpression> </input> Note that the type is not required but recommended, since it helps to understand the possible input values and provides a type safety to be aware of unexpected input values. Input Expression Language The expression language of the input expression can be specified by the expressionLanguage attribute on the inputExpression XML element. The supported expression languages are listed in the User Guide. <input id=\"input1\" label=\"Season\"> <inputExpression id=\"inputExpression1\" typeRef=\"string\" expressionLanguage=\"groovy\"> <text>season</text> </inputExpression> </input> If no expression language is set then the global expression language, which is set on the definitions XML element, is used. <definitions id=\"definitions\" name=\"definitions\" xmlns=\"https://www.omg.org/spec/DMN/20191111/MODEL/\" expressionLanguage=\"groovy\" namespace=\"http://camunda.org/schema/1.0/dmn\"> <!-- ... --> </definitions> In case no global expression language is set, the default expression language is used instead. The default expression language for input expressions is FEEL. Please refer to the User Guide to read more about expression languages. Input Variable Name When the input expression is evaluated then the return value is stored in a variable. The name of the variable can be specified by the camunda:inputVariable extension attribute on the input element. By default, the name is cellInput. To use the attribute you have to define the Camunda DMN namespace xmlns:camunda=\"http://camunda.org/schema/1.0/dmn in the XML. <definitions id=\"definitions\" name=\"definitions\" xmlns=\"https://www.omg.org/spec/DMN/20191111/MODEL/\" xmlns:camunda=\"http://camunda.org/schema/1.0/dmn\" namespace=\"http://camunda.org/schema/1.0/dmn\"> <decision id=\"dish\" name=\"Dish\"> <decisionTable id=\"decisionTable\"> <input id=\"input1\" label=\"Season\" camunda:inputVariable=\"currentSeason\"> <!-- ... --> </input> <!-- ... --> </decisionTable> </decision> </definitions> The variable can be used in an expression of an input entry. For example, the FEEL expression currentSeason != \"Fall\" checks if the season input is not \"Fall\".",
    "url": "/manual/latest/reference/dmn/decision-table/input/index.html"
  },
  {
    "id": "manual/latest/reference/dmn/decision-table/output/index.html",
    "title": "DMN Decision Table Output | docs.cibseven.org",
    "content": "A decision table can have one or more outputs, also called output clauses. An output clause defines the id, label, name and type of a decision table output. An output clause is represented by an output element inside a decisionTable XML element. <definitions xmlns=\"https://www.omg.org/spec/DMN/20191111/MODEL/\" id=\"definitions\" name=\"definitions\" namespace=\"http://camunda.org/schema/1.0/dmn\"> <decision id=\"dish\" name=\"Dish\"> <decisionTable id=\"decisionTable\"> <!-- ... --> <output id=\"output1\" label=\"Dish\" name=\"desiredDish\" typeRef=\"string\" /> <!-- ... --> </decisionTable> </decision> </definitions> Output Id The output id is a unique identifier of the decision table output. It is used by CIB seven to reference the output in the history of evaluated decisions. Therefore, it is required by the Camunda DMN engine. It is set as the id attribute of the output XML element. <output id=\"output1\" label=\"Dish\" name=\"desiredDish\" typeRef=\"string\" /> Output Label An output label is a short description of the output. It is set on the output XML element in the label attribute. Note that the label is not required but recommended, since it helps to understand the decision. <output id=\"output1\" label=\"Dish\" name=\"desiredDish\" typeRef=\"string\" /> Output Name The name of the output is used to reference the value of the output in the decision table result. It is specified by the name attribute on the output XML element. If the decision table has more than one output, then all outputs must have a unique name. <output id=\"output1\" label=\"Dish\" name=\"desiredDish\" typeRef=\"string\" /> Output Type Definition The type of the output clause can be specified by the typeRef attribute on the output XML element. After an output entry is evaluated by the DMN engine, it converts the result to the specified type. The supported types are listed in the User Guide. <output id=\"output1\" label=\"Dish\" name=\"desiredDish\" typeRef=\"string\" /> Note that the type is not required but recommended, since it provides a type safety of the output values. Additionally, the type can be used to transform the output value into another type. For example, transform the output value 80% of type String into a Double using a custom data type.",
    "url": "/manual/latest/reference/dmn/decision-table/output/index.html"
  },
  {
    "id": "manual/latest/reference/dmn/decision-table/reference/dmn11/decision-table/hit-policy/index.html",
    "title": "/manual/latest/reference/dmn/decision-table/hit-policy/",
    "content": "No content available",
    "url": "/manual/latest/reference/dmn/decision-table/reference/dmn11/decision-table/hit-policy/index.html"
  },
  {
    "id": "manual/latest/reference/dmn/decision-table/reference/dmn11/decision-table/input/index.html",
    "title": "/manual/latest/reference/dmn/decision-table/input/",
    "content": "No content available",
    "url": "/manual/latest/reference/dmn/decision-table/reference/dmn11/decision-table/input/index.html"
  },
  {
    "id": "manual/latest/reference/dmn/decision-table/reference/dmn11/decision-table/output/index.html",
    "title": "/manual/latest/reference/dmn/decision-table/output/",
    "content": "No content available",
    "url": "/manual/latest/reference/dmn/decision-table/reference/dmn11/decision-table/output/index.html"
  },
  {
    "id": "manual/latest/reference/dmn/decision-table/reference/dmn11/decision-table/rule/index.html",
    "title": "/manual/latest/reference/dmn/decision-table/rule/",
    "content": "No content available",
    "url": "/manual/latest/reference/dmn/decision-table/reference/dmn11/decision-table/rule/index.html"
  },
  {
    "id": "manual/latest/reference/dmn/decision-table/rule/index.html",
    "title": "DMN Decision Table Rule | docs.cibseven.org",
    "content": "A decision table can have one or more rules. Each rule contains input and output entries. The input entries are the condition and the output entries the conclusion of the rule. If each input entry (condition) is satisfied, then the rule is satisfied and the decision result contains the output entries (conclusion) of this rule. A rule is represented by a rule element inside a decisionTable XML element. <?xml version=\"1.0\" encoding=\"UTF-8\"?> <definitions xmlns=\"https://www.omg.org/spec/DMN/20191111/MODEL/\" id=\"definitions\" name=\"definitions\" namespace=\"http://camunda.org/schema/1.0/dmn\"> <decision id=\"dish\" name=\"Dish\"> <decisionTable id=\"decisionTable\"> <!-- ... --> <rule id=\"rule2-950612891-2\"> <inputEntry id=\"inputEntry21\"> <text>\"Winter\"</text> </inputEntry> <inputEntry id=\"inputEntry22\"> <text><![CDATA[<= 8]]></text> </inputEntry> <outputEntry id=\"outputEntry2\"> <text>\"Roastbeef\"</text> </outputEntry> </rule> <!-- ... --> </decisionTable> </decision> </definitions> Input Entry (Condition) A rule can have one or more input entries, which are the conditions of the rule. Each input entry contains an expression in a text element as child of an inputEntry XML element. The input entry is satisfied when the evaluated expression returns true. <inputEntry id=\"inputEntry41\"> <text>\"Spring\"</text> </inputEntry> Expression Language of an Input Entry The expression language of the input entry can be specified by the expressionLanguage attribute on the inputEntry XML element. The supported expression languages are listed in the User Guide. <inputEntry id=\"inputEntry41\" expressionLanguage=\"juel\"> <text>cellInput == \"Spring\"</text> </inputEntry> If no expression language is set then the global expression language, which is set on the definitions XML element, is used. <definitions id=\"definitions\" name=\"definitions\" xmlns=\"https://www.omg.org/spec/DMN/20191111/MODEL/\" expressionLanguage=\"groovy\" namespace=\"http://camunda.org/schema/1.0/dmn\"> <!-- ... --> </definitions> In case no global expression language is set, the default expression language is used instead. The default expression language for input entries is FEEL. Please refer to the User Guide to read more about expression languages. Output Entry (Conclusion) A rule can have one or more output entries, which are the conclusions of the rule. Each output entry contains an expression in a text element as child of an outputEntry XML element. <outputEntry id=\"outputEntry4\"> <text>\"Steak\"</text> </outputEntry> Expression Language of an Output Entry The expression language of the expression can be specified by the expressionLanguage attribute on the outputEntry XML element. The supported expression languages are listed in the User Guide. <outputEntry id=\"outputEntry4\" expressionLanguage=\"groovy\"> <text>\"Steak\"</text> </outputEntry> If no expression language is set then the global expression language, which is set on the definitions XML element, is used. <definitions id=\"definitions\" name=\"definitions\" xmlns=\"https://www.omg.org/spec/DMN/20191111/MODEL/\" expressionLanguage=\"groovy\" namespace=\"http://camunda.org/schema/1.0/dmn\"> <!-- ... --> </definitions> In case no global expression language is set, the default expression language is used instead. The default expression language for output entries is JUEL. Please refer to the User Guide to read more about expression languages. Empty Entries Empty Input Entry In case an input entry is irrelevant for a rule, the expression is empty, which is always satisfied. <inputEntry id=\"inputEntry41\"> <text/> </inputEntry> If FEEL is used as expression language, then an empty input entry is represented by a -. Otherwise, the expression is empty. Empty Output Entry If the output entry is empty, then the output is ignored and not part of the decision table result. <outputEntry id=\"outputEntry4\"> <text/> </outputEntry> Both Entries Empty In case of a rule has an empty input and output entry, the outcome of evaluation will be determined with precedence of the empty input outcome. Description A rule can be annotated with a description that provides additional information. The description text is set inside the description XML element. <rule id=\"rule4\"> <description>Save money</description> <!-- ... --> </rule>",
    "url": "/manual/latest/reference/dmn/decision-table/rule/index.html"
  },
  {
    "id": "manual/latest/reference/dmn/drg/index.html",
    "title": "Decision Requirements Graph | docs.cibseven.org",
    "content": "A Decision Requirements Graph (DRG) models a domain of decision-making, showing the most important elements involved in it and the dependencies between them. The elements modeled are decisions, input data, and knowledge sources. The visual representation of a DRG is called Decision Requirements Diagram (DRD). In the XML a DRG is represented by the definitions element. <definitions xmlns=\"https://www.omg.org/spec/DMN/20191111/MODEL/\" id=\"dinnerDecisions\" name=\"Dinner Decisions\" namespace=\"http://camunda.org/schema/1.0/dmn\"> <decision id=\"dish\" name=\"Dish\"> <!-- ... --> </decision> <decision id=\"beverages\" name=\"Beverages\"> <!-- ... --> </decision> </definitions> Decision Requirements Graph Name The name describes the DRG. It is set as the name attribute on the definitions element. <definitions xmlns=\"https://www.omg.org/spec/DMN/20191111/MODEL/\" id=\"dinnerDecisions\" name=\"Dinner Decisions\" namespace=\"http://camunda.org/schema/1.0/dmn\"> <!-- ... --> </definitions> Decision Requirements Graph Id The id is the technical identifier of the DRG. It is set in the id attribute on the definitions element. Each DRG should have an unique id when it is deployed to CIB seven. The engine uses the id as the decision requirements definition key of the deployed DecisionRequirementsDefinition. <definitions xmlns=\"https://www.omg.org/spec/DMN/20191111/MODEL/\" id=\"dinnerDecisions\" name=\"Dinner Decisions\" namespace=\"http://camunda.org/schema/1.0/dmn\"> <!-- ... --> </definitions> Decision A decision requirements graph can have one or more decisions. A decision has a name which is shown in the DRD and an id. The decision logic inside the decision must be either a decision table or a decision literal expression. A decision is represented by a decision element inside the definitions XML element. <definitions xmlns=\"https://www.omg.org/spec/DMN/20191111/MODEL/\" id=\"dish\" name=\"Desired Dish\" namespace=\"party\"> <decision id=\"beverages\" name=\"Beverages\"> <decisionTable id=\"decisionTable\"> <!-- ... --> </decisionTable> </decision> </definitions> Required Decisions A decision can have one or more required decisions which it depends on. A required decision is represented by a requiredDecision element inside an informationRequirement XML element. It has a href attribute and the value starts with # followed by the decision id of the required decision. <decision id=\"beverages\" name=\"Beverages\"> <informationRequirement> <requiredDecision href=\"#dish\" /> </informationRequirement> <!-- ... --> </decision> Input Data An input data denotes information used as an input by one or more decisions. It is represented by an inputData element inside the definitions element. <definitions xmlns=\"https://www.omg.org/spec/DMN/20191111/MODEL/\" id=\"dinnerDecisions\" name=\"Dinner Decisions\" namespace=\"http://camunda.org/schema/1.0/dmn\"> <inputData id=\"guestsWithChildren\" name=\"Guests with children?\" /> <decision id=\"beverages\" name=\"Beverages\"> <informationRequirement> <requiredInput href=\"#guestsWithChildren\" /> </informationRequirement> <!-- ... --> </definitions> Note that an input data has no execution semantics and is ignored by the CIB seven DMN engine. Knowledge Source A knowledge source denotes an authority for a Decision. It is represented by a knowledgeSource element inside the definitions element. <definitions xmlns=\"https://www.omg.org/spec/DMN/20191111/MODEL/\" id=\"dinnerDecisions\" name=\"Dinner Decisions\" namespace=\"http://camunda.org/schema/1.0/dmn\"> <knowledgeSource id=\"cookbook\" name=\"Men's Cookbook\" /> <decision id=\"dish\" name=\"Dish\"> <authorityRequirement> <requiredDecision href=\"#cookbook\" /> </authorityRequirement> <!-- ... --> </definitions> Note that a knowledge source has no execution semantics and is ignored by the CIB seven DMN engine.",
    "url": "/manual/latest/reference/dmn/drg/index.html"
  },
  {
    "id": "manual/latest/reference/dmn/feel/index.html",
    "title": "Friendly Enough Expression Language (FEEL) | docs.cibseven.org",
    "content": "Decision Model and Notation (DMN) defines a Friendly Enough Expression Language (FEEL). It can be used to evaluate expressions in a decision table. CIB seven relies on an independently maintained project to provide FEEL support. You can find the documentation about the FEEL Language Reference in the FEEL Scala Engine Documentation (link to external documentation). Please also check out the User Guide to learn more about the integration of the FEEL Scala Engine in CIB seven.",
    "url": "/manual/latest/reference/dmn/feel/index.html"
  },
  {
    "id": "manual/latest/reference/dmn/feel/legacy/data-types/index.html",
    "title": "FEEL Data Types | docs.cibseven.org",
    "content": "Heads Up! This page provides information on the legacy FEEL Engine, that was used before the current Scala-based FEEL Engine was integrated into CIB seven. The Camunda DMN engine supports the following FEEL data types. String FEEL supports Strings. They must be encapsulated in double quotes. They support only the equal comparison operator. Numeric Types FEEL supports numeric types like integer. In the Camunda DMN engine the following numeric types are available: integer long double Numeric types support all comparison operators and ranges. Boolean FEEL supports the boolean value true and false. The boolean type only supports the equal comparison operator. Date FEEL supports date types. In the Camunda DMN engine the following date types are available: date and time To create a date and time value, the function date and time has to be used with a single String parameter. The parameter specifies the date and time in the format yyyy-MM-dd'T'HH:mm:ss. Date types support all comparison operators and ranges.",
    "url": "/manual/latest/reference/dmn/feel/legacy/data-types/index.html"
  },
  {
    "id": "manual/latest/reference/dmn/feel/legacy/index.html",
    "title": "Legacy FEEL Reference | docs.cibseven.org",
    "content": "Heads Up! This page provides information on the legacy FEEL Engine, that was used before the current Scala-based FEEL Engine was integrated into CIB seven.",
    "url": "/manual/latest/reference/dmn/feel/legacy/index.html"
  },
  {
    "id": "manual/latest/reference/dmn/feel/legacy/language-elements/index.html",
    "title": "FEEL Language Elements | docs.cibseven.org",
    "content": "Heads Up! This page provides information on the legacy FEEL Engine, that was used before the current Scala-based FEEL Engine was integrated into CIB seven. The Camunda DMN engine supports FEEL for input entries. The FEEL term for expression in input entries are simple unary tests. These simple unary tests test an input value against an expression and return either true if the test is satisfied or false otherwise. The expression can contain different elements which are described in this sections. Comparison FEEL simple unary tests support the following comparison operators. Please note that the equals operator is empty and not =. Also, a non equal operator such as != does not exist. To express this, negation has to be used. Name Operator Example Description Equal \"Steak\" Test that the input value is equal to the given value. Less < < 10 Test that the input value is less than the given value. Less or Equal <= <= 10 Test that the input value is less than or equal to the given value. Greater > > 10 Test that the input value is greater than the given value. Greater or Equal >= >= 10 Test that the input value is greater than or equal to the given value. Range Some FEEL data types, such as numeric types and date types, can be tested against a range of values. These ranges consist of a start value and an end value. The range specifies if the start and end value is included in the range. Start End Example Description include include [1..10] Test that the input value is greater than or equal to the start value and less than or equal to the end value. exclude include ]1..10] or (1..10] Test that the input value is greater than the start value and less than or equal to the end value. include exclude [1..10[ or [1..10) Test that the input value is greater than or equal to the start value and less than the end value. exclude exclude ]1..10[ or (1..10) Test that the input value is greater than the start value and less than the end value. Disjunction A FEEL simple unary test can be specified as conjunction of expressions. These expressions have to either have comparisons or ranges. The test is true if at least one of conjunct expressions is true. Examples: 3,5,7: Test if the input is either 3, 5 or 7 <2,>10: Test if the input is either less than 2 or greater than 10 10,[20..30]: Test if the input is either 10 or between 20 and 30 \"Spareribs\",\"Steak\",\"Stew\": Test if the input is either the String Spareribs, Steak or Stew date and time(\"2015-11-30T12:00:00\"),date and time(\"2015-12-01T12:00:00\"): Test if the input is either the date November 30th, 2015 at 12:00:00 o’clock or December 1st, 2015 at 12:00:00 o’clock >customer.age,>21: Test if the input is either greater than the age property of the variable customer or greater than 21 Negation A FEEL simple unary test can be negated with the not function. This means if the containing expression returns true, the test will return false. Please note that only one negation as first operator is allowed but it can contain a disjunction. Examples: not(\"Steak\"): Test if the input is not the String Steak not(>10): Test if the input is not greater than 10, which means it is less than or equal to 10 not(3,5,7): Test if the input is neither 3, 5 nor 7 not([20..30]): Test if the input is not between 20 and 30 Qualified Names FEEL simple unary tests can access variables and object properties by qualified names. Examples: x: Test if the input is equal to the variable x >= x: Test if the input is greater than or equal to the variable x < customer.age: Test if the input is less than the age property of the variable customer Date Functions FEEL simple unary tests provide functions to create date types. The Camunda DMN engine supports the following date functions: date and time(\"...\"): Creates a date and time value from a String with the format yyyy-MM-dd'T'HH:mm:ss Examples: date and time(\"2015-11-30T12:00:00\"): Test if the input is the date November 30th, 2015 at 12:00:00 o’clock [date and time(\"2015-11-30T12:00:00\")..date and time(\"2015-12-01T12:00:00\")]: Test if the input is between the date November 30th, 2015 at 12:00:00 o’clock and December 1st, 2015 at 12:00:00 o’clock",
    "url": "/manual/latest/reference/dmn/feel/legacy/language-elements/index.html"
  },
  {
    "id": "manual/latest/reference/dmn/feel/legacy/reference/dmn11/feel/legacy/data-types/index.html",
    "title": "/manual/latest/reference/dmn/feel/legacy/data-types/",
    "content": "No content available",
    "url": "/manual/latest/reference/dmn/feel/legacy/reference/dmn11/feel/legacy/data-types/index.html"
  },
  {
    "id": "manual/latest/reference/dmn/feel/legacy/reference/dmn11/feel/legacy/language-elements/index.html",
    "title": "/manual/latest/reference/dmn/feel/legacy/language-elements/",
    "content": "No content available",
    "url": "/manual/latest/reference/dmn/feel/legacy/reference/dmn11/feel/legacy/language-elements/index.html"
  },
  {
    "id": "manual/latest/reference/dmn/feel/reference/dmn11/feel/legacy/index.html",
    "title": "/manual/latest/reference/dmn/feel/legacy/",
    "content": "No content available",
    "url": "/manual/latest/reference/dmn/feel/reference/dmn11/feel/legacy/index.html"
  },
  {
    "id": "manual/latest/reference/dmn/index.html",
    "title": "DMN 1.3 Reference | docs.cibseven.org",
    "content": "Decision Model and Notation (DMN) is a standard for Business Decision Management. Currently the Camunda DMN engine partially supports DMN 1.3, including Decision Tables, Decision Literal Expressions, Decision Requirements Graphs and the Friendly Enough Expression Language (FEEL).",
    "url": "/manual/latest/reference/dmn/index.html"
  },
  {
    "id": "manual/latest/reference/dmn/reference/dmn11/custom-extensions/index.html",
    "title": "/manual/latest/reference/dmn/custom-extensions/",
    "content": "No content available",
    "url": "/manual/latest/reference/dmn/reference/dmn11/custom-extensions/index.html"
  },
  {
    "id": "manual/latest/reference/dmn/reference/dmn11/decision-literal-expression/index.html",
    "title": "/manual/latest/reference/dmn/decision-literal-expression/",
    "content": "No content available",
    "url": "/manual/latest/reference/dmn/reference/dmn11/decision-literal-expression/index.html"
  },
  {
    "id": "manual/latest/reference/dmn/reference/dmn11/decision-table/index.html",
    "title": "/manual/latest/reference/dmn/decision-table/",
    "content": "No content available",
    "url": "/manual/latest/reference/dmn/reference/dmn11/decision-table/index.html"
  },
  {
    "id": "manual/latest/reference/dmn/reference/dmn11/drg/index.html",
    "title": "/manual/latest/reference/dmn/drg/",
    "content": "No content available",
    "url": "/manual/latest/reference/dmn/reference/dmn11/drg/index.html"
  },
  {
    "id": "manual/latest/reference/dmn/reference/dmn11/feel/index.html",
    "title": "/manual/latest/reference/dmn/feel/",
    "content": "No content available",
    "url": "/manual/latest/reference/dmn/reference/dmn11/feel/index.html"
  },
  {
    "id": "manual/latest/reference/forms/camunda-forms/index.html",
    "title": "Camunda Forms Reference | docs.cibseven.org",
    "content": "This content has moved to docs.camunda.io and is available here for all future versions.",
    "url": "/manual/latest/reference/forms/camunda-forms/index.html"
  },
  {
    "id": "manual/latest/reference/forms/embedded-forms/controls/boolean-inputs/index.html",
    "title": "Boolean Inputs | docs.cibseven.org",
    "content": "Checkbox Checkboxes are HTML <input type=\"checkbox\"> controls. Checkbox controls can be used for boolean variable types. Binding a Checkbox to a Process Variable A checkbox input can be bound to a process variable using the cam-variable-type and cam-variable-name directives: <input type=\"checkbox\" cam-variable-name=\"IS_VIP_CUSTOMER\" cam-variable-type=\"Boolean\" /> In the example above, the checkbox is bound to the variable named IS_VIP_CUSTOMER of type Boolean. Supported Variable Types for Checkboxes The checkbox input field only supports boolean variable types. A checked checkbox corresponds to the value true, an unchecked checkbox corresponds to the value false. Boolean Select Box To bind a <select> box to a Java Boolean variable, the directive cam-variable-type=\"Boolean\" must be used. Example: <select cam-variable-name=\"APPROVED\" cam-variable-type=\"Boolean\"> <option value=\"true\">Yes</option> <option value=\"false\">No</option> </select> Boolean text Input To bind a text input field to a Java Boolean variable, the directive cam-variable-type=\"Boolean\" must be used. Text input fields of type Boolean accept the following string values: true false Meaning that the user has to type the words “true” or “false” into the text input field. Example: <input type=\"text\" cam-variable-name=\"IS_VIP_CUSTOMER\" cam-variable-type=\"Boolean\" />",
    "url": "/manual/latest/reference/forms/embedded-forms/controls/boolean-inputs/index.html"
  },
  {
    "id": "manual/latest/reference/forms/embedded-forms/controls/bpmn-buttons/index.html",
    "title": "BPMN Event Buttons | docs.cibseven.org",
    "content": "These buttons can be used to trigger error and escalation events in user tasks. They will submit all entered values and activate the corresponding boundary event. To learn more about error and escalation events, see our section about events. Error An Error Button can be bound to an error code and error message using the cam-error-code and cam-error-message directive. Providing an error message is optional. <button cam-error-code=\"bpmn-error-543\" cam-error-message=\"anErrorMessage\" /> In the example above, the button is bound to the error code bpmn-error-543 with the message anErrorMessage. Escalation In a similar manner to the error button, an escalation button can be bound to an escalation code using the cam-escalation-code directive. <button cam-escalation-code=\"bpmn-escalation-123\" />",
    "url": "/manual/latest/reference/forms/embedded-forms/controls/bpmn-buttons/index.html"
  },
  {
    "id": "manual/latest/reference/forms/embedded-forms/controls/date-inputs/index.html",
    "title": "Date Inputs | docs.cibseven.org",
    "content": "Date input is supported using an <input type=\"text\"> control. Binding to a Process Variable To bind the input field to a Java Date variable, the directive cam-variable-type=\"Date\" must be used. Example: <input type=\"text\" cam-variable-name=\"CONTRACT_START_DATE\" cam-variable-type=\"Date\" /> Date Format Currently only the ISO Date Format yyyy-MM-dd'T'HH:mm:ss is supported. Example value: 2013-01-23T13:42:42 Using a Date Picker The Form SDK itself does not provide any custom components or widgets. As such it also does not provide a date picker. However, you can integrate third party libraries providing such widgets or write one yourself (see Custom JavaScript). Inside Camunda Tasklist, datepicker support is provided through Angular UI. You can use the Angular UI datepicker directive to offer a datepicker for the date input field. The complete markup of the input field including the datepicker button is shown below. <p class=\"input-group\"> <input type=\"text\" cam-variable-name=\"CONTRACT_START_DATE\" cam-variable-type=\"Date\" class=\"form-control\" uib-datepicker-popup=\"yyyy-MM-dd'T'HH:mm:ss\" is-open=\"dateFieldOpened\" /> <span class=\"input-group-btn\"> <button type=\"button\" class=\"btn btn-default\" ng-click=\"open($event)\"> <i class=\"glyphicon glyphicon-calendar\"></i> </button> </span> </p> In addition to the HTML markup, the following JavaScript must be included in the form file (see Custom JavaScript): <script cam-script type=\"text/form-script\"> $scope.open = function($event) { $event.preventDefault(); $event.stopPropagation(); $scope.dateFieldOpened = true; }; </script> The attributes of the datepicker component are explained below: Additional attributes of the input element: uib-datepicker-popup=\"yyyy-MM-dd'T'HH:mm:ss\": This attribute sets the format of the date which is returned by the datepicker. It must be the ISO Date Format. is-open=\"dateFieldOpened\": This attribute contains the name of the variable, which indicates the open status of the datepicker. It must be the same variable, which is set to true in the open function in the JavaScript snippet. If a form contains multiple datepickers, they must have different values for this attribute. Attributes of the datepicker button: ng-click=\"open($event)\": This attribute contains the name of the function which is called when the datepicker button is clicked. It must be the function name of the JavaScript snippet which sets the is-open variable to true. If a form contains multiple date pickers, they must have different function names, or the name of the is-open variable must be passed to the function.",
    "url": "/manual/latest/reference/forms/embedded-forms/controls/date-inputs/index.html"
  },
  {
    "id": "manual/latest/reference/forms/embedded-forms/controls/files/index.html",
    "title": "File Upload and Download | docs.cibseven.org",
    "content": "Uploading Files File input elements are HTML controls in the form of <input type=\"file\"></input> They allow users to upload files, which will be stored as a process instance variable of the type Bytes. Larger files will take longer to process and may crash the browser, so there is a soft file size limit of 5MB. You can overwrite this limit using the cam-max-filesize directive. To upload larger files without freezing the browser, see the custom javascript section. Files can be uploaded using the cam-variable-name and cam-variable-type directives: <input type=\"file\" cam-variable-name=\"INVOICE_DOCUMENT\" cam-variable-type=\"File\" cam-max-filesize=\"10000000\" /> In the example above, the user can upload a document with a maximum filesize of 10MB. The uploaded file will be stored as process instance variable with the name INVOICE_DOCUMENT. Besides uploading a file, it is also possible to present the user with a download link or displaying files as images. Downloading Files The cam-file-download directive turns a link into a file download link. <a cam-file-download=\"INVOICE_DOCUMENT\"></a> The above link will allow the user to download the file stored in the variable INVOICE_DOCUMENT. If the link has no text content, the filename of the file will be set as text content. Displaying an Uploaded Image If the user uploaded an image, it can be displayed using an <img> tag. There is no special directive for this yet. However, you can make sure that the corresponding variable is fetched (either using javascript or an hidden input field) and then use the generated link as value for the src attribute. <!-- make sure the file is fetched. Alternative: use javascript --> <input type=\"hidden\" cam-variable-name=\"INVOICE_DOCUMENT\"/> <!-- set contentUrl as src of the image--> <img src=\"{{ camForm.variableManager.variable('INVOICE_DOCUMENT').contentUrl }}\"></img> Note: the above example uses the angular js integration.",
    "url": "/manual/latest/reference/forms/embedded-forms/controls/files/index.html"
  },
  {
    "id": "manual/latest/reference/forms/embedded-forms/controls/hidden/index.html",
    "title": "Hidden Input Fields | docs.cibseven.org",
    "content": "Hidden input elements are HTML controls in the form of <input type=\"hidden\"></input> They are not displayed in the form, but can be used to retrieve values to be used in the context of the form (e.g., using Angular bindings). Binding a Hidden Element to a Process Variable A hidden input can be bound to a process variable using the cam-variable-type and cam-variable-name directives: <input type=\"hidden\" cam-variable-name=\"CUSTOMER_ID\" cam-variable-type=\"String\" value=\"testuser\" /> In the example above, the hidden input field is bound to the variable named CUSTOMER_ID of type String and contains the value testuser. Supported Variable Types for Hidden Elements The hidden input field supports the same variable types as the single line text input <input type=\"text\"></input>. See the section on Supported Variable Types for details.",
    "url": "/manual/latest/reference/forms/embedded-forms/controls/hidden/index.html"
  },
  {
    "id": "manual/latest/reference/forms/embedded-forms/controls/index.html",
    "title": "Controls | docs.cibseven.org",
    "content": "The Forms SDK provides a set of directives which simplify working with process variables in an HTML form. These directives work on most of the HTML controls and allow users to declaratively fetch variables from the process engine and have their values written to and read from input fields. If an HTML control is not supported, you need to write custom JavaScript. The cam-variable-name Directive The cam-variable-name directive allows providing the name of a process / task / case variable. If the directive is discovered on an HTML control, the value of the variable is fetched from the server and written to the control. <input type=\"text\" cam-variable-name=\"CUSTOMER_ID\"> The cam-business-key Directive The cam-business-key is aimed to be used on a free text input field in order to define a businessKey at the start of a process. This attribute is only relevant when the form is aimed to start a process. <input type=\"text\" cam-business-key> See also: Setting the business key using Javascript AngularJS support and cam-variable-name If you use the AngularJS integration, the cam-variable-name directive will automatically bind the input to the model in case no binding is provided by the user. The following two markup examples have the same semantics: <input type=\"text\" cam-variable-name=\"CUSTOMER_ID\"> is the same as <input type=\"text\" cam-variable-name=\"CUSTOMER_ID\" ng-model=\"CUSTOMER_ID\"> If the user provides a customer ng-model binding, it is respected: <input type=\"text\" cam-variable-name=\"CUSTOMER_ID\" ng-model=\"customerId\"> Current value: {{customerId}} The cam-variable-type Directive The cam-variable-type directive allows specifying the type of a process / task / case variable. This is required if the variable does not yet exist. The following markup creates a text input field bound to a variable of type Double: <input type=\"text\" cam-variable-name=\"INVOICE_AMOUNT\" cam-variable-type=\"Double\"> Supported Variable Types See the section on variable types for a list of variable types which are supported out of the box. AngularJS Support and cam-variable-type The cam-variable-type directive can be used as validation directive: <input type=\"text\" name=\"invoiceAmount\" cam-variable-name=\"INVOICE_AMOUNT\" cam-variable-type=\"Double\"> <span ng-show=\"myForm.invoiceAmount.$error.camVariableType\"> Input must be a 'Double'. </span>",
    "url": "/manual/latest/reference/forms/embedded-forms/controls/index.html"
  },
  {
    "id": "manual/latest/reference/forms/embedded-forms/controls/inputs/index.html",
    "title": "Text Inputs | docs.cibseven.org",
    "content": "Single line text inputs are <input type=\"text\"> controls. Single line text inputs are the most common input field and allow the user to provide values for different data types. Binding Text Input to a Process Variable A text input can be bound to a process variable using the cam-variable-type and cam-variable-name directives: <input type=\"text\" cam-variable-name=\"CUSTOMER_ID\" cam-variable-type=\"String\" /> In the example above, the text input field is bound to the variable named CUSTOMER_ID of type String. Supported Variable Types for Text Inputs A text input field supports multiple variable types. Binding to existing variables: Note that if you bind the input field to an existing variable, the type of the variable is provided by the process engine and the cam-variable-type directive is not required. String To bind the input field to a String variable, the directive cam-variable-type=\"String\" must be used. Example: <input type=\"text\" cam-variable-name=\"CUSTOMER_ID\" cam-variable-type=\"String\" /> Trimming: Note that the value of the String variable is trimmed before it is submitted to the process engine: leading and trailing whitespace is removed. Integer To bind the input field to a Java Integer variable, the directive cam-variable-type=\"Integer\" must be used. Example: <input type=\"text\" cam-variable-name=\"CUSTOMER_AGE\" cam-variable-type=\"Integer\" /> Long To bind the input field to a Java Long variable, the directive cam-variable-type=\"Long\" must be used. Example: <input type=\"text\" cam-variable-name=\"CUSTOMER_REVENUE\" cam-variable-type=\"Long\" /> Short To bind the input field to a Java Short variable, the directive cam-variable-type=\"Short\" must be used. Example: <input type=\"text\" cam-variable-name=\"CUSTOMER_REVENUE\" cam-variable-type=\"Short\" /> Double To bind the input field to a Java Double variable, the directive cam-variable-type=\"Double\" must be used. Example: <input type=\"text\" cam-variable-name=\"CUSTOMER_REVENUE\" cam-variable-type=\"Double\" />",
    "url": "/manual/latest/reference/forms/embedded-forms/controls/inputs/index.html"
  },
  {
    "id": "manual/latest/reference/forms/embedded-forms/controls/select/index.html",
    "title": "Selects | docs.cibseven.org",
    "content": "Select boxes are HTML controls of the form of <select></select> Binding to a Process Variable A select box can be bound to a process variable using the cam-variable-name directive: <select cam-variable-name=\"foo\" cam-variable-type=\"String\"> <option>bar</option> <option>zar</option> </select> Supported Variable Types The select box supports the same value types as <input type=\"text\">. Populating the Options from a Variable The <option> entries can be populated using a variable. The name of the variable can be provided using the cam-choices directive: <select cam-variable-name=\"PRODUCT_TYPE\" cam-variable-type=\"String\" cam-choices=\"AVAILABLE_PRODUCT_TYPES\"> </select> The directive cam-choices expects the values to be a List or Map (Object). In case of a Map (Object), the keys of the map are used as values of the options. java.util.Map and java.util.List are supported but must be serialized as JSON: Map<String, String> productTypes = new HashMap<String, String>(); productTypes.put(\"001\", \"Notebook\"); productTypes.put(\"002\", \"Server\"); productTypes.put(\"003\", \"Workstation\"); execution.setVariable(\"AVAILABLE_PRODUCT_TYPES\", Spin.JSON(productTypes)); Would be rendered as <select cam-variable-name=\"PRODUCT_TYPE\" cam-variable-type=\"String\" cam-choices=\"AVAILABLE_PRODUCT_TYPES\"> <option value=\"001\">Notebook</option> <option value=\"002\">Server</option> <option value=\"003\">Workstation</option> </select>",
    "url": "/manual/latest/reference/forms/embedded-forms/controls/select/index.html"
  },
  {
    "id": "manual/latest/reference/forms/embedded-forms/controls/textarea/index.html",
    "title": "Textareas | docs.cibseven.org",
    "content": "Textareas are HTML <textarea> elements of the form <textarea></textarea> Binding a Textarea to a Process Variable A textarea input can be bound to a process variable using the cam-variable-type and cam-variable-name directives: <textarea cam-variable-name=\"CUSTOMER_ADDRESS\" cam-variable-type=\"String\"> </textarea> In the example above, the textarea is bound to the variable named CUSTOMER_ADDRESS of type String. Supported Variable Types for Textareas The textarea supports the same variable types as the single line text input <input type=\"text\"></input>. See the section on Supported Variable Types for details.",
    "url": "/manual/latest/reference/forms/embedded-forms/controls/textarea/index.html"
  },
  {
    "id": "manual/latest/reference/forms/embedded-forms/index.html",
    "title": "Embedded Forms Reference | docs.cibseven.org",
    "content": "This reference covers the features of the CIB seven Forms SDK. The Forms SDK simplifies the implementation of user task forms in HTML5 / JavaScript based Applications. The Forms SDK itself is written in JavaScript and can be added to any JavaScript based Application. The Forms SDK and Camunda Tasklist Camunda Tasklist uses the Form SDK for providing support for Embedded Forms. By default, the tasklist uses the Form SDKs AngularJS integration. Features The Forms SDK provides the following features: Form handling: attach to a form existing in the DOM or load a form from a URL. Variable handling: load and submit variables used in the form. Script handling: execute custom JavaScript in Forms Angular JS Integration: The Forms SDK optionally integrates with AngularJS to take advantage of AngularJS form validation and other AngularJS goodies. The following is a simple example of a form with two input fields binding to process variables CUSTOMER_ID and CUSTOMER_REVENUE: <form> <label for=\"customerId\">Customer Id:</label> <input type=\"text\" id=\"customerId\" cam-variable-name=\"CUSTOMER_ID\" cam-variable-type=\"String\"> <label for=\"customerRevenue\">Customer Revenue:</label> <input type=\"text\" id=\"customerRevenue\" cam-variable-name=\"CUSTOMER_REVENUE\" cam-variable-type=\"Double\"> </form> Anti Features The Forms SDK is intended to be lean and small. By design it is not concerned with things like Form Validation: Instead, integrate with existing frameworks such as AngularJS. Components / Widgets: Instead, integrate nicely with existing component libraries like jQuery UI, Angular UI, … Form Generation: Instead, allow users to leverage the complete power of HTML and JavaScript to implement complex forms.",
    "url": "/manual/latest/reference/forms/embedded-forms/index.html"
  },
  {
    "id": "manual/latest/reference/forms/embedded-forms/integrate/angular-js/index.html",
    "title": "AngularJS Integration | docs.cibseven.org",
    "content": "Including the Angular Distribution Make sure you include the AngularJS build of the Forms SDK: <script src=\"angular.min.js\" type=\"text/javascript\"></script> <script src=\"camunda-bpm-sdk-angular.js\" type=\"text/javascript\"></script> Loading the Forms Module Add the Forms SDK as module dependency to your application module: angular.bootstrap(window.document, ['cam.embedded.forms', ...]); Angular Directives & Compilation If the form is loaded from a URL, the SDK makes sure that it is properly compiled and linked to the current Angular scope. This allows using Angular directives in forms loaded dynamically at runtime. <form role=\"form\" name=\"form\"> <input type=\"text\" cam-variable-name=\"CUSTOMER_ID\" cam-variable-type=\"String\" ng-model=\"customerId\"> <p ng-show=\"customerId\">Your input: <em>{{customerId}}</em></p> </form>",
    "url": "/manual/latest/reference/forms/embedded-forms/integrate/angular-js/index.html"
  },
  {
    "id": "manual/latest/reference/forms/embedded-forms/integrate/bootstrapping/index.html",
    "title": "Bootstrapping | docs.cibseven.org",
    "content": "Creating a Client The Forms SDK uses an instance of the CamSDK.Client to communicate with the process engine (over the REST API): var camClient = new CamSDK.Client({ mock: false, apiUri: 'http://localhost:8080/engine-rest' }); Creating a Form In order to create a form, you need to create an instance of CamSDK.Form: new CamSDK.Form({ // ... }); Providing a Task Id In case the form is a task form (i.e., the submission of the form should trigger the completing of a task), you need to provide a taskId: new CamSDK.Form({ client: camClient, // the task ID taskId: 'someTaskId', //... }); Providing a Process Definition Id In case the form is a start form (i.e., the submission of the form should trigger a new process instance to start), you need to provide a processDefinitionId: new CamSDK.Form({ client: camClient, // the process definition ID processDefinitionId: 'someProcessDefinitionId', //... }); Loading a Form from a URL The Forms SDK can automatically load forms from a URL. The URL from which the form should be loaded is referenced using the formElement property. In that case you need to create a container element somewhere in the DOM: <div id=\"formContainer\"> </div> And reference it in the containerElement property when creating the CamSDK.Form instance: new CamSDK.Form({ client: camClient, // URL to the form formUrl: '/url/to/form.html', // the task ID taskId: 'someTaskId', // the container to which the form should be appended. Can be a DOM element or a jQuery wrapper containerElement: $('#formContainer'), done: function(error, camFormInstance) { // .. } }); Using a form existing in the DOM It is also possible to initialize the Form SDK for a form already existing in the DOM. Assuming that you have an HTML <form ...> element present in the DOM: <form id=\"myForm\"> <input ....> </form> You can create an instance of CamSDK.Form and attach it to the existing form like this: new CamSDK.Form({ client: camClient, // the task ID taskId: 'someTaskId', // the form element. Can be a DOM element or a jQuery wrapper formElement: $('#myForm'), done: function(error, camFormInstance) { // .. } });",
    "url": "/manual/latest/reference/forms/embedded-forms/integrate/bootstrapping/index.html"
  },
  {
    "id": "manual/latest/reference/forms/embedded-forms/integrate/full-examples/index.html",
    "title": "Full Example | docs.cibseven.org",
    "content": "Full examples of how to integrate the Forms SDK in a custom application can be found in the CIB seven Examples Repository in Github. Example for standalone usage of the SDK Example for standalone usage of the SDK with AngularJS Integration",
    "url": "/manual/latest/reference/forms/embedded-forms/integrate/full-examples/index.html"
  },
  {
    "id": "manual/latest/reference/forms/embedded-forms/integrate/getting-a-distribution/index.html",
    "title": "Getting a Distribution | docs.cibseven.org",
    "content": "Manual Download The Forms SDK library can be downloaded from Github. Bower Alternatively, the Forms SDK can be installed using the Bower package manager: bower install camunda-bpm-sdk-js --save Dependency Management The Forms SDK depends on the following libraries: JQuery (or a compatible DOM manipulation Library). The Forms SDK optionally depends on the following libraries: AngularJS (v1.2.16). Including the Library Next, you need to add the JavaScript Library to the page. <script src=\"jquery-2.1.1.min.js\" type=\"text/javascript\"></script> <script src=\"camunda-bpm-sdk.min.js\" type=\"text/javascript\"></script> Or, with AngularJS Support: <script src=\"angular.min.js\" type=\"text/javascript\"></script> <script src=\"camunda-bpm-sdk-angular.js\" type=\"text/javascript\"></script>",
    "url": "/manual/latest/reference/forms/embedded-forms/integrate/getting-a-distribution/index.html"
  },
  {
    "id": "manual/latest/reference/forms/embedded-forms/integrate/index.html",
    "title": "Integrating the Forms SDK | docs.cibseven.org",
    "content": "This section explains how to integrate the Forms SDK into a custom HTML 5 Application. (Note: If you are using Camunda Tasklist you can skip this section. Camunda Tasklist readily integrates the Forms SDK.)",
    "url": "/manual/latest/reference/forms/embedded-forms/integrate/index.html"
  },
  {
    "id": "manual/latest/reference/forms/embedded-forms/java-objects/index.html",
    "title": "Working with Java Objects | docs.cibseven.org",
    "content": "This section explains how to work with serialized Java Objects in embedded task forms. Out of the box, you can only work with Java Objects which are serialized in JSON format If Java Classes are serialized using JAX-B, you need to add custom XML parsing and writing logic to the embedded form. Java Objects serialized using Java Serialization cannot be used in forms. Fetching an existing Serialized Java Object Variable The Form SDK will only fetch those variables which are actually used in a form. Since a Complex Java Object is usually not bound to a single input field, we cannot use the cam-variable-name directive. We thus need to fetch the variable programatically: <script cam-script type=\"text/form-script\"> camForm.on('form-loaded', function() { // tell the form SDK to fetch the variable named 'invoiceData' camForm.variableManager.fetchVariable('invoiceData'); }); camForm.on('variables-fetched', function() { // work with the variable (bind it to the current AngularJS $scope) $scope.invoiceData = camForm.variableManager.variableValue('invoiceData'); }); </script> Creating a new Serialized Java Object In case the variable does not yet exist (for instance in a Start Form), you have to create the variable and specify the necessary meta data in order for the process engine to correctly handle the variable as Java Object. <script cam-script type=\"text/form-script\"> var dataObject = $scope.dataObject = {}; camForm.on('form-loaded', function() { // declare variable 'customerData' incuding metadata for serialization camForm.variableManager.createVariable({ name: 'customerData', type: 'Object', value: dataObject, valueInfo: { // indicate that object is serialized as json serializationDataFormat: 'application/json', // provide classname of java object to map to objectTypeName: 'org.cibseven.bpm.example.CustomerData' } }); }); </script> Full Example A full example of this feature can be found in the CIB seven Examples Repository.",
    "url": "/manual/latest/reference/forms/embedded-forms/java-objects/index.html"
  },
  {
    "id": "manual/latest/reference/forms/embedded-forms/javascript/api/index.html",
    "title": "Available API | docs.cibseven.org",
    "content": "Inside a form script, the following built-in variables and functions are available: camForm The camForm variable is an instance of the CamSDK.Form class. It is the primary access point to the form API and allows definition of event handers for participation in the form lifecycle: <form role=\"form\"> ... <script cam-script type=\"text/form-script\"> var variableManager = camForm.variableManager; camForm.on('variables-fetched', function() { // access to all process variables after the form has loaded console.log(variableManager.variables); }); </script> </form> $scope Only available with AngularJS integration. Provides access to the current AngularJS scope: <form role=\"form\"> <input type=\"text\" cam-variable-name=\"CUSTOMER_ID\" cam-variable-type=\"String\" ng-model=\"customerId\" /> <script cam-script type=\"text/form-script\"> camForm.on('variables-applied', function() { // the input field is bound to $scope.customerId $scope.customerId = \"some-id\"; }); </script> </form> inject() Only available with AngularJS integration. <form role=\"form\"> <script cam-script type=\"text/form-script\"> inject(['$http', 'Uri', function($http, Uri) { camForm.on('form-loaded', function() { // use injected $http service for making requests, e.g. $http.get(Uri.appUri('engine://engine/:engine/task/' + camForm.taskId)).then(function(task) { $scope.task = task; }); }); }]); </script> </form>",
    "url": "/manual/latest/reference/forms/embedded-forms/javascript/api/index.html"
  },
  {
    "id": "manual/latest/reference/forms/embedded-forms/javascript/cam-script/index.html",
    "title": "The cam-script Directive | docs.cibseven.org",
    "content": "It is possible to use custom JavaScript in embedded forms. Custom JavaScript can be added to a form by using a <script> tag and adding the cam-script directive: <form role=\"form\"> <script cam-script type=\"text/form-script\"> // custom script goes here </script> </form>",
    "url": "/manual/latest/reference/forms/embedded-forms/javascript/cam-script/index.html"
  },
  {
    "id": "manual/latest/reference/forms/embedded-forms/javascript/debugging/index.html",
    "title": "Debugging Scripts | docs.cibseven.org",
    "content": "If a form script is loaded using an XHR from a web server, it is executed using eval(). To debug it, you need to use browser-specific debugger extensions. Debugging Form Scripts in Google Chrome If you are using the Google Chrome debugger, you can add the debugger; directive to the source code of the script: <form role=\"form\"> <script cam-script type=\"text/form-script\"> debugger; </script> </form>",
    "url": "/manual/latest/reference/forms/embedded-forms/javascript/debugging/index.html"
  },
  {
    "id": "manual/latest/reference/forms/embedded-forms/javascript/examples/index.html",
    "title": "Examples | docs.cibseven.org",
    "content": "The following examples show example scenarios of custom JavaScript in embedded forms. User name from a cam-script This example demonstrates how to retrieve the user name and display it in an embedded form: <form role=\"form\"> <script cam-script type=\"text/form-script\"> inject(['$rootScope', function($rootScope) { $scope.userName = $rootScope.authentication.name; }]); </script> <h1>Greetings {{ userName }}</h1> </form> Load Additional Resources This example includes an image, which is located in the contextPath of the form (i.e., in the same directory). The URL of the image is retrieved via the task form key method of the REST API: <form role=\"form\"> <script cam-script type=\"text/form-script\"> inject(['$http', 'Uri', function($http, Uri) { camForm.on('form-loaded', function() { $http.get(Uri.appUri(\"engine://engine/:engine/task/\" + camForm.taskId + \"/form\")).then(function(result){ $scope.contextPath = result.contextPath; }); }); }]); </script> <img ng-src=\"{{contextPath}}/image.png\" /> </form> Exclude a variable from submit When a variable is loaded, it is also sent back to the server when the form is submitted. If you have a variable that you don’t want to be submitted when the form is completed, you can use the destroyVariable function of the variable manager: <script cam-script type=\"text/form-script\"> camForm.on('form-loaded', function() { // tell the form SDK to fetch the variable named 'invoiceData' camForm.variableManager.fetchVariable('invoiceData'); }); camForm.on('variables-fetched', function() { // work with the variable (bind it to the current AngularJS $scope) $scope.invoiceData = camForm.variableManager.variableValue('invoiceData'); }); camForm.on('submit', function() { // make the variableManager forget about the invoiceData variable camForm.variableManager.destroyVariable('invoiceData'); }); </script> Upload Large Files This example contains a file input element and the script to send it to the server. In contrast to the file input element of the Forms SDK, this example can handle large files, but it also has some drawbacks: Can not be used in the start form of a process (no process instance id exists at this time) Does not take part in the form lifecycle (files could be saved even if the form is not submitted) Can only save one file at a time This example first retrieves the process instance id of the task for the form. It then registers an upload function, which, when executed, uploads the data as a process instance variable with the name uploadedFile <form role=\"form\"> <input id=\"fileUpload\" type=\"file\" /> <button ng-click=\"upload()\">Upload</button> <script cam-script type=\"text/form-script\"> inject(['$http', 'Uri', function($http, Uri) { camForm.on('form-loaded', function() { $http.get(Uri.appUri('engine://engine/:engine/task/' + camForm.taskId)).then(function(result){ $scope.upload = function() { var formData = new FormData(); formData.append('data', document.getElementById('fileUpload').files[0]); $http.post(Uri.appUri('engine://engine/:engine/process-instance/' + result.data.processInstanceId + '/variables/uploadedFile/data'), formData, { transformRequest: angular.identity, headers: {'Content-Type': undefined} }); }; }); }); }]); </script> </form>",
    "url": "/manual/latest/reference/forms/embedded-forms/javascript/examples/index.html"
  },
  {
    "id": "manual/latest/reference/forms/embedded-forms/javascript/generating-businesskey/index.html",
    "title": "Generating a Business Key | docs.cibseven.org",
    "content": "The following example shows how you can generate a business key using Javascript: <form role=\"form\"> <script cam-script type=\"text/form-script\"> camForm.on('submit', function() { camForm.businessKey = 'some-generated-value'; }); </script> </form> As you can see, you can set the businessKey variable on the camForm object. The value you set will be submitted in the start process instance request. Note that the business key can only be set when a process instance is started, not when completing a task.",
    "url": "/manual/latest/reference/forms/embedded-forms/javascript/generating-businesskey/index.html"
  },
  {
    "id": "manual/latest/reference/forms/embedded-forms/javascript/index.html",
    "title": "Javascript | docs.cibseven.org",
    "content": "Docs Get Started CIB seven Security cibseven.org CIB seven 1.1 Introduction Download Licenses Implemented Standards Architecture Overview Supported Environments Extensions Third-Party Libraries CIB seven License Book Public API User Guide Process Engine Process Engine Bootstrapping Process Engine API Process Engine Concepts Process Variables Process Instance Modification Process Instance Restart Delegation Code Expression Language Scripting Templating Custom Code & Security External Tasks Connectors Process Versioning Process Instance Migration Database Database Schema Database Configuration Microsoft SQL Server and Azure SQL Database Configuration MySQL Database Configuration Performance History History configuration User operation log History cleanup Custom implementation Deployment Cache Password Hashing Password Policy Transactions in Processes The Job Executor Multi-Tenancy Id Generators Metrics Incidents Process Engine Plugins Identity Service Authorization Service Deployments Process Diagram Visualization Time zones Decisions Configuration Repository Decision Service Decisions in BPMN & CMMN History Batch Batch operations Error Handling Diagnostics data Process Applications The Process Application class The processes.xml Deployment Descriptor Process Application Event Listeners Process Application Resource Access Maven Project Templates (Archetypes) Runtime Container Integration CIB seven Services JNDI Bindings for CIB seven Services Apache Tomcat WildFly Job Execution with Managed Resources CIB seven Run Spring Framework Integration Bootstrapping Transactions Deployment Spring Bean Resolving Testing Spring Boot Integration Version Compatibility Configuration REST API Web Applications Process Applications Spring Eventing Bridge Developing and Testing Spring Security OAuth2 Integration Quarkus Integration Version Compatibility Configuration Engine CDI Integration Resource Deployments CDI and Java EE Integration JTA Transaction Integration Expression Resolving Contextual Programming Model Built-In Beans CDI Event Bridge Testing Assert Examples Model API BPMN Model API Read a Model Create a Model Delegation Code Fluent Builder API Repository Service Extension Elements CMMN Model API Read a Model Create a Model Delegation Code Repository Service Extension Elements Limitations DMN Model API Read a Model Create a Model Repository Service Extension Attributes Data Formats (XML, JSON, Other) Configuring Spin Integration Data Formats in Processes XML JSON User Task Forms JSF Task Forms DMN Engine Embed Evaluate Decisions Expressions FEEL Engine Type Handling Custom Functions Spin Integration Legacy Behavior Data Types Testing Logging Security Instructions External Task Client Spring Boot Starter Version Compatibility Reference REST API Overview Configure Authentication Usage with a Pre-Built Distribution Embed the API Hypertext Application Language (HAL) Variables in the REST API Date Format OpenAPI Specification ↗ Javadoc ↗ BPMN 2.0 Tasks Service Task Send Task User Task Business Rule Task Script Task Receive Task Manual Task Task Markers Gateways Data-based Exclusive Gateway (XOR) Conditional and Default Sequence Flows Parallel Gateway Inclusive Gateway Event-based Gateway Events Start Events None Events Message Events Timer Events Error Events Escalation Events Signal Events Cancel and Compensation Events Conditional Events Link Events Terminate Events Subprocess Embedded Subprocess Call Activity Event Subprocess Transaction Subprocess Extension Reference Extension Elements Extension Attributes DMN 1.3 Decision Table Input Output Rule Hit Policy Decision Literal Expression Decision Requirements Graph FEEL Legacy FEEL Reference Data Types Language Elements Extension Reference Extension Attributes CMMN 1.1 Classic vs Fluent API CMMN Concepts Plan Items and Item Definitions Plan Item Lifecycles Entry and Exit Criteria Tasks Human Task Process Task Case Task Decision Task Grouping Tasks Stage Milestones Sentries Markers Manual Activation Rule Required Rule Auto Complete Repetition Rule Extension Reference Extension Elements Extension Attributes Migration between Specification Versions 1.0 to 1.1 Forms Embedded Forms Controls Text Inputs Textareas Date Inputs Boolean Inputs Selects Hidden Input Fields File Upload and Download BPMN Event Buttons Javascript The cam-script Directive Available API Participating in the Form Lifecycle Debugging Scripts Generating a Business Key Examples Lifecycle and Events Working with Json Data Working with Java Objects Integrating the Forms SDK Getting a Distribution Bootstrapping AngularJS Integration Full Example Spin Dataformats XML Reading XML Manipulating XML Writing XML Querying XML Mapping XML Configuring XML Handling JSON Reading JSON Writing JSON Querying JSON Mapping JSON Configuring JSON Handling Extending Spin Connectors HTTP Connector SOAP Connector Extending Connect Deployment Descriptors bpm-platform.xml processes.xml Tags <job-executor /> <process-archive /> <process-engine /> Installation Database Schema Remote Engine Distribution Shared Engine Distribution Tomcat Pre-Packaged Distribution Manual Installation Configuration JBoss EAP/WildFly Manual Installation Configuration Docker Spring Boot Web Applications Admin User Management Group Management Tenant Management Authorization Management System Management Configuration Plugins Cockpit Dashboard BPMN Processes Dashboard Process Definition View Process Instance View Failed Jobs Suspension Collapsed Subprocesses DMN Decisions Dashboard Decision Definition View Decision Instance View Deployments Open Tasks Dashboard Extending Configuration Plugins Tasklist Working with Tasklist Dashboard Filters User Assignment Task Lifecycle Plugins Configuration Accessibility Welcome Plugins Configuration Shared Configuration Options Authentication Cookie Security CSRF Prevention HTTP Header Security Examples Notices Update & Migration Rolling Update Camunda Migration Javascript The cam-script Directive Available API Participating in the Form Lifecycle Debugging Scripts Generating a Business Key Examples :( Back to top cibseven.org and docs.cibseven.org are part of CIB seven project — Privacy Statement – CIB software GmbH The CIB seven documentation is based on Camunda 7 Docs from Camunda. Some redesign & naming adoptation was made. The content on this site is licensed under a Creative Commons Attribution-ShareAlike 3.0 Unported License.",
    "url": "/manual/latest/reference/forms/embedded-forms/javascript/index.html"
  },
  {
    "id": "manual/latest/reference/forms/embedded-forms/javascript/lifecycle/index.html",
    "title": "Participating in the Form Lifecycle | docs.cibseven.org",
    "content": "It is possible to participate in the lifecycle of the form. See Form Lifecycle and Events for more details. Fetching Additional Variables When loading the form, the values of all variables used in the form are fetched from the backend. This means that the form SDK only fetches those variables which are actually used in the form. The most convenient way to use a variable is the cam-variable-name directive. However, there are some situations where directive-based usage is inconvenient. In such situations it is useful to declare additional variables programmatically: <form role=\"form\"> <div id=\"my-container\"></div> <script cam-script type=\"text/form-script\"> var variableManager = camForm.variableManager; camForm.on('form-loaded', function() { // this callback is executed *before* the variables are loaded from the server. // if we declare a variable here, its value will be fetched as well variableManager.fetchVariable('customVariable'); }); camForm.on('variables-fetched', function() { // this callback is executed *after* the variables have been fetched from the server var variableValue = variableManager.variableValue('customVariable'); $( '#my-container', camForm.formElement).text(variableValue); }); </script> </form> Submitting Additional Variables Similar to fetching additional variables using a script, it is also possible to add additional variables to the submit: <form role=\"form\"> <script cam-script type=\"text/form-script\"> var variableManager = camForm.variableManager; camForm.on('submit', function() { // this callback is executed when the form is submitted, *before* the submit request to // the server is executed // creating a new variable will add it to the form submit variableManager.createVariable({ name: 'customVariable', type: 'String', value: 'Some Value...', isDirty: true }); }); </script> </form> Implementing Custom Fields The following is a small usage example which combines some of the features explained so far. It uses custom JavaScript to implement a custom interaction with a form field which does not use any cam-variable-* directives. It shows how custom scripting can be used for declaring a variable to be fetched from the backend, writing the variable’s value to a form field, reading the value upon submit. <form role=\"form\"> <!-- custom control which does not use cam-variable* directives --> <input type=\"text\" class=\"form-control\" id=\"customField\"> <script cam-script type=\"text/form-script\"> var variableManager = camForm.variableManager; var customField = $('#customField', camForm.formElement); camForm.on('form-loaded', function() { // fetch the variable 'customVariable' variableManager.fetchVariable('customVariable'); }); camForm.on('variables-fetched', function() { // value has been fetched from the backend var value = variableManager.variableValue('customVariable'); // write the variable value to the form field customField.val(value); }); camForm.on('submit', function(evt) { var fieldValue = customField.val(); var backendValue = variableManager.variable('customVariable').value; if(fieldValue === backendValue) { // prevent submit if value of form field was not changed evt.submitPrevented = true; } else { // set value in variable manager so that it can be sent to backend variableManager.variableValue('customVariable', fieldValue); } }); </script> </form> The above example uses jQuery for interacting with the HTML controls. If you use AngularJS, you can also populate the $scope in the variables-fetched callback and read the values from the $scope in the submit callback: <form role=\"form\"> <!-- custom control which does not use cam-variable* directives but binds to the angular scope --> <input type=\"text\" class=\"form-control\" id=\"customField\" ng-model=\"customerId\"> <script cam-script type=\"text/form-script\"> var variableManager = camForm.variableManager; $scope.customerId = null; camForm.on('form-loaded', function() { // fetch the variable 'customVariable' variableManager.fetchVariable('customVariable'); }); camForm.on('variables-fetched', function() { // value has been fetched, bind to $scope.customerId $scope.customerId = variableManager.variable('customVariable').value; }); camForm.on('submit', function(evt) { // set value in variable manager so that it can be sent to backend variableManager.variableValue('customVariable', $scope.customerId); }); </script> </form>",
    "url": "/manual/latest/reference/forms/embedded-forms/javascript/lifecycle/index.html"
  },
  {
    "id": "manual/latest/reference/forms/embedded-forms/json-data/index.html",
    "title": "Working with Json Data | docs.cibseven.org",
    "content": "Fetching an existing JSON Variable The Form SDK will only fetch those variables which are actually used in a form. Since a JSON object is usually not bound to a single input field, we cannot use the cam-variable-name directive. We thus need to fetch the variable programatically: <script cam-script type=\"text/form-script\"> camForm.on('form-loaded', function() { // tell the form SDK to fetch the variable named 'customer' camForm.variableManager.fetchVariable('customer'); }); camForm.on('variables-fetched', function() { // work with the variable (bind it to the current AngularJS $scope) $scope.customer = camForm.variableManager.variableValue('customer'); }); </script> After that, you can work with the JSON object in your form, e.g., use it in input fields: <input type=\"text\" ng-model=\"customer.firstName\" required /> <input type=\"text\" ng-model=\"customer.lastName\" required /> Creating a new JSON Variable You can use JSON objects in your embedded forms. In order to persist this data in the process instance, you have to explicitely create the variable in the variableManager. This code-snippet creates the variable customer. <script cam-script type=\"text/form-script\"> var customer = $scope.customer = { firstName: 'John', lastName: 'Doe' }; camForm.on('form-loaded', function() { // declare a 'json' variable 'customer' camForm.variableManager.createVariable({ name: 'customer', type: 'json', value: customer }); }); </script> Full Example A full example of this feature can be found in the CIB seven Examples Repository.",
    "url": "/manual/latest/reference/forms/embedded-forms/json-data/index.html"
  },
  {
    "id": "manual/latest/reference/forms/embedded-forms/lifecycle/index.html",
    "title": "Lifecycle and Events | docs.cibseven.org",
    "content": "Events The form is parsed, and variable names are collected from the markup. This means that directives like cam-variable-name are evaluated and the resulting variables are declared in the variableManager. Events: form-loaded is fired after the form has been parsed, and all form directives have been evaluated. In the second phase, a request is made to the server to gather the values of the variables declared in the variable manager. Events: variables-fetched is fired after the request returns and the values of the variables have been merged into the variableManager. If a saved state of the form exists, the variable values are replaced with the saved state. Events: variables-restored is fired after the saved values of the variables have been merged with the values in the variableManager. Next, the variables are applied to the form controls. This means that HTML input fields and select boxes are populated with the variable values present in the variableManager. Events: variables-applied is fired after the values of the variables have been applied to the form controls. The user interacts with the form. In this phase no events are fired. The user can save the form, which causes the current values of the variables to be stored in the localStorage. If the user comes back to the form later, the values are restored. Events: store is fired before the values of the variables are written to the localStorage. An event handler may prevent the values from being stored. variables-stored is fired after the values are written to the localStorage. Finally, the form is completed. Triggering an [BPMN error or escalation event](/manual/latest/reference/bpmn20/tasks/user-task/#reporting-bpmn-error) will submit the form . Events: submit, error or escalation is fired before the submit request is sent to the server. An event handler may prevent the form from being submitted by setting the property `submitPrevented`, `errorPrevented` or `escalationPrevented` to true. submit-success, error-success or escalation-success is fired after the server successfully treated the submission. submit-failed, error-failed or escalation-failed is fired after the server failed at treating the submission or when a network error happened. Event Listeners Event listeners can be registered from custom JavaScript: <form role=\"form\" name=\"form\"> <script cam-script type=\"text/form-script\"> camForm.on('form-loaded', function() { // handle form loaded }); camForm.on('variables-fetched', function() { // handle variables fetched }); camForm.on('variables-restored', function() { // handle variables restored }); camForm.on('variables-applied', function() { // handle variables applied }); camForm.on('store', function(evt) { // handle store // may prevent the store from being executed evt.storePrevented = true; }); camForm.on('variables-stored', function() { // handle variables stored }); camForm.on('submit', function(evt) { // handle submit // may prevent the submit from being executed: evt.submitPrevented = true; }); camForm.on('submit-success', function() { // handle submit-success }); camForm.on('submit-failed', function(evt, res) { // handle submit-failed: var error = res[0]; }); camForm.on('error', function(evt) { // handle error // may prevent the error from being executed: evt.errorPrevented = true; }); camForm.on('error-success', function() { // handle error-success }); camForm.on('error-failed', function(evt, res) { // handle error-failed: var error = res[0]; }); camForm.on('escalation', function(evt) { // handle escalation // may prevent the escalation from being executed: evt.escalationPrevented = true; }); camForm.on('escalation-success', function() { // handle escalation-success }); camForm.on('escalation-failed', function(evt, res) { // handle escalation-failed: var error = res[0]; }); </script> </form>",
    "url": "/manual/latest/reference/forms/embedded-forms/lifecycle/index.html"
  },
  {
    "id": "manual/latest/reference/forms/index.html",
    "title": "Forms Reference | docs.cibseven.org",
    "content": "Docs Get Started CIB seven Security cibseven.org CIB seven 1.1 Introduction Download Licenses Implemented Standards Architecture Overview Supported Environments Extensions Third-Party Libraries CIB seven License Book Public API User Guide Process Engine Process Engine Bootstrapping Process Engine API Process Engine Concepts Process Variables Process Instance Modification Process Instance Restart Delegation Code Expression Language Scripting Templating Custom Code & Security External Tasks Connectors Process Versioning Process Instance Migration Database Database Schema Database Configuration Microsoft SQL Server and Azure SQL Database Configuration MySQL Database Configuration Performance History History configuration User operation log History cleanup Custom implementation Deployment Cache Password Hashing Password Policy Transactions in Processes The Job Executor Multi-Tenancy Id Generators Metrics Incidents Process Engine Plugins Identity Service Authorization Service Deployments Process Diagram Visualization Time zones Decisions Configuration Repository Decision Service Decisions in BPMN & CMMN History Batch Batch operations Error Handling Diagnostics data Process Applications The Process Application class The processes.xml Deployment Descriptor Process Application Event Listeners Process Application Resource Access Maven Project Templates (Archetypes) Runtime Container Integration CIB seven Services JNDI Bindings for CIB seven Services Apache Tomcat WildFly Job Execution with Managed Resources CIB seven Run Spring Framework Integration Bootstrapping Transactions Deployment Spring Bean Resolving Testing Spring Boot Integration Version Compatibility Configuration REST API Web Applications Process Applications Spring Eventing Bridge Developing and Testing Spring Security OAuth2 Integration Quarkus Integration Version Compatibility Configuration Engine CDI Integration Resource Deployments CDI and Java EE Integration JTA Transaction Integration Expression Resolving Contextual Programming Model Built-In Beans CDI Event Bridge Testing Assert Examples Model API BPMN Model API Read a Model Create a Model Delegation Code Fluent Builder API Repository Service Extension Elements CMMN Model API Read a Model Create a Model Delegation Code Repository Service Extension Elements Limitations DMN Model API Read a Model Create a Model Repository Service Extension Attributes Data Formats (XML, JSON, Other) Configuring Spin Integration Data Formats in Processes XML JSON User Task Forms JSF Task Forms DMN Engine Embed Evaluate Decisions Expressions FEEL Engine Type Handling Custom Functions Spin Integration Legacy Behavior Data Types Testing Logging Security Instructions External Task Client Spring Boot Starter Version Compatibility Reference REST API Overview Configure Authentication Usage with a Pre-Built Distribution Embed the API Hypertext Application Language (HAL) Variables in the REST API Date Format OpenAPI Specification ↗ Javadoc ↗ BPMN 2.0 Tasks Service Task Send Task User Task Business Rule Task Script Task Receive Task Manual Task Task Markers Gateways Data-based Exclusive Gateway (XOR) Conditional and Default Sequence Flows Parallel Gateway Inclusive Gateway Event-based Gateway Events Start Events None Events Message Events Timer Events Error Events Escalation Events Signal Events Cancel and Compensation Events Conditional Events Link Events Terminate Events Subprocess Embedded Subprocess Call Activity Event Subprocess Transaction Subprocess Extension Reference Extension Elements Extension Attributes DMN 1.3 Decision Table Input Output Rule Hit Policy Decision Literal Expression Decision Requirements Graph FEEL Legacy FEEL Reference Data Types Language Elements Extension Reference Extension Attributes CMMN 1.1 Classic vs Fluent API CMMN Concepts Plan Items and Item Definitions Plan Item Lifecycles Entry and Exit Criteria Tasks Human Task Process Task Case Task Decision Task Grouping Tasks Stage Milestones Sentries Markers Manual Activation Rule Required Rule Auto Complete Repetition Rule Extension Reference Extension Elements Extension Attributes Migration between Specification Versions 1.0 to 1.1 Forms Embedded Forms Controls Text Inputs Textareas Date Inputs Boolean Inputs Selects Hidden Input Fields File Upload and Download BPMN Event Buttons Javascript The cam-script Directive Available API Participating in the Form Lifecycle Debugging Scripts Generating a Business Key Examples Lifecycle and Events Working with Json Data Working with Java Objects Integrating the Forms SDK Getting a Distribution Bootstrapping AngularJS Integration Full Example Spin Dataformats XML Reading XML Manipulating XML Writing XML Querying XML Mapping XML Configuring XML Handling JSON Reading JSON Writing JSON Querying JSON Mapping JSON Configuring JSON Handling Extending Spin Connectors HTTP Connector SOAP Connector Extending Connect Deployment Descriptors bpm-platform.xml processes.xml Tags <job-executor /> <process-archive /> <process-engine /> Installation Database Schema Remote Engine Distribution Shared Engine Distribution Tomcat Pre-Packaged Distribution Manual Installation Configuration JBoss EAP/WildFly Manual Installation Configuration Docker Spring Boot Web Applications Admin User Management Group Management Tenant Management Authorization Management System Management Configuration Plugins Cockpit Dashboard BPMN Processes Dashboard Process Definition View Process Instance View Failed Jobs Suspension Collapsed Subprocesses DMN Decisions Dashboard Decision Definition View Decision Instance View Deployments Open Tasks Dashboard Extending Configuration Plugins Tasklist Working with Tasklist Dashboard Filters User Assignment Task Lifecycle Plugins Configuration Accessibility Welcome Plugins Configuration Shared Configuration Options Authentication Cookie Security CSRF Prevention HTTP Header Security Examples Notices Update & Migration Rolling Update Camunda Migration Forms Reference Embedded Forms Custom HTML Forms embeddable in Tasklist :( Back to top cibseven.org and docs.cibseven.org are part of CIB seven project — Privacy Statement – CIB software GmbH The CIB seven documentation is based on Camunda 7 Docs from Camunda. Some redesign & naming adoptation was made. The content on this site is licensed under a Creative Commons Attribution-ShareAlike 3.0 Unported License.",
    "url": "/manual/latest/reference/forms/index.html"
  },
  {
    "id": "manual/latest/reference/index.html",
    "title": "Reference | docs.cibseven.org",
    "content": "Docs Get Started CIB seven Security cibseven.org CIB seven 1.1 Introduction Download Licenses Implemented Standards Architecture Overview Supported Environments Extensions Third-Party Libraries CIB seven License Book Public API User Guide Process Engine Process Engine Bootstrapping Process Engine API Process Engine Concepts Process Variables Process Instance Modification Process Instance Restart Delegation Code Expression Language Scripting Templating Custom Code & Security External Tasks Connectors Process Versioning Process Instance Migration Database Database Schema Database Configuration Microsoft SQL Server and Azure SQL Database Configuration MySQL Database Configuration Performance History History configuration User operation log History cleanup Custom implementation Deployment Cache Password Hashing Password Policy Transactions in Processes The Job Executor Multi-Tenancy Id Generators Metrics Incidents Process Engine Plugins Identity Service Authorization Service Deployments Process Diagram Visualization Time zones Decisions Configuration Repository Decision Service Decisions in BPMN & CMMN History Batch Batch operations Error Handling Diagnostics data Process Applications The Process Application class The processes.xml Deployment Descriptor Process Application Event Listeners Process Application Resource Access Maven Project Templates (Archetypes) Runtime Container Integration CIB seven Services JNDI Bindings for CIB seven Services Apache Tomcat WildFly Job Execution with Managed Resources CIB seven Run Spring Framework Integration Bootstrapping Transactions Deployment Spring Bean Resolving Testing Spring Boot Integration Version Compatibility Configuration REST API Web Applications Process Applications Spring Eventing Bridge Developing and Testing Spring Security OAuth2 Integration Quarkus Integration Version Compatibility Configuration Engine CDI Integration Resource Deployments CDI and Java EE Integration JTA Transaction Integration Expression Resolving Contextual Programming Model Built-In Beans CDI Event Bridge Testing Assert Examples Model API BPMN Model API Read a Model Create a Model Delegation Code Fluent Builder API Repository Service Extension Elements CMMN Model API Read a Model Create a Model Delegation Code Repository Service Extension Elements Limitations DMN Model API Read a Model Create a Model Repository Service Extension Attributes Data Formats (XML, JSON, Other) Configuring Spin Integration Data Formats in Processes XML JSON User Task Forms JSF Task Forms DMN Engine Embed Evaluate Decisions Expressions FEEL Engine Type Handling Custom Functions Spin Integration Legacy Behavior Data Types Testing Logging Security Instructions External Task Client Spring Boot Starter Version Compatibility Reference REST API Overview Configure Authentication Usage with a Pre-Built Distribution Embed the API Hypertext Application Language (HAL) Variables in the REST API Date Format OpenAPI Specification ↗ Javadoc ↗ BPMN 2.0 Tasks Service Task Send Task User Task Business Rule Task Script Task Receive Task Manual Task Task Markers Gateways Data-based Exclusive Gateway (XOR) Conditional and Default Sequence Flows Parallel Gateway Inclusive Gateway Event-based Gateway Events Start Events None Events Message Events Timer Events Error Events Escalation Events Signal Events Cancel and Compensation Events Conditional Events Link Events Terminate Events Subprocess Embedded Subprocess Call Activity Event Subprocess Transaction Subprocess Extension Reference Extension Elements Extension Attributes DMN 1.3 Decision Table Input Output Rule Hit Policy Decision Literal Expression Decision Requirements Graph FEEL Legacy FEEL Reference Data Types Language Elements Extension Reference Extension Attributes CMMN 1.1 Classic vs Fluent API CMMN Concepts Plan Items and Item Definitions Plan Item Lifecycles Entry and Exit Criteria Tasks Human Task Process Task Case Task Decision Task Grouping Tasks Stage Milestones Sentries Markers Manual Activation Rule Required Rule Auto Complete Repetition Rule Extension Reference Extension Elements Extension Attributes Migration between Specification Versions 1.0 to 1.1 Forms Embedded Forms Controls Text Inputs Textareas Date Inputs Boolean Inputs Selects Hidden Input Fields File Upload and Download BPMN Event Buttons Javascript The cam-script Directive Available API Participating in the Form Lifecycle Debugging Scripts Generating a Business Key Examples Lifecycle and Events Working with Json Data Working with Java Objects Integrating the Forms SDK Getting a Distribution Bootstrapping AngularJS Integration Full Example Spin Dataformats XML Reading XML Manipulating XML Writing XML Querying XML Mapping XML Configuring XML Handling JSON Reading JSON Writing JSON Querying JSON Mapping JSON Configuring JSON Handling Extending Spin Connectors HTTP Connector SOAP Connector Extending Connect Deployment Descriptors bpm-platform.xml processes.xml Tags <job-executor /> <process-archive /> <process-engine /> Installation Database Schema Remote Engine Distribution Shared Engine Distribution Tomcat Pre-Packaged Distribution Manual Installation Configuration JBoss EAP/WildFly Manual Installation Configuration Docker Spring Boot Web Applications Admin User Management Group Management Tenant Management Authorization Management System Management Configuration Plugins Cockpit Dashboard BPMN Processes Dashboard Process Definition View Process Instance View Failed Jobs Suspension Collapsed Subprocesses DMN Decisions Dashboard Decision Definition View Decision Instance View Deployments Open Tasks Dashboard Extending Configuration Plugins Tasklist Working with Tasklist Dashboard Filters User Assignment Task Lifecycle Plugins Configuration Accessibility Welcome Plugins Configuration Shared Configuration Options Authentication Cookie Security CSRF Prevention HTTP Header Security Examples Notices Update & Migration Rolling Update Camunda Migration Reference REST API Javadoc ↗ BPMN 2.0 DMN 1.3 CMMN 1.1 Forms Spin Dataformats Connectors Deployment Descriptors :( Back to top cibseven.org and docs.cibseven.org are part of CIB seven project — Privacy Statement – CIB software GmbH The CIB seven documentation is based on Camunda 7 Docs from Camunda. Some redesign & naming adoptation was made. The content on this site is licensed under a Creative Commons Attribution-ShareAlike 3.0 Unported License.",
    "url": "/manual/latest/reference/index.html"
  },
  {
    "id": "manual/latest/reference/reference/dmn11/index.html",
    "title": "/manual/latest/reference/dmn/",
    "content": "No content available",
    "url": "/manual/latest/reference/reference/dmn11/index.html"
  },
  {
    "id": "manual/latest/reference/spin/extending-spin/index.html",
    "title": "Extending Spin | docs.cibseven.org",
    "content": "Configuring Data Formats The data formats available to Spin may not always suit your needs. Sometimes, it is necessary to provide configuration. For example, when using Spin to map Java objects to JSON, a format for how dates are serialized has to specified. While the Spin data formats use reasonable default values, they can also be changed. To configure a data format detected by Spin, the SPI org.cibseven.spin.spi.DataFormatConfigurator can be implemented. A configurator specifies which classes it can configure. Spin discovers a configurator by employing Java’s service loader mechanism and will then provide it with all data formats that match the specified class (or are a subclass thereof). The concrete configuration options depend on the actual data format. For example, a Jackson-based JSON data format can modify the ObjectMapper that the data format uses. To provide a custom configurator, you have to Provide a custom implementation of org.cibseven.spin.spi.DataFormatConfigurator Add the configurator’s fully qualified classname to a file named META-INF/services/org.cibseven.spin.spi.DataFormatConfigurator Ensure that the artifact containing the configurator is reachable from Spin’s classloader Custom Dataformats A Spin data format is an implementation of the interface org.cibseven.spin.spi.DataFormat. An implementation of this interface can be registered by implementing the SPI org.cibseven.spin.spi.DataFormatProvider. Spin uses the Java platform’s service loader mechanism to lookup provider implementations at runtime. To provide a custom dataformat, you have to Provide a custom implementation of org.cibseven.spin.spi.DataFormat Provide a custom implementation of org.cibseven.spin.spi.DataFormatProvider Add the provider’s fully qualified classname to a file named META-INF/services/org.cibseven.spin.spi.DataFormatProvider Ensure that the artifact containing the provider is reachable from Spin’s classloader If you now call org.cibseven.spin.DataFormats.getAvailableDataFormats(), then the custom dataformat is returned along with the built-in dataformats. Furthermore, org.cibseven.spin.DataFormats.getDataFormat(String dataFormatName) can be used to explicity retrieve the data format by a specific provider.",
    "url": "/manual/latest/reference/spin/extending-spin/index.html"
  },
  {
    "id": "manual/latest/reference/spin/index.html",
    "title": "Spin Dataformat Reference | docs.cibseven.org",
    "content": "Spin is a library for simple XML and JSON processing on the JVM (Java Virtual Machine), targeting Java and JVM-based scripting languages such as Groovy, JRuby, Jython, JavaScript and Java Expression Language. It provides a comprehensible fluent API for working with different data formats through lightweight wrapper objects. Spin can be used in any Java-based application by adding the following maven dependency to your pom.xml file: CIB seven BOM If you use Spin in combination with the CIB seven process engine, please consult the process engine user guide on Spin integration on how to properly integrate Spin with the engine. Please import the CIB seven BOM to ensure that you use the Spin version matching your process engine version. <dependencyManagement> <dependencies> <dependency> <groupId>org.cibseven.spin</groupId> <artifactId>cibseven-spin-bom</artifactId> <scope>import</scope> <type>pom</type> <version>1.1.0</version> </dependency> </dependencies> </dependencyManagement> <dependencies> <dependency> <groupId>org.cibseven.spin</groupId> <artifactId>cibseven-spin-core</artifactId> </dependency> <dependency> <groupId>org.cibseven.spin</groupId> <artifactId>cibseven-spin-dataformat-all</artifactId> </dependency> </dependencies> CIB seven’s version of Spin is published to artifacts.cibseven.org. See the instruction how to use it.",
    "url": "/manual/latest/reference/spin/index.html"
  },
  {
    "id": "manual/latest/reference/spin/json/01-reading-json/index.html",
    "title": "Reading JSON | docs.cibseven.org",
    "content": "The JSON datatype supports reading JSON from Strings or Readers. Reading JSON from a String: import static org.cibseven.spin.Spin.*; import static org.cibseven.spin.DataFormats.*; SpinJsonNode json = S(\"{\\\"customer\\\": \\\"Kermit\\\"}\", json()); The second paramter json() hints Spin to use the JSON data format for parsing the JSON. Alternatively, you can directly use the JSON(...) function: import static org.cibseven.spin.Spin.*; SpinJsonNode json = JSON(\"{\\\"customer\\\": \\\"Kermit\\\"}\"); String values that represent JSON primitive values can also be read. For example, JSON(\"true\") returns a SpinJsonNode that represents the boolean value true. Reading JSON from a Reader: Spin also supports reading JSON from an instance of java.io.Reader: import static org.cibseven.spin.Spin.*; import static org.cibseven.spin.DataFormats.*; SpinJsonNode json = S(reader, json()); The JSON(...) method also supports readers. The following example shows how to read JSON from a file (error handling ommitted): import static org.cibseven.spin.Spin.*; FileInputStream fis = new FileInputStream(\"/tmp/customer.json\"); InputStreamReader reader = new InputStreamReader(fis, \"utf-8\"); SpinJsonNode json = JSON(reader); Reading JSON using a Script Language JSON can be read from script languages in the same way as from Java. Since script languages use dynamic typing, you do not need to hint the data format but you can use autodetection. The following example demonstrates how to read JSON in Javascript: var customer = S('{\"customer\": \"Kermit\"}'); Reading JSON Properties To fetch properties from the JSON tree you can use .prop(\"name\"). This will return the property as SpinJsonNode and you can use this to get the value of the property as the following examples will demonstrate: in Java: import static org.cibseven.spin.Spin.*; SpinJsonNode json = JSON(\"{\\\"customer\\\": \\\"Kermit\\\"}\"); SpinJsonNode customerProperty = json.prop(\"customer\"); String customerName = customerProperty.stringValue(); in Javascript: var json = S('{\"customer\": \"Kermit\"}'); var customerProperty = json.prop(\"customer\"); var customerName = customerProperty.value(); The Different Value Types The method SpinJsonNode#value() can be used to get the Java equivalent of a String/Boolean/Number or null JSON property. It throws an exception for Object and Array properties. There are also: #stringValue() - gets a Java String representation of the value or throws an exception if the value is not a String #numberValue() - gets a Java Number representation of the value or throws an exception if the value is not a Number #boolValue() - gets a Java Boolean representation of the value or throws an exception if the value is not a Boolean Value type checks of the property isObject() returns boolean hasProp() returns boolean isBoolean() returns boolean isNumber() returns boolean isString() returns boolean isNull() returns boolean isValue() returns boolean isArray() returns boolean Script example (JavaScript): var json = S('{\"over18\":false}'); json.prop('over18').isBoolean() //returns true Fetch Array of Data You can also fetch a list of items if your property is an array of data. in Java: import static org.cibseven.spin.Spin.*; SpinJsonNode json = JSON(\"{\\\"customer\\\": \\[\\\"Kermit\\\", \\\"Waldo\\\"\\]}\"); SpinJsonNode customerProperty = json.prop(\"customer\"); SpinList customers = customerProperty.elements(); SpinJsonNode customer = customers.get(0); String customerName = customer.stringValue(); in Javascript: var json = S('{\"customer\": [\"Kermit\", \"Waldo\"]}'); var customerProperty = json.prop(\"customer\"); var customers = customerProperty.elements(); var customer = customers.get(0) var customerName = customer.value(); Fetch Field Names Spin allows us to use the .fieldNames() method to fetch the names of all child nodes and properties in a node. The following example shows you how to use .fieldNames() in Java and Javascript. in Java: import static org.cibseven.spin.Spin.*; SpinJsonNode json = JSON(\"{\\\"customer\\\": \\[\\\"Kermit\\\", \\\"Waldo\\\"\\]}\"); ArrayList fieldNames = json.fieldNames(); String fieldName1 = fieldNames.get(0) in Javascript: var json = S('{\"customer\": [\"Kermit\", \"Waldo\"]}'); var fieldNames = json.fieldNames(); var fieldName1 = fieldNames.get(0) Set JSON Properties To set a property you can use the .prop(\"name\", object) method. This allows you to set one of the following 5 simple types: String - Example: .prop(\"name\", \"Waldo\") Integer - Example: .prop(\"age\", 42) Long - Example: .prop(\"period\", 4200000000) Float - Example: .prop(\"price\", 42.00) Boolean - Example: .prop(\"active\", true) or one of the 2 following container types: Array - Could contain a number of simple and container types Example in Java: import static org.cibseven.spin.Spin.*; SpinJsonNode json = JSON(\"{\\\"customer\\\": \\[\\\"Kermit\\\", \\\"Waldo\\\"\\]}\"); ArrayList<Object> list = new ArrayList<Object>(); list.add(\"new entry\"); list.add(\"new entry2\"); json.prop(\"new_array\", list); Example in Javascript: var json = S('{\"customer\": [\"Kermit\", \"Waldo\"]}'); var list = [\"new entry\", \"new entry2\"]; json.prop(\"new_array\", list); Object - Could contain a number of simple and container types Example in Java: import static org.cibseven.spin.Spin.*; SpinJsonNode json = JSON(\"{\\\"customer\\\": \\[\\\"Kermit\\\", \\\"Waldo\\\"\\]}\"); Map<String, Object> object = new HashMap<String, Object>(); object.put(\"new_entry\", 42); object.put(\"new_entry2\", \"Yeah!\"); json.prop(\"new_object\", object); Example in Javascript: var json = S('{\"customer\": [\"Kermit\", \"Waldo\"]}'); var object = { \"new_entry\": 1, \"new_entry2\": \"Yeah!\" }; json.prop(\"new_array\", object); Remove JSON Properties There are 2 ways to remove properties from a JSON object. .deleteProp(\"name\") - Removes a property with given name. .deleteProp(<List of names>) - Removes one or more properties with given names. For more details see the following examples for Javascript and Java. Java: import static org.cibseven.spin.Spin.*; SpinJsonNode json = JSON(\"{\\\"customer\\\": \\\"Kermit\\\", \\\"language\\\": \\\"en\\\"}\"); List<String> listOfNames = new ArrayList<String>(); listOfNames.add(\"customer\"); listOfNames.add(\"language\"); // removes only the customer property json.deleteProp(\"customer\"); // removes customer and language json.deleteProp(list); Javascript: var json = S('{\"customer\": [\"Kermit\", \"Waldo\"], \"language\": \"en\"}'); var list = [\"customer\", \"en\"]; // removes only the customer property json.deleteProp(\"customer\"); // removes customer and language json.deleteProp(list); Work with JSON Arrays JSON arrays represent a list of objects. Spin offers the following methods to manipulate this list: .indexOf(<Object>) - Fetches the index of the FIRST occurrence of the searched object. .lastIndexOf(<Object>) - Fetches the index of the LAST occurrence of the searched object. .append(<Object>) - Appends an object to the end of the list. .insertAt(<Index>, <Object>) - Appends an object at the specific index of the list. .insertBefore(<Search object>, <Object>) - Inserts an object before the FIRST occurrence of another object. .insertAfter(<Search object>, <Object>) - Inserts an object after the FIRST occurrence of another object. .remove(<Object>) - Removes the FIRST occurrence of the object. .removeLast(<Object>) - Removes the LAST occurrence of the object. .removeAt(Index) - Removes the list entry at the specified index. These methods allow us to work with JSON arrays in a fast way. To show this, we will use the following JSON Object as an example: { \"test-array\" : [ \"testdata1\", \"testdata2\", 1, 2, true, 1, false, 1 ] } So let’s see how we can manipulate this list in some examples. Example 1 - Get the Index of ’testdata2’ and the Last Occurrence of ‘1’: import static org.cibseven.spin.Spin.*; SpinJsonNode json = JSON(\"{\\\"test-array\\\" : [\\\"testdata1\\\",\\\"testdata2\\\",1,2,true,1,false,1]}\"); SpinJsonNode list = json.prop(\"test-array\"); Integer i = list.indexOf(\"testdata2\"); // Should be '1' Integer j = list.lastIndexOf(1); // Should be '7' var json = S('{\"test-array\" : [\"testdata1\",\"testdata2\",1,2,true,1,false,1]}'); var list = json.prop(\"test-array\"); var i = list.indexOf(\"testdata2\"); // should be 1 var j = list.lastIndexOf(1); // Should be '7' Example 2 - Add and Remove Data to/from the list: import static org.cibseven.spin.Spin.*; SpinJsonNode json = JSON(\"{\\\"test-array\\\" : [\\\"testdata1\\\",\\\"testdata2\\\",1,2,true,1,false,1]}\"); SpinJsonNode list = json.prop(\"test-array\"); list.append(\"test2\"); // at the end of the list there should now be \"test2\" list.remove(\"test2\"); // Aaaand now, it is gone ;) list.insertAt(1, \"test3\"); // test3 should now be inserted before testdata2 list.removeAt(1, \"test3\"); // Aaaand now, it is gone ;) list.insertBefore(true, \"test4\"); // now there should be test4 on index 4 list.insertAfter(true, 5); // So now 5 is on index 6 var json = S('{\"test-array\" : [\"testdata1\",\"testdata2\",1,2,true,1,false,1]}'); var list = json.prop(\"test-array\"); list.append(\"test2\"); // at the end of the list there should now be \"test2\" list.remove(\"test2\"); // Aaaand now, it is gone ;) list.insertAt(1, \"test3\"); // test3 should now be inserted before testdata2 list.removeAt(1, \"test3\"); // Aaaand now, it is gone ;) list.insertBefore(true, \"test4\"); // now there should be test4 on index 4 list.insertAfter(true, 5); // So now 5 is on index 6",
    "url": "/manual/latest/reference/spin/json/01-reading-json/index.html"
  },
  {
    "id": "manual/latest/reference/spin/json/02-writing-json/index.html",
    "title": "Writing JSON | docs.cibseven.org",
    "content": "The JSON datatype supports writing JSON to Strings or Writers. Writing to a String: import static org.cibseven.spin.Spin.JSON; SpinJsonNode jsonNode = JSON(\"{\\\"customer\\\": \\\"Kermit\\\"}\"); String json = jsonNode.toString(); Writing to a Writer import static org.cibseven.spin.Spin.JSON; SpinJsonNode jsonNode = JSON(\"{\\\"customer\\\": \\\"Kermit\\\"}\"); StringWriter writer = jsonNode.writeToWriter(new StringWriter());",
    "url": "/manual/latest/reference/spin/json/02-writing-json/index.html"
  },
  {
    "id": "manual/latest/reference/spin/json/03-querying-json/index.html",
    "title": "Querying JSON | docs.cibseven.org",
    "content": "The JSON datatype supports querying with the JSONPath query language. Querying an Element import static org.cibseven.spin.Spin.JSON; String json = \"{\\\"child\\\": [{\\\"id\\\": 1,\\\"name\\\": \\\"Lucy\\\",\\\"sex\\\": \\\"female\\\"},{\\\"id\\\": 2,\\\"name\\\": \\\"Tracy\\\",\\\"sex\\\": \\\"female\\\"}],\\\"number\\\": 1,\\\"boolean\\\": true}\"; SpinJsonNode child = JSON(json).jsonPath(\"$.child[0]\").element(); Querying an Element List import static org.cibseven.spin.Spin.JSON; String json = \"{\\\"child\\\": [{\\\"id\\\": 1,\\\"name\\\": \\\"Lucy\\\",\\\"sex\\\": \\\"female\\\"},{\\\"id\\\": 2,\\\"name\\\": \\\"Tracy\\\",\\\"sex\\\": \\\"female\\\"}],\\\"number\\\": 1,\\\"boolean\\\": true}\"; SpinList<SpinJsonNode> childs = JSON(json).jsonPath(\"$.child\").elementList(); Querying a String import static org.cibseven.spin.Spin.JSON; String json = \"{\\\"child\\\": [{\\\"id\\\": 1,\\\"name\\\": \\\"Lucy\\\",\\\"sex\\\": \\\"female\\\"},{\\\"id\\\": 2,\\\"name\\\": \\\"Tracy\\\",\\\"sex\\\": \\\"female\\\"}],\\\"number\\\": 1,\\\"boolean\\\": true}\"; String value = JSON(json).jsonPath(\"$.child[0].name\").stringValue(); Querying a Number import static org.cibseven.spin.Spin.JSON; String json = \"{\\\"child\\\": [{\\\"id\\\": 1,\\\"name\\\": \\\"Lucy\\\",\\\"sex\\\": \\\"female\\\"},{\\\"id\\\": 2,\\\"name\\\": \\\"Tracy\\\",\\\"sex\\\": \\\"female\\\"}],\\\"number\\\": 1,\\\"boolean\\\": true}\"; Double count = JSON(json).jsonPath(\"$.number\").numberValue(); Querying a Boolean import static org.cibseven.spin.Spin.JSON; String json = \"{\\\"child\\\": [{\\\"id\\\": 1,\\\"name\\\": \\\"Lucy\\\",\\\"sex\\\": \\\"female\\\"},{\\\"id\\\": 2,\\\"name\\\": \\\"Tracy\\\",\\\"sex\\\": \\\"female\\\"}],\\\"number\\\": 1,\\\"boolean\\\": true}\"; Boolean exists = JSON(json).jsonPath(\"$.boolean\").boolValue(); Filtering a Query Be aware that a filtering expression - the expression in the () - is not allowed to contain double quotes! import static org.cibseven.spin.Spin.JSON; String json = \"{\\\"child\\\": [{\\\"id\\\": 1,\\\"name\\\": \\\"Lucy\\\",\\\"sex\\\": \\\"female\\\"},{\\\"id\\\": 2,\\\"name\\\": \\\"Tracy\\\",\\\"sex\\\": \\\"female\\\"}],\\\"number\\\": 1,\\\"boolean\\\": true}\"; SpinList<SpinJsonNode> girls = JSON(json).jsonPath(\"$.child[?(@.sex == 'female')]\").elementList();",
    "url": "/manual/latest/reference/spin/json/03-querying-json/index.html"
  },
  {
    "id": "manual/latest/reference/spin/json/04-mapping-json/index.html",
    "title": "Mapping JSON | docs.cibseven.org",
    "content": "Spin can deserialize JSON to Java objects and serialize Java objects to JSON by integrating Jackson’s mapping features into its fluent API. Mapping between Representations: Assume we have a class Customer defined as follows: public class Customer { private String name; public String getName() { return name; } public void setName(String name) { this.name = name; } } Mapping JSON to Java: We can map a JSON object {\"name\" : \"Kermit\"} to an instance of Customer as follows: import static org.cibseven.spin.Spin.JSON; Customer customer = JSON(\"{\\\"customer\\\": \\\"Kermit\\\"}\").mapTo(Customer.class); Mapping Java to JSON: We can map the customer back to JSON as follows: import static org.cibseven.spin.Spin.JSON; String json = JSON(customer).toString(); You can also map Java primitives like boolean or number values to the corresponding JSON values. For example, JSON(true) maps to the JSON constant of the boolean value true. However, note that String values are not converted but are interpreted as JSON input (see Reading JSON. For example, JSON(\"a String\") raises an exception because \"a String\" lacks additional escaped quotes and is no valid JSON. Nevertheless, a list of String values is properly converted to a JSON array of String values. Mapping to Generic Types: Assume we have a list of customers that we would declare as List<Customer> in Java. For mapping a JSON array [{\"name\" : \"Kermit\"}, {\"name\" : \"Hugo\"}] to such a list, calling mapTo(ArrayList.class) is not sufficient as Jackson cannot tell of which type the array’s elements are. This case can be handled by providing mapTo with a canonical type string, following Jackson’s conventions: import static org.cibseven.spin.Spin.JSON; String json = \"[{\\\"customer\\\": \\\"Kermit\\\"}, {\\\"customer\\\": \\\"Kermit\\\"}]\" List<Customer> customers = JSON(json).mapTo(\"java.util.ArrayList<somepackage.Customer>\"); Mapping to Polymorphic Types: Mapping JSON to Java objects is particularly tricky as JSON does not contain type information which is required to deserialize it to Java objects. In the above examples, we have explicitly told Spin to map the JSON object to a Customer object using the mapTo method. For nested JSON objects, Jackson is able to infer the desired deserialization type by inspecting the declared fields of the supplied class. However, this does not work for polymorphic types. Consider the following example, where the Customer has a reference to a Car. public class Customer { private String name; private Car car; public String getName() { return name; } public void setName(String name) { this.name = name; } public Car getCar() { return car; } public void setCar(Car car) { this.car = car; } } Assuming that Car is an interface with various implementations, such as StationWagon or Van, Jackson cannot tell which implementation to use based solely on the static structure of Customer. In these cases, Jackson relies on type information that is part of the JSON. See the Jackson documentation for the various options Jackson offers to configure type serialization and deserialization. You can configure these options in Spin as described in the configuration section.",
    "url": "/manual/latest/reference/spin/json/04-mapping-json/index.html"
  },
  {
    "id": "manual/latest/reference/spin/json/05-configuring-json/index.html",
    "title": "Configuring JSON Handling | docs.cibseven.org",
    "content": "Spin can be configured to change JSON parsing, writing and mapping settings, for example to tolerate documents that are not strictly compliant to the standard. Spin uses Jackson to handle JSON. The JSON data format therefore uses an instance of com.fasterxml.jackson.databind.ObjectMapper that can be configured using Spin’s configuration mechanism. The data format class to register a configurator for is org.cibseven.spin.impl.json.jackson.format.JacksonJsonDataFormat. An instance of this class provides a setter for an ObjectMapper that can be used to replace the default object mapper. This logic goes into a configurator class that implements the interface org.cibseven.spin.spi.DataFormatConfigurator. Please refer to the Jackson’s documentation on what configuration options are available.",
    "url": "/manual/latest/reference/spin/json/05-configuring-json/index.html"
  },
  {
    "id": "manual/latest/reference/spin/json/index.html",
    "title": "Handling JSON | docs.cibseven.org",
    "content": "Docs Get Started CIB seven Security cibseven.org CIB seven 1.1 Introduction Download Licenses Implemented Standards Architecture Overview Supported Environments Extensions Third-Party Libraries CIB seven License Book Public API User Guide Process Engine Process Engine Bootstrapping Process Engine API Process Engine Concepts Process Variables Process Instance Modification Process Instance Restart Delegation Code Expression Language Scripting Templating Custom Code & Security External Tasks Connectors Process Versioning Process Instance Migration Database Database Schema Database Configuration Microsoft SQL Server and Azure SQL Database Configuration MySQL Database Configuration Performance History History configuration User operation log History cleanup Custom implementation Deployment Cache Password Hashing Password Policy Transactions in Processes The Job Executor Multi-Tenancy Id Generators Metrics Incidents Process Engine Plugins Identity Service Authorization Service Deployments Process Diagram Visualization Time zones Decisions Configuration Repository Decision Service Decisions in BPMN & CMMN History Batch Batch operations Error Handling Diagnostics data Process Applications The Process Application class The processes.xml Deployment Descriptor Process Application Event Listeners Process Application Resource Access Maven Project Templates (Archetypes) Runtime Container Integration CIB seven Services JNDI Bindings for CIB seven Services Apache Tomcat WildFly Job Execution with Managed Resources CIB seven Run Spring Framework Integration Bootstrapping Transactions Deployment Spring Bean Resolving Testing Spring Boot Integration Version Compatibility Configuration REST API Web Applications Process Applications Spring Eventing Bridge Developing and Testing Spring Security OAuth2 Integration Quarkus Integration Version Compatibility Configuration Engine CDI Integration Resource Deployments CDI and Java EE Integration JTA Transaction Integration Expression Resolving Contextual Programming Model Built-In Beans CDI Event Bridge Testing Assert Examples Model API BPMN Model API Read a Model Create a Model Delegation Code Fluent Builder API Repository Service Extension Elements CMMN Model API Read a Model Create a Model Delegation Code Repository Service Extension Elements Limitations DMN Model API Read a Model Create a Model Repository Service Extension Attributes Data Formats (XML, JSON, Other) Configuring Spin Integration Data Formats in Processes XML JSON User Task Forms JSF Task Forms DMN Engine Embed Evaluate Decisions Expressions FEEL Engine Type Handling Custom Functions Spin Integration Legacy Behavior Data Types Testing Logging Security Instructions External Task Client Spring Boot Starter Version Compatibility Reference REST API Overview Configure Authentication Usage with a Pre-Built Distribution Embed the API Hypertext Application Language (HAL) Variables in the REST API Date Format OpenAPI Specification ↗ Javadoc ↗ BPMN 2.0 Tasks Service Task Send Task User Task Business Rule Task Script Task Receive Task Manual Task Task Markers Gateways Data-based Exclusive Gateway (XOR) Conditional and Default Sequence Flows Parallel Gateway Inclusive Gateway Event-based Gateway Events Start Events None Events Message Events Timer Events Error Events Escalation Events Signal Events Cancel and Compensation Events Conditional Events Link Events Terminate Events Subprocess Embedded Subprocess Call Activity Event Subprocess Transaction Subprocess Extension Reference Extension Elements Extension Attributes DMN 1.3 Decision Table Input Output Rule Hit Policy Decision Literal Expression Decision Requirements Graph FEEL Legacy FEEL Reference Data Types Language Elements Extension Reference Extension Attributes CMMN 1.1 Classic vs Fluent API CMMN Concepts Plan Items and Item Definitions Plan Item Lifecycles Entry and Exit Criteria Tasks Human Task Process Task Case Task Decision Task Grouping Tasks Stage Milestones Sentries Markers Manual Activation Rule Required Rule Auto Complete Repetition Rule Extension Reference Extension Elements Extension Attributes Migration between Specification Versions 1.0 to 1.1 Forms Embedded Forms Controls Text Inputs Textareas Date Inputs Boolean Inputs Selects Hidden Input Fields File Upload and Download BPMN Event Buttons Javascript The cam-script Directive Available API Participating in the Form Lifecycle Debugging Scripts Generating a Business Key Examples Lifecycle and Events Working with Json Data Working with Java Objects Integrating the Forms SDK Getting a Distribution Bootstrapping AngularJS Integration Full Example Spin Dataformats XML Reading XML Manipulating XML Writing XML Querying XML Mapping XML Configuring XML Handling JSON Reading JSON Writing JSON Querying JSON Mapping JSON Configuring JSON Handling Extending Spin Connectors HTTP Connector SOAP Connector Extending Connect Deployment Descriptors bpm-platform.xml processes.xml Tags <job-executor /> <process-archive /> <process-engine /> Installation Database Schema Remote Engine Distribution Shared Engine Distribution Tomcat Pre-Packaged Distribution Manual Installation Configuration JBoss EAP/WildFly Manual Installation Configuration Docker Spring Boot Web Applications Admin User Management Group Management Tenant Management Authorization Management System Management Configuration Plugins Cockpit Dashboard BPMN Processes Dashboard Process Definition View Process Instance View Failed Jobs Suspension Collapsed Subprocesses DMN Decisions Dashboard Decision Definition View Decision Instance View Deployments Open Tasks Dashboard Extending Configuration Plugins Tasklist Working with Tasklist Dashboard Filters User Assignment Task Lifecycle Plugins Configuration Accessibility Welcome Plugins Configuration Shared Configuration Options Authentication Cookie Security CSRF Prevention HTTP Header Security Examples Notices Update & Migration Rolling Update Camunda Migration Handling JSON Reading JSON Writing JSON Querying JSON Mapping JSON Configuring JSON Handling :( Back to top cibseven.org and docs.cibseven.org are part of CIB seven project — Privacy Statement – CIB software GmbH The CIB seven documentation is based on Camunda 7 Docs from Camunda. Some redesign & naming adoptation was made. The content on this site is licensed under a Creative Commons Attribution-ShareAlike 3.0 Unported License.",
    "url": "/manual/latest/reference/spin/json/index.html"
  },
  {
    "id": "manual/latest/reference/spin/xml/01-reading-xml/index.html",
    "title": "Reading XML | docs.cibseven.org",
    "content": "The XML dataformat supports reading XML from Strings or input streams. Reading XML from a String: import static org.cibseven.spin.Spin.*; import static org.cibseven.spin.DataFormats.*; SpinXmlElement xml = S(\"<order />\", xml()); The second paramter xml() hints Spin to use the XML data format for parsing the XML. Alternatively, you can directly use the XML(...) function: import static org.cibseven.spin.Spin.*; SpinXmlElement xml = XML(\"<order />\"); Reading XML from a Reader: Spin also supports reading XML directly from a java.io.Reader: import static org.cibseven.spin.Spin.*; import static org.cibseven.spin.DataFormats.*; SpinXmlElement xml = S(reader, xml()); The XML(...) method also supports readers. The following example shows how to read the XML from a file (error handling ommitted): import static org.cibseven.spin.Spin.*; FileInputStream fis = new FileInputStream(\"/tmp/incomingOrder.xml\"); InputStreamReader reader = new InputStreamReader(fis, \"utf-8\"); SpinXmlElement xml = XML(reader); Reading XML using a Script Language XML can be read from script languages in the same way as from Java. Since script languages use dynamic typing, you do not need to hint the data format but you can use autodetection. The following example demonstrates how to read XML in JavaScript: var orderId = S('<order id=\"1231\" />').attr('id');",
    "url": "/manual/latest/reference/spin/xml/01-reading-xml/index.html"
  },
  {
    "id": "manual/latest/reference/spin/xml/02-manipulating-xml/index.html",
    "title": "Manipulating XML | docs.cibseven.org",
    "content": "The XML data type supports manipulation of XML attributes and child elements. Attributes Checking for Attributes in XML import static org.cibseven.spin.Spin.XML; String xml = \"<order xmlns:cam=\\\"http://camunda.org/example\\\" id=\\\"order1\\\" cam:name=\\\"name\\\" />\"; boolean hasAttr = XML(xml).hasAttr(\"id\"); assertTrue(hasAttr); hasAttr = XML(xml).hasAttrNs(\"http://camunda.org/example\", \"id\"); assertTrue(hasAttr); Reading Attributes from XML import static org.cibseven.spin.Spin.XML; SpinXmlDomAttribute attribute = XML(\"<order id=\\\"order1\\\" />\").attr(\"id\"); String id = XML(\"<order id=\\\"order1\\\" />\").attr(\"id\").value(); The attr method returns a wrapper of the XML attribute and with value the value of the attribute can be accessed. If you want to access an attribute in another namespace, you have to use the attrNs method. import static org.cibseven.spin.Spin.XML; String xml = \"<order xmlns:cam=\\\"http://camunda.org/example\\\" id=\\\"order1\\\" cam:name=\\\"order1\\\" />\"; SpinXmlDomAttribute attribute = XML(xml).attrNs(\"http://camunda.org/example\", \"name\"); You can also get a collection of all attributes or only of a specific namespace. import static org.cibseven.spin.Spin.XML; String xml = \"<order xmlns:cam=\\\"http://camunda.org/example\\\" id=\\\"order1\\\" cam:name=\\\"order1\\\" />\"; // All attributes SpinCollection<SpinXmlDomAttribute> attributes = XML(xml).attrs(); // All attributes of a specific namespace attributes = XML(xml).attrs(\"http://camunda.org/example\"); Or you can directly get all attribute names instead. import static org.cibseven.spin.Spin.XML; String xml = \"<order xmlns:cam=\\\"http://camunda.org/example\\\" id=\\\"order1\\\" cam:name=\\\"order1\\\" />\"; // All attribute names List<String> names = XML(xml).attrNames(); // All attribute names of a specific namespace names = XML(xml).attrNames(\"http://camunda.org/example\"); Writing Attributes to XML It is possible to set a new attribute value directly from the element wrapper or on the attribute wrapper. import static org.cibseven.spin.Spin.XML; String xml = \"<order id=\\\"order1\\\" />\"; XML(xml).attr(\"id\", \"newId\"); SpinXmlDomAttribute attribute = XML(xml).attr(\"id\"); attribute.value(\"newId\"); You can also specify the namespace of the attribute to set. import static org.cibseven.spin.Spin.XML; String xml = \"<order xmlns:cam=\\\"http://camunda.org/example\\\" id=\\\"order1\\\" cam:name=\\\"name\\\" />\"; XML(xml).attrNs(\"http://camunda.org/example\", \"name\", \"newName\"); SpinXmlDomAttribute attribute = XML(xml).attrNs(\"http://camunda.org/example\", \"name\"); attribute.value(\"newName\"); Removing Attributes from XML It is possible to remove an attribute from the element directly or to remove the attribute itself. import static org.cibseven.spin.Spin.XML; String xml = \"<order id=\\\"order1\\\" />\"; SpinXmlDomElement element = XML(xml).removeAttr(\"id\"); assertFalse(element.hasAttr(\"id)); SpinXmlDomAttribute attribute = XML(xml).attr(\"id\"); element = attribute.remove(); assertFalse(element.hasAttr(\"id)); You can also specify the namespace of the attribute to remove. import static org.cibseven.spin.Spin.XML; String xml = \"<order xmlns:cam=\\\"http://camunda.org/example\\\" id=\\\"order1\\\" cam:name=\\\"name\\\" />\"; SpinXmlDomElement element = XML(xml).removeAttrNs(\"http://camunda.org/example\", \"name\"); assertFalse(element.hasAttrNs(\"http://camunda.org/example/\", \"name\")); SpinXmlDomAttribute attribute = XML(xml).attrNs(\"http://camunda.org/example\", \"name\"); element = attribute.remove() assertFalse(element.hasAttrNs(\"http://camunda.org/example\", \"name\")); Text Content It is possible to read and write the text content of an XML element with the textContent method. import static org.cibseven.spin.Spin.XML; SpinXmlDomElement element = XML(\"<customer>Foo</customer>\"); assertEquals(\"Foo\", element.textContent()); element.textContent(\"Bar\"); Child Elements Reading Child Elements from XML Besides attributes, you can also get a unique or all child elements of a specific type. Optionally, a namespace can be passed to the methods as first parameter. import static org.cibseven.spin.Spin.XML; String xml = \"<order xmlns:cam=\\\"http://camunda.org/example\\\">\" + \"<date/><cam:due/><item/><item/><cam:op/><cam:op/></order>\"; SpinXmlDomElement date = XML(xml).childElement(\"date\"); SpinXmlDomElement due = XML(xml).childElement(\"http://camunda.org/example\", \"due\"); SpinCollection<SpinXmlDomElement> items = XML(xml).childElements(\"item\"); SpinCollection<SpinXmlDomElement> ops = XML(xml).childElements(\"http://camunda.org/example\", \"ops\"); Append Child Elements The method append is used to append a single or multiple child elements to an XML element. import static org.cibseven.spin.Spin.XML; SpinXmlTreeElement root = XML(\"<root/>\"); SpinXmlTreeElement child1 = XML(\"<child/>\"); SpinXmlTreeElement child2 = XML(\"<child/>\"); SpinXmlTreeElement child3 = XML(\"<child/>\"); root.append(child1, child2, child3); Remove Child Elements To remove child elements from an XML element, the method remove is used. It accepts single or multiple child elements and removes them from the parent element. import static org.cibseven.spin.Spin.XML; SpinXmlTreeElement root = XML(\"<root><child/><child/><child/></root>\"); root.remove(root.childElements(\"child\")); Replace Elements To replace an element or a child element, the methods replace and replaceChild are used. import static org.cibseven.spin.Spin.XML; SpinXmlTreeElement root = XML(\"<root><date/><order/></root>\"); SpinXmlTreeElement child1 = XML(\"<child/>\"); root.replaceChild(root.childElement(\"date\"), child1); SpinXmlTreeElement child2 = XML(\"<child/>\"); root.childElement(\"order\").replace(child2); Manipulating XML using a Script Language XML can be manipulated from script languages in the same was as from Java. Since script languages use dynamic typing, you do not need to hint the data format but you can use autodetection. The following example demonstrates how to access an attribute and a child element from XML in Python: xml = \"\"\" <order id=\"1231\"> <item id=\"1\"/> </order> \"\"\" assert S(xml).hasAttr('id') order_id = S(xml).attr('id').value() assert order_id == '1231' element = S(xml).attr('order', 'order1') assert element.hasAttr('order') assert element.Attr('order').value() == 'order1' element.removeAttr('order') assert not element.hasAttr('order') item_id = S(xml).childElement('item').attr('id').value() assert item_id == '1'",
    "url": "/manual/latest/reference/spin/xml/02-manipulating-xml/index.html"
  },
  {
    "id": "manual/latest/reference/spin/xml/03-writing-xml/index.html",
    "title": "Writing XML | docs.cibseven.org",
    "content": "The XML datatype supports writing XML to Strings, output streams or writers. Writing to a String: import static org.cibseven.spin.Spin.XML; import org.cibseven.spin.xml.SpinXmlElement; // Create XML element SpinXmlElement element = XML(\"<root id=\\\"test\\\"/>\"); String xml = element.toString(); String value = element.attr(\"id\").value(); Writing to an Output Stream: import static org.cibseven.spin.Spin.XML; import org.cibseven.spin.xml.SpinXmlElement; import org.cibseven.spin.xml.SpinXmlAttribute; // Create XML element SpinXmlElement element = XML(\"<root id=\\\"test\\\"/>\"); try { // Define Output Stream OutputStream outputStream = System.out; // Wrap Output Stream in Writer OutputStreamWriter outputStreamWriter = new OutputStreamWriter(outputStream); // Write element to stream writer element.writeToWriter(outputStreamWriter); // Get attribute from element SpinXmlAttribute attr = element.attr(\"id\"); // Write attribute value to stream writer attr.writeToWriter(outputStreamWriter); // End Output Stream outputStreamWriter.write(\"\\n\"); // Close Output Stream and Writer outputStreamWriter.close(); } catch (IOException e) { // Handle exception if needed } Write to Writer import static org.cibseven.spin.Spin.XML; import org.cibseven.spin.xml.SpinXmlElement; import org.cibseven.spin.xml.SpinXmlAttribute; // Create XML element SpinXmlElement element = XML(\"<root id=\\\"test\\\"/>\"); // Create String Writer StringWriter writer = new StringWriter(); // Write element to Writer element.writeToWriter(writer); // Get attribute from element SpinXmlAttribute attr = element.attr(\"id\"); // Write attribute value to Writer attr.writeToWriter(writer);",
    "url": "/manual/latest/reference/spin/xml/03-writing-xml/index.html"
  },
  {
    "id": "manual/latest/reference/spin/xml/04-querying-xml/index.html",
    "title": "Querying XML | docs.cibseven.org",
    "content": "The XML datatype supports querying with the XPath 1.0 query language. Querying an Element import static org.cibseven.spin.Spin.XML; String xml = \"<root><child id=\\\"child\\\"><a id=\\\"a\\\"/><a id=\\\"b\\\"/></child></root>\"; SpinXmlTreeElement child = XML(xml).xPath(\"/root/child\").element(); Querying an Element List import static org.cibseven.spin.Spin.XML; String xml = \"<root><child id=\\\"child\\\"><a id=\\\"a\\\"/><a id=\\\"b\\\"/></child></root>\"; SpinList<SpinXmlTreeElement> childs = XML(xml).xPath(\"/root/child/a\").elementList(); Querying an Attribute import static org.cibseven.spin.Spin.XML; String xml = \"<root><child id=\\\"child\\\"><a id=\\\"a\\\"/><a id=\\\"b\\\"/></child></root>\"; SpinXmlTreeAttribute attribute = XML(xml).xPath(\"/root/child/@id\").attribute(); Querying an Attribute List import static org.cibseven.spin.Spin.XML; String xml = \"<root><child id=\\\"child\\\"><a id=\\\"a\\\"/><a id=\\\"b\\\"/></child></root>\"; SpinList<SpinXmlTreeAttribute> attributes = XML(xml).xPath(\"/root/child/a/@id\").attributeList(); Querying a String import static org.cibseven.spin.Spin.XML; String xml = \"<root><child id=\\\"child\\\"><a id=\\\"a\\\"/><a id=\\\"b\\\"/></child></root>\"; String value = XML(xml).xPath(\"string(/root/child/@id)\").string(); Querying a Number import static org.cibseven.spin.Spin.XML; String xml = \"<root><child id=\\\"child\\\"><a id=\\\"a\\\"/><a id=\\\"b\\\"/></child></root>\"; Double count = XML(xml).xPath(\"count(/root/child/a)\").number(); Querying a Boolean import static org.cibseven.spin.Spin.XML; String xml = \"<root><child id=\\\"child\\\"><a id=\\\"a\\\"/><a id=\\\"b\\\"/></child></root>\"; Boolean exists = XML(xml).xPath(\"boolean(/root/child)\").bool(); Querying with Namespaces To use namespaces in spin with XML, you can choose one of the following methods or combine both of them. 1. Using a Single Prefix - URI Pair import static org.cibseven.spin.Spin.XML; String xml = \"<root xmlns:t=\\\"http://camunda.org\\\"><t:child id=\\\"child\\\"><a id=\\\"a\\\"/></t:child></root>\"; SpinXmlTreeElement child = XML(xml).xPath(\"/root/t:child\") .ns(\"t\", \"http://camunda.org\"); .element(); 2. Using a Map of Prefix - URI Pairs import static org.cibseven.spin.Spin.XML; String xml = \"<root xmlns:t=\\\"http://camunda.org\\\"><t:child id=\\\"child\\\"><a id=\\\"a\\\"/></t:child></root>\"; Map<String, String> namespaceMap = new HashMap<String, String>(); namespaceMap.put(\"t\", \"http://camunda.org\"); namespaceMap.put(\"s\", \"http://camunda.com\"); SpinXmlTreeElement child = XML(xml).xPath(\"/root/t:child\") .ns(namespaceMap); .element(); If you are using xmlns=\"<URI>\" in your XML file, spin uses DEFAULT as prefix for the namespace. E.g.,: <root xmlns=\"http://camunda.org\"></root> – prefix: DEFAULT, namespace: http://camunda.org so you need to use XML(xml).xPath(\"/DEFAULT:root\") to fetch the correct element.",
    "url": "/manual/latest/reference/spin/xml/04-querying-xml/index.html"
  },
  {
    "id": "manual/latest/reference/spin/xml/05-mapping-xml/index.html",
    "title": "Mapping XML | docs.cibseven.org",
    "content": "Spin can deserialize XML to Java objects and serialize the annotated Java objects to XML by integrating mapping features into its fluent API. JAXB annotations can be added to the involved Java classes to configure the (de-)serialization process but are not required. Mapping between Representations: Assume we have a class Customer defined as follows: @XmlRootElement(name=\"customer\", namespace=\"http://camunda.org/test\") public class Customer { private String name; @XmlElement(namespace=\"http://camunda.org/test\") public String getName() { return name; } public void setName(String name) { this.name = name; } } Mapping XML to Java: We can map the following XML object <?xml version=\"1.0\" encoding=\"UTF-8\"?> <customer xmlns=\"http://camunda.org/example\"> <name>Kermit</name> </customer> to an instance of Customer in the following way: import static org.cibseven.spin.Spin.XML; String xmlInput = \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?><customer xmlns=\\\"http://camunda.org/example\\\"><name>Kermit</name></customer>\"; Customer customer = XML(xmlInput).mapTo(Customer.class); Mapping Java to XML: We can map the customer back to XML as follows: import static org.cibseven.spin.Spin.XML; String xml = XML(customer).toString();",
    "url": "/manual/latest/reference/spin/xml/05-mapping-xml/index.html"
  },
  {
    "id": "manual/latest/reference/spin/xml/06-configuring-xml/index.html",
    "title": "Configuring XML Handling | docs.cibseven.org",
    "content": "Spin can be configured to change XML parsing, writing, and mapping settings. Spin uses JAXB and DOM to handle XML. Therefore, the XML data format uses instances of javax.xml.parsers.DocumentBuilderFactory, javax.xml.transform.TransformerFactory, and javax.xml.bind.JAXBContext that can be configured using Spin’s configuration mechanism. For example, a custom application may provide an implementation of org.cibseven.spin.spi.DataFormatConfigurator that exchanges the JAXBContext. Spin uses and caches the context to improve performance. The data format class to register a configurator for is org.cibseven.spin.impl.xml.dom.format.DomXmlDataFormat. An instance of this class provides setter methods (for the entities mentioned above) that can be used to replace the default object mapper. Refer to the JDK documentation on what configuration can be applied. Safe XML processing The Spin XML data format provides the following configuration properties to enable secure parsing of XML documents: Property Description xxe-processing Toggle the processing of External XML Entities (XXE) in an XML document. Disable to prevent XXE attacks. Default value: false secure-processing Toggle the secure processing of an XML document. Default value: true To provide a custom configuration, you can pass these properties in a Map, to the DataFormats.loadDataFormats(...) method, similar to the example below: Map<String, Object> configurationOptions = new HashMap<>(); configurationOptions.put(\"xxe-processing\", true); configurationOptions.put(\"secure-processing\", false); DataFormats.loadDataFormats(classloader, configurationOptions);",
    "url": "/manual/latest/reference/spin/xml/06-configuring-xml/index.html"
  },
  {
    "id": "manual/latest/reference/spin/xml/index.html",
    "title": "Handling XML | docs.cibseven.org",
    "content": "Docs Get Started CIB seven Security cibseven.org CIB seven 1.1 Introduction Download Licenses Implemented Standards Architecture Overview Supported Environments Extensions Third-Party Libraries CIB seven License Book Public API User Guide Process Engine Process Engine Bootstrapping Process Engine API Process Engine Concepts Process Variables Process Instance Modification Process Instance Restart Delegation Code Expression Language Scripting Templating Custom Code & Security External Tasks Connectors Process Versioning Process Instance Migration Database Database Schema Database Configuration Microsoft SQL Server and Azure SQL Database Configuration MySQL Database Configuration Performance History History configuration User operation log History cleanup Custom implementation Deployment Cache Password Hashing Password Policy Transactions in Processes The Job Executor Multi-Tenancy Id Generators Metrics Incidents Process Engine Plugins Identity Service Authorization Service Deployments Process Diagram Visualization Time zones Decisions Configuration Repository Decision Service Decisions in BPMN & CMMN History Batch Batch operations Error Handling Diagnostics data Process Applications The Process Application class The processes.xml Deployment Descriptor Process Application Event Listeners Process Application Resource Access Maven Project Templates (Archetypes) Runtime Container Integration CIB seven Services JNDI Bindings for CIB seven Services Apache Tomcat WildFly Job Execution with Managed Resources CIB seven Run Spring Framework Integration Bootstrapping Transactions Deployment Spring Bean Resolving Testing Spring Boot Integration Version Compatibility Configuration REST API Web Applications Process Applications Spring Eventing Bridge Developing and Testing Spring Security OAuth2 Integration Quarkus Integration Version Compatibility Configuration Engine CDI Integration Resource Deployments CDI and Java EE Integration JTA Transaction Integration Expression Resolving Contextual Programming Model Built-In Beans CDI Event Bridge Testing Assert Examples Model API BPMN Model API Read a Model Create a Model Delegation Code Fluent Builder API Repository Service Extension Elements CMMN Model API Read a Model Create a Model Delegation Code Repository Service Extension Elements Limitations DMN Model API Read a Model Create a Model Repository Service Extension Attributes Data Formats (XML, JSON, Other) Configuring Spin Integration Data Formats in Processes XML JSON User Task Forms JSF Task Forms DMN Engine Embed Evaluate Decisions Expressions FEEL Engine Type Handling Custom Functions Spin Integration Legacy Behavior Data Types Testing Logging Security Instructions External Task Client Spring Boot Starter Version Compatibility Reference REST API Overview Configure Authentication Usage with a Pre-Built Distribution Embed the API Hypertext Application Language (HAL) Variables in the REST API Date Format OpenAPI Specification ↗ Javadoc ↗ BPMN 2.0 Tasks Service Task Send Task User Task Business Rule Task Script Task Receive Task Manual Task Task Markers Gateways Data-based Exclusive Gateway (XOR) Conditional and Default Sequence Flows Parallel Gateway Inclusive Gateway Event-based Gateway Events Start Events None Events Message Events Timer Events Error Events Escalation Events Signal Events Cancel and Compensation Events Conditional Events Link Events Terminate Events Subprocess Embedded Subprocess Call Activity Event Subprocess Transaction Subprocess Extension Reference Extension Elements Extension Attributes DMN 1.3 Decision Table Input Output Rule Hit Policy Decision Literal Expression Decision Requirements Graph FEEL Legacy FEEL Reference Data Types Language Elements Extension Reference Extension Attributes CMMN 1.1 Classic vs Fluent API CMMN Concepts Plan Items and Item Definitions Plan Item Lifecycles Entry and Exit Criteria Tasks Human Task Process Task Case Task Decision Task Grouping Tasks Stage Milestones Sentries Markers Manual Activation Rule Required Rule Auto Complete Repetition Rule Extension Reference Extension Elements Extension Attributes Migration between Specification Versions 1.0 to 1.1 Forms Embedded Forms Controls Text Inputs Textareas Date Inputs Boolean Inputs Selects Hidden Input Fields File Upload and Download BPMN Event Buttons Javascript The cam-script Directive Available API Participating in the Form Lifecycle Debugging Scripts Generating a Business Key Examples Lifecycle and Events Working with Json Data Working with Java Objects Integrating the Forms SDK Getting a Distribution Bootstrapping AngularJS Integration Full Example Spin Dataformats XML Reading XML Manipulating XML Writing XML Querying XML Mapping XML Configuring XML Handling JSON Reading JSON Writing JSON Querying JSON Mapping JSON Configuring JSON Handling Extending Spin Connectors HTTP Connector SOAP Connector Extending Connect Deployment Descriptors bpm-platform.xml processes.xml Tags <job-executor /> <process-archive /> <process-engine /> Installation Database Schema Remote Engine Distribution Shared Engine Distribution Tomcat Pre-Packaged Distribution Manual Installation Configuration JBoss EAP/WildFly Manual Installation Configuration Docker Spring Boot Web Applications Admin User Management Group Management Tenant Management Authorization Management System Management Configuration Plugins Cockpit Dashboard BPMN Processes Dashboard Process Definition View Process Instance View Failed Jobs Suspension Collapsed Subprocesses DMN Decisions Dashboard Decision Definition View Decision Instance View Deployments Open Tasks Dashboard Extending Configuration Plugins Tasklist Working with Tasklist Dashboard Filters User Assignment Task Lifecycle Plugins Configuration Accessibility Welcome Plugins Configuration Shared Configuration Options Authentication Cookie Security CSRF Prevention HTTP Header Security Examples Notices Update & Migration Rolling Update Camunda Migration Handling XML Reading XML Manipulating XML Writing XML Querying XML Mapping XML Configuring XML Handling :( Back to top cibseven.org and docs.cibseven.org are part of CIB seven project — Privacy Statement – CIB software GmbH The CIB seven documentation is based on Camunda 7 Docs from Camunda. Some redesign & naming adoptation was made. The content on this site is licensed under a Creative Commons Attribution-ShareAlike 3.0 Unported License.",
    "url": "/manual/latest/reference/spin/xml/index.html"
  },
  {
    "id": "manual/latest/update/activiti/index.html",
    "title": "Activiti Migration | docs.cibseven.org",
    "content": "Migrating an existing application from Activiti <= 5.11 (or Camunda fox 6.x - see below) to Camunda 7.0 is straightforward. This page describes the necessary steps. Later upgrade of Camunda 7.0 to Camunda 7.22 is required and described in Camunda version upgrade docs Final migration from Camunda 7.x to CIB seven {{ }} should be straightforward. Getting Help If you are on a more recent Activiti version or if you have any trouble migrating, ask for assistance in the Discussions. We are happy to help you! The changes in short are: Maven Dependencies, e.g., activiti.jar changed to camunda-engine.jar. Package Names changed from org.activiti to org.camunda.bpm for all modules (including engine, CDI and spring). The configuration file changed from activiti.cfg.xml to camunda.cfg.xml. Several (internal) classes are renamed - see the lists below. There are some things which have not changed yet: Database schema and table names. Note that we based our fork on Activiti 5.11 and the tables existent in that version. The activiti: Custom Extensions are kept. A CIB seven namespace will be introduced soon but backwards compatibility will be ensured. We based our fork on the database schema of Activiti 5.11. So please update your project to this database using the update scripts provided by Activiti. If you are using a newer version, best ask for assistance in the Discussions. Exchange Library Exchange the existing library (here shown as Maven dependency) <dependency> <groupId>org.activiti</groupId> <artifactId>activiti</artifactId> <version>5.11</version> </dependency> to <dependency> <groupId>org.camunda.bpm</groupId> <artifactId>camunda-engine</artifactId> <version>7.0.0-Final</version> </dependency> Make sure that you have the Camunda Maven Repository set correctly: <repository> <id>camunda-bpm-nexus</id> <name>camunda Maven Repository</name> <url>https://artifacts.camunda.com/artifactory/public/</url> </repository> Adjust Package Names Just do an Organize Imports in your IDE, that should do the trick as the API class names have not changed. Your IDE should figure out the rest for you. For Eclipse this can be done by clicking on the project and hitting Ctrl-Shift-O. Which Activiti Class Names Have Changed? component Activiti class name Camunda class name engine ActivitiException ProcessEngineException ActivitiClassLoadingException ClassLoadingException ActivitiOptimisticLockingException OptimisticLockingException ActivitiTaskAlreadyClaimedException TaskAlreadyClaimedException ActivitiWrongDbException WrongDbException ActivitRule ProcessEngineRule ActivitiTestCase ProcessEngineTestCase PluggableActivitiTestCase PluggableProcessEngineTestCase AbstractActivitiTestCase AbstractProcessEngineTestCase ResourceActivitiTestCase ResourceProcessEngineTestCase spring ActivitiComponent ProcessEngineComponent SpringActivitiTestCase SpringProcessEngineTestCase cdi ActivitiCdiException ProcessEngineCdiException ActivitiExtension ProcessEngineExtension CdiActivitiTestCase CdiProcessEngineTestCase That’s it - now your application should run again.",
    "url": "/manual/latest/update/activiti/index.html"
  },
  {
    "id": "manual/latest/update/camunda/index.html",
    "title": "Camunda Migration | docs.cibseven.org",
    "content": "Migrating an existing application from Camunda 7.22 to CIB seven 1.0 is straightforward. This page describes the necessary steps. Migration to CIB seven 1.0 CIB seven 1.0 is a special version with minimal changes from Camunda. No source level changes were applied, no library dependencies were changed. We expect migration to this version should be as easy as possible. Only two steps are essential: Change Version to 7.22.0-cibseven My Camunda version is less than 7.22! For Camunda versions before 7.22 please do minor updates before migrating to CIB seven as described in Camunda version upgrade docs. Update your pom.xml files using Camunda and change version used from 7.22.x (usually 7.22.0 for Community Edition) to 7.22.0-cibseven. Setup CIB seven Maven Repository We are not able to deliver artifacts for other projects to any Maven Central repository. Version 7.22.0-cibseven is available only at artifacts.cibseven.org - our public maven repository. You can add this repository to pom.xml for current project or to settings.xml in $M2_HOME (usually $HOME/.m2) folder for current user: <repositories> <repository> <id>mvn-cibseven-public</id> <name>CIB seven Public Repository</name> <url>https://artifacts.cibseven.org/repository/public/</url> </repository> </repositories> Migration to CIB seven 1.1 Don't panic and use OpenRewrite! There are renamings done in this version. It is too boring to do it manually. Just use Migration Script we made for you! CIB seven 1.1 has set of changes for versions, packages and artifacts naming. So you will need to update: Versions used (in pom.xml files): 7.22.0 -> 1.1.0. Artifacts names are changes from camunda-* to cibseven-* (for example camunda-bpm-spring-boot-starter-webapp is called now cibseven-bpm-spring-boot-starter-webapp). Imports used in custom code should now use org.cibseven.foo.bar instead of org.camunda.foo.bar packages. All these changes can be done, using our Migration Script, based on OpenRewrite maven plugin (see GitHub for details).",
    "url": "/manual/latest/update/camunda/index.html"
  },
  {
    "id": "manual/latest/update/index.html",
    "title": "Update and Migration | docs.cibseven.org",
    "content": "These documents provide instructions to update a Java Project or a CIB seven installation to a new version. Depending on which update you want to perform, choose one of the following guides:",
    "url": "/manual/latest/update/index.html"
  },
  {
    "id": "manual/latest/update/rolling-update/index.html",
    "title": "Rolling Update | docs.cibseven.org",
    "content": "Limits for Rolling Updates Rolling updates are not possible prior to Version 7.5. Or in other words: the first update that can be done in the way described on this page is the update from version 7.5.x to 7.6.y. Also note that it is only possible to update from one minor version to the next. For example, it is possible to update from 7.5.3 to 7.6.2 in a rolling fashion but it is not possible to update from 7.5.3 to 7.7.2 in one go. Before the rolling update from one minor to another can be executed, the latest patch, of the current used minor version, must be applied to all nodes before proceeding to the next minor version. More considerations for rolling updates can be found at the bottom of this page. Make sure to read them. What is a Rolling Update? A rolling update is a process to perform a Camunda update in a cluster. The nodes are updated one by one or in groups. During the update process, it is ensured that at least one node is available to handle incoming requests, guaranteeing availability and minimizing downtime. Overview The above picture displays an example system. There are three process engine nodes connected to a shared database. A load balancer distributes requests to the Process Engine nodes. “Process Engine node” shall be an instance of an application or application server hosting a process engine. It must not necessarily be a separate physical host. A rolling update can be orchestrated in a 2 step process: Update the Database Schema, Update the Camunda libraries on all nodes, one by one or in groups. A 3-node cluster is used in this document for illustration. Obviously, the procedure can be generalized to a N-Node cluster. Prerequisite Before the rolling update for minor versions can be executed the nodes and database have to be updated to the latest patch version of the current minor version. To do so the rolling update process can be used. In that case the update will be from 7.X.x to 7.X.y, where y is the latest patch version of the minor version 7.X. Step by Step The following sections provide a step-by-step walkthrough of how to perform a rolling update. In this example, we use the version 7.X to signify the Camunda version the cluster is migrated from. We use 7.Y to signify the Camunda version the cluster is migrated to. Step 1: Update the Database Schema Initially, the database schema is at version 7.X and the Camunda library versions are at 7.X on all nodes: The first step consists of updating the database schema to version 7.Y. Information on where to find the update scripts and how to apply them can be found in the documentation on how to perform updates. As a result, the database schema version is at 7.Y while the Camunda library version is still 7.X: Considerations: Applying the database update scripts while not updating the library version (or in other words using a newer version of the database schema with an older version of the library) is possible since Camunda guarantees backwards compatibility of the database schema. (See the Considerations section at the bottom of this page for details.) Camunda does however not guarantee that the database schema update script can be applied on-line without issues. Depending on the database and the current load, the script can take a long time to run or may block other transactions from making progress. (See the Considerations section at the bottom of this page for details). Users are strongly encouraged to test the schema update script in a staging environment prior to executing it on a production database. Step 2: Update the Nodes After the update of the database schema is completed, the Camunda library version can to be updated. The following steps need to be done for each node or group of nodes. Grouping nodes makes the update process faster, at the expense that fewer nodes are intermittently available to process requests. An approach could be that 33% of the nodes are updated in parallel. In this case 66% of the nodes are available to process the requests and 33% are offline during the update. 2.1 Isolation First, a node is isolated. Usually this means that the load balancer is configured in a way that no new requests are sent to this node. Once all open requests are processed, the node is successfully isolated and can be taken down. 2.2 Update In this step the Camunda library version is updated on an isolated node. The exact way to achieve this depends on the environment: When using an embedded process engine, the application bundling the Camunda libraries needs to be re-packaged with the new version of the libraries and re-deployed. When using a shared process engine, the libraries and applications deployed to the application server need to be updated. After the update is complete, the node can be brought back up. 2.3 Integration In this step an updated node is re-integrated into the cluster. This usually means configuring the load balancer in a way that requests are routed to this node. Important Considerations Backwards Compatibility of Database Schema To facilitate updates, Camunda ensures backwards compatibility of the database schema. Backwards compatibility makes it possible to operate an older version of the process engine on a newer version of the database schema. This property is crucial in the first step of the rolling update process: after the database has been updated, the process engine libraries are still at the previous version. On-line applicability of Db Migration Script Note that Camunda does not guarantee that the migration script is applicable on-line (concurrently to in-flight transactions). While Camunda does its best effort to ensure this property, it is not guaranteed. It is therefore strongly recommended to test the database migration script on a test database with a similar load to the production database. Usage of new Features During the rolling update process, it is not permitted to use new features of the newer engine version. This means that it is not possible to “roll out” a new version of the BPMN processes or of the application making use of new API methods while also updating the library. The reason for this is that while performing a rolling update, there is a time frame in which both older and newer versions of the process engine library operate on the database concurrently. During this time, usage of new features of the new engine like deployment of a BPMN process with a newly supported symbol would cause problems with the old engine. One Minor Releases Only It is only possible to update from one minor version to the next. For example, it is possible to update from 7.5.3 to 7.6.2 in a rolling fashion but it is not possible to update from 7.5.3 to 7.7.2 in one go. Required Version Rolling updates are not possible prior to Version 7.5. Or in other words: the first update that can be done in the way described on this page is the update from version 7.5.x to 7.6.y.",
    "url": "/manual/latest/update/rolling-update/index.html"
  },
  {
    "id": "manual/latest/user-guide/cdi-java-ee-integration/built-in-beans/index.html",
    "title": "Built-In Beans | docs.cibseven.org",
    "content": "The ProcessEngine as well as the services are available for injection via @Inject ProcessEngine, @Inject RepositoryService, and so on. A specific named ProcessEngine and its services can be injected by adding the qualifier @ProcessEngineName('someEngine'). The current process instance and task can be injected via @Inject ProcessInstance or @Inject Task. The current business key can be injected via @Inject @BusinessKey String businessKey. The current process instance id be injected via @Inject @ProcessInstanceId String pid. Process variables are available for injection. Camunda CDI supports Type-safe injection of @BusinessProcessScoped beans using @Inject [additional qualifiers] Type fieldName. Unsafe injection of other process variables using the @ProcessVariable(name?) qualifier: @Inject @ProcessVariable private Object accountNumber; @Inject @ProcessVariable(\"accountNumber\") private Object account; In order to reference process variables using EL, we have similar options: @Named @BusinessProcessScoped beans can be referenced directly. Other process variables can be referenced using the ProcessVariables-bean via #{processVariables['accountNumber']}. Inject a process engine based on contextual data While a specific process engine can be accessed by adding the qualifier @ProcessEngineName('name') to the injection point, this requires that it is known which process engine is used at design time. A more flexible approach is to resolve the process engine at runtime based on contextual information such as the logged in user. In this case, @Inject can be used without a @ProcessEngineName annotation. To implement resolution from contextual data, the producer bean org.cibseven.bpm.engine.cdi.impl.ProcessEngineServicesProducer must be extended. The following code implements a contextual resolution of the engine by the currently authenticated user. Note that which contextual data is used and how it is accessed is entirely up to you. @Specializes public class UserAwareEngineServicesProvider extends ProcessEngineServicesProducer { // User can be any object containing user information from which the tenant can be determined @Inject private UserInfo user; @Specializes @Produces @RequestScoped public ProcessEngine processEngine() { // okay, maybe this should involve some more logic ;-) String engineForUser = user.getTenant(); ProcessEngine processEngine = BpmPlatform.getProcessEngineService().getProcessEngine(engineForUser); if(processEngine != null) { return processEngine; } else { return ProcessEngines.getProcessEngine(engineForUser, false); } } @Specializes @Produces @RequestScoped public RuntimeService runtimeService() { return processEngine().getRuntimeService(); } @Specializes @Produces @RequestScoped public TaskService taskService() { return processEngine().getTaskService(); } ... } The above code makes selecting the process engine based on the current user’s tenant completely transparent. For each request, the currently authenticated user is retrieved and the correct process engine is looked up. Note that the class UserInfo represents any kind of context object that identifies the current tenant. For example, it could be a JAAS principal. The produced engine can be accessed in the following way: @Inject private RuntimeService runtimeService;",
    "url": "/manual/latest/user-guide/cdi-java-ee-integration/built-in-beans/index.html"
  },
  {
    "id": "manual/latest/user-guide/cdi-java-ee-integration/contextual-programming-model/index.html",
    "title": "Contextual Programming Model | docs.cibseven.org",
    "content": "In this section we briefly look at the contextual process execution model used by the Camunda CDI extension. A BPMN business process is typically a long-running interaction, comprised of both user and system tasks. At runtime, a process is split-up into a set of individual units of work, performed by users and/or application logic. In Camunda CDI, a process instance can be associated with a CDI scope, the association representing a unit of work. This is particularly useful if a unit of work is complex, for instance if the implementation of a user task is a complex sequence of different forms and “non-process-scoped” state needs to be kept during this interaction. In the default configuration, process instances are associated with the “broadest” active scope, starting with the conversation and falling back to the request if the conversation context is not active. Associate a conversation with a process instance When resolving @BusinessProcessScoped beans or injecting process variables, we rely on an existing association between an active CDI scope and a process instance. The Camunda CDI integration provides the org.cibseven.bpm.engine.cdi.BusinessProcess bean for controlling the association, most prominently: The startProcessBy*(...)-methods, mirroring the respective methods exposed by the RuntimeService allowing to start and subsequently associate a business process. The resumeProcessById(String processInstanceId), allowing to associate the process instance with the provided Id. The resumeTaskById(String taskId), allowing to associate the task with the provided Id (and by extension, the corresponding process instance). Once a unit of work like a user task is completed, the completeTask() method can be called to disassociate the conversation/request from the process instance. This signals the engine that the current task is completed and makes the process instance proceed. Note that the BusinessProcess-bean is a @Named bean, which means that the exposed methods can be invoked using expression language, for example from a JSF page. The following JSF2 snippet begins a new conversation and associates it with a user task instance, the Id of which is passed as a request parameter (e.g., pageName.jsf?taskId=XX): <f:metadata> <f:viewParam name=\"taskId\" /> <f:event type=\"preRenderView\" listener=\"#{businessProcess.startTask(taskId, true)}\" /> </f:metadata> Declaratively controlling the process Camunda CDI allows declaratively starting process instances and completing tasks using annotations. The @org.cibseven.bpm.engine.cdi.annotation.StartProcess annotation allows to start a process instance either by “key” or by “name”. Note that the process instance is started after the annotated method returns. Example: @StartProcess(\"authorizeBusinessTripRequest\") public String submitRequest(BusinessTripRequest request) { // do some work return \"success\"; } Depending on the configuration of the CIB seven engine, the code of the annotated method and the starting of the process instance will be combined in the same transaction. The @org.cibseven.bpm.engine.cdi.annotation.CompleteTask-annotation works in the same way: @CompleteTask(endConversation=false) public String authorizeBusinessTrip() { // do some work return \"success\"; } The @CompleteTask annotation offers the possibility to end the current conversation. The default behavior is to end the conversation after the call to the engine returns. Ending the conversation can be disabled, as shown in the example above. Work with @BusinessProcessScoped beans Using Camunda CDI, the lifecycle of a bean can be bound to a process instance. To this extent, a custom context implementation is provided, namely the BusinessProcessContext. Instances of BusinessProcessScoped beans are stored as process variables in the current process instance. On deployment, beans annotated with BusinessProcessScoped are validated for being “passivation capable”, which means that they must implement the Serializable interface, and their references (dependencies) must be “passivation capable” as well. You can read more about the “passivation capable” criteria in the CDI specification. The following is an example of a “passivation capable” process scoped bean: @Named @BusinessProcessScoped public class BusinessTripRequest implements Serializable { private static final long serialVersionUID = 1L; private String startDate; private String endDate; // ... } Sometimes, we want to work with process scoped beans, in the absence of an association with a process instance, for example before starting a process. If no process instance is currently active, instances of BusinessProcessScoped beans are temporarily stored in a local scope (i.e., the Conversation or the Request, depending on the context). If this scope is later associated with a business process instance, the bean instances are flushed to the process instance.",
    "url": "/manual/latest/user-guide/cdi-java-ee-integration/contextual-programming-model/index.html"
  },
  {
    "id": "manual/latest/user-guide/cdi-java-ee-integration/expression-resolving/index.html",
    "title": "Expression Resolving | docs.cibseven.org",
    "content": "The cibseven-engine-cdi and cibseven-engine-cdi-jakarta libraries expose CDI beans via Expression Language, using a custom resolver. This makes it possible to reference beans from the process: <userTask id=\"authorizeBusinessTrip\" name=\"Authorize Business Trip\" camunda:assignee=\"#{authorizingManager.account.username}\" /> Where “authorizingManager” could be a bean provided by a producer method: @Inject @ProcessVariable private Object businessTripRequesterUsername; @Produces @Named public Employee authorizingManager() { TypedQuery<Employee> query = entityManager.createQuery(\"SELECT e FROM Employee e WHERE e.account.username='\" + businessTripRequesterUsername + \"'\", Employee.class); Employee employee = query.getSingleResult(); return employee.getManager(); } We can use the same feature to call a business method of an EJB in a service task, using the camunda:expression=\"${myEjb.method()}\"-extension. Note that this requires a @Named-annotation on the MyEjb-class.",
    "url": "/manual/latest/user-guide/cdi-java-ee-integration/expression-resolving/index.html"
  },
  {
    "id": "manual/latest/user-guide/cdi-java-ee-integration/index.html",
    "title": "CDI and Java EE Integration | docs.cibseven.org",
    "content": "The cibseven-engine-cdi and cibseven-engine-cdi-jakarta modules provide programming model integration with CDI (Context and Dependency Injection). CDI is the Jakarta EE/Java EE standard for Dependency Injection. The CIB seven CDI integration leverages both the configuration of the CIB seven engine and the extensibility of CDI. The most prominent features are: A custom El-Resolver for resolving CDI beans (including EJBs) from the process. Support for @BusinessProcessScoped beans (CDI beans, the lifecycle of which are bound to a process instance). Declarative control over a process instance using annotations. The Process Engine is hooked-up to the CDI event bus. Works with Jakarta EE, Java EE, and Java SE. Support for unit testing. Quarkus Engine Extension Since Quarkus ArC does not aim to fully implement CDI 2.0, you cannot use the full range of features the cibseven-engine-cdi module provides. Read about the limitations in the Quarkus Integration guide. Maven Dependency To use the cibseven-engine-cdi module inside your application, you must include the following Maven dependency: Please import the CIB seven BOM to ensure correct versions for every CIB seven project. <dependency> <groupId>org.cibseven.bpm</groupId> <artifactId>cibseven-engine-cdi</artifactId> </dependency> For Jakarta EE 9+ containers, use the following dependency instead: <dependency> <groupId>org.cibseven.bpm</groupId> <artifactId>cibseven-engine-cdi-jakarta</artifactId> </dependency> There is a project template for Maven called camunda-archetype-ejb-war, which gives you a complete running project, including CDI integration.",
    "url": "/manual/latest/user-guide/cdi-java-ee-integration/index.html"
  },
  {
    "id": "manual/latest/user-guide/cdi-java-ee-integration/jta-transaction-integration/index.html",
    "title": "JTA Transaction Integration | docs.cibseven.org",
    "content": "Embedded Process Engine The process engine transaction management can integrate with JTA and Jakarta Transactions. To use transaction manager integration, you need to use the org.cibseven.bpm.engine.impl.cfg.JtaProcessEngineConfiguration for JTA integration only. org.cibseven.bpm.engine.impl.cfg.JakartaTransactionProcessEngineConfiguration for Jakarta Transactions integration only. org.cibseven.bpm.engine.cdi.CdiJtaProcessEngineConfiguration for additional CDI expression resolution support. The process engine requires access to an implementation of javax.transaction.TransactionManager or jakarta.transaction.TransactionManager respectively. Not all application servers provide such an implementation. Most notably, IBM WebSphere and Oracle WebLogic historically did not provide this implementation. To achieve JTA transaction integration on these containers, users should use the Spring Framework Abstraction and configure the process engine using the SpringProcessEngineConfiguration. When you configure a transaction manager, make sure that it actually manages the data source that you have configured for the process engine. If that is not the case, the data source works in auto-commit mode. This can lead to inconsistencies in the database, because transaction commits and rollbacks are no longer performed. Shared Process Engine The shared process engine distributions for Java EE and Jakarta EE Application Servers (Wildfly, JBoss EAP, IBM WebSphere Application Server, Oracle WebLogic Application Server) provide JTA or Jakarta Transactions integration out of the box. Example The following example shows how to integrate your custom business logic into a transaction of the process engine: @Named @Dependent public class MyBean { @Inject public RuntimeService runtimeService; @Transactional public void doSomethingTransactional() { // Here you can do transactional stuff in your domain model and it will be // combined in the same transaction as the the following RuntimeService API // call to start a process instance: runtimeService.startProcessInstanceByKey(\"my-process\"); } } Using JTA transaction integration with WebSphere Liberty CIB seven allows to mark a transaction as “rollback only” by calling UserTransaction#setRollbackOnly(). If this code is executed within a CIB seven Job, the Job is marked as failed, and can be retried. WebSphere Liberty doesn’t support this behavior of CIB seven. When calling UserTransaction#setRollbackOnly() in WebSphere Liberty, the transaction is rolled back silently, and the Camunda process engine is unable to unlock the job and decrease the job retry count. As a workaround, you can throw a RuntimeException after invoking the UserTransaction#setRollbackOnly(). The Camunda process engine will catch this Exception and handle the transaction rollback inside a job correctly.",
    "url": "/manual/latest/user-guide/cdi-java-ee-integration/jta-transaction-integration/index.html"
  },
  {
    "id": "manual/latest/user-guide/cdi-java-ee-integration/the-cdi-event-bridge/index.html",
    "title": "CDI Event Bridge | docs.cibseven.org",
    "content": "The process engine can be hooked-up to the CDI event bus. We call this the “CDI Event Bridge”. This allows us to be notified of process events using standard CDI event mechanisms. In order to enable CDI event support for an embedded process engine, enable the corresponding parse listener in the configuration: <property name=\"postParseListeners\"> <list> <bean class=\"org.cibseven.bpm.engine.cdi.impl.event.CdiEventSupportBpmnParseListener\" /> </list> </property> Now the engine is configured for publishing events using the CDI event bus. The above configuration can be used in combination with an embedded process engine. If you want to use this feature in combination with the shared process engine in a multi application environment, you need to add the CdiEventListener as process application event listener. See next section. The following gives an overview of how process events can be received in CDI beans. In CDI, we can declaratively specify event observers using the @Observes-annotation. Event notification is type-safe. The type of process events is org.cibseven.bpm.engine.cdi.BusinessProcessEvent. The following is an example of a simple event observer method: public void onProcessEvent(@Observes BusinessProcessEvent businessProcessEvent) { // handle event } This observer would be notified of all events. If we want to restrict the set of events the observer receives, we can add qualifier annotations: @BusinessProcessDefinition: restricts the set of events to a certain process definition. Example: public void onProcessEvent(@Observes @BusinessProcessDefinition(\"billingProcess\") BusinessProcessEvent businessProcessEvent) { // handle event } @StartActivity: restricts the set of events by a certain activity. For example: public void onActivityEvent(@Observes @StartActivity(\"shipGoods\") BusinessProcessEvent businessProcessEvent) { // handle event } is invoked whenever an activity with the id “shipGoods” is entered. @EndActivity: restricts the set of events by a certain activity. The following method is invoked whenever an activity with the id “shipGoods” is left: public void onActivityEvent(@Observes @EndActivity(\"shipGoods\") BusinessProcessEvent businessProcessEvent) { // handle event } @TakeTransition: restricts the set of events by a certain transition. @CreateTask: restricts the set of events by a certain task. The following is invoked whenever a task with the definition key (id in BPMN XML) “approveRegistration” is created: public void onTaskEvent(@Observes @CreateTask(\"approveRegistration\") BusinessProcessEvent businessProcessEvent) { // handle event } @AssignTask: restricts the set of events by a certain task. The following is invoked whenever a task with the definition key (id in BPMN XML) “approveRegistration” is assigned: public void onTaskEvent(@Observes @AssignTask(\"approveRegistration\") BusinessProcessEvent businessProcessEvent) { // handle event } @CompleteTask: restricts the set of events by a certain task. The following is invoked whenever a task with the definition key (id in BPMN XML) “approveRegistration” is completed: public void onTaskEvent(@Observes @CompleteTask(\"approveRegistration\") BusinessProcessEvent businessProcessEvent) { // handle event } @DeleteTask: restricts the set of events by a certain task. The following is invoked whenever a task with the definition key (id in BPMN XML) “approveRegistration” is deleted: public void onTaskEvent(@Observes @DeleteTask(\"approveRegistration\") BusinessProcessEvent businessProcessEvent) { // handle event } The qualifiers named above can be combined freely. For example, to receive all events generated when leaving the “shipGoods” activity in the “shipmentProcess”, we could write the following observer method: public void beforeShippingGoods(@Observes @BusinessProcessDefinition(\"shippingProcess\") @EndActivity(\"shipGoods\") BusinessProcessEvent evt) { // handle event } In the default configuration, event listeners are invoked synchronously and in the context of the same transaction. CDI transactional observers (only available in combination with JakartaEE / JavaEE / EJB), allow to control when the event is handed to the observer method. Using transactional observers, we can for example assure that an observer is only notified if the transaction in which the event is fired succeeds: public void onShipmentSuceeded( @Observes(during=TransactionPhase.AFTER_SUCCESS) @BusinessProcessDefinition(\"shippingProcess\") @EndActivity(\"shipGoods\") BusinessProcessEvent evt) { // send email to customer } Note: BusinessProcessEvent.getTask will return an instance of DelegateTask (in case the event is a task event). If the listener is invoked after the transaction has completed, the DelegateTask object cannot be used for modifying variables. The CDI Event Bridge in a process application To use the CDI Event Bridge in combination with a multi application deployment and the shared process engine, the CdiEventListener needs to be added as a Process Application Execution Event Listener. Example configuration for Servlet Process Application: @ProcessApplication public class InvoiceProcessApplication extends ServletProcessApplication { protected CdiEventListener cdiEventListener = new CdiEventListener(); public ExecutionListener getExecutionListener() { return cdiEventListener; } public TaskListener getTaskListener() { return cdiEventListener; } } Example configuration for EJB Process Application: @Singleton @Startup @ConcurrencyManagement(ConcurrencyManagementType.BEAN) @TransactionAttribute(TransactionAttributeType.REQUIRED) @ProcessApplication @Local(ProcessApplicationInterface.class) public class MyEjbProcessApplication extends EjbProcessApplication { protected CdiEventListener cdiEventListener = new CdiEventListener(); @PostConstruct public void start() { deploy(); } @PreDestroy public void stop() { undeploy(); } public ExecutionListener getExecutionListener() { return cdiEventListener; } public TaskListener getTaskListener() { return cdiEventListener; } }",
    "url": "/manual/latest/user-guide/cdi-java-ee-integration/the-cdi-event-bridge/index.html"
  },
  {
    "id": "manual/latest/user-guide/cibseven-run/index.html",
    "title": "CIB seven Run | docs.cibseven.org",
    "content": "This guide gives an introduction to CIB seven Run, a pre-packaged, lightweight distribution of CIB seven. CIB seven Run is easy to configure and does not require Java knowledge. Prerequisites and audience To use this guide, you should at least know what CIB seven is and what it does. Check out the Get Started guides if you have never used CIB seven before. The Installation guide is also worth looking at if you are completely new to CIB seven. This guide will teach you about CIB seven Run and how to configure it. It can serve as a reference page for configuration and operation options. It will not give you a step-by-step guide on how to install CIB seven Run. Head over to the Installation guide for details on how to install and start CIB seven Run. What is CIB seven Run? CIB seven Run is a full distribution of CIB seven. It includes: CIB seven web applications Cockpit Tasklist Admin REST API An example application Starting with CIB seven Run To start with CIB seven Run, download the distribution and unpacking it. You will find the following structure: cibseven-run ├── configuration/ │ ├── keystore/ │ │ └── put your SSL key store here if you want to use HTTPS │ ├── resources/ │ │ └── put your BPMN files, forms and scripts here │ ├── sql/ │ │ └── necessary SQL scripts to prepare your database system │ ├── userlib/ │ │ └── put your database driver and other required JARs here │ ├── default.yml │ └── production.yml ├── internal/ ├── start.bat └── start.sh └── shutdown.sh └── shutdown.bat Execute one of the two start scripts (start.bat for Windows, start.sh for Linux/Mac). After a few seconds, you can access the CIB seven web apps via http://localhost:8080/camunda/app/, the REST API via http://localhost:8080/engine-rest/. When executing one of the two start scripts without any arguments, CIB seven Run will start with a default configuration as a detached process. To shut down CIB seven Run in “detached” mode, use one of the two shutdown scripts (shutdown.bat for Windows, shutdown.sh for Linux/Mac). By explicitly passing arguments to one of the two CIB seven Run start scripts, the default detached mode is disabled and you can configure CIB seven Run according to your needs. Furthermore, CIB seven Run will start as a foreground process unless the --detached argument is explicitly passed to the start.bat or start.sh script. Start script arguments The start scripts (start.bat for Windows, start.sh for Linux/Mac) accept the following arguments: Argument Description Default state --webapps Enables the CIB seven web apps enabled --rest Enables the REST API enabled --example Enables the example application. enabled --production Applies the `production.yaml` configuration file. disabled --detached Starts CIB seven Run as a detached process. This is the default behavior of the start scripts. To disable it, explicitly pass a valid argument to the script. enabled --oauth2 Enables Spring Security OAuth2 integration. See dedicated Spring Security OAuth2 Integration documentation for details. false --help Prints a message showing the available start script arguments. - Starting CIB seven Run using Docker CIB seven Run is also available as a Docker image. Please see the CIB seven Run section of the CIB seven Docker documentation here for more details. Optional components By default, CIB seven Run launches with the web apps, REST API and example modules. If you want to enable only a subset of them, execute the start script through a command-line interface with any of the --webapps, --rest or --example properties to enable the specific modules. Example application By default, CIB seven Run deploys and launches an example application on startup. When launched, this application creates deployments with multiple BPMN and DMN definitions as well as form resources and starts instances of the defined processes. You can disable the deployment of the example application itself by enabling any combination of the other modules with the --webapps and --rest properties of the start script. That way, the example application will not be launched and its resources will not be present on the classpath of CIB seven Run. You can also disable the launch of the example application by setting the application property camunda.bpm.run.example.enabled to false or removing it from the application properties. That way, the example application and its resources will be present on the classpath of CIB seven Run. However, the example application will not be started. Disabling the example application with any of those mechanisms will NOT delete any deployments or process instances from CIB seven Run once they are created. You have to delete this data manually through the web apps, the REST API, or by cleaning the database configured in the application properties. Choose between default and production configuration CIB seven Run ships with two different configuration files which are both located in the configuration folder. The default.yml configuration only contains necessary configuration like the H2 database, a demo user and CORS for REST calls from a client application. The production.yml configuration is intended to provide the recommended properties according to the Security Instructions. When using CIB seven Run in a production environment, make sure to base your custom configuration on this one and carefully read through the security instructions. By default, Run launches with the default.yml configuration. To enable the production.yml configuration, execute the start script with the --production property. Using --production disables the example application. It can be enabled by explicitly passing --example to the start script. However, we do not recommended to use the example application in production. Connect to a Database CIB seven Run is pre-configured to use a file-based H2 database for testing. The database schema and all required tables are automatically created when the engine starts up for the first time. If you want to use a custom standalone database, follow these steps: Make sure your database is among the supported database systems. Create a database schema for CIB seven yourself. Install the database schema to create all required tables and default indices using our database schema installation guide. Drop a JDBC driver jar for your database system in the configuration/userlib folder. Add the JDBC URL and login credentials to the configuration file like described below. Restart CIB seven Run Deploy BPMN Models In the unpacked distro, you will find a resources folder. All files (including BPMN, DMN, CMMN, form, and script files) will be deployed when you start CIB seven Run. You can reference forms and scripts in the BPMN diagram with embedded:deployment:/my-form.html, cibseven-forms:deployment:/myform.form, or deployment:/my-script.js. The deployment requires adding an extra / as a prefix to the filename. Deployments via the REST API are still possible. Configure CIB seven Run Just like all the other distros, you can tailor CIB seven Run to your needs. To do this, you only have to edit one of the configuration files that you can find in the configuration folder. Note: CIB seven Run is based on the CIB seven Spring Boot Starter. All configuration properties from the camunda-spring-boot-starter are available to customize CIB seven Run. Database The distro comes with a file-based h2 database for testing. It is recommended to connect to a standalone database system for use in production. Prefix Property name Description Default value spring.datasource .url The jdbc URL for the database. - .driver-class-name The class name of the JDBC driver for your database system. Remember to put the driver jar for your database system in configuration/userlib. - .username The username for the database connection. - .password The password for the database connection. - Authentication To add authentication to requests against the REST API, you can enable basic authentication. Prefix Property name Description Default value camunda.bpm.run.auth .enabled Switch to enable basic authentication for requests to the REST API. false .authentication Authentication method, currently only basic is supported. basic Cross-Origin Resource Sharing If you want to allow cross-origin requests to the REST API, you need to enable CORS. Prefix Property name Description Default value camunda.bpm.run.cors .enabled Switch to enable CORS. false .allowed-origins Origins that are allowed to make CORS requests. Multiple origins can be separated with commas. To support both HTTP authentication and CORS, allowed-origins must not be \\*. To allow Camunda Modeler to deploy with authentication, including file:// in the allowed origins. \\* (all origins, including file://) .allowed-headers Headers that are allowed to be passed with CORS requests. Multiple headers can be separated with commas. Origin, Accept, X-Requested-With, Content-Type, Access-Control-Request-Method, Access-Control-Request-Headers .exposed-headers Headers that can be read by browsers from a CORS response. Simple response headers should not be included in this list. Multiple headers can be separated with commas. None .allow-credentials A boolean flag that helps a browser determine it can make a CORS request using credentials. false .preflight-maxage Determines how long a browser can cache the result of a pre-flight request in seconds. 1800 REST CIB seven Run can be configured to disable the REST endpoint which exposes the WADL file via a property. Prefix Property name Description Default value camunda.bpm.run.rest .disable-wadl Disables the REST endpoint /application.wadl. Web Application Description Language (WADL) is an XML description of the deployed RESTful web application. false Deployment CIB seven Run also supports configuration options for customizing the deployment. Prefix Property name Description Default value camunda.bpm.run.deployment .deploy-changed-only When set to true, only deployments with changed resources will be deployed to the engine database. When set to false, all deployments will be deployed without filtering their resources. The property can be useful for controlling the deployment behaviour of the engine in case of restarts, similar to the Spring Framework Integration true LDAP Identity Service CIB seven can manage users and authorizations on its own, but if you want to use an existing LDAP authentication database you can enable the LDAP Identity Service Plugin which provides read-only access to the LDAP repository. Find all available configuration properties in the LDAP Plugin Guide Prefix Property name Description Default value camunda.bpm.run.ldap .enabled Switch to enable the LDAP identity service plugin. false LDAP Administrator Authorization You can also use the Administrator Authorization plugin to ensure the appropriate LDAP user or group gains administrative access. Review all the available configuration options in the Administrator Authorization plugin section of our documentation. In the table below, observe the CIB seven Run-specific properties for the Administrator Authorization plugin. Prefix Property name Description Default value camunda.bpm.run.admin-auth .enabled Switch to enable the Administrator Authorization plugin. false Plugin registration CIB seven Run supports two types of plugins. Process engine plugins can be used to extend the process engine configuration to add more functionality. Webapp plugins are used to extend one of the CIB seven webapps (i.e. Cockpit, Tasklist, Admin, Welcome). Both types of plugins are supported in CIB seven Run but have to be registered differently. Process engine plugin registration CIB seven provides a process engine plugin mechanism to enable users to add and adjust process engine features by extending the process engine configuration. You can use plugins developed by CIB, Camunda, or by third-party developers. Get more details on how process engine plugins work on the dedicated process engine plugins documentation section. In the table below, observe the CIB seven Run-specific properties for registering process engine plugins. Prefix Property name Description Default value camunda.bpm.run .process-engine-plugins Define your process engine plugin configurations under this YAML property. Empty List camunda.bpm.run.process-engine-plugins .plugin-class Part of a process-engine-plugins list item. Defines the process engine plugin class. none .plugin-parameters Part of a process-engine-plugins list item. Defines the process engine plugin parameters as key:value pairs. Empty Map Perform the following steps in CIB seven Run to register process engine plugins: Find and read the process engine plugin documentation. Find the canonical name of the process engine plugin Java class that implements the ProcessEnginePlugin interface. Find out if the process engine plugin provides any configuration parameters. You will be able to configure your plugin using those parameters. If the plugin does not provide any properties, skip this step. Download the process engine plugin .jar file and place it to the ${RUN_HOME}/configuration/userlib/ directory. In your CIB seven Run configuration file, add the process engine plugin class and any configuration parameters as list items under the process-engine-plugins YAML property. Once complete, your YAML configuration file should look similar to the following: camunda.bpm.run.process-engine-plugins: - plugin-class: canonical.name.of.the.PluginClass Example process engine plugin registration Let’s say that you want to register a process engine plugin called TestPlugin. The following information is available: The plugin is provided in a .jar archive called camunda-bpm-test-plugin.jar. The name of the Java class that implements the ProcessEnginePlugin interface is TestPlugin. The canonical name of this class is org.cibseven.bpm.run.test.plugins.TestPlugin. The TestPlugin exposes the following two configuration parameters: parameterOne - a String value parameterTwo - a Boolean value We’ll take the following steps: Place the camunda-bpm-test-first-plugin.jar archive in the ${RUN_HOME}/configuration/userlib/ directory. Add the following content to your CIB seven Run YAML configuration file. camunda.bpm.run.process-engine-plugins: - plugin-class: org.cibseven.bpm.run.test.plugins.TestPlugin plugin-parameters: parameterOne: valueOne parameterTwo: true In the example above, we use the TestPlugin canonical name as a YAML key. The YAML value consists of a collection of key-value pairs that represent the configuration parameters for the TestPlugin and their values. Some process engine plugins don’t have configuration parameters. For these, you only need to define the plugin-class YAML property, like so: camunda.bpm.run.process-engine-plugins: - plugin-class: org.cibseven.bpm.run.test.plugins.TestPlugin - plugin-class: org.cibseven.bpm.run.test.plugins.AnotherPlugin Start CIB seven Run. The TestPlugin will be read from the YAML configuration and registered with the process engine. Webapp plugin registration CIB seven provides a mechanism to extend the CIB seven Webapps with your own functionality. You can add plugins at various plugin points. For example, the processes dashboard in Cockpit. A webapp plugin is a maven jar project that provides a server-side and a client-side extension to the webapp. You can find more information about how to structure your plugins here. To register a webapp plugin, simply drop the jar file into the configuration/userlib folder. See the Starting with CIB seven Run section of this guide to find out how to navigate the directories of CIB seven Run. Example application launch CIB seven Run comes with a demo application that deploys resources and starts process instances. You can disable the start of that application so it does not create deployments and process instances. The resources of the application are however still accessible on the classpath of CIB seven Run. Consult the example application section for further details. Prefix Property name Description Default value camunda.bpm.run.example .enabled Switch to enable the example application. false HTTPS CIB seven Run supports HTTPS over SSL. To enable it, you will need a valid SSL certificate signed by a trusted provider and stored in a key store file (either .jks or .p12). For testing, we included a self-signed certificate. You should not use this in production. To enable it, add the following properties to your configuration file. server: ssl: key-store: classpath:keystore.p12 key-store-password: camunda key-store-type: pkcs12 key-alias: camunda key-password: camunda port: 8443 After starting CIB seven Run, you can access the webapps via https://localhost:8443/camunda/app/ and the REST API via https://localhost:8443/engine-rest/. Prefix Property name Description Default value server.ssl .key-store Name of the key store file that holds the SSL certificate. This file must be placed in the configuration/keystore folder and has to be either a .jks or a .p12 file. - .key-store-password Password to access the key store. - .key-store-type Type of the key store. Can either be jks or p12 - .key-alias Name that identifies the SSL certificate in the key store. - .key-password Password to access the SSL certificate in the key store. - Logging CIB seven provides fine-grained and customizable logging. An overview of the available logging categories can be found in the Logging User Guide. To configure the logging behavior in CIB seven Run, customize your configuration file with the following properties. For more information on logging configuration visit the Spring Boot Logging Guide. Prefix Property name Description Default value logging .level.root Set a logging level for all available logging categories. Value can be one of the following: OFF. ERROR. WARN. INFO. DEBUG. FATAL. TRACE - .level.{logger-name} Set a logging level for a specific logging category. Find an overview over the available categories in the Logging User Guide. Value can be one of the following: OFF. ERROR. WARN. INFO. DEBUG. FATAL. TRACE - .file.name Specify a log file location. (e.g. logs/cibseven-run-log.txt) -",
    "url": "/manual/latest/user-guide/cibseven-run/index.html"
  },
  {
    "id": "manual/latest/user-guide/data-formats/configuring-spin-integration/index.html",
    "title": "Configuring Spin Integration | docs.cibseven.org",
    "content": "To use Spin with the process engine, the following is required: The Spin libraries must be on the engine’s classpath The Spin process engine plugin must be registered with the process engine The following sections go into the details of integrating Spin with the process engine. Note that when you use a pre-built Camunda distribution, Spin is already integrated. Artifacts There are three types of Spin artifacts as follows. cibseven-spin-core cibseven-spin-core is a jar that contains only the core Spin classes. It can be combined with single data format artifacts. CIB seven provides the artifacts cibseven-spin-dataformat-json-jackson and cibseven-spin-dataformat-xml-dom (cibseven-spin-dataformat-xml-dom-jakarta for Jakarta XML Binding 4.0 support) that implement JSON and XML processing. These artifacts transitively pull in libraries they need. For example, cibseven-spin-dataformat-json-jackson has a dependency to jackson-databind. cibseven-spin-dataformat-all cibseven-spin-dataformat-all is a fat jar that contains cibseven-spin-core, cibseven-spin-dataformat-json-jackson and cibseven-spin-dataformat-xml-dom as well as all their dependencies. The dependencies are shaded into the spinjar package namespace. Note that the package relocation means that you cannot develop against the original namespaces. Example: cibseven-spin-dataformat-json-jackson uses jackson-databind for object (de-)serialization. A common use case is declaring Jackson annotations in custom classes to finetune JSON handling. With relocated dependencies, annotations in the com.fasterxml.jackson namespace will not be recognized by Spin. In that case, consider using cibseven-spin-core. Keep in mind the implications this may have as described in the Integration Use Cases section. cibseven-engine-plugin-spin cibseven-engine-plugin-spin is a process engine plugin that integrates Spin with a process engine. For example, it registers variable serializers that enable the process engine to store Java objects as JSON. Configuration properties of the Spin plugin The Spin process engine plugin provides the following configuration options: Property Description enableXxeProcessing Toggle the processing of External XML Entities (XXE) in an XML document. Disable to prevent XXE attacks. Default value: false enableSecureXmlProcessing Toggle the secure processing of an XML document. Default value: true Maven coordinates Import the CIB seven BOM to ensure that you use the right version of Spin that is tested to work with your version of the process engine. All Spin artifacts have the group id org.cibseven.spin, so in order to import cibseven-spin-core, we can write: <dependency> <groupId>org.cibseven.spin</groupId> <artifactId>cibseven-spin-core</artifactId> <!-- The version is omitted here, because it is managed via the BOM. Declare a concrete version if you do not use the BOM --> </dependency> Integration Use Cases Depending on the application and process engine setup, it is recommended to use either cibseven-engine-plugin-spin and cibseven-spin-core (plus individual data formats) or cibseven-engine-plugin-spin and cibseven-spin-dataformat-all. The following sections explain when to use which for the most common use cases. Embedded Process Engine If your application manages its own process engine, then using cibseven-engine-plugin-spin with cibseven-spin-core is the recommended approach. Declare the dependencies in the compile scope so that the Spin libraries and their dependencies are added to your application when you bundle it. Configure org.cibseven.spin.plugin.impl.SpinProcessEnginePlugin as a process engine plugin according to the process engine plugin documentation. Application with Camunda Spring Boot Starter Add the dependencies to cibseven-engine-plugin-spin and cibseven-spin-core (along with cibseven-spin-dataformat-json-jackson and cibseven-spin-dataformat-xml-dom as needed) to your application. If you need to use Jakarta XML Binding 4.0 (e.g. Springboot version 3.x.x), use cibseven-spin-dataformat-xml-dom-jakarta instead of cibseven-spin-dataformat-xml-dom. The Spin process engine plugin will be automatically registered with the process engine. Shared Process Engine If you use a shared process engine, Spin is usually installed as a shared library in the application server. Check the installation guide for your application server for how to set up Spin with a shared engine. When using a pre-built distribution of CIB seven, Spin is already pre-configured. Depending on the type of application server, cibseven-engine-plugin-spin should be used with either cibseven-spin-core or cibseven-spin-dataformat-all. In the pre-packaged distributions, the following artifacts are used: Tomcat: cibseven-spin-dataformat-all is provided in Tomcat’s shared library path. Using cibseven-spin-dataformat-all avoids classpath pollution with Spin’s dependencies. For example, this ensures that applications are not forced to use Spin’s version of Jackson. Wildfly: cibseven-spin-core (along with cibseven-spin-dataformat-json-jackson and cibseven-spin-dataformat-xml-dom) are deployed as modules. Thanks to Wildfly’s module system, classpath pollution is not an issue. Whenever a process application is deployed, it receives an implicit module dependency to cibseven-spin-core. If you want to program against the Spin APIs in your process application, you need to declare a dependency to Spin in your application. As Spin is provided by the application server, the following is important: Make sure to set the dependencies to scope provided. This avoids that a copy of the dependencies is packaged with your application, resulting in various classloading problems at runtime. Make sure to depend on the same Spin artifacts that the application server provides, i.e. either cibseven-spin-core or cibseven-spin-dataformat-all.",
    "url": "/manual/latest/user-guide/data-formats/configuring-spin-integration/index.html"
  },
  {
    "id": "manual/latest/user-guide/data-formats/data-formats-in-processes/index.html",
    "title": "Data Formats in Processes | docs.cibseven.org",
    "content": "The main entry point to Spin’s functionality is the static function org.cibseven.spin.Spin.S that can be used to process documents or to map Java objects to a document format. The returned value of this function is a Spin wrapper, which is an intermediary representation of a document and that offers functions for manipulation of the underlying document. Additionally, the functions org.cibseven.spin.Spin.XML and org.cibseven.spin.Spin.JSON can be used that return a strongly-typed Spin wrapper of the provided documents which is useful when writing Java. Refer to the Spin reference documentation on how these methods can be used and what API is offered by the Spin wrappers. The following subsections describe the integration points of the process engine and Spin. For specific documentation on data formats like XML and JSON, please refer to the XML section and the JSON section. Expression Language Integration The Spin engine plugin registers the Spin API entry functions in the context used for expression evaluation. It can therefore be used at all points where the engine allows expression language. Scripting Integration Similar to the EL integration, the Spin functions can be accessed from custom scripts in the supported languages JavaScript, Groovy, Python and Ruby. See the scripting section on how scripting is configured in general in CIB seven. Native JSON and XML Variable Values When working with JSON or XML payloads it wouldn’t be convenient to treat the payload as strings because then features like path-expressions and accessing properties couldn’t be used. Additionally, you do not always need or want a class in your system to represent the JSON/XML. That is why Spin provides native variable values to work with JSON and XML. The Spin API enables access and manipulation of the data in an easy way. Parsing and serialization can be done with a single command. Serializing Process Variables Whenever custom Java objects are set as process variables, they have to be persisted to the database. Thus, a Java object instance has to be serialized. The engine’s default serialization uses standard Java object serialization which ends up as machine-readable bytes in the database. This approach is limited in that the database values cannot be introspected and that a client reading the object has to possess the respective Java class. To alleviate these issues, by using the Spin engine plugin, variables can be serialized using Spin’s data formats. The plugin registers a serializer that looks up all available data formats and offers them for serialization. Extending Serialization Spin offers two interfaces that can be implemented to provide custom data formats and to configure serialization. Every process application may provide a different set of data format providers and configurators. CIB seven then instantiates process-application-specific data formats and ensures that they are only accessible when code is executed within the process application’s context. See the section on process application resource access to understand when the process engine operates in the context of a process application and how a context switch can be enforced. Limitation Data formats provided or configured on process application level currently only apply to the serialization of Object-type variables. Native Spin variables and the Spin standalone API (e.g. S(\"{...}\").prop(\"...\")) only use globally configured data formats.",
    "url": "/manual/latest/user-guide/data-formats/data-formats-in-processes/index.html"
  },
  {
    "id": "manual/latest/user-guide/data-formats/index.html",
    "title": "Data Formats (XML, JSON, Other) | docs.cibseven.org",
    "content": "Spin Dataformat Reference This section explains how to work with data formats such as XML or JSON in CIB seven. The Spin Dataformat Reference provides a complete reference of all data manipulation features available. While CIB seven is a Java platform, process data is not always represented by Java objects. When interacting with external systems, serialized formats such as JSON or XML are often used. While such process variables can be treated by the engine as plain String objects, there is a significant effort required to process such data like parsing, manipulating or mapping from/to Java objects. Thus, CIB seven offers an optional component that eases the work with this kind of data in the process engine. The Camunda Spin project provides data format functionality and can be plugged into the engine. It is a wrapper around well-known libraries for processing data formats like XML and JSON and integrates with the engine’s data handling functionality. Spin is designed to be extensible so that custom data formats can be added to those provided out of the box. As an introductory example, assume a process instance that retrieves a customer’s profile by invoking a RESTful XML web service and that stores the result in a variable called customer. Let the customer variable have the following content: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <customer xmlns=\"http://camunda.org/example\" name=\"Jonny\"> <address> <street>12 High Street</street> <postcode>1234</postcode> </address> </customer> With Spin integrated into the engine, the following expression can be used to evaluate the customer’s post code in a conditional sequence flow: ${XML(customer).xPath(\"/customer/address/postcode\").element().textContent() == \"1234\"} Camunda Spin provides the following engine functionality: Fluent APIs for reading, manipulating and writing text-based data formats like JSON and XML wherever code is plugged into a process Integration of the Spin API functions into the expression language Integration of the Spin API functions into scripting environments Native JSON and XML variable value types Serializing Java process variables by mapping objects to Spin data formats like JSON and XML",
    "url": "/manual/latest/user-guide/data-formats/index.html"
  },
  {
    "id": "manual/latest/user-guide/data-formats/json/index.html",
    "title": "JSON | docs.cibseven.org",
    "content": "For working with JSON, the Spin functions org.cibseven.spin.Spin.S and org.cibseven.spin.Spin.JSON can be used as entry points. The latter offers strongly-typed access to Spin’s JSON API and is preferable when writing Java code. In scripting environments, only the S function is available. The returned Spin wrapper offers methods for manipulating and writing JSON as well as mapping JSON to Java. Furthermore, the entry functions can be provided with Java objects that get implicitly converted to Spin’s intermediary JSON format. The following provides examples on how Camunda Spin can be used in the process engine to work with JSON data. For illustration purposes, let us assume that a String process variable customer containing JSON exists. It has the following content: { \"name\" : \"jonny\", \"address\" : { \"street\" : \"12 High Street\", \"post code\" : 1234 } } If you want to learn how to use JSON objects in an embedded form, please take a look at the Embedded Forms Reference. Further documentation about the usage of Spin can be found in the Camunda Spin Dataformat Reference. Expression Language Integration The Spin entry functions can be used wherever the process engine allows expression language. The following BPMN snippet shows a conditional sequence flow expression based on the customer’s post code: ... <sequenceFlow> <conditionExpression xsi:type=\"tFormalExpression\"> ${S(customer).prop(\"address\").prop(\"post code\").numberValue() == 1234} </conditionExpression> </sequenceFlow> ... If your variable is already a JSON variable value, and not a string like in the previous example, you can omit the S(...) call and directly access the variable: ... <sequenceFlow> <conditionExpression xsi:type=\"tFormalExpression\"> ${customer.jsonPath(\"$.address.post code\").numberValue() == 1234} </conditionExpression> </sequenceFlow> ... Scripting Integration The following example is a script implemented in JavaScript. The script makes use of the Spin API to extract the address object from the customer, add a city name and set it as a process variable: ... <scriptTask id=\"task\" name=\"Script Task\" scriptFormat=\"javascript\"> <script> <![CDATA[ var address = S(customer).prop(\"address\"); address.prop(\"city\", \"New York\"); execution.setVariable(\"address\", address.toString()); ]]> </script> </scriptTask> ... Native JSON Variable Value The native variable value for JSON makes it possible to easily parse a JSON string and wrap it inside an object without the need to have a class representing the JSON. Suppose we want to save the JSON inside a process variable for later use, we could do the following inside a JavaDelegate: public class MyDelegate implements JavaDelegate { @Override public void execute(DelegateExecution execution) throws Exception { String json = \"{\\\"name\\\" : \\\"jonny\\\",\" + \"\\\"address\\\" : {\" + \"\\\"street\\\" : \\\"12 High Street\\\",\" + \"\\\"post code\\\" : 1234\" + \"}\" + \"}\"; JsonValue jsonValue = SpinValues.jsonValue(json).create(); execution.setVariable(\"customerJonny\", jsonValue); } } The call to SpinValues.jsonValue(...).create() will transform the string into a Jackson object wrapped by Spin. If we wanted to retrieve the JSON in another JavaDelegate and, e.g., add some more information, we could do this easily: public class AddDataDelegate implements JavaDelegate { @Override public void execute(DelegateExecution execution) throws Exception { JsonValue customer = execution.getVariableTyped(\"customerJonny\"); customer.getValue().prop(\"creditLimit\", 1000.00); //{\"name\":\"jonny\",\"address\":{\"street\":\"12 High Street\",\"post code\":1234},\"creditLimit\":1000.0} } } When retrieving the JSON value via execution.getVariableTyped() there are two options: serialized and deserialized. Retrieving the variable deserialized by calling either getVariableTyped(\"name\") or getVariableTyped(\"name\", true), the JsonValue contains the wrapped Jackson object to represent the JSON data. Calling getVariableTyped(\"name\", false) results in JsonValue containing only the raw string, which is advantageous if you only need the string, e.g., to pass it to another API. Serializing Process Variables A Java object can be serialized using Spin’s built-in JSON data format. Let us assume that there are two java classes, com.example.Customer and com.example.Address, with the following structure: public class Customer { protected String name; protected Address address; /* constructor, getters and setters omitted for brevity */ } public class Address { protected String street; protected int postCode; /* constructor, getters and setters omitted for brevity */ } The following Java code sets a process variable to a Customer object that is serialized using Spin’s JSON data format: Address address = new Address(\"12 High Street\", 1234); Customer customer = new Customer(\"jonny\", address); ProcessInstance processInstance = runtimeService.startProcessInstanceByKey(\"aProcess\"); ObjectValue typedCustomerValue = Variables.objectValue(customer).serializationDataFormat(\"application/json\").create(); runtimeService.setVariable(processInstance.getId(), \"customer\", typedCustomerValue); The decisive statement is ObjectValue typedCustomerValue = Variables.objectValue(customer).serializationDataFormat(\"application/json\").create(); This creates a variable value from the Customer object. The invocation serializationDataFormat(\"application/json\") tells the process engine in which format the variable should be serialized. This name must match the name of a data format known to Spin. For example, application/json is the name of the built-in JSON data format. Once the variable is set, its serialized value can be retrieved using the type variable API. For example: ObjectValue customer = runtimeService.getVariableTyped(processInstance.getId(), \"customer\"); String customerJson = customer.getValueSerialized(); /* customerJson matches: { \"name\" : \"jonny\", \"address\" : { \"street\" : \"12 High Street\", \"postCode\" : 1234 } } */ Retrieving the variable will deserialize the serialized value if it is not cached already. Please bear in mind that this can pose a security risk if untrusted sources are allowed to store serialized values in process variables that can trigger malicious code execution upon deserialization. Consult the Security Instructions for further information on this. Default Serialization Format The engine can be configured to persist all objects for which no explicit data format is specified as JSON. The process engine configuration offers a property defaultSerializationFormat. To configure default JSON serialization, set this property to application/json. Now, the invocation runtimeService.setVariable(processInstance.getId(), \"customer\", new Customer()) directly serializes the customer object as JSON without explicit declaration of the format.",
    "url": "/manual/latest/user-guide/data-formats/json/index.html"
  },
  {
    "id": "manual/latest/user-guide/data-formats/xml/index.html",
    "title": "XML | docs.cibseven.org",
    "content": "For working with XML, the Spin functions org.cibseven.spin.Spin.S and org.cibseven.spin.Spin.XML can be used as entry points. The latter offers strongly-typed access to Spin’s XML API and is preferable when writing Java code. In scripting environments, only the S function is available. The returned Spin wrapper offers methods for manipulating and writing XML as well as mapping XML to Java. Furthermore, the entry functions can be provided with Java objects that get implicitly converted to Spin’s intermediary XML format. The following provides examples on how Camunda Spin can be used in the process engine to work with XML data. For illustration purposes, let us assume that a String process variable customer containing XML exists. It has the following content: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <customer xmlns=\"http://camunda.org/example\" name=\"Jonny\"> <address> <street>12 High Street</street> <postCode>1234</postCode> </address> </customer> Further documentation about the usage of Spin can be found in the Camunda Spin Dataformat Reference. Expression Language Integration The Spin entry functions can be used wherever the process engine allows expression language. The following BPMN snippet shows a conditional sequence flow expression based on the customer’s post code: ... <sequenceFlow> <conditionExpression xsi:type=\"tFormalExpression\"> ${XML(customer).xPath(\"/customer/address/postCode\").element().textContent() == \"1234\"} </conditionExpression> </sequenceFlow> ... If your variable is already an XML variable value and not a string like in the previous example, you can omit the XML(...) call and directly access the variable: ... <sequenceFlow> <conditionExpression xsi:type=\"tFormalExpression\"> ${customer.xPath(\"/customer/address/postCode\").element().textContent() == \"1234\"} </conditionExpression> </sequenceFlow> ... Scripting Integration The following example is a script implemented in JavaScript. The script makes use of the Spin API to extract the address object from the customer, add a city name and set it as a process variable: ... <scriptTask id=\"task\" name=\"Script Task\" scriptFormat=\"javascript\"> <script> <![CDATA[ var address = S(customer).element(\"address\"); var city = XML(\"<city>New York</city>\"); address.append(city); execution.setVariable(\"address\", address.toString()); ]]> </script> </scriptTask> ... Native XML Variable Value The native variable value for XML makes it possible to easily parse an XML string and wrap it inside an object without the need to have a class representing the XML. Suppose we want to save the XML inside a process variable for later use, we could do the following inside a JavaDelegate: public class MyDelegate implements JavaDelegate { @Override public void execute(DelegateExecution execution) throws Exception { String xml = \"<customer xmlns=\\\"http:\\\\/\\\\/camunda.org/example\\\" name=\\\"Jonny\\\">\" + \"<address>\" + \"<street>12 High Street</street>\" + \"<postCode>1234</postCode>\" + \"</address>\" + \"</customer>\"; XmlValue xmlValue = SpinValues.xmlValue(xml).create(); execution.setVariable(\"customerJonny\", xmlValue); } } The call to SpinValues.xmlValue(...).create() will transform the string into a DomXML object wrapped by Spin. If we wanted to retrieve the XML in another JavaDelegate and, e.g., add some more information, we could do this easily: public class AddDataDelegate implements JavaDelegate { @Override public void execute(DelegateExecution execution) throws Exception { XmlValue customer = execution.getVariableTyped(\"customerJonny\"); SpinXmlElement xmlElement = customer.getValue().append(Spin.XML(\"<creditLimit>1000.00</creditLimit>\")); customer = SpinValues.xmlValue(xmlElement).create(); execution.setVariable(\"customerJonny\", customer); //<?xml version=\"1.0\" encoding=\"UTF-8\"?><customer xmlns=\"http:\\/\\/camunda.org/example\" name=\"Jonny\"><address><street>12 High Street</street><postCode>1234</postCode></address><creditLimit xmlns=\"\">1000.00</creditLimit></customer> } } When retrieving the XML value via execution.getVariableTyped() there are two options: serialized and deserialized. Retrieving the variable deserialized by calling either getVariableTyped(\"name\") or getVariableTyped(\"name\", true) the XmlValue contains the wrapped DomXML object to represent the XML data. Calling getVariableTyped(\"name\", false) results in XmlValue containing only the raw string, which is advantageous if you only need the string to pass it to, e.g., another API. Serializing Process Variables A Java object can be serialized using Spin’s built-in XML data format. Let us assume that there are two Java classes, com.example.Customer and com.example.Address. Spin’s default XML format relies on JAXB which is why JAXB annotations like @XmlRootElement, @XmlAttribute, and @XmlElement can be used to configure the serialization process. Note though that these annotations are not required. The classes look as follows: @XmlRootElement(namespace = \"http://camunda.org/example\") public class Customer { protected String name; protected Address address; @XmlAttribute public String getName() { .. } @XmlElement(namespace = \"http://camunda.org/example\") public Address getAddress() { .. } /* constructor and setters omitted for brevity */ } public class Address { protected String street; protected int postCode; @XmlElement(namespace = \"http://camunda.org/example\") public String getStreet() { .. } @XmlElement(namespace = \"http://camunda.org/example\") public int getPostCode() { .. } /* constructor and setters omitted for brevity */ } The following Java code sets a process variable to a Customer object that is serialized using Spin’s XML data format: Address address = new Address(\"12 High Street\", 1234); Customer customer = new Customer(\"jonny\", address); ProcessInstance processInstance = runtimeService.startProcessInstanceByKey(\"aProcess\"); ObjectValue typedCustomerValue = Variables.objectValue(customer).serializationDataFormat(\"application/xml\").create(); runtimeService.setVariable(processInstance.getId(), \"customer\", typedCustomerValue); The decisive statement is ObjectValue typedCustomerValue = Variables.objectValue(customer).serializationDataFormat(\"application/xml\").create(); This creates a variable value from the customer object. The invocation serializationDataFormat(\"application/xml\") tells the process engine in which format the variable should be serialized. This name must match the name of a data format known to Spin. For example, application/xml is the name of the built-in XML data format. Once the variable is set, its serialized value can be retrieved using the type variable API. For example: ObjectValue customer = runtimeService.getVariableTyped(processInstance.getId(), \"customer\"); String customerXml = customer.getValueSerialized(); /* customerXml matches: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <customer xmlns=\"http://camunda.org/example\" name=\"Jonny\"> <address> <street>12 High Street</street> <postCode>1234</postCode> </address> </customer> */ Retrieving the variable will deserialize the serialized value if it is not cached already. Please bear in mind that this can pose a security risk if untrusted sources are allowed to store serialized values in process variables that can trigger malicious code execution upon deserialization. Consult the Security Instructions for further information on this. Default Serialization Format The engine can be configured to persist all objects for which no explicit data format is specified as XML. The process engine configuration offers a property defaultSerializationFormat. To configure default XML serialization, set this property to application/xml. Now, the invocation runtimeService.setVariable(processInstance.getId(), \"customer\", new Customer()) directly serializes the customer object as XML without explicit declaration of the format.",
    "url": "/manual/latest/user-guide/data-formats/xml/index.html"
  },
  {
    "id": "manual/latest/user-guide/dmn-engine/data-types/index.html",
    "title": "Data Types in the DMN Engine | docs.cibseven.org",
    "content": "A decision table allows to specify the types of inputs and outputs. When the DMN engine evaluates an input or an output, it checks if the type of the value matches the specified type. If the types do not match, the engine tries to transform the value into the specified type or throws an exception. The DMN engine supports basic types which can be extended by custom types. Supported Data Types The following types are supported by the DMN engine: Data Type Can transform from Produce values of type string java.lang.Object StringValue boolean java.lang.Boolean, java.lang.String BooleanValue integer java.lang.Number, java.lang.String IntegerValue long java.lang.Number, java.lang.String LongValue double java.lang.Number, java.lang.String DoubleValue date java.util.Date, java.lang.String, java.time.LocalDateTime, java.time.ZonedDateTime DateValue Each data type transformer produces a typed value which contains the value and additional type informations. If the given type does not match one of the above types then the value is transformed into an untyped value by default. Working with Dates The DMN engine supports a date type which is a combination of date and time. By default, the data type transformer accept objects of the types: java.util.Date Strings having the format yyyy-MM-dd'T'HH:mm:ss java.time.LocalDateTime java.time.ZonedDateTime If you prefer another format or different representation of a date, implement a custom type and replace the default transformer. Setting the Data Type of an Input The type of a decision table input is specified by the typeRef attribute on the inputExpression element. <decision> <decisionTable> <input id=\"orderSum\" label=\"Order sum\"> <inputExpression typeRef=\"double\"> <text>sum</text> </inputExpression> </input> <!-- ... --> </decisionTable> </decision> Setting the Data Type of an Output The type of a decision table output is specified by the typeRef attribute on the output element. <decision> <decisionTable> <!-- ... --> <output id=\"result\" label=\"Check Result\" name=\"result\" typeRef=\"string\" /> <!-- ... --> </decisionTable> </decision> Setting the Data Type of a Variable The type of a decision literal expression result is specified by the typeRef attribute on the variable element. <decision> <variable name=\"result\" typeRef=\"string\" /> <!-- ... --> </decision> Implement a Custom Data Type Use of Internal API Please be aware that these APIs are not part of the public API and may change in later releases. The default data types of the DMN engine can be extended or replaced by custom types. For example, you can add a new type for time or change the transformation to support a different date format or localized boolean constants. To do this, implement a new DmnDataTypeTransformer . The transformation is processed in the transform() method and returns a typed value. If it cannot successfully transform a value, it must throw an IllegalArgumentException. public class CustomDataTypeTransformer implements DmnDataTypeTransformer { public TypedValue transform(Object value) throws IllegalArgumentException { // transform the value into a typed value return typedValue; } } To use this data type transformer in the DMN engine, add it to the DMN engine configuration.",
    "url": "/manual/latest/user-guide/dmn-engine/data-types/index.html"
  },
  {
    "id": "manual/latest/user-guide/dmn-engine/embed/index.html",
    "title": "Embedding the DMN Engine | docs.cibseven.org",
    "content": "The CIB seven DMN engine can be used as a library in a custom application. To achieve this, add the cibseven-engine-dmn artifact to the classpath of the application and then configure and build a decision engine instance. This section provides the required maven coordinates to add the DMN engine as a dependency to your project. It then shows how to configure and build a new DMN engine instance. Maven Coordinates The CIB seven DMN engine is released to Maven Central. Start by importing the cibseven-engine-dmn BOM to ensure correct dependency management. Next, include the cibseven-engine-dmn artifact in the dependencies section. Building a DMN Engine To build a new DMN engine, create a DMN engine configuration. Configure it as needed and then build a new DMN engine from it. // create default DMN engine configuration DmnEngineConfiguration configuration = DmnEngineConfiguration .createDefaultDmnEngineConfiguration(); // configure as needed // ... // build a new DMN engine DmnEngine dmnEngine = configuration.buildEngine(); Configuration of the DMN Engine This section gives more insights of embedded DMN engine configuration. In case you want to use DMN engine as part of the BPMN engine, please refer to the DMN Engine Configuration section of the User Guide for the configuration in that scenario. Decision Table Evaluation Listeners The DMN engine configuration allows you add a custom decision table evaluation listener . A decision table evaluation listener is notified after a decision table has been evaluated. It receives an evaluation event which contains the result of the evaluation. You can decide if the listener should be notified before or after the default listeners. // create default DMN engine configuration DmnEngineConfiguration configuration = DmnEngineConfiguration .createDefaultDmnEngineConfiguration(); // instantiate the listener DmnDecisionTableEvaluationListener myListener = ...; // notify before default listeners configuration.getCustomPreDecisionTableEvaluationListeners() .add(myListener); // notify after default listeners configuration.getCustomPostDecisionTableEvaluationListeners() .add(myListener); A specialized evaluation listener is the metric collector , which records the number of executed decision elements. This metric can be used to monitor the workload of a decision engine. // create default DMN engine configuration DmnEngineConfiguration configuration = DmnEngineConfiguration .createDefaultDmnEngineConfiguration(); // create your metric collector DmnEngineMetricCollector metricCollector = ...; // set the metric collector configuration.setEngineMetricCollector(metricCollector); Decision Evaluation Listeners The DMN engine configuration allows you add a custom decision evaluation listener . A decision evaluation listener is notified after a decision with all the required decisions has been evaluated. It receives an evaluation event which contains the result of the evaluation. You can decide if the listener should be notified before or after the default listeners. // create default DMN engine configuration DmnEngineConfiguration configuration = DmnEngineConfiguration .createDefaultDmnEngineConfiguration(); // instantiate the listener DmnDecisionEvaluationListener myListener = ...; // notify before default listeners configuration.getCustomPreDecisionEvaluationListeners() .add(myListener); // notify after default listeners configuration.getCustomPostDecisionEvaluationListeners() .add(myListener); Customizing and Extending the DMN Engine Use of Internal API Please be aware that these APIs are not part of the public API and may change in later releases. The default DMN engine configuration has further customization and extension points. Customize DMN Transformation It is possible to customize the transformation of DMN by providing a DMN transformer or configuring the default one . Register DMN Transform Listeners The simplest customization is to provide a transform listener . The Listener is notified after a DMN element is transformed. The listener can modify the transformed object. // with a default DMN engine configuration DefaultDmnEngineConfiguration configuration = (DefaultDmnEngineConfiguration) DmnEngineConfiguration .createDefaultDmnEngineConfiguration(); // instantiate transform listener DmnTransformListener myTransformListener = ... ; // add the transform listener configuration.getTransformer() .getTransformListeners() .add(myTransformListener); Register DMN Element Transform Handler While the transform listener allows modifying of the transformed objects, it does not support instantiating custom subclasses. This can be achieved using a custom transform handler . A transform handler is registered for a given DMN model API type like a DecisionTable. First, implement a transform handler which can transform a decision table . public class MyDecisionTableHandler extends DmnElementTransformHandler<DecisionTable, MyDecisionTableImpl> { public MyDecisionTableImpl handleElement(DmnElementTransformContext context, DecisionTable element) { // implement } } Then, register an instance of the handler in the default DMN transformer element handler registry. // with a default DMN engine configuration DefaultDmnEngineConfiguration configuration = (DefaultDmnEngineConfiguration) DmnEngineConfiguration .createDefaultDmnEngineConfiguration(); // add the handler configuration.getTransformer() .getElementTransformHandlerRegistry() .addHandler(DecisionTable.class, new MyDecisionTableHandler()); Register DMN Data Type Transformers The DMN engine supports a set of built-in data types. It is possible to override existing types with new types. Assume you want to support a local date format type. To achieve this, override the existing date transformer by implementing a custom transformer: public class GermanDateDataTypeTransformer extends DateDataTypeTransformer { protected SimpleDateFormat format = new SimpleDateFormat(\"dd.MM.yyyy HH:mm:ss\"); protected Date transformString(String value) { try { return format.parse(value); } catch (ParseException e) { throw new IllegalArgumentException(e); } } } Then, register an instance of the handler in the default DMN transformer element handler registry: // with a default DMN engine configuration DefaultDmnEngineConfiguration configuration = (DefaultDmnEngineConfiguration) DmnEngineConfiguration .createDefaultDmnEngineConfiguration(); // add the data type transformer, // overriding the existing type \"date\": configuration .getTransformer() .getDataTypeTransformerRegistry() .addTransformer(\"date\", new GermanDateDataTypeTransformer()); It is also possible to add a new data type by implementing a new transformer and registering it for a non-existing type name: // with a default DMN engine configuration DefaultDmnEngineConfiguration configuration = (DefaultDmnEngineConfiguration) DmnEngineConfiguration .createDefaultDmnEngineConfiguration(); // add the data type transformer for custom type \"currency\" configuration .getTransformer() .getDataTypeTransformerRegistry() .addTransformer(\"currency\", new currencyTypeTransformer()); Register Hit Policy Handlers The DMN engine supports a subset of the DMN 1.3 hit policies. It is possible to implement new hit policies or override an existing hit policy implementation. // with a default DMN engine configuration DefaultDmnEngineConfiguration configuration = (DefaultDmnEngineConfiguration) DmnEngineConfiguration .createDefaultDmnEngineConfiguration(); // get the DmnHitPolicyHandlerRegistry DmnHitPolicyHandlerRegistry hitPolicyHandlerRegistry = configuration .getTransformer() .getHitPolicyHandlerRegistry(); // register handler you own priority hit policy handler hitPolicyHandlerRegistry .addHandler(HitPolicy.PRIORITY, null, new MyPriorityHitPolicyHandler()); Change default expression languages A DMN decision table has multiple expressions which are evaluated when the table is executed. The default expression language for every expression type can be configured. The following expression types exist: Input Expression: Used to specify the input of a column in a decision table. The default language for input expressions in the DMN engine is FEEL. Input Entry: Used to specify the condition of a rule in a decision table. The default language for input entries in the DMN engine is FEEL. Output Entry: Used to specify the output of a rule in a decision table. The default language for output entries in the DMN engine is FEEL. The default expression language of a DMN decision literal expression can also be configured, the default in the DMN engine is FEEL. Read more about the default expressions in the corresponding section. It is possible to change the default expression language on the DMN engine configuration: DefaultDmnEngineConfiguration configuration = (DefaultDmnEngineConfiguration) DmnEngineConfiguration .createDefaultDmnEngineConfiguration(); configuration .setDefaultInputExpressionExpressionLanguage(\"javascript\"); Please note that the chosen language must be available in the classpath. By default JUEL and FEEL are available. If the JDK includes a JavaScript implementation like Rhino or Nashorn, then javascript is available as well. It is also possible to use other script languages like groovy, python or ruby. Just make sure that the corresponding libraries are available on the classpath at runtime. Customize Expression and Script Resolving The default DMN engine resolves the supported expression and script languages using different providers. To evaluate JUEL expressions, the DMN engine uses the ElProvider configured in the DMN engine configuration. To use another implementation of the Unified Expression Language, replace this implementation. // with a default DMN engine configuration DefaultDmnEngineConfiguration configuration = (DefaultDmnEngineConfiguration) DmnEngineConfiguration .createDefaultDmnEngineConfiguration(); // set a custom el provider configuration.setElProvider(new MyElProvider()); To configure the FEEL engine used you can provide a custom FeelEngineFactory . // with a default DMN engine configuration DefaultDmnEngineConfiguration configuration = (DefaultDmnEngineConfiguration) DmnEngineConfiguration .createDefaultDmnEngineConfiguration(); // set a custom feel engine factory configuration.setFeelEngineFactory(new MyFeelEngineFactory()); Script languages are resolved by the DmnScriptEngineResolver . To customize the script engine resolving, provide an own implementation. // with a default DMN engine configuration DefaultDmnEngineConfiguration configuration = (DefaultDmnEngineConfiguration) DmnEngineConfiguration .createDefaultDmnEngineConfiguration(); // set custom script engine resolver configuration.setScriptEngineResolver(new MyScriptEngineResolver()); Logging The DMN engine uses SLF4J as logging API. The cibseven-dmn-engine artifact does not have a dependency to any of the existing SLF4J backends. This means that you can choose which backend you want to use. One example would be LOGBack, or if you want to use Java util logging, you could use the slf4j-jdk14 artifact. For more information on how to configure and use SLF4J, please refer to the user manual.",
    "url": "/manual/latest/user-guide/dmn-engine/embed/index.html"
  },
  {
    "id": "manual/latest/user-guide/dmn-engine/evaluate-decisions/index.html",
    "title": "Evaluating Decisions using the DMN Engine API | docs.cibseven.org",
    "content": "The DMN engine interface exposes methods for parsing and evaluating DMN Decisions. Parse Decisions Decisions can be parsed from an InputStream or transformed from a DmnModelInstance . This example shows how to parse a decision from an input stream: // create a default DMN engine DmnEngine dmnEngine = DmnEngineConfiguration .createDefaultDmnEngineConfiguration() .buildEngine(); InputStream inputStream = ... // parse all decision from the input stream List<DmnDecision> decisions = dmnEngine.parseDecisions(inputStream); The next example uses the DMN Model API to first create a DmnModelInstance and then transform the decisions: // create a default DMN engine DmnEngine dmnEngine = DmnEngineConfiguration .createDefaultDmnEngineConfiguration() .buildEngine(); // read a DMN model instance from a file DmnModelInstance dmnModelInstance = Dmn.readModelFromFile(...); // parse the decisions List<DmnDecision> decisions = dmnEngine.parseDecisions(dmnModelInstance); The Decision Key A DMN XML file can contain multiple decisions - grouped by the decision requirements graph. To distinguish the decisions, every decision must have an id attribute. <?xml version=\"1.0\" encoding=\"UTF-8\"?> <definitions xmlns=\"https://www.omg.org/spec/DMN/20191111/MODEL/\" id=\"definitions\" name=\"definitions\" namespace=\"http://camunda.org/schema/1.0/dmn\"> <decision id=\"first-decision\" name=\"First Decision\"> <decisionTable> <output id=\"output1\"/> </decisionTable> </decision> <decision id=\"second-decision\" name=\"Second Decision\"> <decisionTable> <output id=\"output2\"/> </decisionTable> </decision> </definitions> The id of a decision in the XML is called key in the context of the DMN engine. To only parse a specific decision from a DMN file, you specify the decision key which corresponds to the id attribute in the XML file. // create a default DMN engine DmnEngine dmnEngine = DmnEngineConfiguration .createDefaultDmnEngineConfiguration() .buildEngine(); // read the DMN XML file as input stream InputStream inputStream = ... // parse only the decision with the key \"second-decision\" DmnDecision decision = dmnEngine.parseDecision(\"second-decision\", inputStream); Parse Decision Requirements Graph In addition to parsing all contained decisions of a decision requirements graph (DRG), the DMN engine can also parse the DRG itself from an InputStream or a DmnModelInstance. // parse the drg from an input stream DmnDecisionRequirementsGraph drg = dmnEngine.parseDecisionRequirementsGraph(inputStream); // get the keys of all containing decisions Set<String> decisionKeys = drg.getDecisionKeys(); // get a containing decision by key DmnDecision decision = drg.getDecision(\"decision\"); // get all containing decisions Collection<DmnDecision> decisions = drg.getDecisions(); The DRG is represented in the XML by the definitions element. The id of the DRG in the XML is called key in the context of the DMN engine. Decision Tables only It is possible to check if a parsed decision is implemented as decision table by using the method isDecisionTable() . // create a default DMN engine DmnEngine dmnEngine = DmnEngineConfiguration .createDefaultDmnEngineConfiguration() .buildEngine(); // read the DMN XML file as input stream InputStream inputStream = ... // parse all decision from the input stream List<DmnDecision> decisions = dmnEngine.parseDecisions(inputStream); // get the first decision DmnDecision decision = decisions.get(0); // do something if it is a decision table if (decision.isDecisionTable()) { // ... } Evaluate Decisions To evaluate (or “execute”) a decision, either pass an already transformed DmnDecision or use a DMN model instance or input stream in combination with a decision key. As input to the evaluation, a set of input variables must be provided. // create a default DMN engine DmnEngine dmnEngine = DmnEngineConfiguration .createDefaultDmnEngineConfiguration() .buildEngine(); // read the DMN XML file as input stream InputStream inputStream = ...; // parse the DMN decision from the input stream DmnDecision decision = dmnEngine.parseDecision(\"decisionKey\", inputStream); // create the input variables VariableMap variables = ...; // evaluate the decision result = dmnEngine.evaluateDecision(decision, variables); // or if the decision is implemented as decision table then you can also use result = dmnEngine.evaluateDecisionTable(decision, variables); Pass Variables To provide the input variables for a decision evaluation you can use a Java Map<String, Object>, resp. a VariableMap or a VariableContext. The following example shows how to use a VariableMap. // create the input variables VariableMap variables = Variables.createVariables() .putValue(\"x\", \"camunda\") .putValue(\"y\", 2015); // evaluate the decision with the input variables result = dmnEngine.evaluateDecision(decision, variables); Alternatively, a VariableContext can be used. Use the VariableContext to support lazy-loading of variables. Interpret the Decision Result The evaluation of a DMN decision returns a DmnDecisionResult . If the decision is implemented as decision table then the result is a list of the matching decision rule results. These results represent a mapping from an output name to an output value. If the decision is instead implemented as decision literal expression then the result is a list which contains only one entry. This entry represents the expression value and is mapped to the variable name. Assume the following example of making a decision to select a dish. The decision table returns the desiredDish as the output. Assume that the decision table is executed with the following input variables: season: “Spring” guestCount: 14 There is a matching rule in the table for the given inputs. The DmnDecisionResult thus consists of one DmnDecisionResultEntries which contains the key desiredDish. To access the output value, get() method of DmnDecisionResultEntries is used: DmnDecisionResult decisionResult = dmnEngine.evaluateDecision(decision, variables); // the size will be 1 int size = decisionResult.size(); // get the matching rule DmnDecisionResultEntries ruleResult = decisionResult.get(0); // get output values by name Object result = ruleResult.get(\"desiredDish\"); The result objects expose additional convenience methods: DmnDecisionResult decisionResult = dmnEngine.evaluateDecision(decision, variables); // returns the first rule result DmnDecisionResultEntries ruleResult = decisionResult.getFirstResult(); // returns first rule result // but asserts that only a single one exists decisionResult.getSingleResult(); // collects only the entries for an output column decisionResult.collectEntries(\"desiredDish\"); // returns the first output entry ruleResult.getFirstEntry(); // also returns the first output entry // but asserts that only a single one exists ruleResult.getSingleEntry(); // shortcut to returns the single output entry of the single rule result // - combine getSingleResult() and getSingleEntry() decisionResult.getSingleEntry(); Note that the decision can also be evaluated using the evaluateDecisionTable() method if it is implemented as decision table. In this case, evaluation returns a DmnDecisionTableResult which is semantically equal and provides the same methods as a DmnDecisionResult. Decisions with Required Decisions If a decision has one or more required decisions, then the required decisions are evaluated first. The results of this evaluations are passed as input for the evaluation of the decision. Assume the following example of making a decision to select beverages. The following decision requirements diagram shows that the Beverages decision requires the Dish decision (from the previous example). When the Beverages decision is evaluated then the DMN engine evaluates the Dish decision first. Assume that the decision is evaluated with the following input variables: season: “Spring” guestCount: 14 guestsWithChildren: false With the above inputs, Dish decision table has one matching rule and generates the output value Stew that is mapped to the output variable desiredDish. The output result of the Dish decision is used as input of the Beverages decision. That means that the input expression desiredDish of the Beverages decision returns the output value Stew of the Dish decision. In general, a decision can access the results (i.e., the output values) of required decisions by there output name. As result, the Beverages decision has two matching rules and generates the output values Guiness and Water. DmnDecision decision = dmnEngine.parseDecision(\"beverages\", inputStream); DmnDecisionResult decisionResult = dmnEngine.evaluateDecision(decision, variables); List<String> beverages = decisionResult.collectEntries(\"beverages\"); Hit Policy of Required Decisions The hit policy of a required decision can affect the result that is passed as input to the requiring decision. If the required decision has a COLLECT hit policy with aggregator then the decision result (i.e. output value) is only the aggregated value. In case of a hit policy with multiple matched rules (i.e., COLLECT without aggregator or RULE ORDER), the output variable is mapped to a list of output values, even if only one rule matched.",
    "url": "/manual/latest/user-guide/dmn-engine/evaluate-decisions/index.html"
  },
  {
    "id": "manual/latest/user-guide/dmn-engine/expressions-and-scripts/index.html",
    "title": "Expressions in the DMN Engine | docs.cibseven.org",
    "content": "Decision tables and decision literal expressions allow specifying different types of expressions. This section describes which types of expressions exist. It lists which expression languages are supported and demonstrates how to change the used expression language for an expression. Expressions in DMN As shown in the decision table and decision literal expression reference, four types of expressions are supported: Input Expression: sets the input value for an input column of the decision table Input Entry: used to determine if a rule of the decision table is applicable Output Entry: returns a value which is added to the output of a matched rule of the decision table Literal Expression: used to determine the value of a decision literal expression You can read more on this in the DMN 1.3 reference. In the DMN 1.3 XML, expressions can be found in the XML elements inputExpression, inputEntry, outputEntry and literalExpression: <definitions xmlns=\"https://www.omg.org/spec/DMN/20191111/MODEL/\" id=\"definitions\" name=\"definitions\" namespace=\"http://camunda.org/schema/1.0/dmn\"> <decision id=\"decision\" name=\"Decision\"> <decisionTable> <input id=\"input\"> <!-- the input expression determines the input value of a column --> <inputExpression> <text>age</text> </inputExpression> </input> <output id=\"output\"/> <rule id=\"rule1\"> <!-- the input entry determines if the rule is applicable --> <inputEntry> <text>[18..30]</text> </inputEntry> <!-- the output entry determines the rule if it is applicable --> <outputEntry> <text>\"okay\"</text> </outputEntry> </rule> </decisionTable> </decision> <decision id=\"decision2 name=\"Decision 2\"> <!-- the literal expression determines the value of this decision --> <literalExpression> <text>a + b</text> </literalExpression> </decision> </definitions> Supported Expression Languages The Camunda DMN engine supports two expression languages out of the box: JUEL: A Camunda-maintained implementation of the Java Unified Expression Language FEEL: The Friendly Enough Expression Language of the DMN 1.2 standard. Depending on the JDK you use, there may also be a Javascript implementation available like Rhino or Nashhorn. You can also use every other script language which provides a JSR-223 implementation. This includes groovy, python and ruby. To use these languages you have to add the corresponding dependency to your project. For example, to use groovy as language for expressions add these dependencies to your project pom.xml: <dependency> <groupId>org.apache.groovy</groupId> <artifactId>groovy</artifactId> <version>${GROOVY_VERSION}</version> </dependency> <dependency> <groupId>org.apache.groovy</groupId> <artifactId>groovy-jsr223</artifactId> <version>${GROOVY_VERSION}</version> </dependency> <dependency> <groupId>org.apache.groovy</groupId> <artifactId>groovy-json</artifactId> <version>${GROOVY_VERSION}</version> </dependency> <dependency> <groupId>org.apache.groovy</groupId> <artifactId>groovy-xml</artifactId> <version>${GROOVY_VERSION}</version> </dependency> <dependency> <groupId>org.apache.groovy</groupId> <artifactId>groovy-templates</artifactId> <version>${GROOVY_VERSION}</version> </dependency> <dependency> <groupId>org.apache.groovy</groupId> <artifactId>groovy-dateutil</artifactId> <version>${GROOVY_VERSION}</version> </dependency> <dependency> <groupId>org.apache.groovy</groupId> <artifactId>groovy-datetime</artifactId> <version>${GROOVY_VERSION}</version> </dependency> Default Expression Languages The default expression languages of the different expression types in the DMN engine are as follows: Input Expression: FEEL Input Entry: FEEL Output Entry: FEEL Literal Expression: FEEL Legacy Behavior You can find how to go back to the legacy behavior, where JUEL was used for input expressions, output entries and literal expressions here. The default language can be changed by setting it directly in the DMN 1.3 XML as global expression language with the expressionLanguage attribute of the definitions element: <!-- this sets the default expression language for all expressions --> <!-- in this file to javascript --> <definitions xmlns=\"https://www.omg.org/spec/DMN/20191111/MODEL/\" id=\"definitions\" name=\"definitions\" namespace=\"http://camunda.org/schema/1.0/dmn\" expressionLanguage=\"javascript\"> <decision id=\"decision\" name=\"Decision\"> <decisionTable> <!-- ... --> </decisionTable> </decision> </definitions> Additionally, it is possible to change the default expression language in the default DMN engine configuration as described in the user guide. Configuring the Expression Language It is also possible to set the language for each expression individually using the expressionLanguage attribute: <definitions xmlns=\"https://www.omg.org/spec/DMN/20191111/MODEL/\" id=\"definitions\" name=\"definitions\" namespace=\"http://camunda.org/schema/1.0/dmn\"> <decision id=\"decision\" name=\"Decision\"> <decisionTable> <input id=\"input\"> <!-- use javascript for this input expression --> <inputExpression expressionLanguage=\"javascript\"> <text>age</text> </inputExpression> </input> <output id=\"output\"/> <rule id=\"rule1\"> <!-- use juel for this input entry --> <inputEntry expressionLanguage=\"juel\"> <text><![CDATA[cellInput >= 18 && cellInput <= 30]]></text> </inputEntry> <!-- use javascript for this output entry --> <outputEntry expressionLanguage=\"javascript\"> <text>\"okay\"</text> </outputEntry> </rule> </decisionTable> </decision> <decision id=\"decision2\" name=\"Decision 2\"> <!-- use groovy for this literal expression --> <literalExpression expressionLanguage=\"groovy\"> <text>a + b</text> </literalExpression> </decision> </definitions> If you want to use another Java Unified Expression Language or FEEL implementation, you can replace the default implementations in the DMN engine configuration. This way you can also change the JSR-223 script engine resolving, for example if you want to configure the script engine before using it.",
    "url": "/manual/latest/user-guide/dmn-engine/expressions-and-scripts/index.html"
  },
  {
    "id": "manual/latest/user-guide/dmn-engine/feel/custom-functions/index.html",
    "title": "FEEL Engine Custom Functions | docs.cibseven.org",
    "content": "CIB seven provides a wrapper for the FEEL Scala Engine to implement Custom Functions, which can be called in expressions and unary tests. Custom Function Behavior Please note that the Custom Function Mechanism of the Standalone FEEL Scala Engine might behave differently. You can add Custom Functions to the Process Engine (or the Standalone DMN Engine) only programmatically through a Process Engine Plugin. Read more about it in the section about how to Register Custom Function Providers. Implement a Custom Function To implement a Custom Function, create a sub-class of FeelCustomFunctionProvider. The following code example shows how to implement a Custom Function: import org.cibseven.bpm.dmn.feel.impl.scala.function.CustomFunction; import org.cibseven.bpm.dmn.feel.impl.scala.function.FeelCustomFunctionProvider; import java.util.Collection; import java.util.HashMap; import java.util.Map; import java.util.Optional; public class CustomFunctionProvider implements FeelCustomFunctionProvider { protected Map<String, CustomFunction> functions = new HashMap<>(); public CustomFunctionProvider() { CustomFunction function = CustomFunction.create() .setParams(\"x\", \"y\") .setFunction(args -> { long argX = (long) args.get(0); long argY = (long) args.get(1); return argX + argY; }) .build(); functions.put(\"myFunction\", function); } @Override public Optional<CustomFunction> resolveFunction(String functionName) { return Optional.ofNullable(functions.get(functionName)); } @Override public Collection<String> getFunctionNames() { return functions.keySet(); } } When calling CustomFunction.create(), a builder is returned that you can use to configure the Custom Function. The builder has the following configuration options: #setParams(String... params) Defines the parameter names of the Custom Function Passed arguments in FEEL must not follow a strict order when calling the parameter name explicitly: myFunction(y: 5, x: 3) #enableVarargs() Enables variable arguments When enabled, the function can have variable arguments for the last parameter The last argument is of type list #setFunction(Function<List<Object>, Object> function) Passes an object of type java.util.function.Function with a list of objects as arguments and an object as the return value Cannot be used together with #setReturnValue #setReturnValue(Object result) Sets the return value The return value is defined on the registration of the function and cannot be changed later on Cannot be used together with #setFunction Register Custom Function Providers You can register the Custom Function Providers using a configuration property. Process Engine You can register Custom Function Providers in the Process Engine Configuration with the help of the property dmnFeelCustomFunctionProviders using a Process Engine Plugin. Standalone DMN Engine The DMN Engine has a property feelCustomFunctionProviders of type List in the DefaultDmnEngineConfiguration to register Custom Function Providers. Type Handling This section describes which argument types are passed into a Custom Function and which types you can return. Argument Types All Java types listed in the “Return Types” section of the FEEL Type Handling documentation can be passed into a Custom Function. Return Types All Java types listed in the “Return Types” section of the FEEL Type Handling documentation plus the types listed in the FEEL Data Types documentation can be returned by a Custom Function.",
    "url": "/manual/latest/user-guide/dmn-engine/feel/custom-functions/index.html"
  },
  {
    "id": "manual/latest/user-guide/dmn-engine/feel/index.html",
    "title": "FEEL Engine | docs.cibseven.org",
    "content": "FEEL is part of the DMN specification and stands for “Friendly Enough Expression Language”. You can use it to evaluate expressions in a decision table. You can use the Expression Language in the following DMN Notation Elements: Input Expressions Input Entries Output Entries Literal Expressions This documentation covers everything integration-specific about the FEEL Scala Engine (opens external link) in the Camunda DMN Engine. Heads Up! If you come from a CIB seven version <= 7.12.x and already use FEEL, please read the documentation about the FEEL Engine Legacy Behavior.",
    "url": "/manual/latest/user-guide/dmn-engine/feel/index.html"
  },
  {
    "id": "manual/latest/user-guide/dmn-engine/feel/legacy-behavior/index.html",
    "title": "FEEL Engine Legacy Behavior | docs.cibseven.org",
    "content": "If you come from a Camunda version <= 7.12.x and already use FEEL, it might be that you need to migrate your DMN models. Refer Camunda docs on how to do this. If you don’t want to migrate your DMN models right now, you can also restore the legacy FEEL behavior by flipping a config flag: To see how this legacy behavior can be enabled again in CIB seven, please see the dmnFeelEnableLegacyBehavior engine configuration property. To enable this behavior in a standalone DMN Engine setup, please refer to the DefaultDmnEngineConfiguration enableFeelLegacyBehavior and setEnableFeelLegacyBehavior methods Heads Up! By using the legacy FEEL Engine, the Camunda DMN Engine only supports FEEL for Input Entries of a decision table – this corresponds to FEEL simple unary tests.",
    "url": "/manual/latest/user-guide/dmn-engine/feel/legacy-behavior/index.html"
  },
  {
    "id": "manual/latest/user-guide/dmn-engine/feel/spin-integration/index.html",
    "title": "FEEL Engine Spin Integration | docs.cibseven.org",
    "content": "This page documents how CIB seven Spin can be used together with the Scala FEEL Engine. Furthermore, it is shown how Spin data types are mapped to FEEL data types, as well as some rules when the former data structures are transformed into the latter. Where can the Spin integration be found The Spin integration for the FEEL Engine is implemented into the Spin Process Engine Plugin since it is expected that the Process Engine should be capable of using Spin, if another component of CIB seven (here, the FEEL Engine) supports its usage. In the case of a standalone DMN Engine setup, the Spin Process Engine Plugin would need to be added as a dependency as well, and the DMN Engine will pick up the necessary classes to enable the Spin FEEL Engine integration. The Maven coordinates for the Spin Process Engine Plugin can be found below: <dependency> <groupId>org.cibseven.bpm</groupId> <artifactId>cibseven-engine-plugin-spin</artifactId> <version>${cibseven.version}</version> </dependency> How does the Spin integration work The Spin integration consists of a Spin “Data Types”-dedicated implementation of the FEEL Engine ValueMapper interface. The SpinValueMapper implementation intercepts any objects of types: SpinJsonNode SpinXmlElement An object of these types, passed as a variable to the FEEL Engine will be converted to the appropriate FEEL data type. Below, you can find an example of how this can be done: // define a JSON variable SpinJsonNode json = Spin.JSON(\"{\\\"customer\\\": \\\"Kermit\\\", \\\"language\\\": \\\"en\\\"}\"); // create a variable map and store the JSON variable VariableMap variables = Variables.createVariables().putValue(\"jsonVariable\", json); // evaluate a decision containing a FEEL expression that uses the JSON variable dmnEngine.evaluateDecision(decisionWithFEEL, variables); What is the FEEL data type mapping of JSON/XML variables When converting JSON/XML variables to a FEEL data type, the provided JSON/XML structure will be mapped to a Context FEEL type. The actual values contained in the data structure will be mapped to the supported FEEL data types documented in the external FEEL documentation here. Spin JSON Variables of type SpinJsonNode are transformed into an equal context, meaning that no transformation happens, it’s basically the JSON structure. Spin JSON: { \"name\": \"Kermit\", \"address\": { \"city\": \"Berlin\", \"zip-code\": 10961 } } FEEL context: { name : \"Kermit\", address : { city : \"Berlin\", zipCode : 10961 } } Spin XML Variables of type SpinXmlElement are transformed into context applying the following rules: every XML element is a context entry every XML attribute is a context entry with prefix @ under the element’s entry multiple XML elements with the same are grouped in the context as list the inner content of an XML element is set as context entry $content if the element or the attribute has a namespace then the context entry has the prefix <NAMESPACE>$ Spin XML: <customer name=\"Kermit\"> <address city=\"Berlin\" zipCode=\"10961\" /> </customer> FEEL context: { customer : { @name : \"Kermit\", address : { @city : \"Berlin\", @zipCode : \"10961\" } } }",
    "url": "/manual/latest/user-guide/dmn-engine/feel/spin-integration/index.html"
  },
  {
    "id": "manual/latest/user-guide/dmn-engine/feel/type-handling/index.html",
    "title": "FEEL Engine Type Handling | docs.cibseven.org",
    "content": "This documentation covers supported types of variable values when used in a FEEL expression and supported output types. In DMN, when defining a typeRef attribute on a Variable, Input or Output element, the DMN Engine tries to convert the result value of the corresponding Literal Expression, Input Expression or the Output Entry. When no typeRef attribute is specified, the DMN Engine passes the return value of the FEEL Engine directly without any conversion. Please see the documentation about Supported Data Types in DMN to learn more about the typeRef attribute. The FEEL Engine might support more types than listed below. However, this page defines which of the types are known for being… …well integrable in CIB seven …covered by automated tests Supported Variable Value Types The variable value types listed in this section can be handled by the FEEL Engine when passing. Java Native Types java.lang.String java.lang.Float java.lang.Double java.lang.Integer java.lang.Long java.lang.Boolean java.util.Date java.util.Map java.util.List Spin Types org.cibseven.spin.json.SpinJsonNode org.cibseven.spin.xml.SpinXmlElement For more information about the Camunda Spin integration, please see the documentation about FEEL Engine Spin Integration. Return Types The table displays: Which return value of a FEEL Expression maps to which Java type Which CIB seven specific variable type is assigned for the respective Java type FEEL Expression Example FEEL Engine Return Type Camunda Variable Type null null null \"foo\" java.lang.String string 3.1415 java.lang.Double double 3 java.lang.Long long true java.lang.Boolean boolean time(\"11:45:30\") java.time.LocalTime object time(\"11:45:30+02:00\") time(\"10:31:10@Europe/Paris\") org.cibseven.feel.syntaxtree.ZonedTime object date(\"2017-03-10\") java.time.LocalDate object date and time(\"2019-08-12T22:22:22\") java.time.LocalDateTime object date and time(\"2019-08-12T22:22:22+02:00\") date and time(\"2019-08-12T22:22:22@Europe/Berlin\") java.time.ZonedDateTime object duration(\"P4D\") java.time.Duration object duration(\"P1Y6M\") java.time.Period object { \"foo\": \"bar\" } java.util.Map * object [ \"foo\", \"bar\", \"baz\" ] java.util.List * object * Since the FEEL Engine is based on the Scala Library, a Scala-specific implementation type for Map and List is used",
    "url": "/manual/latest/user-guide/dmn-engine/feel/type-handling/index.html"
  },
  {
    "id": "manual/latest/user-guide/dmn-engine/index.html",
    "title": "DMN Engine | docs.cibseven.org",
    "content": "The Camunda DMN engine is a Java library which can evaluate DMN decision tables. It implements version 1.3 of the OMG DMN standard to the extent documented in the DMN reference. The DMN engine can be used as library embedded in an application or in combination with CIB seven. This section covers how to embed the library and use it to evaluate decisions. For more information on the integration in CIB seven, please see the corresponding section. You can read more about the DMN 1.3 standard in the DMN reference. A complete example how to embed the decision engine and test decisions can be found on GitHub.",
    "url": "/manual/latest/user-guide/dmn-engine/index.html"
  },
  {
    "id": "manual/latest/user-guide/dmn-engine/testing/index.html",
    "title": "Testing Decisions with the DMN Engine | docs.cibseven.org",
    "content": "To easily test DMN decisions in a JUnit test, the DMN engine provides a JUnit Rule. The DmnEngineRule creates a new default DMN engine. The DMN engine can be used in test cases to parse and evaluate decisions. public class DecisionTest { @Rule public DmnEngineRule dmnEngineRule = new DmnEngineRule(); @Test public void test() { DmnEngine dmnEngine = dmnEngineRule.getDmnEngine(); // load DMN file InputStream inputStream = ...; //create and add variables VariableMap variables = Variables.createVariables(); DmnDecision decision = dmnEngine.parseDecision(\"decision\", inputStream); DmnDecisionResult result = dmnEngine.evaluateDecision(decision, variables); // assert the result // ... } } If you want to create a DMN engine with a custom configuration, you can pass this to the DMN engine rule. public class DecisionTest { @Rule public DmnEngineRule dmnEngineRule = new DmnEngineRule(createCustomConfiguration()); public DmnEngineConfiguration createCustomConfiguration() { // create and return custom configuration return ...; } @Test public void test() { DmnEngine customDmnEngine = dmnEngineRule.getDmnEngine(); // ... } } The DmnDecisionResult implements the interface List<DmnDecisionResultEntries>. Whereas the DmnDecisionResultEntries implements the interface Map<String, Object>. This allows you to use common List or Map asserts.",
    "url": "/manual/latest/user-guide/dmn-engine/testing/index.html"
  },
  {
    "id": "manual/latest/user-guide/ext-client/compatibility-matrix/index.html",
    "title": "Version Compatibility | docs.cibseven.org",
    "content": "Each version of CIB seven is bound to a specific version of the External Task Clients. CIB seven and its compatible Java External Task Client always share the same version. CIB seven version NodeJS client 7.22.0-cibseven 3.1.x 1.1 3.1.x Only these default combinations are recommended (and supported) by Camunda. Nevertheless, each version of the External Task Clients can be combined with newer patch versions of the CIB seven Workflow Engine.",
    "url": "/manual/latest/user-guide/ext-client/compatibility-matrix/index.html"
  },
  {
    "id": "manual/latest/user-guide/ext-client/index.html",
    "title": "External Task Client | docs.cibseven.org",
    "content": "The CIB seven External Task Client allows you to set up remote service tasks for your workflow. There is a supported Java as well as JavaScript implementation. Features Complete External Tasks Extend the lock duration of External Tasks Unlock External Tasks Report BPMN errors and failures Share variables with the Workflow Engine Bootstrapping the Client The client allows to handle service tasks of type “external”. In order to configure and instantiate the client, all supported implementations offer a convenient interface. The communication between the client and the CIB seven workflow engine is HTTP. Hence, the respective URL of the REST API is a mandatory information. Request Interceptors To add additional HTTP headers to the performed REST API requests, the request interceptor method can be used. This becomes necessary, in the context of e.g. authentication. Basic Authentication In some cases it is necessary to secure the REST API of the CIB seven workflow engine via Basic Authentication. For such situations a Basic Authentication implementation is provided by the client. Once configured with user credentials, the basic authentication header is added to each REST API request. Custom Interceptor Custom interceptors can be added while bootstrapping the client. For more details regarding the implementation please check the documentation related to the client of interest. Topic Subscription If a Service Task of the type “External” is placed inside a workflow, a topic name must be specified. The corresponding BPMN 2.0 XML could look as follows: ... <serviceTask id=\"checkCreditScoreTask\" name=\"Check credit score\" camunda:type=\"external\" camunda:topic=\"creditScoreChecker\" /> ... As soon as the Workflow Engine reached an External Task in a BPMN process, a corresponding activity instance is created, which is waiting to be fetched and locked by a client. The client subscribes to the topic and fetches continuously for newly appearing External Tasks provided by the Workflow Engine. Each fetched External Task is marked with a temporary lock. Like this, no other clients can work on this certain External Task in the meanwhile. A lock is valid for the specified period of time and can be extended. When setting up a new topic subscription, it is mandatory to specify the topic name and a handler function. Once a topic has been subscribed, the client can start receiving work items by polling the process engine’s API. Handler Handlers can be used to implement custom methods which are invoked whenever an External Task is fetched and locked successfully. For each topic subscription an External Task handler interface is provided. The handlers are invoked sequentially for each fetched-and-locked external task. Completing Tasks Once the custom methods specified in the handler are completed, the External Task can be completed. This means for the Workflow Engine that the execution will move on. For this purpose, all supported implementations have a complete method which can be called within the handler function. However, the External Task can only be completed, if it is currently locked by the client. Extending the Lock Duration of Tasks Sometimes the completion of custom methods takes longer than expected. In this case the lock duration needs to be extended. This action can be performed by calling an extendLock method passing the new lock duration. The lock duration can only be extended, if the External Task is currently locked by the client. Unlocking Tasks If an External Task is supposed to be unlocked so that other clients are allowed to fetch and lock this task again, an unlock method can be called. The External Task can only be unlocked, if the task is currently locked by the client. Reporting Failures If the client faces a problem that makes it impossible to complete the External Task successfully, this problem can be reported to the Workflow Engine. A failure can only be reported, if the External Task is currently locked by the client. You can find a detailed documentation about this action in the CIB seven User Guide. Reporting BPMN Errors Error boundary events are triggered by BPMN errors. A BPMN error can only be reported, if the External Task is currently locked by the client. You can find a detailed documentation about this action in the CIB seven User Guide. Variables Both external tasks clients are compatible with all data types the CIB seven Engine supports. Variables can be accessed/altered using typed or the untyped API. Process and Local Variables Variables can be treated as process or local variables. The former is set on the highest possible hierarchy of the variable scope and available to its child scopes in the entire process. If a variable, in contrast, is supposed to be set exactly on the provided execution scope, the local type can be used. Note: setting variables does not make sure that variables are persisted. Variables which were set locally on client-side are only available during runtime and get lost if they are not shared with the Workflow Engine by successfully completing the External Task of the current lock. Untyped Variables Untyped variables are stored by using the respective type of their values. It is possible to store/retrieve only a single variable or multiple variables at once. Typed Variables Setting typed variables requires the type to be specified explicitly. Typed variables can also be retrieved, the received object provides a variety of information besides type and value. Of course it is also possible to set and get multiple typed variables. Example: Using Typed JSON, XML and Object variables // obtained via subscription ExternalTaskService externalTaskService = ..; ExternalTask externalTask = ..; VariableMap variables = Variables.createVariables(); JsonValue jsonCustomer = externalTask.getVariableTyped(\"customer\"); // deserialize jsonCustomer.getValue() to customer object // and modify ... variables.put(\"customer\", ClientValues.jsonValue(customerJsonString)); XmlValue xmlContract = externalTask.getvariableTyped(\"contract\"); // deserialize xmlContract.getValue() to contract object // and modify ... variables.put(\"contract\", ClientValues.xmlValue(contractXmlString)); TypedValue typedInvoice = externalTask.getVariableTyped(\"invoice\"); Invoice invoice = (Invoice) typedInvoice.getValue(); // modify invoice object variables.put(\"invoice\", ClientValue.objectValue(invoice) .serializationDataFormat(\"application/xml\").create(); externalTaskService.complete(externalTask, variables); Logging The client implementations support logging various events in the client lifecycle. Hence situations like the following can be reported: External Tasks could not be fetched and locked successfully An exception occurred… while invoking a handler while deserializing variables while invoking a request interceptor … For more details, please check the documentation related to the client of interest. Accessing the internal Apache HttpClientBuilder If there is a need to even further customize the communication of the client, you can get access to the Apache HttpClientBuilder using the ExternalTaskClientBuilder ’s customizeHttpClient method. The method accepts a Consumer as parameter that gives you access to the internal Apache HttpClientBuilder: ExternalTaskClient.create() .baseUrl(\"localhost\") .customizeHttpClient((HttpClientBuilder httpClientBuilder) -> httpClientBuilder.setDefaultRequestConfig(RequestConfig.custom() .setResponseTimeout(Timeout.ofSeconds(30)) .build())) .build(); Examples Complete examples of how to set up the different External Task Clients can be found on Camunda’s GitHub (Java, JavaScript). External task throughput For a high throughput of external tasks, you should balance between the number of external task instances, the number of clients and the duration of handling the work. A rule of thumb for long running tasks (maybe more than 30 secs) would be, to fetch-and-lock the tasks one by one (maskTasks = 1) and adjust the Long Polling interval to your needs (maybe 60 secs, asyncResponseTime = 60000). The Java client supports exponential backoff, default by 500 ms with factor 2, limited by 60000 ms. This could be shorted to your needs, too. As the external task clients do not use any threading internally, you should start as many clients as needed and balance the load with your operating system.",
    "url": "/manual/latest/user-guide/ext-client/index.html"
  },
  {
    "id": "manual/latest/user-guide/ext-client/spring-boot-starter/index.html",
    "title": "External Task Client Spring Boot Starter | docs.cibseven.org",
    "content": "CIB seven provides a Spring Boot Starter for the External Task Client. This allows you to easily add the External Task Client to your Spring Boot application by adding the following Maven dependency to your pom.xml file: <dependency> <groupId>org.cibseven.bpm.springboot</groupId> <artifactId>cibseven-bpm-spring-boot-starter-external-task-client</artifactId> <version>1.1.0</version> </dependency> Please check External Task Client Spring Boot Starter Examples at Camunda GitHub. The Client can subscribe to one or more topic names that are defined in your BPMN process model. When the execution waits in an External Task, the Client executes your custom business logic. For instance, the customer’s credit score is checked, and if successful, the External Task can be marked as completed and the execution proceeds. Requirements External Task Client Spring Boot Starter requires Java 17. Topic Subscription The interface which allows implementing the custom business logic and interacting with the Engine is called ExternalTaskHandler. A subscription is identified by a topic name and configured with a reference to the ExternalTaskHandler bean. You can subscribe the Client to the topic name creditScoreChecker by defining a bean with the return type ExternalTaskHandler and annotate this bean with: @ExternalTaskSubscription(\"creditScoreChecker\") The annotation requires at least the topic name. However, you can apply more configuration options by either referencing the topic name in your application.yml file: camunda.bpm.client: base-url: http://localhost:8080/engine-rest subscriptions: creditScoreChecker: process-definition-key: loan_process include-extension-properties: true variable-names: defaultScore Or, by defining configuration attributes in the annotation: @ExternalTaskSubscription( topicName = \"creditScoreChecker\", processDefinitionKey = \"loan_process\", includeExtensionProperties = true, variableNames = \"defaultScore\" ) Please find the complete list of attributes in the Javadocs . Please Note: A property defined in the application.yml file always overrides the respective attribute defined programmatically via annotation. Handler Configuration Example Please consider the following complete handler bean example: @Configuration @ExternalTaskSubscription(\"creditScoreChecker\") public class CreditScoreCheckerHandler implements ExternalTaskHandler { @Override public void execute(ExternalTask externalTask, ExternalTaskService externalTaskService) { // add your business logic here } } If you want to define multiple handler beans within one configuration class, you can do it as follows: @Configuration public class HandlerConfiguration { @Bean @ExternalTaskSubscription(\"creditScoreChecker\") public ExternalTaskHandler creditScoreCheckerHandler() { return (externalTask, externalTaskService) -> { // add your business logic here externalTaskService.complete(externalTask); }; } @Bean @ExternalTaskSubscription(\"loanGranter\") public ExternalTaskHandler loanGranterHandler() { return (externalTask, externalTaskService) -> { // add your business logic here externalTaskService.complete(externalTask); }; } } Open/close a Topic Subscription When not further configured, a topic subscription is automatically opened when the Spring Boot application starts, meaning the Client starts immediately to fetch External Tasks related to the topic name. There might be situations in which a topic subscription should not be opened immediately when the application starts. You can control this via the auto-open flag. The interface SpringTopicSubscription allows you to open or close a topic programmatically as soon as the subscription has been initialized. The initialization process is triggered as soon as the application is started. When the subscription has been initialized, a SubscriptionInitializedEvent is emitted, and the topic subscription can be opened or closed: @Configuration public class SubscriptionInitializedListener implements ApplicationListener<SubscriptionInitializedEvent> { @Override public void onApplicationEvent(SubscriptionInitializedEvent event) { SpringTopicSubscription topicSubscription = event.getSource(); String topicName = topicSubscription.getTopicName(); boolean isOpen = topicSubscription.isOpen(); if (\"creditScoreChecker\".equals(topicName)) { if(!isOpen) { // Start fetching for External Tasks topicSubscription.open(); } else { // Stop fetching for External Tasks topicSubscription.close(); } } } } Configuration application.yml file The central configuration point is the application.yml file. Client Bootstrapping Please make sure to configure the properties together with the prefix: camunda.bpm.client An example configuration could look as follows: camunda.bpm.client: base-url: http://localhost:8080/engine-rest worker-id: spring-boot-worker basic-auth: username: admin password: admin Available properties: Property name Description Default value base-url Mandatory: Base url of the CIB seven Runtime REST API. worker-id A custom worker id the Workflow Engine is aware of. Note: make sure to choose a unique worker id. hostname + 128 bit UUID max-tasks Specifies the maximum number of tasks that can be fetched within one request. 10 use-priority Specifies whether tasks should be fetched based on their priority or arbitrarily. true use-create-time Specifies whether tasks should be fetched based on their create time in descending order. Use this property in disjunction with order-by-create-time property or a SpringExternalTaskClientException will be thrown. false order-by-create-time Specifies whether tasks should be fetched based on their createTime with the given configured order. It can be either \"asc\" or \"desc\". Use this property in disjunction with use-create-time property or a SpringExternalTaskClientException will be thrown. null async-response-timeout Asynchronous response (long polling) is enabled if a timeout is given. Specifies the maximum waiting time for the response of fetched and locked External Tasks. The response is performed immediately if External Tasks are available at the moment of the request. null disable-auto-fetching Disables immediate fetching for external tasks after bootstrapping the Client. To start fetching ExternalTaskClient#start() must be called. false disable-backoff-strategy Disables the client-side backoff strategy. When set to true, a BackoffStrategy bean is ignored. Heads-up: Please bear in mind that disabling the client-side backoff can lead to heavy load situations on the engine side. To avoid this, please specify an appropriate async-response-timeout. false lock-duration Specifies for how many milliseconds an External Task is locked. Must be greater than zero. It is overridden by the lock duration configured on a topic subscription 20,000 date-format Specifies the date format to de-/serialize date variables. yyyy-MM-dd'T'HH:mm:ss.SSSZ default-serialization-format Specifies the serialization format that is used to serialize objects when no specific format is requested. application/json basic-auth.username Specifies the username credential of the REST API to be authenticated with. basic-auth.password Specifies the password credential of the REST API to be authenticated with. Topic Subscription The properties for topic subscriptions go under: camunda.bpm.client.subscriptions The configuration properties can be applied for each topic name as follows: camunda.bpm.client: # ADD CLIENT CONFIGURATION HERE subscriptions: creditScoreChecker: process-definition-key: loan_process include-extension-properties: true variable-names: defaultScore loanGranter: process-definition-key: loan_process Available properties: Property name Description Default value ${TOPIC_NAME} The Service Task's topic name in the BPMN process model the Client subscribes to. auto-open When false, topic subscription can be opened after the application starts calling SpringTopicSubscription#open(). Otherwise, the Client immediately starts to fetch for External Tasks. true lock-duration Specifies for how many milliseconds an External Task is locked. Must be greater than zero. Overrides the lock duration configured on bootstrapping the Client. 20,000 variable-names Variable names of variables that are supposed to be retrieved. All variables are retrieved by default. null local-variables Whether or not variables from greater scope than the External Task should be fetched. When false, all variables visible in the scope will be fetched. When true, only local variables to the scope of the External Task will be fetched. false include-extension-properties Whether or not to include custom extension properties for fetched External Tasks. When true, all extensionProperties defined in the External Service Task will be provided. When false, extensionProperties defined in the External Service Task will be ignored. false business-key Only External Tasks related to the specified business key are fetched. process-definition-id Only External Tasks related to the specified process definition id are fetched. process-definition-id-in Only External Tasks related to the specified list of process definition ids are fetched. List of ids have logical OR semantic. process-definition-key Only External Tasks related to the specified process definition key are fetched. process-definition-key-in Only External Tasks related to the specified list of process definition keys are fetched. List of keys have logical OR semantic. process-definition-version-tag Only External Tasks related to the specified process definition version tag are fetched. process-variables Only External Tasks related to the specified map of process variables (key: variable name, value: variable value) are fetched. Map of variables have logical OR semantic. without-tenant-id Only External Tasks without a tenant id are fetched. tenant-id-in Only External Tasks related to the specified list of tenant ids are fetched. List of ids have logical OR semantic. Logging To log the Client’s internal workings, you can set the level of the logger org.cibseven.bpm.client.spring to DEBUG. You can set the log level in your application.yml file as follows: logging.level.org.cibseven.bpm.client.spring: DEBUG For debugging, it might be helpful to increase the level of the logger org.cibseven.bpm.client as well. Request Interceptor A request interceptor is called whenever the Client performs an HTTP request. You can use this extension point, for example, to implement a custom authentication strategy like OAuth 2.0. You can register one or more request interceptors by defining beans of type ClientRequestInterceptor: @Configuration public class RequestInterceptorConfiguration implements ClientRequestInterceptor { // ... } Backoff Strategy By default, the Client uses an exponential backoff strategy. You can replace it with a custom strategy by defining a bean of type BackoffStrategy: @Configuration public class BackoffStrategyConfiguration implements BackoffStrategy { // ... } Resolving Properties String-based Client configuration properties can be resolved from a custom properties file by defining a bean of type PropertySourcesPlaceholderConfigurer: @Configuration public class PropertyPlaceholderConfiguration extends PropertySourcesPlaceholderConfigurer { public PropertyPlaceholderConfiguration() { // Specify the *.properties file name that contains the property placeholders Resource location = new ClassPathResource(\"client.properties\"); setLocation(location); } } When using the example shown above, the Client tries to resolve string-based properties from a client.properties file as follows: client.baseUrl=http://localhost:8080/engine-rest client.workerId=spring-boot-worker client.dateFormat=yyyy-MM-dd'T'HH:mm:ss.SSSZ client.serializationFormat=application/json Make sure to reference the respective placeholders defined above in your application.yml file: camunda.bpm.client: base-url: ${client.baseUrl} worker-id: ${client.workerId} date-format: ${client.dateFormat} default-serialization-format: ${client.serializationFormat} Custom Client You can bootstrap the Client programmatically, which skips the internal creation of the Client: @Configuration public class CustomClientConfiguration { @Bean public ExternalTaskClient customClient() { return ExternalTaskClient.create() .baseUrl(\"http://localhost:8080/engine-rest\") .build(); } } Beans You can define handler beans, but more beans are defined internally, and they are beyond your control. However, these beans can be accessed via auto wiring. Client Bean When not already defined by the user (see Custom Client), a bean with the name externalTaskClient of type ExternalTaskClient is constructed. Subscription Bean Based on a handler bean annotated with @ExternalTaskSubscription, a subscription bean of type SpringTopicSubscription is constructed. The bean name is composed of: handler bean name + \"Subscription\" For instance, the following handler bean definition: @Bean @ExternalTaskSubscription(\"creditScoreChecker\") public ExternalTaskHandler creditScoreCheckerHandler() { // ... } Will result in the subscription bean name: creditScoreCheckerHandlerSubscription Spring-only Module If you want to use Spring instead of Spring Boot, you can add the following Maven dependency to your pom.xml file: <dependency> <groupId>org.cibseven.bpm</groupId> <artifactId>cibseven-external-task-client-spring</artifactId> <version>1.1.0</version> </dependency> To bootstrap the Client, use the class annotation @EnableExternalTaskClient. You can find all configuration attributes in the Javadocs .",
    "url": "/manual/latest/user-guide/ext-client/spring-boot-starter/index.html"
  },
  {
    "id": "manual/latest/user-guide/index.html",
    "title": "User Guide | docs.cibseven.org",
    "content": "This document targets Developers who want to use Camunda Process Engine in their applications.",
    "url": "/manual/latest/user-guide/index.html"
  },
  {
    "id": "manual/latest/user-guide/logging/index.html",
    "title": "Logging | docs.cibseven.org",
    "content": "This page provides information about logging in CIB seven. SLF4J Most CIB seven modules, including the CIB seven engine, use slf4j as logging “facade”. This allows users to direct logging output to the logging “backend” of their choice, such as logback or log4j. Preconfigured Logging with a Shared Process Engine When installing CIB seven as a shared process engine in an application server, CIB seven logging is pre-configured. On all application servers except Wildfly, logging is pre-configured using the slf4j-jdk14 bridge. This means that CIB seven effectively re-directs all its logging to Java Util Logging. Both SLF4J API and the slf4j-jdk14 bridge are available in a shared classpath which means that they are available in the classpath of all applications deployed on these servers. On Wildfly, logging is directed to the JBoss logging infrastructure. The SLF4J API is not available in the classpath of custom applications by default. Adding a Logging Backend for Embedded Use When using the CIB seven Maven modules in a custom application, only the slf4j API is pulled in transitively. If you do not provide any backend, nothing will actually be logged. In the following, we provide two alternative examples of how to set up logging. See the SLF4J Documentation for more detailed information on how to add a logging backend. Example Using Java Util Logging If you do not care for a specific logging backend, the simplest option is to direct logging to Java Util Logging by adding the following maven dependency: <dependency> <groupId>org.slf4j</groupId> <artifactId>slf4j-jdk14</artifactId> <version>1.7.26</version> </dependency> Example Using Logback For a more sophisticated logging setup we recommend using Logback. To do so, the following steps are necessary: Add the logback dependency <dependency> <groupId>ch.qos.logback</groupId> <artifactId>logback-classic</artifactId> <version>1.1.2</version> </dependency> Add a file named logback.xml. Example configuration: <configuration> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <!-- encoders are assigned the type ch.qos.logback.classic.encoder.PatternLayoutEncoder by default --> <encoder> <pattern>%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern> </encoder> </appender> <!-- cibseven --> <logger name=\"org.cibseven\" level=\"info\" /> <!-- common dependencies --> <logger name=\"org.apache.ibatis\" level=\"info\" /> <logger name=\"javax.activation\" level=\"info\" /> <logger name=\"org.springframework\" level=\"info\" /> <root level=\"debug\"> <appender-ref ref=\"STDOUT\" /> </root> </configuration> Also make sure to make mybatis use SLF4J as logger by adding LogFactory.useSlf4jLogging(); somewhere in your setup code. Process Data Context In order to provide details on the current execution context of log statements, we set process execution-specific data in the Mapped Diagnostic Context (MDC). The process data is held in the MDC for the time of process execution and removed from it after the execution context is successfully left. In case of arising exceptions upon execution, the data is kept in the MDC until the calling context, i.e. the JobExecutor or the surrounding command, finished its logging. The keys at which the properties are accessible in the MDC can be defined in the process engine configuration. In order to access the MDC data, you need to adjust the logging pattern of your logging configuration. An example using Logback could look as follows <configuration> ... <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder> <pattern>%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} context:[%X] - %msg%n</pattern> </encoder> </appender> ... </configuration> By adding the context:[%X] to your configuration, all values that are present in the MDC at the time the log statement is created will be displayed. Please refer to the manual of your logging framework for further information on how to access the MDC, e.g. the Logback documentation. Logging Categories Process Engine The process engine logs on the following categories Logger Description org.cibseven.bpm.application logs details for the deployed process application on the engine org.cibseven.bpm.container logs container operations in the engine org.cibseven.bpm.engine.bpmn.behavior logs operations performed on bpmn activities org.cibseven.bpm.engine.bpmn.parser logs events that occur during the parsing of the bpmn models org.cibseven.bpm.engine.cfg logs process engine configuration's initialization details org.cibseven.bpm.engine.cmd logs the start and end of all commands that the engine performs org.cibseven.bpm.engine.cmmn.behavior logs exceptions that occur during cmmn execution for incompatible cmmn behavior org.cibseven.bpm.engine.cmmn.operation logs exceptions during execution of cmmn operations org.cibseven.bpm.engine.cmmn.transformer logs cmmn transformer operations performed by the engine org.cibseven.bpm.engine.context command context logs including executing atomic operations and bpmn stack traces during exceptions You can override the default DEBUG log level for bpmn stack traces, see the Logging level parameters section. org.cibseven.bpm.engine.core logs engine's core operations, e.g. performing atomic operations org.cibseven.bpm.engine.dmn logs exceptions that occur during decision evaluation org.cibseven.bpm.dmn.feel logs events that occur during decision evaluation with the JUEL FEEL Engine org.cibseven.bpm.dmn.feel.scala logs events that occur during decision evaluation with the Scala FEEL Engine org.cibseven.feel.FeelEngine logs events that occur during expression evaluation with the Scala FEEL Engine org.cibseven.bpm.engine.externaltask logger for the external task org.cibseven.bpm.engine.identity logger of the IdentityService, for example logs information whether a user is locked org.cibseven.bpm.engine.incident logs details during incident processing org.cibseven.bpm.engine.jobexecutor logs operations performed by the job executor, such as job acquisition org.cibseven.bpm.engine.metrics logs details regarding the engine metrics org.cibseven.bpm.engine.migration logs exceptions that occur during process migration org.cibseven.bpm.engine.persistence logs the identity of all entities that the engine inserts/deletes/updates in the database org.cibseven.bpm.engine.plugin.admin logs authorization details for administrators if AdministratorAuthorizationPlugin is enabled org.cibseven.bpm.engine.pvm logs the Process Virtual Machine (PVM) operations, e.g. entering/leaving an activity, creating/destroying a scope org.cibseven.bpm.engine.rest.exception logs the exceptions thrown in the REST API org.cibseven.bpm.engine.script logs script processing details, e.g. evaluating, compiling org.cibseven.bpm.engine.security logs exceptions that occur during password hashing org.cibseven.bpm.engine.test logger used in the engine tests org.cibseven.bpm.engine.tx logs transaction details, e.g. commits and rollbacks org.cibseven.bpm.engine.util logs engine utility operations like xml parsing, reading streams, class loading issues, parsing intervals/duration, etc. org.cibseven.bpm.webapp logs events from the CIB seven web apps (Cockpit, Tasklist, and Admin), like user-initiated log in and log out events and cache validation time information. By default, the engine output contains logs with level ERROR, WARNING, and INFO. To enable more log output, e.g. for the purpose of debugging, configure the level of a logger to DEBUG or TRACE. Heads Up! The output of loggers can change with newer CIB seven versions. Heads Up! In Tomcat, logging is handled by java.util.logging via Tomcat’s JULI implementation. Note that the log levels DEBUG and TRACE are called FINE and FINEST in this environment. When to use engine loggers? Increasing the level of some engine loggers can provide more insights to analyze the engine behavior. Please be aware, some of the loggers can create large amounts of output when changing their level to DEBUG or TRACE. In this section, common scenarios are listed where increasing the engine log levels can be helpful. Database statements To check the database statements performed by the engine in most of the cases, it will be sufficient to increase the level of org.cibseven.bpm.engine.persistence and org.cibseven.bpm.engine.impl.persistence.entity loggers. On level DEBUG, they log all SQL statements with their parameters. When set to TRACE, the results of the statements are logged in addition. Note if a query has many results, the log output will be large. However, some of the statements are not covered by only these two loggers. The full list to see all of the engine database statements is: org.cibseven.bpm.engine.persistence org.cibseven.bpm.engine.impl.persistence.entity org.cibseven.bpm.engine.impl.history.event org.cibseven.bpm.engine.impl.batch org.cibseven.bpm.engine.impl.cmmn.entity org.cibseven.bpm.engine.impl.dmn.entity.repository org.cibseven.bpm.engine.history Here is an example of how the server log will look like: 25-Nov-2019 15:15:57.870 FINE [thread-1] o.c.c.l.BaseLogger.logDebug ENGINE-03006 Cache state after flush: [ PERSISTENT GroupEntity[development] ] 25-Nov-2019 15:15:57.871 FINE [thread-1] o.c.c.l.BaseLogger.logDebug ENGINE-03009 SQL operation: 'INSERT'; Entity: 'AuthorizationEntity[id=19ac0d96-0f8e-11ea-8b01-e4a7a094a9d6]' 25-Nov-2019 15:15:57.871 FINE [thread-1] o.a.i.l.j.BaseJdbcLogger.debug ==> Preparing: insert into ACT_RU_AUTHORIZATION ( ID_, TYPE_, GROUP_ID_, USER_ID_, RESOURCE_TYPE_, RESOURCE_ID_, PERMS_, REV_ ) values ( ?, ?, ?, ?, ?, ?, ?, 1 ) 25-Nov-2019 15:15:57.872 FINE [thread-1] o.a.i.l.j.BaseJdbcLogger.debug ==> Parameters: 19ac0d96-0f8e-11ea-8b01-e4a7a094a9d6(String), 1(Integer), development(String), null, 2(Integer), development(String), 2(Integer) 25-Nov-2019 15:17:17.075 FINE [thread-2] o.a.i.l.j.BaseJdbcLogger.debug ==> Preparing: update ACT_ID_GROUP set REV_ = ?, NAME_ = ?, TYPE_ = ? where ID_ = ? and REV_ = ? 25-Nov-2019 15:17:17.076 FINE [thread-2] o.a.i.l.j.BaseJdbcLogger.debug ==> Parameters: 2(Integer), Dev-Department(String), DEV(String), development(String), 1(Integer) To enable the logging for a specific database entity, please provide the namespace of the MyBatis mapper (all mappers). Usually it is the full class name of that entity, e.g.: org.cibseven.bpm.engine.impl.batch.BatchEntity org.cibseven.bpm.engine.impl.persistence.entity.JobEntity org.cibseven.bpm.engine.impl.persistence.entity.VariableInstanceEntity For further information please visit the MyBatis documentation about logging.. Diagnosing Job Execution To investigate the Job Execution behavior, as a start switch the level of the following loggers to DEBUG: org.cibseven.bpm.engine.impl.persistence.entity.JobEntity - logs the job execution statements org.cibseven.bpm.engine.jobexecutor - further job execution logs such as job acquisition and execution operations org.cibseven.bpm.engine.cmd - the start/end of commands will help to determinate in which command the job is being executed The server log will contain logs similar to: 25-Nov-2019 15:45:27.613 INFO [main] o.c.c.l.BaseLogger.logInfo ENGINE-14014 Starting up the JobExecutor[org.cibseven.bpm.engine.impl.jobexecutor.RuntimeContainerJobExecutor]. 25-Nov-2019 15:45:27.615 INFO [Thread-6] o.c.c.l.BaseLogger.logInfo ENGINE-14018 JobExecutor[org.cibseven.bpm.engine.impl.jobexecutor.RuntimeContainerJobExecutor] starting to acquire jobs 25-Nov-2019 15:45:27.619 FINE [Thread-6] o.c.c.l.BaseLogger.logDebug ENGINE-13005 Starting command -------------------- AcquireJobsCmd ---------------------- 25-Nov-2019 15:45:27.620 FINE [Thread-6] o.c.c.l.BaseLogger.logDebug ENGINE-13009 opening new command context 25-Nov-2019 15:45:27.689 FINE [Thread-6] o.a.i.l.j.BaseJdbcLogger.debug ==> Preparing: select RES.ID_, RES.REV_, RES.DUEDATE_, RES.PROCESS_INSTANCE_ID_, RES.EXCLUSIVE_ from ACT_RU_JOB RES where (RES.RETRIES_ > 0) and ( RES.DUEDATE_ is null or RES.DUEDATE_ <= ? ) and (RES.LOCK_OWNER_ is null or RES.LOCK_EXP_TIME_ < ?) and RES.SUSPENSION_STATE_ = 1 and (RES.DEPLOYMENT_ID_ is null ) and ( ( RES.EXCLUSIVE_ = 1 and not exists( select J2.ID_ from ACT_RU_JOB J2 where J2.PROCESS_INSTANCE_ID_ = RES.PROCESS_INSTANCE_ID_ -- from the same proc. inst. and (J2.EXCLUSIVE_ = 1) -- also exclusive and (J2.LOCK_OWNER_ is not null and J2.LOCK_EXP_TIME_ >= ?) -- in progress ) ) or RES.EXCLUSIVE_ = 0 ) LIMIT ? OFFSET ? 25-Nov-2019 15:45:27.692 FINE [Thread-6] o.a.i.l.j.BaseJdbcLogger.debug ==> Parameters: 2019-11-25 15:45:27.621(Timestamp), 2019-11-25 15:45:27.621(Timestamp), 2019-11-25 15:45:27.621(Timestamp), 3(Integer), 0(Integer) 25-Nov-2019 15:45:27.693 FINE [Thread-6] o.a.i.l.j.BaseJdbcLogger.debug <== Total: 1 25-Nov-2019 15:45:27.695 FINE [Thread-6] o.c.c.l.BaseLogger.logDebug ENGINE-13011 closing existing command context 25-Nov-2019 15:45:27.699 FINE [Thread-6] o.a.i.l.j.BaseJdbcLogger.debug ==> Preparing: update ACT_RU_JOB SET REV_ = ?, LOCK_EXP_TIME_ = ?, LOCK_OWNER_ = ?, DUEDATE_ = ?, PROCESS_INSTANCE_ID_ = ?, EXCLUSIVE_ = ? where ID_= ? and REV_ = ? 25-Nov-2019 15:45:27.703 FINE [Thread-6] o.a.i.l.j.BaseJdbcLogger.debug ==> Parameters: 90(Integer), 2019-11-25 15:50:27.695(Timestamp), 62eae13f-c636-4a21-a80e-c82fc028a959(String), 2019-11-25 00:01:00.0(Timestamp), null, true(Boolean), 9e1a4275-0c41-11ea-8035-e4a7a094a9d6(String), 89(Integer) 25-Nov-2019 15:45:27.706 FINE [Thread-6] o.c.c.l.BaseLogger.logDebug ENGINE-13006 Finishing command -------------------- AcquireJobsCmd ---------------------- Find more information for Diagnosing the Job Executor in this blog post - The Job Executor: What Is Going on in My Process Engine?. Diagnosing Deadlocks The engine logging will provide further insights in case of deadlock issues by increasing the level of the command and the persistence loggers. First, determine the resource involved in the deadlock, then try to narrow down, which are the two transactions blocking each other: org.cibseven.bpm.engine.persistence - the persistence logger will log all the identity of engine entities to find the involved resources causing the deadlock org.cibseven.bpm.engine.cmd - the command output will help to determinate the scope of the involved transactions which are causing the deadlock When the issue occurs for a specific entity (e.g. VariableInstance), consider enabling the logger of that entity as well (org.cibseven.bpm.engine.impl.persistence.entity.VariableInstanceEntity). Then the output will include the statements of these entities to observe the changes which are performed. Here is a sample of what traces the server log file will contain when increasing the level of these loggers. 25-Nov-2019 16:00:50.675 FINE [thread-1] o.c.c.l.BaseLogger.logDebug ENGINE-13005 Starting command -------------------- RemoveExecutionVariablesCmd ---------------------- 25-Nov-2019 16:00:50.676 FINE [thread-1] o.c.c.l.BaseLogger.logDebug ENGINE-13009 opening new command context 25-Nov-2019 16:00:50.718 FINE [thread-1] o.c.c.l.BaseLogger.logDebug ENGINE-03006 Cache state after flush: [ PERSISTENT VariableInstanceEntity[0ec1ab1d-0f8d-11ea-8b01-e4a7a094a9d6] PERSISTENT ProcessDefinitionEntity[invoice:2:ae69d3b4-0c41-11ea-a8eb-e4a7a094a9d6] PERSISTENT HistoricVariableUpdateEventEntity[5eba854e-0f94-11ea-92d9-e4a7a094a9d6] PERSISTENT ExecutionEntity[0ec04b8b-0f8d-11ea-8b01-e4a7a094a9d6] PERSISTENT UserOperationLogEntryEventEntity[5ebb6faf-0f94-11ea-92d9-e4a7a094a9d6] PERSISTENT HistoricVariableInstanceEntity[ddea4bef-0f93-11ea-b2ca-e4a7a094a9d6] ] 25-Nov-2019 16:00:50.722 FINE [thread-1] o.c.c.l.BaseLogger.logDebug ENGINE-03008 Flush Summary: [ INSERT UserOperationLogEntryEventEntity[5ebb6faf-0f94-11ea-92d9-e4a7a094a9d6] INSERT HistoricVariableUpdateEventEntity[5eba854e-0f94-11ea-92d9-e4a7a094a9d6] DELETE VariableInstanceEntity[ddea4bef-0f93-11ea-b2ca-e4a7a094a9d6] UPDATE HistoricVariableInstanceEntity[ddea4bef-0f93-11ea-b2ca-e4a7a094a9d6] ] 25-Nov-2019 16:00:50.725 FINE [thread-1] o.c.c.l.BaseLogger.logDebug ENGINE-03009 SQL operation: 'INSERT'; Entity: 'HistoricVariableUpdateEventEntity[id=5eba854e-0f94-11ea-92d9-e4a7a094a9d6]' 25-Nov-2019 16:00:50.726 FINE [thread-1] o.c.c.l.BaseLogger.logDebug ENGINE-03009 SQL operation: 'DELETE'; Entity: 'VariableInstanceEntity[id=ddea4bef-0f93-11ea-b2ca-e4a7a094a9d6]' 25-Nov-2019 16:00:50.727 FINE [thread-1] o.a.i.l.j.BaseJdbcLogger.debug ==> Preparing: delete from ACT_RU_VARIABLE where ID_ = ? and REV_ = ? 25-Nov-2019 16:00:50.728 FINE [thread-1] o.a.i.l.j.BaseJdbcLogger.debug ==> Parameters: ddea4bef-0f93-11ea-b2ca-e4a7a094a9d6(String), 2(Integer) 25-Nov-2019 16:00:50.730 FINE [thread-1] o.c.c.l.BaseLogger.logDebug ENGINE-03009 SQL operation: 'UPDATE'; Entity: 'HistoricVariableInstanceEntity[id=ddea4bef-0f93-11ea-b2ca-e4a7a094a9d6]' 25-Nov-2019 16:00:50.737 FINE [thread-1] o.c.c.l.BaseLogger.logDebug ENGINE-13006 Finishing command -------------------- RemoveExecutionVariablesCmd ---------------------- The snippet contains the start and of RemoveExecutionVariablesCmd, the flush summary of the operation, and the database statements of the variable instance. Legacy: Java Util Logging Some CIB seven modules still use Java Util Logging directly. The use of Java Util Logging in these modules is considered deprecated and will be gradually migrated to slf4j in future releases. List of modules still using Java Util Logging: cibseven-ejb-service cibseven-ejb-client cibseven-jobexecutor-ra cibseven-jobexecutor-rar cibseven-engine-cdi cibseven-engine-spring cibseven-engine-rest Wildfly Subsystems",
    "url": "/manual/latest/user-guide/logging/index.html"
  },
  {
    "id": "manual/latest/user-guide/model-api/bpmn-model-api/create-a-model/index.html",
    "title": "Create a Model | docs.cibseven.org",
    "content": "To create a new BPMN model from scratch you have to create an empty BPMN model instance with the following method: BpmnModelInstance modelInstance = Bpmn.createEmptyModel(); The next step is to create a BPMN definitions element. Set the target namespace on it and add it to the newly created empty model instance. Definitions definitions = modelInstance.newInstance(Definitions.class); definitions.setTargetNamespace(\"http://camunda.org/examples\"); modelInstance.setDefinitions(definitions); Usually you want to add a process to your model. This follows the same 3 steps as the creation of the BPMN definitions element: Create a new instance of the BPMN element Set attributes and child elements of the element instance Add the newly created element instance to the corresponding parent element Process process = modelInstance.newInstance(Process.class); process.setId(\"process\"); definitions.addChildElement(process); To simplify this repeating procedure, you can use a helper method like this one. protected <T extends BpmnModelElementInstance> T createElement(BpmnModelElementInstance parentElement, String id, Class<T> elementClass) { T element = parentElement.getModelInstance().newInstance(elementClass); element.setAttributeValue(\"id\", id, true); parentElement.addChildElement(element); return element; } After you created the elements of your process like start event, tasks, gateways and end event, you have to connect the elements with sequence flows. Again, this follows the same 3 steps of element creation and can be simplified by the following helper method. public SequenceFlow createSequenceFlow(Process process, FlowNode from, FlowNode to) { String identifier = from.getId() + \"-\" + to.getId(); SequenceFlow sequenceFlow = createElement(process, identifier, SequenceFlow.class); process.addChildElement(sequenceFlow); sequenceFlow.setSource(from); from.getOutgoing().add(sequenceFlow); sequenceFlow.setTarget(to); to.getIncoming().add(sequenceFlow); return sequenceFlow; } Validate the model against the BPMN 2.0 specification and convert it to an XML string or save it to a file or stream. // validate the model Bpmn.validateModel(modelInstance); // convert to string String xmlString = Bpmn.convertToString(modelInstance); // write to output stream OutputStream outputStream = new OutputStream(...); Bpmn.writeModelToStream(outputStream, modelInstance); // write to file File file = new File(...); Bpmn.writeModelToFile(file, modelInstance); Example 1: Create a Simple Process With One User Task With the basic helper methods from above it is very easy and straightforward to create simple processes. First, create a process with a start event, user task and an end event. The following code creates this process using the helper methods from above (without the DI elements). // create an empty model BpmnModelInstance modelInstance = Bpmn.createEmptyModel(); Definitions definitions = modelInstance.newInstance(Definitions.class); definitions.setTargetNamespace(\"http://camunda.org/examples\"); modelInstance.setDefinitions(definitions); // create the process Process process = createElement(definitions, \"process-with-one-task\", Process.class); // create start event, user task and end event StartEvent startEvent = createElement(process, \"start\", StartEvent.class); UserTask task1 = createElement(process, \"task1\", UserTask.class); task1.setName(\"User Task\"); EndEvent endEvent = createElement(process, \"end\", EndEvent.class); // create the connections between the elements createSequenceFlow(process, startEvent, task1); createSequenceFlow(process, task1, endEvent); // validate and write model to file Bpmn.validateModel(modelInstance); File file = File.createTempFile(\"bpmn-model-api-\", \".bpmn\"); Bpmn.writeModelToFile(file, modelInstance); Example 2: Create a Simple Process With Two Parallel Tasks Even more complex processes can be created with a few lines of code with the standard BPMN model API. // create an empty model BpmnModelInstance modelInstance = Bpmn.createEmptyModel(); Definitions definitions = modelInstance.newInstance(Definitions.class); definitions.setTargetNamespace(\"http://camunda.org/examples\"); modelInstance.setDefinitions(definitions); // create elements StartEvent startEvent = createElement(process, \"start\", StartEvent.class); ParallelGateway fork = createElement(process, \"fork\", ParallelGateway.class); ServiceTask task1 = createElement(process, \"task1\", ServiceTask.class); task1.setName(\"Service Task\"); UserTask task2 = createElement(process, \"task2\", UserTask.class); task2.setName(\"User Task\"); ParallelGateway join = createElement(process, \"join\", ParallelGateway.class); EndEvent endEvent = createElement(process, \"end\", EndEvent.class); // create flows createSequenceFlow(process, startEvent, fork); createSequenceFlow(process, fork, task1); createSequenceFlow(process, fork, task2); createSequenceFlow(process, task1, join); createSequenceFlow(process, task2, join); createSequenceFlow(process, join, endEvent); // validate and write model to file Bpmn.validateModel(modelInstance); File file = File.createTempFile(\"bpmn-model-api-\", \".bpmn\"); Bpmn.writeModelToFile(file, modelInstance);",
    "url": "/manual/latest/user-guide/model-api/bpmn-model-api/create-a-model/index.html"
  },
  {
    "id": "manual/latest/user-guide/model-api/bpmn-model-api/delegation-code/index.html",
    "title": "Delegation Code | docs.cibseven.org",
    "content": "If you use Delegation Code, you can access the BPMN model instance and current element of the executed process. If a BPMN model is accessed, it will be cached to avoid redundant database queries. Java Delegate If your class implements the org.cibseven.bpm.engine.delegate.JavaDelegate interface, you can access the BPMN model instance and the current flow element. In the following example the JavaDelegate was added to a service task in the BPMN model. Therefore the returned flow element can be cast to a ServiceTask. public class ExampleServiceTask implements JavaDelegate { public void execute(DelegateExecution execution) throws Exception { BpmnModelInstance modelInstance = execution.getBpmnModelInstance(); ServiceTask serviceTask = (ServiceTask) execution.getBpmnModelElementInstance(); } } Execution Listener If your class implements the org.cibseven.bpm.engine.delegate.ExecutionListener interface, you can access the BPMN model instance and the current flow element. As an Execution Listener can be added to several elements like process, events, tasks, gateways and sequence flows, it can not be guaranteed which type the flow element will be. public class ExampleExecutionListener implements ExecutionListener { public void notify(DelegateExecution execution) throws Exception { BpmnModelInstance modelInstance = execution.getBpmnModelInstance(); FlowElement flowElement = execution.getBpmnModelElementInstance(); } } Task Listener If your class implements the org.cibseven.bpm.engine.delegate.TaskListener interface, you can access the BPMN model instance and the current user task since a Task Listener can only be added to a user task. public class ExampleTaskListener implements TaskListener { public void notify(DelegateTask delegateTask) { BpmnModelInstance modelInstance = delegateTask.getBpmnModelInstance(); UserTask userTask = delegateTask.getBpmnModelElementInstance(); } }",
    "url": "/manual/latest/user-guide/model-api/bpmn-model-api/delegation-code/index.html"
  },
  {
    "id": "manual/latest/user-guide/model-api/bpmn-model-api/extension-elements/index.html",
    "title": "Extension Elements | docs.cibseven.org",
    "content": "Custom extension elements are a standardized way to extend the BPMN model. The Camunda extension elements are fully implemented in the BPMN model API, but unknown extension elements can also easily be accessed and added. Every BPMN BaseElement can have a child element of the type extensionElements. This element can contain all sorts of extension elements. To access the extension elements you have to call the getExtensionElements() method and, if no such child element exists, you must create one first. StartEvent startEvent = modelInstance.newInstance(StartEvent.class); ExtensionElements extensionElements = startEvent.getExtensionElements(); if (extensionElements == null) { extensionElements = modelInstance.newInstance(ExtensionElements.class); startEvent.setExtensionElements(extensionElements); } Collection<ModelElementInstance> elements = extensionElements.getElements(); After that you can add or remove extension elements to the collection. CamundaFormData formData = modelInstance.newInstance(CamundaFormData.class); extensionElements.getElements().add(formData); extensionElements.getElements().remove(formData); You can also access a query-like interface to filter the extension elements. extensionElements.getElementsQuery().count(); extensionElements.getElementsQuery().list(); extensionElements.getElementsQuery().singleResult(); extensionElements.getElementsQuery().filterByType(CamundaFormData.class).singleResult(); Additionally, there are some shortcuts to add new extension elements. You can use the namespaceUri and the elementName to add your own extension elements. Or you can use the class of a known extension element type, e.g., the camunda extension elements. The extension element is added to the BPMN element and returned so that you can set attributes or add child elements. ModelElementInstance element = extensionElements.addExtensionElement(\"http://example.com/bpmn\", \"myExtensionElement\"); CamundaExecutionListener listener = extensionElements.addExtensionElement(CamundaExecutionListener.class); Another helper method exists for the fluent builder API which allows you to add prior defined extension elements. CamundaExecutionListener camundaExecutionListener = modelInstance.newInstance(CamundaExecutionListener.class); camundaExecutionListener.setCamundaClass(\"org.cibseven.bpm.MyJavaDelegte\"); startEvent.builder() .addExtensionElement(camundaExecutionListener);",
    "url": "/manual/latest/user-guide/model-api/bpmn-model-api/extension-elements/index.html"
  },
  {
    "id": "manual/latest/user-guide/model-api/bpmn-model-api/fluent-builder-api/index.html",
    "title": "Fluent Builder API | docs.cibseven.org",
    "content": "To create simple BPMN processes we provide a fluent builder API. With this API you can easily create basic processes in a few lines of code. In the generate process fluent api quickstart we demonstrate how to create a rather complex process with 5 tasks and 2 gateways within less than 50 lines of code. The fluent builder API is not nearly complete but provides you with the following basic elements: process start event exclusive gateway parallel gateway script task service task user task signal event definition end event subprocess Create a Process With the Fluent Builder API To create an empty model instance with a new process the method Bpmn.createProcess() is used. After this, you can add as many tasks and gateways as you like. At the end you must call done() to return the generated model instance. For example, a simple process with one user task can be created like this: BpmnModelInstance modelInstance = Bpmn.createProcess() .startEvent() .userTask() .endEvent() .done(); To add a new element you have to call a function which is named like the element to add. Additionally you can set attributes of the last created element. For example, let’s set the name of the process and mark it as executable and also give the user task a name. BpmnModelInstance modelInstance = Bpmn.createProcess() .name(\"Example process\") .executable() .startEvent() .userTask() .name(\"Some work to do\") .endEvent() .done(); As you can see, a sequential process is really simple and straightforward to model, but often you want branches and a parallel execution path, which is also possible with the fluent builder API. Just add a parallel or exclusive gateway and model the first path till an end event or another gateway. After that, call the moveToLastGateway() method and you return to the last gateway and can model the next path. BpmnModelInstance modelInstance = Bpmn.createProcess() .startEvent() .userTask() .parallelGateway() .scriptTask() .endEvent() .moveToLastGateway() .serviceTask() .endEvent() .done(); This example models a process with a user task after the start event followed by a parallel gateway with two parallel outgoing execution paths, each with a task and an end event. Normally you want to add conditions on outgoing flows of an exclusive gateway which is also simple with the fluent builder API. Just use the method condition() and give it a label and an expression. BpmnModelInstance modelInstance = Bpmn.createProcess() .startEvent() .userTask() .exclusiveGateway() .name(\"What to do next?\") .condition(\"Call an agent\", \"#{action = 'call'}\") .scriptTask() .endEvent() .moveToLastGateway() .condition(\"Create a task\", \"#{action = 'task'}\") .serviceTask() .endEvent() .done(); If you want to use the moveToLastGateway() method but have multiple incoming sequence flows at your current position, you have to use the generic moveToNode method with the id of the gateway. This could for example happen if you add a join gateway to your process. For this purpose and for loops, we added the connectTo(elementId) method. BpmnModelInstance modelInstance = Bpmn.createProcess() .startEvent() .userTask() .parallelGateway(\"fork\") .serviceTask() .parallelGateway(\"join\") .moveToNode(\"fork\") .userTask() .connectTo(\"join\") .moveToNode(\"fork\") .scriptTask() .connectTo(\"join\") .endEvent() .done() This example creates a process with three parallel execution paths which all join in the second gateway. Notice that the first call of moveToNode is not necessary, because at this point the joining gateway only has one incoming sequence flow, but was used for consistency. BpmnModelInstance modelInstance = Bpmn.createProcess() .startEvent() .userTask() .id(\"question\") .exclusiveGateway() .name(\"Everything fine?\") .condition(\"yes\", \"#{fine}\") .serviceTask() .userTask() .endEvent() .moveToLastGateway() .condition(\"no\", \"#{!fine}\") .userTask() .connectTo(\"question\") .done() This example creates a parallel gateway with a feedback loop in the second execution path. To create an embedded subprocess with the fluent builder API, you can directly add it to your process building or you can detach it and create flow elements of the subprocess later on. // Directly define the subprocess BpmnModelInstance modelInstance = Bpmn.createProcess() .startEvent() .subProcess() .camundaAsync() .embeddedSubProcess() .startEvent() .userTask() .endEvent() .subProcessDone() .serviceTask() .endEvent() .done(); // Detach the subprocess building modelInstance = Bpmn.createProcess() .startEvent() .subProcess(\"subProcess\") .serviceTask() .endEvent() .done(); SubProcess subProcess = (SubProcess) modelInstance.getModelElementById(\"subProcess\"); subProcess.builder() .camundaAsync() .embeddedSubProcess() .startEvent() .userTask() .endEvent(); The example below shows how to create a throwing signal event definition and define the payload that this signal will contain. By using the camundaIn methods, it is possible to define which process variables will be included in the signal payload, define an expression that will be resolved in the signal-catching process instances, or declare that all of the process variables in the signal-throwing process instance should be passed. It is also possible to define a business key that will be assigned to the signal-catching process instances. BpmnModelInstance modelInstance = Bpmn.createProcess() .startEvent() .intermediateThrowEvent(\"throw\") .signalEventDefinition(\"signal\") .camundaInSourceTarget(\"source\", \"target1\") .camundaInSourceExpressionTarget(\"${'sourceExpression'}\", \"target2\") .camundaInAllVariables(\"all\", true) .camundaInBusinessKey(\"aBusinessKey\") .throwEventDefinitionDone() .endEvent() .done(); Extend a Process With the Fluent Builder API With the fluent builder API you can not only create processes, you can also extend existing processes. For example, imagine a process containing a parallel gateway with the id gateway. You now want to add another execution path to it for a new service task which has to be executed every time. BpmnModelInstance modelInstance = Bpmn.readModelFromFile(new File(\"PATH/TO/MODEL.bpmn\")); ParallelGateway gateway = (ParallelGateway) modelInstance.getModelElementById(\"gateway\"); gateway.builder() .serviceTask() .name(\"New task\") .endEvent(); Another use case is to insert new tasks between existing elements. Imagine a process containing a user task with the id task1 which is followed by a service task. And now you want to add a script task and a user task between these two. BpmnModelInstance modelInstance = Bpmn.readModelFromFile(new File(\"PATH/TO/MODEL.bpmn\")); UserTask userTask = (UserTask) modelInstance.getModelElementById(\"task1\"); SequenceFlow outgoingSequenceFlow = userTask.getOutgoing().iterator().next(); FlowNode serviceTask = outgoingSequenceFlow.getTarget(); userTask.getOutgoing().remove(outgoingSequenceFlow); userTask.builder() .scriptTask() .userTask() .connectTo(serviceTask.getId()); Common Model Patterns Controlling Transaction Boundaries The transaction boundaries of a process created with the fluent builder API can be controlled using the camundaAsyncBefore() and camundaAsyncAfter() methods offered for various process constructs. BpmnModelInstance modelInstance = Bpmn.createProcess() .startEvent() .serviceTask(\"servicetask\") .camundaAsyncBefore() .userTask(\"task\") .camundaAsyncAfter() .done(); The service task in the example above will have a transaction boundary before its execution and the user task will have a transaction boundary after its completion. If an activity has multi-instance characteristics, the camundaAsyncBefore() and camundaAsyncAfter() methods apply to the multi-instance body as a whole. The transaction boundaries of the individual occurrences (instances) of the multi-instance can be controlled with similar methods, called from within the multi-instance builder. BpmnModelInstance modelInstance = Bpmn.createProcess() .startEvent() .serviceTask(\"servicetask\") .camundaAsyncBefore() // multi-instance body .multiInstance() .camundaAsyncBefore() // every instance .parallel() .multiInstanceDone() .endEvent() .done(); Generation of Diagram Interchange To render the process, BPMN diagram elements are necessary. The fluent builder generates BPMN Shapes and BPMN Edges and places them automatically for flow nodes and sequence flows. final BpmnModelInstance myProcess = Bpmn.createExecutableProcess(\"process-payments\") .startEvent() .serviceTask() .name(\"Process Payment\") .endEvent() .done(); System.out.println(Bpmn.convertToString(myProcess)); This example creates a BPMN containing both semantic elements (e.g., service task etc.) and diagram elements: <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?> <definitions xmlns:bpmndi=\"http://www.omg.org/spec/BPMN/20100524/DI\" xmlns:camunda=\"http://camunda.org/schema/1.0/bpmn\" xmlns:dc=\"http://www.omg.org/spec/DD/20100524/DC\" xmlns:di=\"http://www.omg.org/spec/DD/20100524/DI\" id=\"definitions_dfb1f18e-6034-448e-abae-0eb2f41469da\" targetNamespace=\"http://www.omg.org/spec/BPMN/20100524/MODEL\" xmlns=\"http://www.omg.org/spec/BPMN/20100524/MODEL\"> <!-- Generated BPMN Semantic Elements --> <process id=\"process-payments\" isExecutable=\"true\"> <startEvent id=\"startEvent_2b0abd37-75a9-47dd-9838-63f1390d7515\"> <outgoing>sequenceFlow_b1eec5b5-889d-4e75-854d-59768fbdc8a2</outgoing> </startEvent> <serviceTask id=\"serviceTask_f4c2413f-5b26-49e8-b71c-2603e469ce09\" name=\"Process Payment\"> <incoming>sequenceFlow_b1eec5b5-889d-4e75-854d-59768fbdc8a2</incoming> <outgoing>sequenceFlow_5839394a-c0c2-4a5b-aa81-9412f169cc35</outgoing> </serviceTask> <sequenceFlow id=\"sequenceFlow_b1eec5b5-889d-4e75-854d-59768fbdc8a2\" sourceRef=\"startEvent_2b0abd37-75a9-47dd-9838-63f1390d7515\" targetRef=\"serviceTask_f4c2413f-5b26-49e8-b71c-2603e469ce09\"/> <endEvent id=\"endEvent_8087f927-a53b-4126-95fc-c057736f3b73\"> <incoming>sequenceFlow_5839394a-c0c2-4a5b-aa81-9412f169cc35</incoming> </endEvent> <sequenceFlow id=\"sequenceFlow_5839394a-c0c2-4a5b-aa81-9412f169cc35\" sourceRef=\"serviceTask_f4c2413f-5b26-49e8-b71c-2603e469ce09\" targetRef=\"endEvent_8087f927-a53b-4126-95fc-c057736f3b73\"/> </process> <!-- Generated Diagram Elements --> <bpmndi:BPMNDiagram id=\"BPMNDiagram_5b66dfb7-097b-4610-9681-43abb3ff97da\"> <bpmndi:BPMNPlane bpmnElement=\"process-payments\" id=\"BPMNPlane_ad88b4cf-9d7a-4b86-8386-f8db23ff388d\"> <bpmndi:BPMNShape bpmnElement=\"startEvent_2b0abd37-75a9-47dd-9838-63f1390d7515\" id=\"BPMNShape_d6c4e3c5-150c-43f7-adf8-1d388f466a69\"> <dc:Bounds height=\"36.0\" width=\"36.0\" x=\"100.0\" y=\"100.0\"/> </bpmndi:BPMNShape> <bpmndi:BPMNShape bpmnElement=\"serviceTask_f4c2413f-5b26-49e8-b71c-2603e469ce09\" id=\"BPMNShape_51006773-13df-4327-a4cf-a5952c39e86a\"> <dc:Bounds height=\"80.0\" width=\"100.0\" x=\"186.0\" y=\"78.0\"/> </bpmndi:BPMNShape> <bpmndi:BPMNEdge bpmnElement=\"sequenceFlow_b1eec5b5-889d-4e75-854d-59768fbdc8a2\" id=\"BPMNEdge_fb360594-8863-4d5d-b515-49e02a88d55d\"> <di:waypoint x=\"136.0\" y=\"118.0\"/> <di:waypoint x=\"186.0\" y=\"118.0\"/> </bpmndi:BPMNEdge> <bpmndi:BPMNShape bpmnElement=\"endEvent_8087f927-a53b-4126-95fc-c057736f3b73\" id=\"BPMNShape_23930820-5507-45a0-8630-b5e45ee8dd4d\"> <dc:Bounds height=\"36.0\" width=\"36.0\" x=\"336.0\" y=\"100.0\"/> </bpmndi:BPMNShape> <bpmndi:BPMNEdge bpmnElement=\"sequenceFlow_5839394a-c0c2-4a5b-aa81-9412f169cc35\" id=\"BPMNEdge_07ed502e-069f-42a0-bd1b-fed0d68efbda\"> <di:waypoint x=\"286.0\" y=\"118.0\"/> <di:waypoint x=\"336.0\" y=\"118.0\"/> </bpmndi:BPMNEdge> </bpmndi:BPMNPlane> </bpmndi:BPMNDiagram> </definitions> The default behavior is that each newly added flow element will be placed next to the previous flow element. When flow elements are added to an embedded subprocess, then the subprocess is resized when the subprocess border is reached. Therefore, it is recommended to first add all new elements to the subprocess and to then create the following elements. Otherwise it could lead to overlapping elements in the diagram. Branches of gateways are placed one below the other. Auto layout is not provided, therefore the elements of different branches may overlap.",
    "url": "/manual/latest/user-guide/model-api/bpmn-model-api/fluent-builder-api/index.html"
  },
  {
    "id": "manual/latest/user-guide/model-api/bpmn-model-api/index.html",
    "title": "BPMN Model API | docs.cibseven.org",
    "content": "The BPMN model API enables easy extraction of information from an existing process definition, editing an existing process definition or creating a complete new one without manual XML parsing. Note: Currently the BPMN model API does not support the entire BPMN 2.0 specification. The list of already supported BPMN 2.0 elements can be found in the source code package org.cibseven.bpm.model.bpmn.instance .",
    "url": "/manual/latest/user-guide/model-api/bpmn-model-api/index.html"
  },
  {
    "id": "manual/latest/user-guide/model-api/bpmn-model-api/read-a-model/index.html",
    "title": "Read a Model | docs.cibseven.org",
    "content": "If you already created a BPMN model and want to process it through the BPMN model API, you can import it with the following methods. // read a model from a file File file = new File(\"PATH/TO/MODEL.bpmn\"); BpmnModelInstance modelInstance = Bpmn.readModelFromFile(file); // read a model from a stream InputStream stream = [...] BpmnModelInstance modelInstance = Bpmn.readModelFromStream(stream); After you imported your model you can search for elements by their id or by the type of element. // find element instance by ID StartEvent start = (StartEvent) modelInstance.getModelElementById(\"start\"); // find all elements of the type task ModelElementType taskType = modelInstance.getModel().getType(Task.class); Collection<ModelElementInstance> taskInstances = modelInstance.getModelElementsByType(taskType); For every element instance you can now read and edit the attribute values. You can do this by either using the provided helper methods or the generic XML model API. If you added custom attributes to the BPMN elements, you can always access them with the generic XML model API. StartEvent start = (StartEvent) modelInstance.getModelElementById(\"start\"); // read attributes by helper methods String id = start.getId(); String name = start.getName(); // edit attributes by helper methods start.setId(\"new-id\"); start.setName(\"new name\"); // read attributes by generic XML model API (with optional namespace) String custom1 = start.getAttributeValue(\"custom-attribute\"); String custom2 = start.getAttributeValueNs(\"custom-attribute-2\", \"http://camunda.org/custom\"); // edit attributes by generic XML model API (with optional namespace) start.setAttributeValue(\"custom-attribute\", \"new value\"); start.setAttributeValueNs(\"custom-attribute\", \"http://camunda.org/custom\", \"new value\"); You can also access the child elements of an element or references to other elements. For example, a sequence flow references a source and a target element while a flow node (like start event, tasks, etc.) has child elements for incoming and outgoing sequence flows. For example, the following BPMN model was created by the BPMN model API as an example for a simple process. <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?> <definitions targetNamespace=\"http://camunda.org/examples\" xmlns=\"http://www.omg.org/spec/BPMN/20100524/MODEL\"> <process id=\"process-with-one-task\"> <startEvent id=\"start\"> <outgoing>start-task1</outgoing> </startEvent> <userTask id=\"task1\"> <incoming>start-task1</incoming> <outgoing>task1-end</outgoing> </userTask> <endEvent id=\"end\"> <incoming>task1-end</incoming> </endEvent> <sequenceFlow id=\"start-task1\" sourceRef=\"start\" targetRef=\"task1\"/> <sequenceFlow id=\"task1-end\" sourceRef=\"task1\" targetRef=\"end\"/> </process> </definitions> You can now use the BPMN model API to get the source and target flow node of the sequence flow with the ID start-task1. // read bpmn model from file BpmnModelInstance modelInstance = Bpmn.readModelFromFile(new File(\"/PATH/TO/MODEL.bpmn\")); // find sequence flow by id SequenceFlow sequenceFlow = (SequenceFlow) modelInstance.getModelElementById(\"start-task1\"); // get the source and target element FlowNode source = sequenceFlow.getSource(); FlowNode target = sequenceFlow.getTarget(); // get all outgoing sequence flows of the source Collection<SequenceFlow> outgoing = source.getOutgoing(); assert(outgoing.contains(sequenceFlow)); With these references you can easily create helper methods for different use cases. For example, if you want to find the following flow nodes of a task or a gateway you can use a helper method like the following. public Collection<FlowNode> getFlowingFlowNodes(FlowNode node) { Collection<FlowNode> followingFlowNodes = new ArrayList<FlowNode>(); for (SequenceFlow sequenceFlow : node.getOutgoing()) { followingFlowNodes.add(sequenceFlow.getTarget()); } return followingFlowNodes; }",
    "url": "/manual/latest/user-guide/model-api/bpmn-model-api/read-a-model/index.html"
  },
  {
    "id": "manual/latest/user-guide/model-api/bpmn-model-api/respository-service/index.html",
    "title": "Repository Service | docs.cibseven.org",
    "content": "It is also possible to access the BPMN model instance by the process definition id using the Repository Service, as the following incomplete test sample code shows. Please see the generate-jsf-form quickstart for a complete example. public void testRepositoryService() { runtimeService.startProcessInstanceByKey(PROCESS_KEY); String processDefinitionId = repositoryService.createProcessDefinitionQuery() .processDefinitionKey(PROCESS_KEY).singleResult().getId(); BpmnModelInstance modelInstance = repositoryService.getBpmnModelInstance(processDefinitionId); }",
    "url": "/manual/latest/user-guide/model-api/bpmn-model-api/respository-service/index.html"
  },
  {
    "id": "manual/latest/user-guide/model-api/cmmn-model-api/create-a-model/index.html",
    "title": "Create a Model | docs.cibseven.org",
    "content": "To create a new CMMN model from scratch, you have to create an empty CMMN model instance with the following method: CmmnModelInstance modelInstance = Cmmn.createEmptyModel(); The next step is to create a CMMN definitions element. Set the target namespace on it and add it to the newly created empty model instance. Definitions definitions = modelInstance.newInstance(Definitions.class); definitions.setTargetNamespace(\"http://camunda.org/examples\"); modelInstance.setDefinitions(definitions); Usually you want to add a case to your model. This follows the same 3 steps as the creation of the CMMN definitions element: Create a new instance of the CMMN element Set attributes and child elements of the element instance Add the newly created element instance to the corresponding parent element Case caseElement = modelInstance.newInstance(Case.class); caseElement.setId(\"a-case\"); definitions.addChildElement(caseElement); To simplify this repeating procedure, you can use a helper method like this one. protected <T extends CmmnModelElementInstance> T createElement(CmmnModelElementInstance parentElement, String id, Class<T> elementClass) { T element = modelInstance.newInstance(elementClass); element.setAttributeValue(\"id\", id, true); parentElement.addChildElement(element); return element; } Validate the model against the CMMN 1.1 specification and convert it to an XML string or save it to a file or stream. // validate the model Cmmn.validateModel(modelInstance); // convert to string String xmlString = Cmmn.convertToString(modelInstance); // write to output stream OutputStream outputStream = new OutputStream(...); Cmmn.writeModelToStream(outputStream, modelInstance); // write to file File file = new File(...); Cmmn.writeModelToFile(file, modelInstance);",
    "url": "/manual/latest/user-guide/model-api/cmmn-model-api/create-a-model/index.html"
  },
  {
    "id": "manual/latest/user-guide/model-api/cmmn-model-api/delegation-code/index.html",
    "title": "Delegation Code | docs.cibseven.org",
    "content": "If you use Delegation Code, you can access the CMMN model instance and current element of the executed case. If a CMMN model is accessed, it will be cached to avoid redundant database queries. Case Execution Listener If your class implements the org.cibseven.bpm.engine.delegate.CaseExecutionListener interface, you can access the CMMN model instance and the plan item element. As a Case Execution Listener can be added to several elements like case plan model, human task, etc., it can not be guaranteed which type the flow element will be. public class ExampleCaseExecutionListener implements CaseExecutionListener { public void notify(DelegateCaseExecution caseExecution) throws Exception { CmmnModelInstance modelInstance = execution.getCmmnModelInstance(); CmmnElement cmmnElement = execution.getCmmnModelElementInstance(); } }",
    "url": "/manual/latest/user-guide/model-api/cmmn-model-api/delegation-code/index.html"
  },
  {
    "id": "manual/latest/user-guide/model-api/cmmn-model-api/extension-elements/index.html",
    "title": "Extension Elements | docs.cibseven.org",
    "content": "Custom extension elements are a standardized way to extend the CMMN model. The Camunda extension elements are fully implemented in the CMMN model API but unknown extension elements can also easily be accessed and added. Every CMMN CmmnElement can have a child element of the type extensionElements. This element can contain all sorts of extension elements. To access the extension elements you have to call the getExtensionElements() method and, if no such child element exists, you must create one first. HumanTask humanTask = modelInstance.newInstance(HumanTask.class); ExtensionElements extensionElements = humanTask.getExtensionElements(); if (extensionElements == null) { extensionElements = modelInstance.newInstance(ExtensionElements.class); humanTask.setExtensionElements(extensionElements); } Collection<ModelElementInstance> elements = extensionElements.getElements(); After that you can add or remove extension elements to the collection. CamundaCaseExecutionListener listener = modelInstance.newInstance(CamundaCaseExecutionListener.class); extensionElements.getElements().add(listener); extensionElements.getElements().remove(listener); You can also access a query-like interface to filter the extension elements. extensionElements.getElementsQuery().count(); extensionElements.getElementsQuery().list(); extensionElements.getElementsQuery().singleResult(); extensionElements.getElementsQuery().filterByType(CamundaCaseExecutionListener.class).singleResult(); Additionally, there are some shortcuts to add new extension elements. You can use the namespaceUri and the elementName to add your own extension elements. Or you can use the class of a known extension element type, e.g., the Camunda extension elements. The extension element is added to the CMMN element and returned so that you can set attributes or add child elements. ModelElementInstance element = extensionElements.addExtensionElement(\"http://example.com/cmmn\", \"myExtensionElement\"); CamundaCaseExecutionListener listener = extensionElements.addExtensionElement(CamundaCaseExecutionListener.class);",
    "url": "/manual/latest/user-guide/model-api/cmmn-model-api/extension-elements/index.html"
  },
  {
    "id": "manual/latest/user-guide/model-api/cmmn-model-api/index.html",
    "title": "CMMN Model API | docs.cibseven.org",
    "content": "The CMMN model API enables easy extraction of information from an existing case definition, editing of an existing case definition or creating a complete new one without manual XML parsing.",
    "url": "/manual/latest/user-guide/model-api/cmmn-model-api/index.html"
  },
  {
    "id": "manual/latest/user-guide/model-api/cmmn-model-api/limitations/index.html",
    "title": "Limitations | docs.cibseven.org",
    "content": "The CMMN model API is able to read CMMN 1.1 as well as CMMN 1.0 models. Its primary use case is to work with models of the latest version, such that there are limitations when editing CMMN models of prior versions. ModelElementType#getTypeNamespace() returns CMMN 1.1 namespace for elements which are present in CMMN 1.0 and CMMN 1.1 CMMN#createEmptyModel() always creates a CMMN 1.1 model. CMMN 1.0 models cannot be created anymore. It is not possible to change and save an existing CMMN 1.0 model. CMMN 1.0 attributes and elements that have been removed in CMMN 1.1 cannot be added to a CMMN 1.1 model. Their accessor methods are marked @Deprecated. For a list of affected elements confer the guide on migrating CMMN models between specification versions.",
    "url": "/manual/latest/user-guide/model-api/cmmn-model-api/limitations/index.html"
  },
  {
    "id": "manual/latest/user-guide/model-api/cmmn-model-api/read-a-model/index.html",
    "title": "Read a Model | docs.cibseven.org",
    "content": "If you already created a CMMN model and want to process it through the CMMN model API, you can import it with the following methods. // read a model from a file File file = new File(\"PATH/TO/MODEL.cmmn\"); CmmnModelInstance modelInstance = Cmmn.readModelFromFile(file); // read a model from a stream InputStream stream = [...] CmmnModelInstance modelInstance = Cmmn.readModelFromStream(stream); After you imported your model you can search for elements by their id or by the type of element. // find element instance by ID HumanTask humanTask = (HumanTask) modelInstance.getModelElementById(\"HumanTask_1\"); // find all elements of the type HumanTask ModelElementType humanTaskType = modelInstance.getModel().getType(HumanTask.class); Collection<ModelElementInstance> humanTaskInstances = modelInstance.getModelElementsByType(humanTaskType); For every element instance you can now read and edit the attribute values. You can do this by either using the provided helper methods or the generic XML model API. If you added custom attributes to the CMMN elements, you can always access them with the generic XML model API. HumanTask humanTask = (HumanTask) modelInstance.getModelElementById(\"HumanTask_1\"); // read attributes by helper methods String id = humanTask.getId(); String name = humanTask.getName(); // edit attributes by helper methods humanTask.setId(\"new-id\"); humanTask.setName(\"new name\"); // read attributes by generic XML model API (with optional namespace) String custom1 = humanTask.getAttributeValue(\"custom-attribute\"); String custom2 = humanTask.getAttributeValueNs(\"custom-attribute-2\", \"http://camunda.org/custom\"); // edit attributes by generic XML model API (with optional namespace) humanTask.setAttributeValue(\"custom-attribute\", \"new value\"); humanTask.setAttributeValueNs(\"custom-attribute\", \"http://camunda.org/custom\", \"new value\"); You can also access the child elements of an element or references to other elements. For example, a plan item references a definition element (like human task, process task, etc.) while the referenced definition element contains default control. Consider the following simple CMMN model: <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?> <definitions targetNamespace=\"http://camunda.org/examples\" xmlns=\"http://www.omg.org/spec/CMMN/20151109/MODEL\"> <case id=\"case-with-one-task\"> <casePlanModel id=\"CasePlanModel_1\"> <planItem id=\"PI_HumanTask_1\" definitionRef=\"HumanTask_1\" name=\"A Task\" /> <humanTask id=\"HumanTask_1\"> <defaultControl> <manualActivationRule> <condition>${false}</condition> </manualActivationRule> </defaultControl> </humanTask> </casePlanModel> </case> </definitions> You can now use the CMMN model API to get the definition of the plan item with the ID PI_HumanTask_1. // read cmmn model from file File file = new File(\"PATH/TO/MODEL.cmmn\"); CmmnModelInstance modelInstance = Cmmn.readModelFromFile(file); // find plan item by id PlanItem planItem = (PlanItem) modelInstance.getModelElementById(\"PI_HumanTask_1\"); // get the definition element PlanItemDefinition definition = planItem.getDefinition(); // get the default control DefaultControl defaultControl = definition.getDefaultControl(); ManualActivationRule rule = defaultControl.getManualActivationRule();",
    "url": "/manual/latest/user-guide/model-api/cmmn-model-api/read-a-model/index.html"
  },
  {
    "id": "manual/latest/user-guide/model-api/cmmn-model-api/repository-service/index.html",
    "title": "Repository Service | docs.cibseven.org",
    "content": "It is also possible to access the CMMN model instance by the case definition id using the Repository Service, as the following incomplete test sample code shows. public void testRepositoryService() { String caseDefinitionId = repositoryService.createCaseDefinitionQuery() .caseDefinitionKey(CASE_KEY).singleResult().getId(); CmmnModelInstance modelInstance = repositoryService .getCmmnModelInstance(caseDefinitionId); }",
    "url": "/manual/latest/user-guide/model-api/cmmn-model-api/repository-service/index.html"
  },
  {
    "id": "manual/latest/user-guide/model-api/dmn-model-api/create-a-model/index.html",
    "title": "Create a Model | docs.cibseven.org",
    "content": "To create a new DMN model from scratch, you have to create an empty DMN model instance with the following method: DmnModelInstance modelInstance = Dmn.createEmptyModel(); The next step is to create a DMN definitions element. Set the target namespace on it and add it to the newly created empty model instance. Definitions definitions = modelInstance.newInstance(Definitions.class); definitions.setNamespace(\"http://camunda.org/schema/1.0/dmn\"); definitions.setName(\"definitions\"); definitions.setId(\"definitions\"); modelInstance.setDefinitions(definitions); Usually you want to add a decision to your model. This follows the same 3 steps as the creation of the DMN definitions element: Create a new instance of the DMN element Set attributes and child elements of the element instance Add the newly created element instance to the corresponding parent element Decision decision = modelInstance.newInstance(Decision.class); decision.setId(\"testGenerated\"); decision.setName(\"generationtest\"); definitions.addChildElement(decision); To simplify this repeating procedure, you can use a helper method like this one: protected <T extends DmnModelElementInstance> T createElement(DmnModelElementInstance parentElement, String id, Class<T> elementClass) { T element = modelInstance.newInstance(elementClass); element.setAttributeValue(\"id\", id, true); parentElement.addChildElement(element); return element; } Validate the model against the DMN 1.3 specification and convert it to an XML string or save it to a file or stream. DMN 1.3 diagram The resulting XML string will reference the DMN 1.3 specification. // validate the model Dmn.validateModel(modelInstance); // convert to string String xmlString = Dmn.convertToString(modelInstance); // write to output stream OutputStream outputStream = new OutputStream(...); Dmn.writeModelToStream(outputStream, modelInstance); // write to file File file = new File(...); Dmn.writeModelToFile(file, modelInstance);",
    "url": "/manual/latest/user-guide/model-api/dmn-model-api/create-a-model/index.html"
  },
  {
    "id": "manual/latest/user-guide/model-api/dmn-model-api/extension-attributes/index.html",
    "title": "Extension Attributes | docs.cibseven.org",
    "content": "Custom extensions are a standardized way to extend the DMN model. The Camunda extension attributes are fully implemented in the DMN model API. Every DMN Decision element can have the attributes historyTimeToLive and versionTag. To access the extension attributes, you have to call the Decision#getCamundaHistoryTimeToLiveString() and Decision#getVersionTag() methods. String historyTimeToLive = decision.getCamundaHistoryTimeToLiveString(); String versionTag = decision.getVersionTag(); To set attributes, use Decision#setCamundaHistoryTimeToLiveString() and Decision#setVersionTag() decision.setCamundaHistoryTimeToLiveString(\"1000\"); decision.setVersionTag(\"1.0.0\"); Every Input element can have an inputVariable attribute. This attribute specifies the variable name which can be used to access the result of the input expression in an input entry expression. It can be set and fetched similarly, calling Input#setCamundaInputVariable() and Input#getCamundaInputVariable(): input.setCamundaInputVariable(\"camundaInput\"); String camundaInput = input.getCamundaInputVariable();",
    "url": "/manual/latest/user-guide/model-api/dmn-model-api/extension-attributes/index.html"
  },
  {
    "id": "manual/latest/user-guide/model-api/dmn-model-api/index.html",
    "title": "DMN Model API | docs.cibseven.org",
    "content": "The DMN model API enables easy extraction of information from an existing decision definition, editing of an existing decision definition or creating a completely new one without manual XML parsing.",
    "url": "/manual/latest/user-guide/model-api/dmn-model-api/index.html"
  },
  {
    "id": "manual/latest/user-guide/model-api/dmn-model-api/read-a-model/index.html",
    "title": "Read a Model | docs.cibseven.org",
    "content": "If you already created a DMN model and want to process it through the DMN model API, you can import it with the following methods: // read a model from a file File file = new File(\"PATH/TO/MODEL.dmn\"); DmnModelInstance modelInstance = Dmn.readModelFromFile(file); // read a model from a stream InputStream stream = [...] DmnModelInstance modelInstance = Dmn.readModelFromStream(stream); After you imported your model, you can search for elements by their id or by the type of element. // find element instance by ID DecisionTable decisionTable = modelInstance.getModelElementById(\"decisionTable1\"); // find all elements of the type DecisionTable ModelElementType decisionTableType = modelInstance.getModel() .getType(DecisionTable.class); Collection<ModelElementInstance> decisionTableInstances = modelInstance.getModelElementsByType(decisionTableType); For every element instance you can now read and edit the attribute values. You can do this by either using the provided helper methods or the generic XML model API. If you added custom attributes to the DMN elements, you can always access them with the generic XML model API. DecisionTable decisionTable = modelInstance.getModelElementById(\"decisionTable1\"); // read attributes by helper methods String outputLabel = decisionTable.getOutputLabel(); Collection<Input> inputs = decisionTable.getInputs(); // edit attributes by helper methods decisionTable.setOutputLabel(\"new-label\"); // read attributes by generic XML model API (with optional namespace) String custom1 = decisionTable.getAttributeValue(\"custom-attribute\"); String custom2 = decisionTable.getAttributeValueNs(\"custom-attribute-2\", \"http://camunda.org/custom\"); // edit attributes by generic XML model API (with optional namespace) decisionTable.setAttributeValue(\"custom-attribute\", \"new value\"); decisionTable.setAttributeValueNs(\"custom-attribute\", \"http://camunda.org/custom\", \"new value\"); You can also access the child elements of an element or references to other elements. For example, a decision has a required decision which it depends on. A required decision is represented by a requiredDecision element inside an informationRequirement XML element. Consider the following simple DMN model: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <definitions xmlns=\"https://www.omg.org/spec/DMN/20191111/MODEL/\" id=\"dish\" name=\"Dish\" namespace=\"test-drd-2\"> <decision id=\"dish-decision\" name=\"Dish Decision\"> <informationRequirement> <requiredDecision href=\"#season\" /> </informationRequirement> <decisionTable id=\"dishDecisionTable\"> <input id=\"seasonInput\" label=\"Season\"> <inputExpression id=\"seasonInputExpresion\" typeRef=\"string\"> <text>season</text> </inputExpression> </input> <output id=\"output\" label=\"Dish\" name=\"desiredDish\" typeRef=\"string\"/> <rule id=\"dishRule1\"> <inputEntry id=\"dishInputEntry1\"> <text><![CDATA[\"Spring\"]]></text> </inputEntry> <outputEntry id=\"dishOutputEntry1\"> <text><![CDATA[\"Salad\"]]></text> </outputEntry> </rule> ... </decisionTable> </decision> <decision id=\"season\" name=\"Season decision\"> <decisionTable id=\"seasonDecisionTable\"> <input id=\"temperatureInput\" label=\"Weather in Celsius\"> <inputExpression id=\"temperatureInputExpression\" typeRef=\"integer\"> <text>temperature</text> </inputExpression> </input> <output id=\"seasonOutput\" label=\"season\" name=\"season\" typeRef=\"string\" /> <rule id=\"seasonRule1\"> <inputEntry id=\"seasonInputEntry1\"> <text><![CDATA[<10]]></text> </inputEntry> <outputEntry id=\"seasonOutputEntry1\"> <text><![CDATA[\"Winter\"]]></text> </outputEntry> </rule> ... </decisionTable> </decision> </definitions> You can now use the DMN model API to get the input elements of the required decisions. // read dmn model from file File file = new File(\"PATH/TO/MODEL.dmn\"); DmnModelInstance modelInstance = Dmn.readModelFromFile(file); // find the main decision by ID Decision decision = modelInstance.getModelElementById(\"dish-decision\"); // get the information requirements Collection<InformationRequirement> informationRequirements = decision.getInformationRequirements(); // get the input of the required decisions for (InformationRequirement informationRequirement : informationRequirements) { Decision requiredDecision = informationRequirement.getRequiredDecision(); DecisionTable decisionTable = requiredDecision.getUniqueChildElementByType(DecisionTable.class); Collection<Input> inputs = decisionTable.getInputs(); ... }",
    "url": "/manual/latest/user-guide/model-api/dmn-model-api/read-a-model/index.html"
  },
  {
    "id": "manual/latest/user-guide/model-api/dmn-model-api/repository-service/index.html",
    "title": "Repository Service | docs.cibseven.org",
    "content": "It is also possible to access the DMN model instance by the decision definition id using the Repository Service, as the following incomplete test sample code shows: public void testRepositoryService() { String decisionDefinitionId = repositoryService.createDecisionDefinitionQuery() .decisionDefinitionKey(DECISION_KEY).singleResult().getId(); DmnModelInstance modelInstance = repositoryService .getDmnModelInstance(decisionDefinitionId); }",
    "url": "/manual/latest/user-guide/model-api/dmn-model-api/repository-service/index.html"
  },
  {
    "id": "manual/latest/user-guide/model-api/index.html",
    "title": "Model API | docs.cibseven.org",
    "content": "The provided model APIs are simple and lightweight libraries for parsing, creating, editing and writing XML files. The model APIs are based on a general XML model API which is useful for general XML processing.",
    "url": "/manual/latest/user-guide/model-api/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-applications/index.html",
    "title": "Process Applications | docs.cibseven.org",
    "content": "A process application is an ordinary Java application that uses the Camunda process engine for BPM and workflow functionality. Most such applications will start their own process engine (or use a process engine provided by the runtime container), deploy some BPMN 2.0 process definitions and interact with process instances derived from these process definitions. Since most process applications perform very similar bootstrapping, deployment and runtime tasks, we generalized this functionality into a Java Class which is named - Surprise! - ProcessApplication. The concept is similar to the javax.ws.rs.core.Application class in JAX-RS: adding the process application class allows you to bootstrap and configure the provided services. Adding a ProcessApplication class to your Java application provides your applications with the following services: Bootstrap embedded process engine(s) or look up container managed process engine(s). You can define multiple process engines in a file named processes.xml which is added to your application. The ProcessApplication class makes sure this file is picked up and the defined process engines are started and stopped as the application is deployed/undeployed. Automatic deployment of classpath BPMN 2.0 resources. You can define multiple deployments (process archives) in the processes.xml file. The ProcessApplication class makes sure the deployments are performed upon deployment of your application. Scanning your application for process definition resource files (ending in *.bpmn20.xml or *.bpmn) is supported as well. Resolution of application-local Java Delegate implementations and Beans in case of a multi-application deployment. The ProcessApplication class allows your Java Application to expose your local Java Delegate implementations or Spring/CDI beans to a shared, container managed process engine. This way you can start a single process engine that dispatches to multiple process applications that can be (re-)deployed independently. Transforming an existing Java Application into a process application is easy and non-intrusive. You simply have to add: A ProcessApplication class: The ProcessApplication class constitutes the interface between your application and the process engine. There are different base classes you can extend to reflect different environments (e.g., Servlet vs. EJB Container). A processes.xml file to META-INF: The deployment descriptor file allows you to provide a declarative configuration of the deployment(s) that this process application makes to the process engine. It can be empty (see the empty processes.xml section) and serve as simple marker file. If it is not present then the engine will start up but auto-deployment will not be performed. Tutorial You might want to check out the Getting Started Tutorial first as it explains the creation of a process application step by step or the Project Templates for Maven, which give you a complete running process application out of the box.",
    "url": "/manual/latest/user-guide/process-applications/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-applications/maven-archetypes/index.html",
    "title": "Maven Project Templates (Archetypes) | docs.cibseven.org",
    "content": "We provide several project templates for Maven, which are also called Archetypes. They enable a quickstart for developing production-ready process applications using CIB seven. We incorporated best practices for different application types into the templates to help you start off with a solid base. The Archetypes can be used to generate projects as detailed in the different usage sections. In case generating a project from an Archetype on your own is not feasible, we also provide a template GitHub repository for every Archetype. Overview of Available Maven Archetypes The following archetypes are currently provided. They are distributed via our Maven repository: https://artifacts.camunda.com/artifactory/camunda-bpm/ ArchetypeDescription Camunda Cockpit Plugin Plugin for Camunda Cockpit, contains REST-Backend, MyBatis database query, HTML and JavaScript frontend, Ant build script for one-click deployment Process Application (EJB, WAR) Process application that uses a shared CIB seven engine in a Java EE Container, e.g., Wildfly. Contains: Camunda EJB Client, Camunda CDI Integration, BPMN Process, Java Delegate as CDI bean, HTML5- & JSF-based start and task forms, configuration for JPA (Hibernate), JUnit Test with in-memory engine and visual process test coverage, Arquillian Test for Wildfly, Maven Plugins or Ant build script for one-click deployment in Eclipse Process Application (Servlet, WAR) Process application that uses a shared CIB seven engine in a Servlet Container, e.g., Apache Tomcat. Contains: Servlet process application, BPMN Process, Java Delegate, HTML5-based start and task forms, JUnit Test with in-memory engine, Maven Plugins or Ant build script for one-click deployment in Eclipse Camunda Spring Boot Application Application that uses the Camunda Spring Boot Starter. Contains: Spring Boot Process Application, Camunda Webapps, BPMN Process, Java Delegate, HTML5-based start and task forms, JUnit Test with in-memory engine, Maven Plugins for packing as an executable application. Camunda Spring Boot Application with Demo Users Same as the Spring Boot Application archetype and additionally creates demo users and groups for easy start with the Camunda Webapps (use demo/demo to log in). Process Engine Plugin An example for a process engine plugin. Contains: Process engine plugin, BPMN Parse Listener that is registered via the plugin, Task Listener that is added to every user task, JUnit Test with in-memory engine. Template repositories We provide a template repository for every Camunda Archetype. Every repository contains a project generated from one specific template. You can find the whole list on GitHub. With every new release of the Archetypes, we will update those repositories with a new version as well. This allows to investigate possible update paths from one Camunda version to another and also enables you to simply update your existing project by pulling in the latest changes. In case you need more flexibility and customization for your project, you can generate a project on your own using one of the methods detailed in the next sections. Usage in Eclipse IDE Summary Add archetype catalog (Preferences -> Maven -> Archetypes -> Add Remote Catalog): https://artifacts.camunda.com/artifactory/camunda-bpm/ Create Maven project from archetype (File -> New -> Project… -> Maven -> Maven Project) Detailed Instructions Go to Preferences -> Maven -> Archetypes -> Add Remote Catalog Enter the following URL and description, click on Verify… to test the connection and if that worked click on OK to save the catalog. Catalog File: https://artifacts.camunda.com/artifactory/camunda-bpm/ Description: CIB seven Now you should be able to use the archetypes when creating a new Maven project in Eclipse: Go to File -> New -> Project… and select Maven -> Maven Project Select a location for the project or just keep the default setting. Select the archetype from the catalog that you created before. Specify Maven coordinates and Camunda version and finish the project creation. The resulting project should look like this: Troubleshooting Sometimes the creation of the very first Maven project fails in Eclipse. If that happens to you, just try it again. Most of the times the second try works. If the problem persists, contact us. Usage in IntelliJ IDEA On the “Welcome to IntelliJ IDEA” screen, click on “Configure” and select “Plugins” in the dropdown. In the plugins dialog, click on “Browse repositories…”. Search for the plugin “Maven Archetype Catalogs” and click on “Install”. Restart IntelliJ IDEA. On the “Welcome to IntelliJ IDEA” screen, click on “Configure” and select “Preferences” in the dropdown. In the preferences window, navigate to: “Build, Execution, Deployment > Build Tools > Maven Archetype Catalogs”. In the Maven Archetype Catalogs window, click on the “+” button, and in the opened “Add Archetype Catalog URL” modal window add the URL of the catalog file: https://artifacts.camunda.com/artifactory/camunda-bpm/archetype-catalog.xml. To create a Maven project from an archetype, click on the “Welcome to IntelliJ IDEA” screen on “Create New Project”. In the new project dialog, click on the left side on “Maven”, check “Create from archetype” and select any org.camunda.bpm.archetype entry. Usage on Command Line Interactive Run the following command in a terminal to generate a project. Maven will allow you to select an archetype and ask you for all parameters needed to configure it: mvn archetype:generate -Dfilter=org.camunda.bpm.archetype: Full Automation The following command completely automates the project generation and can be used in shell scripts or Ant builds: mvn archetype:generate \\ -DinteractiveMode=false \\ -DarchetypeGroupId=org.camunda.bpm.archetype \\ -DarchetypeArtifactId=camunda-archetype-ejb-war \\ -DarchetypeVersion=7.10.0 \\ -DgroupId=org.example.camunda.bpm \\ -DartifactId=camunda-bpm-ejb-project \\ -Dversion=0.0.1-SNAPSHOT \\ -Dpackage=org.example.bpm.ejb Source Code and Customization You can also customize the project templates for your own technology stack. Just fork them on GitHub!",
    "url": "/manual/latest/user-guide/process-applications/maven-archetypes/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-applications/process-application-event-listeners/index.html",
    "title": "Process Application Event Listeners | docs.cibseven.org",
    "content": "The process engine supports defining two types of event listeners: Task Event Listeners and Execution Event Listeners. Task Event listeners allow to react to Task Events (Tasks are Created, Assigned, Completed). Execution Listeners allow to react to events fired as execution progresses through the diagram: Activities are Started, Ended and Transitions are being taken. When using the process application API, the process engine makes sure that Events are delegated to the right process application. For example, assume there is a process application deployed as “invoice.war” which deploys a process definition named “invoice”. The invoice process has a task named “archive invoice”. The application “invoice.war” further provides a Java Class implementing the ExecutionListener interface and is configured to be invoked whenever the END event is fired on the “archive invoice” activity. The process engine makes sure that the event is delegated to the listener class located inside the process application: On top of the Execution and Task Listeners which are explicitly configured in the BPMN 2.0 XML, the process application API supports defining a global ExecutionListener and a global TaskListener which are notified about all events happening in the processes deployed by a process application: @ProcessApplication public class InvoiceProcessApplication extends ServletProcessApplication { public TaskListener getTaskListener() { return new TaskListener() { public void notify(DelegateTask delegateTask) { // handle all Task Events from Invoice Process } }; } public ExecutionListener getExecutionListener() { return new ExecutionListener() { public void notify(DelegateExecution execution) throws Exception { // handle all Execution Events from Invoice Process } }; } } To use the global process application Event Listeners, you need to activate the corresponding Process Engine Plugin: <process-engine name=\"default\"> ... <plugins> <plugin> <class>org.cibseven.bpm.application.impl.event.ProcessApplicationEventListenerPlugin</class> </plugin> </plugins> </process-engine> Note that the plugin is activated by default in the pre-packaged CIB seven distributions. The process application Event Listener interface is also a good place for adding the CdiEventListener bridge if you want to use CDI Events in combination with the shared process engine.",
    "url": "/manual/latest/user-guide/process-applications/process-application-event-listeners/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-applications/process-application-resources/index.html",
    "title": "Process Application Resource Access | docs.cibseven.org",
    "content": "Process applications provide and logically group resources specific to the processes they contain. There are resources that are part of the application itself, like a classloader and its classes and resources, as well as resources managed by the process engine at runtime, like a set of scripting engines or Spin data formats. This section describes under which conditions the process engine looks up resources on process application level and how that lookup can be enforced. Context Switch When executing a process instance, the process engine has to know which process application provides the corresponding resources. It then internally performs a context switch. This has the following effects: The thread context class loader is set to the process application classloader. This enables loading classes from the process application, e.g., a Java Delegate implementation. The process engine can access the resources it manages for that particular process application. This enables invoking scripting engines or Spin data formats specific to the process application. For example, before invoking a Java Delegate, the process engine performs a context switch into the respective process application. It is therefore able to set the thread context classloader to the process application classloader. If no context switch is performed, only those resources are available that are accessible on the process engine level. This is typically a different classloader and a different set of managed resources. Mechanics behind the Context Switch Note that the actual mechanics behind the context switch are platform dependent. For example: in a servlet container like Apache Tomcat, it is only necessary to set the Thread’s current Context Classloader to the web application Classloader. Context specific operations like the resolution of application-local JNDI names all build on this. In an EJB container, this is more complex. This is why the ProcessApplication class is an EJB itself in that environment (see: EJB Process Application). The process engine can then add an invocation of a business method of that EJB to the call stack and have the Application Server perform its specific logic behind the scenes. A context switch is guaranteed in the following cases: Delegation Code Invocation: Whenever delegation code like Java Delegates, execution/task listeners (Java code or scripts), etc. is called by the process engine Explicit Process Application Context Declaration: For every engine API invocation, when a process application was declared using the utility class org.cibseven.bpm.application.ProcessApplicationContext Declare Process Application Context Process application context must be declared whenever custom code uses the engine API that is not part of delegation code and when a context switch is needed for proper function. Example To clarify the use case, we assume that a process application employs the feature to serialize object-type variables in the JSON format. However, for that application JSON serialization shall be customized (think about the numerous ways to serialize a date as a JSON string). The process application therefore contains a Camunda Spin data format configurator implementation that configures the Spin JSON data format in the desired way. In turn, the process engine manages a Spin data format for that specific process application to serialize object values with. Now, we assume that a Java servlet calls the process engine API to submit a Java object and serialize it with the JSON format. The code might look as follows: public class ObjectValueServlet extends HttpServlet { protected void doGet(HttpServletRequest req, HttpServletResponse resp) { JsonSerializable object = ...; // a custom Java object ObjectValue jsonValue = Variables .objectValue(jsonSerializable) .serializationDataFormat(\"application/json\") .create(); RuntimeService runtimeService = ...; // obtain runtime service runtimeService.setVariable(\"processInstanceId\", \"variableName\", jsonValue); } } Note that the engine API is not called from within delegation code but from a servlet instead. The process engine is therefore not aware of the process application context and cannot perform a context switch to use the correct JSON data format for variable serialization. In consequence, the process application-specific JSON configuration does not apply. In such a case, the process application context can be declared by using the static methods that the class org.cibseven.bpm.application.ProcessApplicationContext provides. In particular, the method #setCurrentProcessApplication declares the process application to switch into for following engine API invocations. The method #clear resets this declaration. In the example, we wrap the #setVariable invocation accordingly: try { ProcessApplicationContext.setCurrentProcessApplication(\"nameOfTheProcessApplication\"); runtimeService.setVariable(\"processInstanceId\", \"variableName\", jsonValue); } finally { ProcessApplicationContext.clear(); } Now, the process engine knows in which context to execute the #setVariable call in. It therefore can access the correct JSON data format and serializes the variable correctly. Java API The methods ProcessApplicationContext#setCurrentProcessApplication declare process application context for all following API invocations until ProcessApplicationContext#clear is called. It is therefore advised to use a try-finally block to ensure clearance even when exceptions are raised. In addition, the methods ProcessApplicationContext#withProcessApplicationContext execute a Callable and declare the context during the Callable’s execution. Programming Model Integration Declaring process application context whenever engine API is invoked can result in highly repetitive code. Depending on your programming model, you may consider declaring the context in a place that applies to all the desired business logic in a cross-cutting manner. For example, in CDI it is possible to define method invocation interceptors that trigger based on the presence of annotations. Such an interceptor can identify the process application based on the annotation and declare the context transparently.",
    "url": "/manual/latest/user-guide/process-applications/process-application-resources/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-applications/the-process-application-class/index.html",
    "title": "The Process Application class | docs.cibseven.org",
    "content": "You can delegate the bootstrapping of the process engine and process deployment to a process application class. The basic ProcessApplication functionality is provided by the org.cibseven.bpm.application.AbstractProcessApplication base class. Based on this class there is a set of environment-specific sub classes that realize integration within a specific environment: ServletProcessApplication: To be used for process applications in a Servlet container like Apache Tomcat. JakartaServletProcessApplication: To be used for process applications in a Jakarta Servlet 5.0+ container like WildFly 27 and above. EjbProcessApplication: To be used in a Java EE application server like IBM WebSphere Application Server. JakartaEjbProcessApplication: To be used in a Jakarta EE 9+ application server like Wildfly 27+. EmbeddedProcessApplication: To be used when embedding the process engine in an ordinary Java SE application. SpringProcessApplication: To be used for bootstrapping the process application from a Spring Application Context. In the following section, we walk through the different implementations and discuss where and how they can be used. The ServletProcessApplication and JakartaServletProcessApplication Jakarta Servlet environments The JakartaServletProcessApplication can only be used in environments working with Jakarta Servlet 5.0 and above like WildFly 27+. The mechanisms described herein for the ServletProcessApplication apply in the same way. Supported on: Apache Tomcat, Wildfly. The Servlet process application is supported on all containers. Read the note about Servlet Process Application and EJB/Java EE containers Packaging: WAR (or embedded WAR inside EAR) The ServletProcessApplication class is the base class for developing process applications based on the Servlet Specification (Java Web Applications). The servlet process application implements the Java EE javax.servlet.ServletContextListener interface which allows it to participate in the deployment lifecycle of your Web application The following is an example of a Servlet Process Application: package org.cibseven.bpm.example.loanapproval; import org.cibseven.bpm.application.ProcessApplication; import org.cibseven.bpm.application.impl.ServletProcessApplication; @ProcessApplication(\"Loan Approval App\") public class LoanApprovalApplication extends ServletProcessApplication { // empty implementation } Notice the @ProcessApplication annotation. This annotation fulfills two purposes: provide the name of the ProcessApplication: You can provide a custom name for your process application using the annotation: @ProcessApplication(\"Loan Approval App\"). If no name is provided, a name is automatically detected. In case of a servlet process application, the name of the ServletContext is used. trigger auto-deployment. In a Servlet 3.0 container, the annotation is sufficient for making sure that the process application is automatically picked up by the servlet container and automatically added as a ServletContextListener to the Servlet Container deployment. This functionality is realized by a javax.servlet.ServletContainerInitializer implementation named org.cibseven.bpm.application.impl.ServletProcessApplicationDeployer which is located in the camunda-engine module. The implementation works for both embedded deployment of the camunda-engine.jar as a web application library in the WEB-INF/lib folder of your WAR file, or for the deployment of the camunda-engine.jar as a shared library in the shared library (e.g., Apache Tomcat global lib/ folder) directory of your application server. The Servlet 3.0 Specification foresees both deployment scenarios. In case of embedded deployment, the ServletProcessApplicationDeployer is notified once, when the web application is deployed. In case of deployment as a shared library, the ServletProcessApplicationDeployer is notified for each WAR file containing a class annotated with @ProcessApplication (as required by the Servlet 3.0 Specification). This means that in case you deploy to a Servlet 3.0 compliant container (such as Apache Tomcat) annotating your class with @ProcessApplication is sufficient. There is a project template for Maven called camunda-archetype-servlet-war, which gives you a complete running project based on a servlet process application. Using Servlet process applications inside an EJB/Jakarta EE/Java EE container such as Wildfly You can use the ServletProcessApplication inside an EJB / Java EE container such as Wildfly 26 and below. In Jakarta EE 9+ containers like WildFly 27 and above, you need to use the JakartaServletProcessApplication. Process application bootstrapping and deployment will work in the same way as in a Servlet container. However, you will not be able to use all Jakarta EE/Java EE features at runtime. In contrast to the EjbProcessApplication (see the next section), the ServletProcessApplication and JakartaServletProcessApplication do not perform proper Jakarta EE/Java EE cross-application context switching. When the process engine invokes Java Delegates from your application, only the Context Class Loader of the current Thread is set to the classloader of your application. This does allow the process engine to resolve Java Delegate implementations from your application but the container will not perform an EE context switch to your application. As a consequence, if you use the Servlet process application inside a Jakarta EE/Java EE container, you will not be able to use features like: Using CDI beans and EJBs as JavaDelegate implementations in combination with the Job Executor. Uusing @RequestScoped CDI Beans with the Job Executor. Looking up JNDI resources from the application’s naming scope. If your application does not use such features, it is perfectly fine to use the servlet process application inside an EE container. In that case you only get servlet specification guarantees. The EjbProcessApplication and JakartaEjbProcessApplication Jakarta EJB environments The JakartaEjbProcessApplication can only be used in environments working with Jakarta EJB. The mechanisms described herein for the EjbProcessApplication apply in the same way. Supported on: Wildfly. The EjbProcessApplication is supported on Java EE 6 to Java EE 8 containers like WildFly 26 and below. The JakartaEjbProcessApplication is supported on Jakarta EE 9+ containers like WildFly 27 and above. It is not supported on Servlet Containers like Apache Tomcat. It may be adapted to work inside Java EE 5 Containers. Packaging: JAR, WAR, EAR The EjbProcessApplication and JakartaEjbProcessApplication are the base classes for developing Jakarta EE/Java EE-based process applications. An EJB process application class itself must be deployed as an EJB. To add an EJB process application to your Java application, you have two options: Bundle the Camunda EJB Client: we provide a generic, reusable EJB process application implementation (named org.cibseven.bpm.application.impl.ejb.DefaultEjbProcessApplication) bundled as a maven artifact. You can add this implementation to your application as a maven dependency. Use the camunda-ejb-client artifact for Java EE or the camunda-ejb-client-jakarta artifact for Jakarta EE 9+ applications. Write a custom EJB process application: if you want to customize the behavior of the EjbProcessApplication or JakartaEjbProcessApplication, you can write a custom subclass of the respective class and add it to your application. Both options are explained in greater detail below. Bundling the Camunda EJB Client Jar The most convenient option for deploying a process application to a Java EE EJB container is by adding the following maven dependency to your maven project: Please import the CIB seven BOM to ensure correct versions for every CIB seven project. <dependency> <groupId>org.cibseven.bpm.javaee</groupId> <artifactId>cibseven-ejb-client</artifactId> </dependency> For Jakarta EE 9+ EJB containers, use the following dependency instead: <dependency> <groupId>org.cibseven.bpm.javaee</groupId> <artifactId>cibseven-ejb-client-jakarta</artifactId> </dependency> The Camunda EJB Client contains a reusable default implementation of the respective EJB process application as a Singleton Session Bean with auto-activation. This deployment option requires that your project is a composite deployment (such as a WAR or EAR) since you need to add a library JAR file. You could of course use something like the maven shade plugin for adding the class contained in the Camunda EJB Client artifact to a JAR-based deployment. We always recommend using the Camunda EJB Client over deploying a custom EjbProcessApplication class unless you want to customize the behavior of the EjbProcessApplication. There is a project template for Maven called camunda-archetype-servlet-war, which gives you a complete running project based on a Java EE servlet process application. Deploying a Custom EjbProcessApplication Class If you want to customize the behavior of the EjbProcessApplication class you have the option of writing a custom EjbProcessApplication class. The following is an example of such an implementation: @Singleton @Startup @ConcurrencyManagement(ConcurrencyManagementType.BEAN) @TransactionAttribute(TransactionAttributeType.REQUIRED) @ProcessApplication @Local(ProcessApplicationInterface.class) public class MyEjbProcessApplication extends EjbProcessApplication { @PostConstruct public void start() { deploy(); } @PreDestroy public void stop() { undeploy(); } } Expose Servlet Context Path Using a Custom EJB process application If your application is a WAR (or a WAR inside an EAR) and you want to use embedded forms or external task forms inside the Tasklist application, then your custom EJB process application must expose the servlet context path of your application as a property. This enables the Tasklist to resolve the path to the embedded or external task forms. Therefore, your custom EJB process application must be extended by a Map and a getter-method for that Map as follows: @Singleton @Startup @ConcurrencyManagement(ConcurrencyManagementType.BEAN) @TransactionAttribute(TransactionAttributeType.REQUIRED) @ProcessApplication @Local(ProcessApplicationInterface.class) public class MyEjbProcessApplication extends EjbProcessApplication { protected Map<String, String> properties = new HashMap<String, String>(); @PostConstruct public void start() { deploy(); } @PreDestroy public void stop() { undeploy(); } public Map<String, String> getProperties() { return properties; } } Furthermore, to provide the servlet context path a custom Java EE javax.servlet.ServletContextListener must be added to your application. Inside your custom implementation of the ServletContextListener you have to inject your custom EJB process application using the @EJB annotation, resolve the servlet context path and expose the servlet context path through the ProcessApplicationInfo#PROP_SERVLET_CONTEXT_PATH property inside your custom EJB process application. This can be done as follows: public class ProcessArchiveServletContextListener implements ServletContextListener { @EJB private ProcessApplicationInterface processApplication; public void contextInitialized(ServletContextEvent contextEvent) { String contextPath = contextEvent.getServletContext().getContextPath(); Map<String, String> properties = processApplication.getProperties(); properties.put(ProcessApplicationInfo.PROP_SERVLET_CONTEXT_PATH, contextPath); } public void contextDestroyed(ServletContextEvent arg0) { } } Finally, the custom ProcessArchiveServletContextListener has to be added to your WEB-INF/web.xml file: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <web-app version=\"2.5\" xmlns=\"http://java.sun.com/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd\"> <listener> <listener-class>org.my.project.ProcessArchiveServletContextListener</listener-class> </listener> ... </web-app> Invocation Semantics of the EJB process application The fact that the EJB process application exposes itself as a Session Bean Component inside the EJB container determines the invocation semantics when invoking code from the process application and the nature of the ProcessApplicationReference held by the process engine. When the process engine invokes the EJB process application, it gets EJB invocation semantics. For example, if your process application provides a JavaDelegate implementation, the process engine will call the EjbProcessApplication’s execute(Callable) method and from that method invoke the JavaDelegate. This makes sure that the call is intercepted by the EJB container and “enters” the process application legally. the JavaDelegate may take advantage of the EJB process application’s invocation context and resolve resources from the component’s environment (such as a java:comp/BeanManager). Big pile of EJB interceptors | | +--------------------+ | |Process Application | invoke v | | ProcessEngine ----------------OOOOO--> Java Delegate | | | | | +--------------------+ The EJB process application allows to hook into the invocation by overriding the execute(Callable callable, InvocationContext invocationContext) method. It provides the context of the current invocation (e.g., the execution) and can be used to execute custom code, for example initialize the security context before a service task is invoked. public class MyEjbProcessApplication extends EjbProcessApplication { @Override public <T> T execute(Callable<T> callable, InvocationContext invocationContext) { if(invocationContext != null) { // execute custom code (e.g. initialize the security context) } return execute(callable); } } When the EJB process application registers with a process engine (see ManagementService#registerProcessApplication(String, ProcessApplicationReference), the process application passes a reference to itself to the process engine. This reference allows the process engine to reference the process application. The EJB process application takes advantage of the EJB Containers naming context and passes a reference containing the EJB process application’s Component Name to the process engine. Whenever the process engine needs access to process application, the actual component instance is looked up and invoked. The EmbeddedProcessApplication Supported on: JVM, Apache Tomcat, Wildfly Packaging: JAR, WAR, EAR The org.cibseven.bpm.application.impl.EmbeddedProcessApplication can only be used in combination with an embedded process engine. Usage in combination with a Shared Process Engine is not supported as the class performs no process application context switching at runtime. The embedded process application also does not provide auto-startup. You need to manually call the #deploy method of your process application: // instantiate the process application MyProcessApplication processApplication = new MyProcessApplication(); // deploy the process application processApplication.deploy(); // interact with the process engine ProcessEngine processEngine = BpmPlatform.getDefaultProcessEngine(); processEngine.getRuntimeService().startProcessInstanceByKey(...); // undeploy the process application processApplication.undeploy(); Where the class MyProcessApplication could look like this: @ProcessApplication( name=\"my-app\", deploymentDescriptors={\"path/to/my/processes.xml\"} ) public class MyProcessApplication extends EmbeddedProcessApplication { } Remember that to make a manually managed EmbeddedProcessApplication work, you will have to register your ProcessEngine on the RuntimeContainer: RuntimeContainerDelegate runtimeContainerDelegate = RuntimeContainerDelegate.INSTANCE.get(); runtimeContainerDelegate.registerProcessEngine(processEngine); The SpringProcessApplication Supported on: JVM, Apache Tomcat. Packaging: JAR, WAR, EAR The org.cibseven.bpm.engine.spring.application.SpringProcessApplication class allows bootstrapping a process application through a Spring Application Context. You can either reference the SpringProcessApplication class from an XML-based application context configuration file or use an annotation-based setup. If your application is a web application you should use org.cibseven.bpm.engine.spring.application.SpringServletProcessApplication as it provides support for exposing the servlet context path through the ProcessApplicationInfo#PROP_SERVLET_CONTEXT_PATH property. We recommend to always use SpringServletProcessApplication unless the deployment is not a web application. Using this class requires the org.springframework:spring-web module to be on the classpath. Configuring a Spring Process Application The following shows an example of how to bootstrap a SpringProcessApplication inside a Spring application context XML file: <beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"> <bean id=\"invoicePa\" class=\"org.cibseven.bpm.engine.spring.application.SpringServletProcessApplication\" /> </beans> Remember to additionally add a META-INF/processes.xml file. If you are manually managing your processEngine, you will have to register it on the RuntimeContainerDelegate as described in the EmbeddedProcessEngine section. Process Application Name The SpringProcessApplication will use the bean name (id=\"invoicePa\" in the example above) as auto-detected name for the process application. Make sure to provide a unique process application name here (unique across all process applications deployed on a single application server instance). As an alternative, you can provide a custom subclass of SpringProcessApplication (or SpringServletProcessApplication) and override the getName() method. Configure a Managed Process Engine Using Spring If you use a Spring process application, you may want to configure your process engine inside the Spring application context Xml file (as opposed to the processes.xml file). In this case, you must use the org.cibseven.bpm.engine.spring.container.ManagedProcessEngineFactoryBean class for creating the process engine object instance. In addition to creating the process engine object, this implementation registers the process engine with the CIB seven infrastructure so that the process engine is returned by the ProcessEngineService. The following is an example of how to configure a managed process engine using Spring. <beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"> <bean id=\"dataSource\" class=\"org.springframework.jdbc.datasource.TransactionAwareDataSourceProxy\"> <property name=\"targetDataSource\"> <bean class=\"org.springframework.jdbc.datasource.SimpleDriverDataSource\"> <property name=\"driverClass\" value=\"org.h2.Driver\"/> <property name=\"url\" value=\"jdbc:h2:mem:camunda;DB_CLOSE_DELAY=1000\"/> <property name=\"username\" value=\"sa\"/> <property name=\"password\" value=\"\"/> </bean> </property> </bean> <bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"> <property name=\"dataSource\" ref=\"dataSource\"/> </bean> <bean id=\"processEngineConfiguration\" class=\"org.cibseven.bpm.engine.spring.SpringProcessEngineConfiguration\"> <property name=\"processEngineName\" value=\"default\" /> <property name=\"dataSource\" ref=\"dataSource\"/> <property name=\"transactionManager\" ref=\"transactionManager\"/> <property name=\"databaseSchemaUpdate\" value=\"true\"/> <property name=\"jobExecutorActivate\" value=\"false\"/> </bean> <!-- using ManagedProcessEngineFactoryBean allows registering the ProcessEngine with the BpmPlatform --> <bean id=\"processEngine\" class=\"org.cibseven.bpm.engine.spring.container.ManagedProcessEngineFactoryBean\"> <property name=\"processEngineConfiguration\" ref=\"processEngineConfiguration\"/> </bean> <bean id=\"repositoryService\" factory-bean=\"processEngine\" factory-method=\"getRepositoryService\"/> <bean id=\"runtimeService\" factory-bean=\"processEngine\" factory-method=\"getRuntimeService\"/> <bean id=\"taskService\" factory-bean=\"processEngine\" factory-method=\"getTaskService\"/> <bean id=\"historyService\" factory-bean=\"processEngine\" factory-method=\"getHistoryService\"/> <bean id=\"managementService\" factory-bean=\"processEngine\" factory-method=\"getManagementService\"/> </beans>",
    "url": "/manual/latest/user-guide/process-applications/the-process-application-class/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-applications/the-processes-xml-deployment-descriptor/index.html",
    "title": "The processes.xml Deployment Descriptor | docs.cibseven.org",
    "content": "The processes.xml deployment descriptor contains the deployment metadata for a process application. The following example is a simple example of a processes.xml deployment descriptor: <process-application xmlns=\"http://www.camunda.org/schema/1.0/ProcessApplication\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <process-archive name=\"loan-approval\"> <process-engine>default</process-engine> <properties> <property name=\"isDeleteUponUndeploy\">false</property> <property name=\"isScanForProcessDefinitions\">true</property> </properties> </process-archive> </process-application> A single deployment (process-archive) is declared. The process archive has the name loan-approval and is deployed to the process engine with the name default. Two additional properties are specified: isDeleteUponUndeploy: this property controls whether the undeployment of the process application should entail that the process engine deployment is deleted from the database. The default setting is false. If this property is set to true, undeployment of the process application leads to the removal of the deployment (including process instances) from the database. isScanForProcessDefinitions: if this property is set to true, the classpath of the process application is automatically scanned for deployable resources. Deployable resources must end in .bpmn20.xml, .bpmn, .cmmn11.xml, .cmmn, .dmn11.xml or .dmn. See Deployment Descriptor Reference for complete documentation of the syntax of the processes.xml file. Empty processes.xml The processes.xml may optionally be empty (left blank). In this case default values are used. The empty processes.xml corresponds to the following configuration: <process-application xmlns=\"http://www.camunda.org/schema/1.0/ProcessApplication\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <process-archive> <properties> <property name=\"isDeleteUponUndeploy\">false</property> <property name=\"isScanForProcessDefinitions\">true</property> </properties> </process-archive> </process-application> The empty processes.xml will scan for process definitions and perform a single deployment to the default process engine. Location of the processes.xml File The default location of the processes.xml file is META-INF/processes.xml. CIB seven will parse and process all processes.xml files on the classpath of a process application. Composite process applications (WAR / EAR) may carry multiple subdeployments providing a META-INF/processes.xml file. In an apache maven based project, add the the processes.xml file to the src/main/resources/META-INF folder. Custom Location for the processes.xml File If you want to specify a custom location for the processes.xml file, you need to use the deploymentDescriptors property of the @ProcessApplication annotation: @ProcessApplication( name=\"my-app\", deploymentDescriptors={\"path/to/my/processes.xml\"} ) public class MyProcessApp extends ServletProcessApplication { } The provided path(s) must be resolvable through the ClassLoader#getResourceAsStream(String)-Method of the classloader returned by the AbstractProcessApplication#getProcessApplicationClassloader() method of the process application. Multiple distinct locations are supported. Configure Process Engines in the processes.xml File The processes.xml file can also be used for configuring one or multiple process engine(s). The following is an example of a configuration of a process engine inside a processes.xml file: <process-application xmlns=\"http://www.camunda.org/schema/1.0/ProcessApplication\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <process-engine name=\"my-engine\"> <configuration>org.cibseven.bpm.engine.impl.cfg.StandaloneInMemProcessEngineConfiguration</configuration> </process-engine> <process-archive name=\"loan-approval\"> <process-engine>my-engine</process-engine> <properties> <property name=\"isDeleteUponUndeploy\">false</property> <property name=\"isScanForProcessDefinitions\">true</property> </properties> </process-archive> </process-application> The <configuration>...</configuration> property allows specifying the name of a process engine configuration class to be used when building the process engine. Specify Tenant-Ids for Process Archives in the processes.xml File For Multi-Tenancy with Tenant-Identifiers, you can specify a tenant-id of a process archive by setting the attribute tenantId. If a tenant-id is set then all containing resources will be deployed for the given tenant-id. The following is an example of a processes.xml file which contains one process archive with a tenant-id: <process-application xmlns=\"http://www.camunda.org/schema/1.0/ProcessApplication\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <process-archive name=\"loan-approval\" tenantId=\"tenant1\"> <process-engine>default</process-engine> <properties> <property name=\"isDeleteUponUndeploy\">false</property> <property name=\"isScanForProcessDefinitions\">false</property> </properties> </process-archive> </process-application> Note that the processes.xml file can contain multiple process archives with different tenant-ids. Process Application Deployment When deploying a set of BPMN 2.0 files to the process engine, a process deployment is created. The process deployment is performed to the process engine database so that when the process engine is stopped and restarted, the process definitions can be restored from the database and execution can continue. When a process application performs a deployment, in addition to the database deployment it will create a registration for this deployment with the process engine. This is illustrated in the following figure: Deployment of the process application “invoice.war” is illustrated on the left hand side: The process application “invoice.war” deploys the invoice.bpmn file to the process engine. The process engine checks the database for a previous deployment. In this case, no such deployment exists. As a result, a new database deployment deployment-1 is created for the process definition. The process application is registered for the deployment-1 and the registration is returned. When the process application is undeployed, the registration for the deployment is removed (see right hand side of the illustration above). After the registration is cleared, the deployment is still present in the database. The registration allows the process engine to load additional Java Classes and resources from the process application when executing the processes. In contrast to the database deployment, which can be restored whenever the process engine is restarted, the registration of the process application is kept as in-memory state. This in-memory state is local to an individual cluster node, allowing us to undeploy or redeploy a process application on a particular cluster node without affecting the other nodes and without having to restart the process engine. If the Job Executor is deployment aware, job execution will also stop for jobs created by this process application. However, as a consequence, the registration also needs to be re-created when the application server is restarted. This happens automatically if the process application takes part in the application server deployment lifecycle. For instance, ServletProcessApplications are deployed as ServletContextListeners and when the servlet context is started, it creates the deployment and registration with the process engine. The redeployment process is illustrated in the next figure: (a) Left hand side: invoice.bpmn has not changed: The process application “invoice.war” deploys the invoice.bpmn file to the process engine. The process engine checks the database for a previous deployment. Since deployment-1 is still present in the database, the process engine compares the xml content of the database deployment with the bpmn20.xml file from the process application. In this case, both xml documents are identical which means that the existing deployment can be resumed. The process application is registered for the existing deployment deployment-1. (b) Right hand side: invoice.bpmn has changed: The process application “invoice.war” deploys the invoice.bpmn file to the process engine. The process engine checks the database for a previous deployment. Since deployment-1 is still present in the database, the process engine compares the xml content of the database deployment with the invoice.bpmn file from the process application. In this case, changes are detected which means that a new deployment must be created. The process engine creates a new deployment deployment-2, containing the updated invoice.bpmn process. The process application is registered for the new deployment deployment-2 AND the existing deployment deployment-1. The resuming of the previous deployment (deployment-1) is a feature called resumePreviousVersions and is activated by default. There are two different possibilities how to resume previous deployments. The first one, which is the default way, is that a previous deployment will be resolved based on the process definition keys. Depending on the processes you deploy with your process application all deployments will be resumed that contain process definitions with the same key. The second option is to resume deployments based on the deployment name (more precisely the value of the name attribute of the process archive). That way you can delete a process in a new deployment but the process application will register itself for the previous deployments and therefore also for the deleted process. This makes it possible that the running process instances of the deleted process can continue for this process application. To activate this behavior you have set the property isResumePreviousVersions to true and the property resumePreviousBy to deployment-name: <process-application xmlns=\"http://www.camunda.org/schema/1.0/ProcessApplication\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <process-archive name=\"loan-approval\"> ... <properties> ... <property name=\"isResumePreviousVersions\">true</property> <property name=\"resumePreviousBy\">deployment-name</property> </properties> </process-archive> </process-application> If you want to deactivate this feature, you have to set the property to false in processes.xml file: <process-application xmlns=\"http://www.camunda.org/schema/1.0/ProcessApplication\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <process-archive name=\"loan-approval\"> ... <properties> ... <property name=\"isResumePreviousVersions\">false</property> </properties> </process-archive> </process-application>",
    "url": "/manual/latest/user-guide/process-applications/the-processes-xml-deployment-descriptor/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/authorization-service/index.html",
    "title": "Authorization Service | docs.cibseven.org",
    "content": "Camunda allows users to authorize access to the data it manages. This makes it possible to configure which user can access which process instances, tasks, etc… Authorization has a performance cost and introduces some complexity. It should only be used if required. When is Authorization required? Not every CIB seven setup needs to enable authorization. In many scenarios, CIB seven is embedded into an application and the application itself ensures that users can only access data they are authorized to access. Generally speaking, authorization is only required if untrusted parties interact with the process engine API directly. If you embed the process engine into a Java application, you usually do not need to enable authorization. The application can control how the API is accessed. Situations in which authorization is required: Camunda Rest API is made accessible to users who should not have full access, even after authentication. Camunda Webapplication is made accessible to users who should not have full access, even after authentication. Other situations in which an untrusted user can directly construct the queries and commands executed on the process engine. Situations in which authorization is not required An application completely controls the API methods invoked on the process engine. Camunda Webapplication is made accessible to users who can have full access after authentication. Example Assume that you have the following authorization requirement: As a regular user, I can only see the tasks that are assigned to me. If the engine is embedded into a Java application, the application can easily ensure this by restricting the task query on the assignee property. The application can guarantee this since the Camunda API is not directly exposed to the user. By contrast, if the Camunda Rest API is directly exposed over the network to a Javascript application, then a malicious user, once authenticated, can send a request to the server querying all tasks, even the ones that are not assigned to this user. In this case, authorization needs to be turned on to ensure the user only sees the tasks which he is authorized to see, regardless of the query parameters. Basic Principles Authorizations An Authorization assigns a set of Permissions to an identity to interact with a given Resource. Examples User ‘jonny’ is authorized to create new users Group ‘marketing’ is not authorized to delete the Group ‘sales’ Group ‘marketing’ is not allowed to use the tasklist application. Identities CIB seven distinguishes between two types of identities: users and groups. Authorizations can either range over all users (userId = ANY), an individual user or a group of users. Permissions A Permission defines the way an identity is allowed to interact with a certain resource. The basic permissions available in the engine are: None All Read Update Create Delete Access Note that the permission None does not mean no permissions are granted. Instead, it represents “no action”. Additionally, the All permission will vanish from a user if a single permission is revoked. For detailed list of available permissions please check Permission by resource section. A single authorization object may assign multiple permissions to a single user and resource: authorization.addPermission(Permissions.READ); authorization.addPermission(Permissions.UPDATE); authorization.addPermission(Permissions.DELETE); Resources Resources are the entities the user interacts with. The following resources are available: Resource Name Integer representation Resource Id Application (Cockpit, Tasklist, ...) 0 admin/cockpit/tasklist/* Authorization 4 Authorization Id Batch 13 Batch Id Decision Definition 10 Decision Definition Key Decision Requirements Definition 14 Decision Requirements Definition Key Deployment 9 Deployment Id Filter 5 Filter Id Group 2 Group Id Group Membership 3 Group Id Process Definition 6 Process Definition Key Process Instance 8 Process Instance Id Task 7 Task Id Historic Task 19 Historic Task Id Historic Process Instance 20 Historic Process Instance Id Tenant 11 Tenant Id Tenant Membership 12 Tenant Id User 1 User Id Report 15 Report Id Dashboard 16 Dashboard Id User Operation Log Category 17 User Operation Log Entry Category System 21 *System resources do not support individual resource ids. You have to use them with a wildcard id (*). Note: The Resource Id should be ‘*’ when you create new authorization with CREATE permissions only. Authorization Type There are three types of authorizations: Authorization type Description Integer representation Global Authorization (AUTH_TYPE_GLOBAL) Ranges over all users and groups (userId = ANY) and are usually used for fixing the \"base\" permission for a resource. 0 Grant Authorization (AUTH_TYPE_GRANT) Ranges over users and groups and grants a set of permissions. Grant authorizations are commonly used for adding permissions to a user or group that the global authorization revokes. 1 Revoke Authorization (AUTH_TYPE_REVOKE) Ranges over users and groups and revokes a set of permissions. Revoke authorizations are commonly used for revoking permissions to a user or group that the global authorization grants. 2 Performance of REVOKE Authorizations See the Performance Considerations section on this Page. Authorization Precedence Authorizations may range over all users, an individual user or a group of users, or they may apply to an individual resource instance or all instances of the same type (resourceId = ANY). The precedence is as follows: An authorization applying to an individual resource instance precedes over an authorization applying to all instances of the same resource type. An authorization for an individual user precedes over an authorization for a group. A Group authorization precedes over a GLOBAL authorization. A Group GRANT authorization precedes over a Group REVOKE authorization. A User GRANT authorization precedes over a User REVOKE authorization. When are Authorizations checked? Authorizations are checked if the configuration option authorizationEnabled is set to true (default value is false). there is a currently authenticated user. The last item means that even if authorization is enabled, authorization checks are only performed if a user is currently authenticated. If no user is authenticated, then the engine does not perform any checks. When using the Camunda Webapps, it is always ensured that a user is authenticated before the user can access any restricted resources. When embedding the process engine into a custom application, the application needs to take care of authentication if it needs authorization checks to be performed. Authentication vs. Authorization Authentication and Authorization are two distinct concepts as explained here. Permissions by Resource This section explains which permissions are available on which resources. Read, Update, Create, Delete The permissions Read, Update, Create, and Delete are available for most of the resources. The following table gives an overview for which resources they are available: Read Update Create Delete Authorization X X X X Batch X X X X Decision Definition X X Decision Requirements Definition X Deployment X X X Filter X X X X Group X X X X Group Membership X X Process Definition X X X Process Instance X X X X Task X X X X Historic Task X Historic Process Instance X Tenant X X X X Tenant Membership X X User X X X X User Operation Log Category X X X To execute an operation asynchronously, only a Create permission on the Batch Resource is required. However, when executing the same operation synchronously, the specific permissions (e.g. Delete on Process Instance Resource) are checked. For example, a user without the Update permission on the Process Instance Resource and granted Create permission on the Batch Resource can modify multiple process instances asynchronously by creating a batch. However, the user can’t execute this operation synchronously. Additional Task Permissions In addition to Update, Read, and Delete, the following permissions are available on the Task Resource: Task Assign Task Work Update Variable A user can perform different actions on a task, like assigning the task, claiming the task or completing the task. If a user has Update permissions on a task (or Update Task permissions on the corresponding process definition), the user is authorized to perform all these task actions. If finer grained authorizations are required, the permissions Task Work and Task Assign can be used. The intuition behind Task Work is that it only authorizes the user to work on a task (i.e., claim and complete it) but not assign it to another user or in another way “distribute work” to colleagues. If a user has Update Variable permission on a task (or Update Task Variable permission on the corresponding process definition) the user is authorized to perform set/remove task variable actions. The table below shows a detailed overview on which permissions authorize a user to perform which task actions: Task Work Task Assign Update Variable Update Claim X X Complete X X Add Candidate User X X Delete Candidate User X X Set Assignee X X Set Owner X X Add Candidate Group X X Delete Candidate Group X X Save X X Set Priority X X Set Name X X Set Description X X Set Due Date X X Set Follow Up Date X X Set Local Variable X X Remove Local Variable X X GRANT and REVOKE authorizations with Task Work, Task Assign, and Update Variable permissions precede over Update and Update Task. Default Task Permissions When a user is related to a task as an assignee, a candidate user, a part of a candidate group, or an owner, these users obtain the default permissions as either Task Work or Update, based on the process engine configuration property defaultUserPermissionNameForTask. If the “defaultUserPermissionNameForTask” configuration option is not set, then by default Update permission is granted. Additional Process Definition Permissions In Addition to Update, Read and Delete, the following permissions are available on the Process Definition Resource: Read Task Update Task Task Work Task Assign Create Instance Read Instance Update Instance Retry Job Suspend Suspend Instance Update Instance Variable Update Task Variable Migrate Instance Delete Instance Read History Delete History Update History The Create Instance permission is required to start new process instances. Start new process instance To perform that action, the user also needs to have Create permission on the process instance resource. GRANT and REVOKE authorizations with Retry Job, Suspend, Suspend Instance, Update Instance Variable, and Update Task Variable permissions precede over Update. Keep in mind that user who is allowed to perform variable updates could trigger other changes in the process by updating a variable. For example, successful evaluation of conditional event related to this variable. Additional Process Instance Permissions In addition to Create, Read, Update, and Delete, the following permissions are available on the Process Instance Resource: Retry Job Suspend Update Variable GRANT and REVOKE authorizations with Retry Job, Suspend, and Update Variable permissions precede over Update. Keep in mind that user who is allowed to perform variable updates could trigger other changes in the process by updating a variable. For example, successful evaluation of conditional event related to this variable. Additional Decision Definition Permissions In addition to Update, Read, and Delete, the following permissions are available on the Decision Definition Resource: Create Instance Read History Delete History The Create Instance permission is required to evaluate decisions with the decision service. Additional Batch Permissions In addition to Create, Update, Read, and Delete, the following permissions are available on the Batch Resource: Read History Delete History Create Batch Migrate Process Instances Create Batch Modify Process Instances Create Batch Restart Process Instances Create Batch Delete Running Process Instances Create Batch Delete Finished Process Instances Create Batch Delete Decision Instances Create Batch Set Job Retries Create Batch Set External Task Retries Create Batch Update Process Instances Suspend Create Batch Set Removal Time Create Batch Set Variables Create Batch Correlate Messages GRANT and REVOKE authorizations with “Create Batch …” permissions precede over Create. Default Read Variable Permissions When the enforceSpecificVariablePermission process engine configuration is enabled, in order to read variables, the user needs to be granted the following permissions: In case of Tasks Read Variable (for process and standalone tasks) In case of Historic Tasks Read Variable (only enforced when Historic Instance Permissions are enabled) In case of Process Definitions Read Instance Variable (for runtime process instance variables) Read History Variable (for historic variables) Read Task Variable (for runtime task variables) Application Permissions The resource “Application” uniquely supports the Access permission. The Access permission controls whether a user has access to a Camunda web application or not. Out of the box, it can be granted for the following applications (resource ids): admin cockpit tasklist optimize * (Any / All) User Operation Log Permissions The resource “User Operation Log Category” controls whether a user can access user operation log entries from the specified categories. Out of the box, it can be granted for the following categories (resource ids): TaskWorker Admin Operator * (Any / All) Historic Instance Permissions The resources control whether a user can read the history related to a specific instance. Compared to runtime permissions, historic permissions are not immediately removed when the related instance has been finished. The Removal-Time-based History Cleanup Strategy removes historic permissions at a later point. You can enable the permissions with the help of a process engine configuration flag: <property name=\"enableHistoricInstancePermissions\">true</property> The feature is disabled by default because of two reasons: When enabled, the SQL queries are more complex because additional authorization checks are performed. More complex queries may degrade the performance. When enabled and an Identity Link is added to a Task, the respective User or Group is authorized to read the associated history (e. g. for the Task, Variable, or Identity Link History). For CIB seven versions <= 7.12, the history is not readable in this case. Historic Task Permissions When permission is granted to a Historic Task, you can use the following queries to retrieve the entities related to the Historic Task: Historic Task Instance Query Historic Variable Instance Query Historic Detail Query Identity Link Log Query User Operation Log Query Historic Process Instance Permissions When permission is granted to a Historic Process Instance, you can use the following queries to retrieve the entities related to the Historic Process Instance: Historic Process Instance Query Historic Activity Instance Query Historic Task Instance Query Historic Variable Instance Query Historic Detail Query Identity Link Log Query Historic Incident Query Job Log Query External Task Log Query User Operation Log Query System permissions Permissions for the system resource are usually granted to operations engineers who supervise processes and applications and ensure they run smoothly from a technical perspective. Typically, those people do not need full access to the system like an administrator does. They must be able to access and change system information, including system properties, metrics, database information, telemetry, and license key data. Administrators will not need to have system permissions because their role already grants them access to all features. See also the Administrators section. The following table gives an overview of the features that the system permissions grant access to. Read Set Delete Configure Telemetry (Deprecated) X Get Telemetry Data X Get Telemetry Status (Deprecated) X Get Database Table Count X Get Database Table Name X Get Database Table Meta Data X Get History Level X Get Property X Set Property X Delete Property X Get License Key X Set License Key X Delete License Key X Register Process Application X Unregister Process Application X Get Process Application for Deployment X Register Deployment X Unregister Deployment X Get Registered Deployment X Delete Metrics X Delete Task Metrics X Query Schema Log X Administrators CIB seven has no explicit concept of “administrator” beyond it being a user who has been granted all authorizations on all resources. The “camunda-admin” Group When downloading the CIB seven distribution, the invoice example application creates a group with id camunda-admin and grants all authorizations on all resources to this group. In absense of the demo application, this task is performed by the Camunda Admin Web Application. If the Camunda webapplication is started for the first time and no user exists in the database, it asks you to perform the “initial setup”. In this process, the camunda-admin group is created and granted all permissions on all resources. LDAP The group “camunda-admin” is not created when using LDAP (since LDAP is only accessed in a read-only way). Also see the below section on the administrator authorization plugin. The Administrator Authorization Plugin The administrator authorization plugin is a process engine plugin with the following functionality: when the process engine is started, it grants administrative access to a configured group or user. Effectively this means that it grants all permissions on all resources to the configured group or user. Usually this is used to bootstrap an LDAP installation: granting administrative access to an initial user who can then log in to Admin and configure additional authorizations using the UI. The following is an example of how to configure the administrator authorization plugin in bpm-platform.xml / processes.xml: <process-engine name=\"default\"> ... <plugins> <plugin> <class>org.cibseven.bpm.engine.impl.plugin.AdministratorAuthorizationPlugin</class> <properties> <property name=\"administratorUserName\">admin</property> </properties> </plugin> </plugins> </process-engine> The plugin will make sure that administrator authorizations (ALL permissions) are granted on all resources whenever the process engine is started. It is not necessary to configure all LDAP users and groups which should have administrator authorization. It is usually enough to configure a single user and use that user to log into the webapplication and create additional authorizations using the User Interface. Complete list of configuration properties: Property Description administratorUserName The name of the administrator user. If this name is set to a non-null and non-empty value, the plugin will create user-level Administrator authorizations on all built-in resources. administratorGroupName The name of the administrator group. If this name is set to a non-null and non-empty value, the plugin will create group-level Administrator authorizations on all built-in resources. Configuration Options This section explains available process engine configuration options related to authorization. Enable Authorization Checks Authorization checks can be globally enabled or disabled using the configuration option authorizationEnabled. The default setting for this configuration option is false. Enable Authorization Checks for User Code The configuration option authorizationEnabledForCustomCode controls whether authorization checks are performed for commands executed by delegation code (i.e., a Java Delegate). The default setting for this configuration option is false. Check Revoke Authorizations The configuration option authorizationCheckRevokes controls whether authorization checks take into account authorizations of type Revoke. Available values are: always: Always enables check for revoke authorizations. This mode is equal to the < 7.5 behavior. NOTE: Checking revoke authorizations is very expensive for resources with a high potential cardinality like tasks or process instances and can render authorized access to the process engine effectively unusable on most databases. You are therefore strongly discouraged from using this mode. never: Never checks for revoke authorizations. This mode has best performance and effectively disables the use of revoke authorizations. Note: It is strongly recommended to use this mode. auto (default value): This mode only checks for revoke authorizations if at least one revoke authorization currently exits for the current user or one of the groups the user is a member of. To achieve this it is checked once per command whether potentially applicable revoke authorizations exist. Based on the outcome, the authorization check then uses revoke or not. NOTE: Checking revoke authorizations is very expensive for resources with a high potential cardinality like tasks or process instances and can render authorized access to the process engine effectively unusable on most databases. Also see the Performance Considerations section on this page. Java API example An authorization is created between a user/group and a resource. It describes the user/group’s permissions to access that resource. An authorization may express different permissions, such as the permission to Read, Update, and Delete the resource. (See Authorization for details). To grant the permission to access a certain resource, an authorization object is created. For example, to give access to a certain filter: Authorization auth = authorizationService.createNewAuthorization(AUTH_TYPE_GRANT); // The authorization object can be configured either for a user or a group: auth.setUserId(\"john\"); // -OR- auth.setGroupId(\"management\"); //and a resource: auth.setResource(\"filter\"); auth.setResourceId(\"2313\"); // a resource can also be a process definition auth.setResource(Resources.PROCESS_INSTANCE); // the process defintion key is the resource id auth.setResourceId(\"invoice\"); // finally the permissions to access that resource can be assigned: auth.addPermission(Permissions.READ); // more than one permission can be granted auth.addPermission(Permissions.CREATE); // and the authorization object is saved: authorizationService.saveAuthorization(auth); As a result, the given user or group will have permission to Read the referenced filter. Another possible example would be to restrict the group of persons who are allowed to start a specific process: //we need to authorizations, one to access the process definition and another one to create process instances Authorization authProcessDefinition = authorizationService.createNewAuthorization(AUTH_TYPE_GRANT); Authorization authProcessInstance = authorizationService.createNewAuthorization(AUTH_TYPE_GRANT); authProcessDefinition.setUserId(\"johnny\"); authProcessInstance.setUserId(\"johnny\"); authProcessDefinition.setResource(Resources.PROCESS_DEFINITION); authProcessInstance.setResource(Resources.PROCESS_INSTANCE); //the resource id for a process definition is the process definition key authProcessDefinition.setResourceId(\"invoice\"); //asterisk to allow the start of a process instance authProcessInstance.setResourceId(\"*\") // allow the user to create instances of this process definition authProcessDefinition.addPermission(Permissions.CREATE_INSTANCE); // and to create processes authProcessInstance.addPermission(Permissions.CREATE); authorizationService.saveAuthorization(authProcessDefinition); authorizationService.saveAuthorization(authProcessInstance); Camunda Admin Webapp The Camunda Admin Webapplication provides an out of the box UI for configuring Authorizations. Performance Considerations Authorizations are calculated by the database which is most efficient. Example: when performing a task query, the database query only returns the tasks for which the user has a READ authorization. Performance of Checking Grant Authorizations When only Grant authorizations are used, the check is very efficient since the authorization table can be joined with the resource table (task table, process instance table, etc…). Performance of Checking Revoke Authorizations Revoke authorizations are expensive to check. The check needs to consider the precedence of authorizations. Example: a user level Grant is stronger than a group level Revoke. A sequence of nested SQL CASE statements and a subselect is used to account for the precedence. This has two downsides: The check scales linearly with the cardinality of the resource table (doubling the number of tasks makes the query twice as slow) The particular construct based on CASE statements performs extremely poorly on the following databases: PostgreSQL, DB2 On these databases, revoke authorizations are effectively unusable. Also see the Configuration Options section on this page.",
    "url": "/manual/latest/user-guide/process-engine/authorization-service/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/batch/index.html",
    "title": "Batch | docs.cibseven.org",
    "content": "Batch is a concept to offload workload from the current execution to be processed in the background. This allows to run a process engine command asynchronously on a large set of instances without blocking. It also decouples the separate command invocations from each other. For example the process instance migration command can be executed using a batch. This allows to migrate process instances asynchronously. In a synchronous process instance migration, all migrations are executed in a single transaction. First of all, this requires all of them to succeed to commit the transaction. For a large set of process instances, the transaction can also become too large to even be committed to the database. With batch migration both of these traits change. A batch executes the migration in smaller chunks, each using a single transaction. Benefits: asynchronous (non-blocking) execution execution can utilize multiple threads and job executors decoupling of execution, i.e., every batch execution job uses its own transaction Disadvantages: manual polling for completion of the batch contention with other jobs executed by the process engine a batch can fail partially while a subset was already executed, e.g., some process instances were migrated where others failed Technically, a batch represents a set of jobs which execute a command in the context of the process engine. The batch utilizes the job executor of the process engine to execute the batch jobs. A single batch consists of three job types: Seed job: creates all batch execution jobs required to complete the batch Execution jobs: the actual execution of the batch command, e.g., the process instance migration Monitor job: after the seed job finished, it monitors the progress of the batch execution and completion API The following gives an overview of the Java API for batches. Creating a Batch A batch is created by executing a process engine command asynchronously. You can find a list of currently supported batch types in the Batch operations. The Java API can be used to create Batch command. Refer to specific commands for exact usage examples. Query a Batch You can query a running batch by the id and the type, for example to query for all running process instance migration batches. List<Batch> migrationBatches = processEngine.getManagementService() .createBatchQuery() .type(Batch.TYPE_PROCESS_INSTANCE_MIGRATION) .list(); Batch Statistics You can query for statistics of batches by using the management service. The batch statistics will contain information about the remaining, completed and failed batch execution jobs. List<BatchStatistics> migrationBatches = processEngine.getManagementService() .createBatchStatisticsQuery() .type(Batch.TYPE_PROCESS_INSTANCE_MIGRATION) .list(); History of a Batch For the history level FULL a historic batch entry is created. You can query it using the history service. HistoricBatch historicBatch = processEngine.getHistoryService() .createHistoricBatchQuery() .batchId(batch.getId()) .singleResult(); The history also contains job log entries for the seed, monitor and execution jobs. You can query the corresponding job log entries by the specific job definition id. HistoricBatch historicBatch = ... List<HistoricJobLog> batchExecutionJobLogs = processEngine.getHistoryService() .createHistoricJobLogQuery() .jobDefinitionId(historicBatch.getBatchJobDefinitionId()) .orderByTimestamp() .list(); You can make a configuration for history cleanup of the finished historic batch operations. Suspend a Batch To pause the execution of a batch and all corresponding jobs, a batch can be suspended using the management service. processEngine.getManagementService() .suspendBatchById(\"myBatch\"); A suspended batch can then be activated again, also using the management service. processEngine.getManagementService() .activateBatchById(\"myBatch\"); Delete a Batch A running batch can be deleted using the management service. // Delete a batch preserving the history of the batch processEngine.getManagementService() .deleteBatch(\"myBatch\", false); // Delete a batch include history of the batch processEngine.getManagementService() .deleteBatch(\"myBatch\", true); A historic batch can be deleted using the history service. processEngine.getHistoryService() .deleteHistoricBatch(\"myBatch\"); For a running batch which still executes jobs it is recommended to suspend the batch before deleting it. See the Suspend a Batch section for details. Priority of a Batch As all batch jobs are executed using the job executor, it is possible to use the job prioritization feature to adjust the priority of batch jobs. The default batch job priority is set by the process engine configuration batchJobPriority. It is possible to adjust the priority of a specific batch job definition or even a single batch job using the management service. Batch batch = ...; String batchJobDefinitionId = batch.getBatchJobDefinitionId(); processEngine.getManagementService() .setOverridingJobPriorityForJobDefinition(batchJobDefinitionId, 100, true); Operation log Please note that a user operation log is written for Batch creation itself only, execution of the seed job as well as individual jobs that perform operations are performed by Job Executor and therefore are not considered to be user operations. Job Definitions Seed Job A batch initially creates a seed job. This seed will be repeatedly executed to create all batch execution jobs. For example if a user starts a process instance migration batch for 1000 process instances. With the default process engine configuration the seed job will create 10 batch execution jobs on every invocation. Every execution job will migrate 1 process instance. In sum the seed job will be invoked 100 times, until it has created the 1000 execution jobs required to complete the batch. The Java API can be used to get the job definition for the seed job of a batch: Batch batch = ...; JobDefinition seedJobDefinition = processEngine.getManagementService() .createJobDefinitionQuery() .jobDefinitionId(batch.getSeedJobDefinitionId()) .singleResult(); To pause the creation of further batch execution jobs, the seed job definition can be suspended with the management service: processEngine.getManagementService() .suspendJobByJobDefinitionId(seedJobDefinition.getId()); Execution Jobs The execution of a batch is split into several execution jobs. The specific number of jobs depends on the total jobs of the batch and the process engine configuration (see seed job). Every execution job executes the actual batch command for a given number of invocations, e.g., migrate a number of process instances. The execution jobs will be executed by the job executor. They behave like other jobs which means they can fail and the job executor will retry failed batch execution jobs. Also, there will be incidents for failed batch execution jobs with no retries left. The Java API can be used to get the job definition for the execution jobs of a batch, e.g., for a process instance migration batch: Batch batch = ...; JobDefinition executionJobDefinition = processEngine.getManagementService() .createJobDefinitionQuery() .jobDefinitionId(batch.getBatchJobDefinitionId()) .singleResult(); To pause the execution of further batch execution jobs, the batch job definition can be suspended with the management service: processEngine.getManagementService() .suspendJobByJobDefinitionId(executionJobDefinition.getId()); Monitor Job After all batch execution jobs were created by the seed job a monitor job is created for the batch. This job regularly polls if the batch has been completed, i.e., all batch execution jobs were completed. The polling interval can be configured by the batchPollTime (default: 30 seconds) property of the process engine configuration. The Java API can be used to get the job definition for the monitor job of a batch: Batch batch = ...; JobDefinition monitorJobDefinition = processEngine.getManagementService() .createJobDefinitionQuery() .jobDefinitionId(batch.getMonitorJobDefinitionId()) .singleResult(); To prevent the completion of the batch, i.e., deletion of the runtime data, the monitor job definition can be suspended with the management service: processEngine.getManagementService() .suspendJobByJobDefinitionId(monitorJobDefinition.getId()); Configuration You can configure the number of jobs created by every seed job invocation batchJobsPerSeed (default: 100) and the number of invocations per batch execution job invocationsPerBatchJob (default: 1) in the process engine configuration. The number of invocations per batch execution job can be changed for each batch operation type individually with the help of the process engine configuration property invocationsPerBatchJobByBatchType. In case you haven’t specified the invocations per batch job by type, the configuration falls back to the global configuration specified via invocationsPerBatchJob. You can configure the property in three ways: Programmatically with the help of a Process Engine Plugin In Spring-based environments via Spring XML Configuration <bean id=\"processEngineConfiguration\" class=\"org.cibseven.bpm.engine.impl.cfg.StandaloneInMemProcessEngineConfiguration\"> <!-- ... --> <property name=\"invocationsPerBatchJobByBatchType\"> <map> <entry key=\"process-set-removal-time\" value=\"10\" /> <entry key=\"historic-instance-deletion\" value=\"3\" /> <!-- in case of custom batch operations --> <entry key=\"my-custom-operation\" value=\"7\" /> </map> </property> </bean> In Spring Boot environment via the application.yaml file camunda.bpm.generic-properties.properties: invocations-per-batch-job-by-batch-type: process-set-removal-time: 10 historic-instance-deletion: 3 my-custom-operation: 7 # in case of custom batch operations",
    "url": "/manual/latest/user-guide/process-engine/batch/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/batch-operations/index.html",
    "title": "Batch operations | docs.cibseven.org",
    "content": "The following operations can be executed asynchronously Process Instance Migration Cancellation of running Process Instances Deletion of Historic Process Instances Update suspend state of process instances Setting retries and due dates of jobs using the builder pattern Setting retries of jobs associated with Process Instances Process Instance Modification Process Instance Restart Setting retries of external tasks Set Variables to Process Instances Correlate Messages to Process Instances Set a Removal Time to Historic Process Instances Set a Removal Time to Historic Decision Instances Set a Removal Time to Historic Batches All batch operations rely on corresponding methods that provide the possibility to operate on a list of entities synchronously. Please refer to the general Batch documentation to understand the creation process better. Asynchronous operations can be performed based on a list of specific instances as well as on the result of a query providing a resulting list of instances. If both a list of instances and a query are provided, the resulting set of affected instances will consist of the union of those two subsets. All listed batch operations, except Set a Removal Time to Historic Batches, are deployment-aware. In particular, this means that the seed job and execution jobs will receive a deploymentId so deployment-aware job executors can pick up those jobs of a batch that need to be executed on their nodes. The deployment id of the seed job is chosen from the list of involved deployments. This list is derived from the resulting set of affected instances. Execution jobs only contain elements of the same deployment and are bound to that deployment’s id. Cancellation Of Running Process Instances Cancellation of running process instances can be performed asynchronously using the following Java API method invocation: List<String> processInstanceIds = ...; runtimeService.deleteProcessInstancesAsync(processInstanceIds,null, REASON); There are overloaded methods of the above which allow you to control the following parameters: skipCustomListeners: Skip execution listener invocation for activities that are started or ended as part of this request. skipSubprocesses: Skip deletion of the subprocesses related to deleted processes as part of this request. skipIoMappings: Skip the IO Mappings if the process instance contains any which would prevent the deletion otherwise. Deletion Of Historic Process Instances Deletion of historic process instances can be performed asynchronously using the following Java API method invocation: List<String> historicProcessInstanceIds = ...; historyService.deleteHistoricProcessInstancesAsync( historicProcessInstanceIds, TEST_REASON); Update Suspend State Of Process Instances Update the suspension state of multiple process instances asynchronously using the following Java API method invocation: List<String> processInstanceIds = ...; runtimeService.updateProcessInstanceSuspensionState().byProcessInstanceIds( processInstanceIds).suspendAsync(); Setting retries and due dates of jobs using the builder pattern Setting retries of jobs can be performed asynchronously using a builder. There are two general ways to reference jobs: by job ids/job queries or by process. Here are demonstrations of how to use both APIs: managementService.setJobRetriesByJobsAsync(retries) .jobIds(myJobIdList) .jobQuery(myJobQuery) .dueDate(myDueDate) .executeAsync(); managementService.setJobRetriesByProcessAsync(retries) .processInstanceIds(myProcessInstanceIdsList) .processInstanceQuery(myProcessInstanceQuery) .historicProcessInstanceQuery(myHistoricProcessInstanceQuery) .dueDate(myDueDate) .executeAsync(); Setting Retries Of Jobs Associated With Process Instances Setting retries of jobs associated with process instances can be performed asynchronously using the following Java API method invocation: List<String> processInstanceIds = ...; int retries = ...; managementService.setJobRetriesAsync( processInstanceIds, null, retries); Setting Retries Of External Tasks Setting retries of external tasks can be performed asynchronously using the following Java API method invocation: List<String> externalTaskIds = ...; externalTaskService.setRetriesAsync( externalTaskIds, TEST_REASON); Set Variables to Process Instances Sometimes it is necessary to add or update data of an already running process instance. For example, when a user entered incorrect data at the beginning of a process, the data needs to be corrected on-the-fly. This batch operation helps you to set variables to the root scope of process instances asynchronously. You can either (1) filter for process instances using a HistoricProcessInstanceQuery or a ProcessInstanceQuery or (2) pass a set of process instance ids directly. Please see below how to call the Java API: List<String> processInstanceIds = ...; Map<String, Object> variables = Variables.putValue(\"my-variable\", \"my-value\"); runtimeService.setVariablesAsync(processInstanceIds, variables); Known limitations Currently, it is not possible to set transient variables via batch operation. However, you can set transient variables synchronously. The execution jobs of this batch can be scheduled by the job executor as exclusive jobs. As a result, the execution of some of this batch’s jobs may be delayed by other exclusive jobs that are related to the same process instance that the variables should be set to. However, exclusive scheduling only happens when the jobs of this batch relate to exactly one process instance. This can be controlled by configuring the invocationsPerBatchJob property. Correlate Messages to Process Instances This batch operation helps you to correlate messages to multiple process instances asynchronously. Furthermore, you can set variables to the root scope of those process instances as well. You can either (1) filter for process instances using a HistoricProcessInstanceQuery or a ProcessInstanceQuery or (2) pass a set of process instance ids directly. Please see below how to call the Java API: List<String> processInstanceIds = ...; Map<String, Object> variables = Variables.putValue(\"my-variable\", \"my-value\"); Batch batch = runtimeService.createMessageCorrelationAsync(\"myMessage\") .setVariables(variables) .processInstanceIds(processInstanceIds) .correlateAllAsync(); Known limitations It is not possible to correlate to process definition-level start message events via this batch operation. However, you can correlate to start messages synchronously. The execution jobs of this batch can be scheduled by the job executor as exclusive jobs. As a result, the execution of some of this batch’s jobs may be delayed by other exclusive jobs that are related to the same process instance that the message should be correlated to. However, exclusive scheduling only happens when the jobs of this batch relate to exactly one process instance. This can be controlled by configuring the [invocationsPerBatchJob][] property. Set a Removal Time Sometimes it is necessary to postpone or even prevent the deletion of certain historic instances. A removal time can be set asynchronously to historic processes, decisions and batches. The following modes can be chosen: Absolute: Sets the removal time to an arbitrary date .absoluteRemovalTime(Date removalTime) Cleared: Resets the removal time (represented as null-value); Instances without a removal time are not cleaned-up .clearedRemovalTime() Calculated: Recalculates the removal time based on the Workflow Engine’s settings (base time + TTL) .calculatedRemovalTime() Historic process and decision instances can be part of a hierarchy. To set the same removal time for all instances within a hierarchy, the method .hierarchical() needs to be called. Setting removal time to running process instances would delete data from historic database tables (i.e. tables starting with ACT_HI_*), but not from runtime database tables (i.e. tables starting with ACT_RU_*). Historic Process Instances HistoricProcessInstanceQuery query = historyService.createHistoricProcessInstanceQuery(); Batch batch = historyService.setRemovalTimeToHistoricProcessInstances() .absoluteRemovalTime(new Date()) // sets an absolute removal time // .clearedRemovalTime() // resets the removal time to null // .calculatedRemovalTime() // calculation based on the engine's configuration .byQuery(query) .byIds(\"693206dd-11e9-b7cb-be5e0f7575b7\", \"...\") // .hierarchical() // sets a removal time across the hierarchy .executeAsync(); Historic Decision Instances HistoricDecisionInstanceQuery query = historyService.createHistoricDecisionInstanceQuery(); Batch batch = historyService.setRemovalTimeToHistoricDecisionInstances() .absoluteRemovalTime(new Date()) // sets an absolute removal time // .clearedRemovalTime() // resets the removal time to null // .calculatedRemovalTime() // calculation based on the engine's configuration .byQuery(query) .byIds(\"693206dd-11e9-b7cb-be5e0f7575b7\", \"...\") // .hierarchical() // sets a removal time across the hierarchy .executeAsync(); Known limitation The .hierarchical() flag for the decision instances batch operation only sets the removal time within the decision hierarchy. If a decision was called by a Business Rule Task, the calling process instances (including other process instances that are present in the hierarchy) are not updated. To update all child instances along the hierarchy of a root process instance (all process as well as decision instances), please use the batch operation for process instances with the .hierarchical() flag enabled. Historic Batches HistoricBatchQuery query = historyService.createHistoricBatchQuery(); Batch batch = historyService.setRemovalTimeToHistoricBatches() .absoluteRemovalTime(new Date()) // sets an absolute removal time // .clearedRemovalTime() // resets the removal time to null // .calculatedRemovalTime() // calculation based on the engine's configuration .byQuery(query) .byIds(\"693206dd-11e9-b7cb-be5e0f7575b7\", \"...\") .executeAsync(); Updating in chunks The batch operations update the removal time of all historic entities related to the respective root element, e.g. a historic process instance. Those updates are done within one database transaction. For large numbers of related entities, those updates can take too long, the database transactions time out, and the execution jobs of the batch fail. Additionally, this can block the job executor, trying to execute these long-running batch execution jobs. For historic process instances, you can therefore configure the batch operation to update related historic database tables in chunks using .updateInChunks(). This limits the number of rows updated per related table to the defined removalTimeUpdateChunkSize in the process engine configuration. You can override this limit per batch execution with the chunkSize(int chunkSize) option. With this configuration, the batch execution jobs handle exactly one historic process instance each, fixing the invocationsPerBatchJob property to 1. Furthermore, the batch execution jobs repeat until all related historic tables are updated completely. This spreads the database updates over multiple transactions and helps keeping them within transaction timeout boundaries. Performance considerations The .updateInChunks() flag for the historic process instances batch operation leads to more complex update queries that contain clauses to limit the number of updated rows. This can degrade the update performance on some databases. Only use this option for scenarios with large numbers of historic elements related to the historic process instance that otherwise block the job executor for a long time or run into database transaction timeouts. Using this chunked update mode on running process instances is possible but can lead to inconsistent history views. We recommend using this on completed or canceled process instances.",
    "url": "/manual/latest/user-guide/process-engine/batch-operations/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/connectors/index.html",
    "title": "Connectors | docs.cibseven.org",
    "content": "With the dependency cibseven-connect, the process engine supports simple connectors. Currently the following connector implementations exist: Connector ID REST HTTP http-connector SOAP HTTP soap-http-connector It is also possible to implement your own custom connector in CIB seven. For more information about extending connectors please visit the Connector reference. Configure CIB seven Connect As CIB seven Connect is available only partially when using the process engine (check the list below). With a pre-built distribution, CIB seven Connect is already preconfigured. The following connect artifacts exist: cibseven-connect-core: a jar that contains only the core Connect classes. The artifact already is available as dependency to the process engine. In addition to cibseven-connect-core, single connector implementations like cibseven-connect-http-client and camunda-connect-soap-http-client exist. These dependencies should be used when the default connectors have to be reconfigured or when custom connector implementations are used. cibseven-connect-connectors-all: a single jar without dependencies that contains the HTTP and SOAP connectors. cibseven-engine-plugin-connect: a process engine plugin to add Connect to CIB seven. Maven Coordinates Please import the CIB seven BOM to ensure correct versions for every CIB seven project. cibseven-connect-core cibseven-connect-core contains the core classes of Connect. Additionally, the HTTP and SOAP connectors can be added with the dependencies cibseven-connect-http-client and cibseven-connect-soap-http-client. These artifacts will transitively pull in their dependencies, like Apache HTTP client. For integration with the engine, the artifact cibseven-engine-plugin-connect is needed. Given that the BOM is imported, the Maven coordinates are as follows: <dependency> <groupId>org.cibseven.connect</groupId> <artifactId>cibseven-connect-core</artifactId> </dependency> <dependency> <groupId>org.cibseven.connect</groupId> <artifactId>cibseven-connect-http-client</artifactId> </dependency> <dependency> <groupId>org.cibseven.connect</groupId> <artifactId>cibseven-connect-soap-http-client</artifactId> </dependency> <dependency> <groupId>org.cibseven.bpm</groupId> <artifactId>cibseven-engine-plugin-connect</artifactId> </dependency> cibseven-connect-connectors-all This artifact contains the HTTP and SOAP connectors as well as their dependencies. To avoid conflicts with other versions of these dependencies, the dependencies are relocated to different packages. cibseven-connect-connectors-all has the following Maven coordinates: <dependency> <groupId>org.cibseven.connect</groupId> <artifactId>cibseven-connect-connectors-all</artifactId> </dependency> Configure the Process Engine Plugin cibseven-engine-plugin-connect contains a class called org.cibseven.connect.plugin.impl.ConnectProcessEnginePlugin that can be registered with a process engine using the plugin mechanism. For example, a bpm-platform.xml file with the plugin enabled would look as follows: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <bpm-platform xmlns=\"http://www.camunda.org/schema/1.0/BpmPlatform\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.camunda.org/schema/1.0/BpmPlatform http://www.camunda.org/schema/1.0/BpmPlatform \"> ... <process-engine name=\"default\"> ... <plugins> <plugin> <class>org.cibseven.connect.plugin.impl.ConnectProcessEnginePlugin</class> </plugin> </plugins> ... </process-engine> </bpm-platform> When using a pre-built distribution of CIB seven, the plugin is already pre-configured. Use Connectors To use a connector, you have to add the CIB seven extension element connector. The connector is configured by a unique connectorId, which specifies the used connector implementation. The ids of the currently supported connectors can be found at the beginning of this section. Additionally, an input/output mapping is used to configure the connector. The required input parameters and the available output parameters depend on the connector implementation. Additional input parameters can also be provided to be used within the connector. As an example, a shortened configuration of the Camunda SOAP connector implementation is shown. A complete example can be found in the Camunda examples repository on GitHub. <serviceTask id=\"soapRequest\" name=\"Simple SOAP Request\"> <extensionElements> <camunda:connector> <camunda:connectorId>soap-http-connector</camunda:connectorId> <camunda:inputOutput> <camunda:inputParameter name=\"url\"> http://example.com/webservice </camunda:inputParameter> <camunda:inputParameter name=\"payload\"> <![CDATA[ <soap:Envelope ...> ... // the request envelope </soap:Envelope> ]]> </camunda:inputParameter> <camunda:outputParameter name=\"result\"> <![CDATA[ ... // process response body ]]> </camunda:outputParameter> </camunda:inputOutput> </camunda:connector> </extensionElements> </serviceTask> A full example of the REST connector can also be found in the Camunda examples repository on GitHub.",
    "url": "/manual/latest/user-guide/process-engine/connectors/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/database/database-configuration/index.html",
    "title": "Database Configuration | docs.cibseven.org",
    "content": "There are two ways to configure the database that the CIB seven engine will use. The first option is to define the JDBC properties of the database: jdbcUrl: JDBC URL of the database. jdbcDriver: implementation of the driver for the specific database type. jdbcUsername: username to connect to the database. jdbcPassword: password to connect to the database. Note that the engine uses Apache MyBatis internally for persistence. The data source that is constructed based on the provided JDBC properties will have the default MyBatis connection pool settings. The following attributes can optionally be set to tweak that connection pool (taken from the MyBatis documentation): jdbcMaxActiveConnections: The maximum number of active connections that the connection pool can contain at any given time. Default is 10. jdbcMaxIdleConnections: The maximum number of idle connections that the connection pool can contain at any given time. jdbcMaxCheckoutTime: The amount of time in milliseconds that a connection can be ‘checked out’ for from the connection pool before it is forcefully returned. Default is 20000 (20 seconds). jdbcMaxWaitTime: This is a low level setting that gives the pool a chance to print a log status and re-attempt the acquisition of a connection in the case that it takes unusually long (to avoid failing silently forever if the pool is misconfigured). Default is 20000 (20 seconds). jdbcStatementTimeout: The amount of time in seconds the JDBC driver will wait for a response from the database. Default is null which means that there is no timeout. This setting is not supported for the H2 database. Jdbc Batch Processing Another configuration - jdbcBatchProcessing - sets if batch processing mode must be used when sending SQL statements to the database. When switched off, statements are executed one by one. Values: true (default), false. Known issues with batch processing: batch processing is not working for Oracle versions earlier than 12. when using batch processing on MariaDB and DB2, jdbcStatementTimeout is being ignored. Example database configuration <property name=\"jdbcUrl\" value=\"jdbc:h2:mem:camunda;DB_CLOSE_DELAY=1000\" /> <property name=\"jdbcDriver\" value=\"org.h2.Driver\" /> <property name=\"jdbcUsername\" value=\"sa\" /> <property name=\"jdbcPassword\" value=\"\" /> Alternatively, a javax.sql.DataSource implementation can be used (e.g., DBCP from Apache Commons): <bean id=\"dataSource\" class=\"org.apache.commons.dbcp.BasicDataSource\" > <property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\" /> <property name=\"url\" value=\"jdbc:mysql://localhost:3306/camunda?sendFractionalSeconds=false\" /> <property name=\"username\" value=\"camunda\" /> <property name=\"password\" value=\"camunda\" /> <property name=\"defaultAutoCommit\" value=\"false\" /> </bean> <bean id=\"processEngineConfiguration\" class=\"org.cibseven.bpm.engine.impl.cfg.StandaloneProcessEngineConfiguration\"> <property name=\"dataSource\" ref=\"dataSource\" /> ... Note that Camunda does not ship with a library that allows to define such a data source. So you have to make sure that the libraries (e.g., from DBCP) are on your classpath. The following properties can be set, regardless of whether you are using the JDBC or data source approach: databaseType: It’s normally not necessary to specify this property as it is automatically analyzed from the database connection meta data. Should only be specified in case automatic detection fails. Possible values: {h2, mysql, oracle, postgres, mssql, db2, mariadb}. This setting will determine which create/drop scripts and queries will be used. See the ‘supported databases’ section for an overview of which types are supported. databaseSchemaUpdate: Allows to set the strategy to handle the database schema on process engine boot and shutdown. true (default): Upon building the process engine, a check is performed whether the Camunda tables exist in the database. If they don’t exist, they are created. It must be ensured that the version of the DB schema matches the version of the process engine library, unless performing a Rolling Update. Updates of the database schema have to be done manually as described in the Update and Migration Guide. false: Does not perform any checks and assumes that the Camunda table exist in the database. It must be ensured that the version of the DB schema matches the version of the process engine library, unless performing a Rolling Update. Updates of the database schema have to be done manually as described in the Update and Migration Guide. create-drop: Creates the schema when the process engine is being created and drops the schema when the process engine is being closed. Supported Databases For information on supported databases please refer to Supported Environments Here are some sample JDBC urls: H2: jdbc:h2:tcp://localhost/camunda MySQL: jdbc:mysql://localhost:3306/camunda?autoReconnect=true&sendFractionalSeconds=false Oracle: jdbc:oracle:thin:@localhost:1521:xe PostgreSQL: jdbc:postgresql://localhost:5432/camunda DB2: jdbc:db2://localhost:50000/camunda MSSQL: jdbc:sqlserver://localhost:1433/camunda MariaDB: jdbc:mariadb://localhost:3306/camunda Additional Database Schema Configuration Business Key The unique constraint for the business key is removed in the runtime and history tables and the database schema create and drop scripts. If you rely on the constraint, you can add it manually to your schema by issuing following sql statements: DB2 Runtime: alter table ACT_RU_EXECUTION add UNI_BUSINESS_KEY varchar (255) not null generated always as (case when \"BUSINESS_KEY_\" is null then \"ID_\" else \"BUSINESS_KEY_\" end); alter table ACT_RU_EXECUTION add UNI_PROC_DEF_ID varchar (64) not null generated always as (case when \"PROC_DEF_ID_\" is null then \"ID_\" else \"PROC_DEF_ID_\" end); create unique index ACT_UNIQ_RU_BUS_KEY on ACT_RU_EXECUTION(UNI_PROC_DEF_ID, UNI_BUSINESS_KEY); History: alter table ACT_HI_PROCINST add UNI_BUSINESS_KEY varchar (255) not null generated always as (case when \"BUSINESS_KEY_\" is null then \"ID_\" else \"BUSINESS_KEY_\" end); alter table ACT_HI_PROCINST add UNI_PROC_DEF_ID varchar (64) not null generated always as (case when \"PROC_DEF_ID_\" is null then \"ID_\" else \"PROC_DEF_ID_\" end); create unique index ACT_UNIQ_HI_BUS_KEY on ACT_HI_PROCINST(UNI_PROC_DEF_ID, UNI_BUSINESS_KEY); H2 Runtime: alter table ACT_RU_EXECUTION add constraint ACT_UNIQ_RU_BUS_KEY unique(PROC_DEF_ID_, BUSINESS_KEY_); History: alter table ACT_HI_PROCINST add constraint ACT_UNIQ_HI_BUS_KEY unique(PROC_DEF_ID_, BUSINESS_KEY_); MSSQL Runtime: create unique index ACT_UNIQ_RU_BUS_KEY on ACT_RU_EXECUTION (PROC_DEF_ID_, BUSINESS_KEY_) where BUSINESS_KEY_ is not null; History: create unique index ACT_UNIQ_HI_BUS_KEY on ACT_HI_PROCINST (PROC_DEF_ID_, BUSINESS_KEY_) where BUSINESS_KEY_ is not null; MySQL Runtime: alter table ACT_RU_EXECUTION add constraint ACT_UNIQ_RU_BUS_KEY UNIQUE (PROC_DEF_ID_, BUSINESS_KEY_); History: alter table ACT_HI_PROCINST add constraint ACT_UNIQ_HI_BUS_KEY UNIQUE (PROC_DEF_ID_, BUSINESS_KEY_); Oracle Runtime: create unique index ACT_UNIQ_RU_BUS_KEY on ACT_RU_EXECUTION (case when BUSINESS_KEY_ is null then null else PROC_DEF_ID_ end, case when BUSINESS_KEY_ is null then null else BUSINESS_KEY_ end); History: create unique index ACT_UNIQ_HI_BUS_KEY on ACT_HI_PROCINST (case when BUSINESS_KEY_ is null then null else PROC_DEF_ID_ end, case when BUSINESS_KEY_ is null then null else BUSINESS_KEY_ end); PostgreSQL Runtime: alter table ACT_RU_EXECUTION add constraint ACT_UNIQ_RU_BUS_KEY UNIQUE (PROC_DEF_ID_, BUSINESS_KEY_); History: alter table ACT_HI_PROCINST add constraint ACT_UNIQ_HI_BUS_KEY UNIQUE (PROC_DEF_ID_, BUSINESS_KEY_); Isolation Level Configuration Most database management systems provide four different isolation levels to be set. For instance the levels defined by ANSI/USO SQL are (from low to high isolation): READ UNCOMMITTED READ COMMITTED REPEATABLE READS SERIALIZABLE The required isolation level to run Camunda with is READ COMMITTED, which may have a different name according to your database system. Setting the level to REPEATABLE READS is known to cause deadlocks, so one needs to be careful, when changing the isolation level. When initializing the engine, a check is performed in order to determine if the transaction isolation level set for the database is different from the recommended one. If it is, an exception will be thrown. This behaviour can be disabled by setting the skipIsolationLevelCheck flag to true. Doing this will prevent an exception from being thrown and a warning message will be logged instead. See here for more details about this and other properties.",
    "url": "/manual/latest/user-guide/process-engine/database/database-configuration/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/database/database-schema/index.html",
    "title": "Database Schema | docs.cibseven.org",
    "content": "The database schema of the process engine consists of multiple tables. The table names all start with ACT. The second part is a two-character identification of the use case of the table. This use case will also roughly match the service API. ACT_RE_*: RE stands for repository. Tables with this prefix contain ‘static’ information such as process definitions and process resources (images, rules, etc.). ACT_RU_*: RU stands for runtime. These are the runtime tables that contain the runtime data of process instances, user tasks, variables, jobs, etc. The engine only stores the runtime data during process instance execution and removes the records when a process instance ends. This keeps the runtime tables small and fast. ACT_ID_*: ID stands for identity. These tables contain identity information such as users, groups, etc. ACT_HI_*: HI stands for history. These are the tables that contain historical data such as past process instances, variables, tasks, etc. ACT_GE_*: General data, which is used in various use cases. The main tables of the process engines are the entities of process definitions, executions, tasks, variables and event subscriptions. Their relationship is shown in the following UML model. Process Definitions (ACT_RE_PROCDEF) The ACT_RE_PROCDEF table contains all deployed process definitions. It includes information like the version details, the resource name or the suspension state. Executions (ACT_RU_EXECUTION) The ACT_RU_EXECUTION table contains all current executions. It includes information like the process definition, parent execution, business key, the current activity and different metadata about the state of the execution. Tasks (ACT_RU_TASK) The ACT_RU_TASK table contains all open tasks of all running process instances. It includes information like the corresponding process instance, execution and also metadata such as creation time, assignee or due date. Variables (ACT_RU_VARIABLE) The ACT_RU_VARIABLE table contains all currently set process or task variables. It includes the names, types and values of the variables and information about the corresponding process instance or task. Event Subscriptions (ACT_RU_EVENT_SUBSCR) The ACT_RU_EVENT_SUBSCR table contains all currently existing event subscriptions. It includes the type, name and configuration of the expected event along with information about the corresponding process instance and execution. Schema Log (ACT_GE_SCHEMA_LOG) The ACT_GE_SCHEMA_LOG table contains a history of the database schema version. New entries to the table are written when changes to the database schema are made. On database creation the initial entry is added. Every update script adds a new entry containing an id, the version the database was updated to and the date and time (timestamp) of the update. To retrieve entries from the schema log, the SchemaLogQuery-API can be used: List<SchemaLogEntry> entries = managementService.createSchemaLogQuery().list(); Metrics Log (ACT_RU_METER_LOG) The ACT_RU_METER_LOG table contains a collection of runtime metrics that can help draw conclusions about usage, load and performance of CIB seven. Metrics are reported as numbers in the Java long range and count the occurrence of specific events. Please find detailed information about how metrics are collected in the Metrics User Guide. The default configuration of the MetricsReporter will create one row per metric in ACT_RU_METER_LOG every 15 minutes. Task Metrics Log (ACT_RU_TASK_METER_LOG) The ACT_RU_TASK_METER_LOG table contains a collection of task related metrics that can help draw conclusions about usage, load and performance of the BPM platform. Task metrics contain a pseudonymized and fixed-length value of task assignees and their time of appearance. Please find detailed information about how task metrics are collected in the Metrics User Guide. Every assignment of a task to an assignee will create one row in ACT_RU_TASK_METER_LOG. Entity Relationship Diagrams The database is not part of the public API. The database schema may change for MINOR and MAJOR version updates. Please note: The following diagrams are based on the MySQL database schema. For other databases the diagram may be slightly different. The following Entity Relationship Diagrams visualize the database tables and their explicit foreign key constraints, grouped by Engine with focus on BPMN, Engine with focus on DMN, Engine with focus on CMMN, the Engine History and the Identity. Please note that the diagrams do not visualize implicit connections between the tables. Engine BPMN Engine DMN Engine CMMN History To allow different configurations and to keep the tables more flexible, the history tables contain no foreign key constraints. Identity",
    "url": "/manual/latest/user-guide/process-engine/database/database-schema/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/database/index.html",
    "title": "Database | docs.cibseven.org",
    "content": "Docs Get Started CIB seven Security cibseven.org CIB seven 1.1 Introduction Download Licenses Implemented Standards Architecture Overview Supported Environments Extensions Third-Party Libraries CIB seven License Book Public API User Guide Process Engine Process Engine Bootstrapping Process Engine API Process Engine Concepts Process Variables Process Instance Modification Process Instance Restart Delegation Code Expression Language Scripting Templating Custom Code & Security External Tasks Connectors Process Versioning Process Instance Migration Database Database Schema Database Configuration Microsoft SQL Server and Azure SQL Database Configuration MySQL Database Configuration Performance History History configuration User operation log History cleanup Custom implementation Deployment Cache Password Hashing Password Policy Transactions in Processes The Job Executor Multi-Tenancy Id Generators Metrics Incidents Process Engine Plugins Identity Service Authorization Service Deployments Process Diagram Visualization Time zones Decisions Configuration Repository Decision Service Decisions in BPMN & CMMN History Batch Batch operations Error Handling Diagnostics data Process Applications The Process Application class The processes.xml Deployment Descriptor Process Application Event Listeners Process Application Resource Access Maven Project Templates (Archetypes) Runtime Container Integration CIB seven Services JNDI Bindings for CIB seven Services Apache Tomcat WildFly Job Execution with Managed Resources CIB seven Run Spring Framework Integration Bootstrapping Transactions Deployment Spring Bean Resolving Testing Spring Boot Integration Version Compatibility Configuration REST API Web Applications Process Applications Spring Eventing Bridge Developing and Testing Spring Security OAuth2 Integration Quarkus Integration Version Compatibility Configuration Engine CDI Integration Resource Deployments CDI and Java EE Integration JTA Transaction Integration Expression Resolving Contextual Programming Model Built-In Beans CDI Event Bridge Testing Assert Examples Model API BPMN Model API Read a Model Create a Model Delegation Code Fluent Builder API Repository Service Extension Elements CMMN Model API Read a Model Create a Model Delegation Code Repository Service Extension Elements Limitations DMN Model API Read a Model Create a Model Repository Service Extension Attributes Data Formats (XML, JSON, Other) Configuring Spin Integration Data Formats in Processes XML JSON User Task Forms JSF Task Forms DMN Engine Embed Evaluate Decisions Expressions FEEL Engine Type Handling Custom Functions Spin Integration Legacy Behavior Data Types Testing Logging Security Instructions External Task Client Spring Boot Starter Version Compatibility Reference REST API Overview Configure Authentication Usage with a Pre-Built Distribution Embed the API Hypertext Application Language (HAL) Variables in the REST API Date Format OpenAPI Specification ↗ Javadoc ↗ BPMN 2.0 Tasks Service Task Send Task User Task Business Rule Task Script Task Receive Task Manual Task Task Markers Gateways Data-based Exclusive Gateway (XOR) Conditional and Default Sequence Flows Parallel Gateway Inclusive Gateway Event-based Gateway Events Start Events None Events Message Events Timer Events Error Events Escalation Events Signal Events Cancel and Compensation Events Conditional Events Link Events Terminate Events Subprocess Embedded Subprocess Call Activity Event Subprocess Transaction Subprocess Extension Reference Extension Elements Extension Attributes DMN 1.3 Decision Table Input Output Rule Hit Policy Decision Literal Expression Decision Requirements Graph FEEL Legacy FEEL Reference Data Types Language Elements Extension Reference Extension Attributes CMMN 1.1 Classic vs Fluent API CMMN Concepts Plan Items and Item Definitions Plan Item Lifecycles Entry and Exit Criteria Tasks Human Task Process Task Case Task Decision Task Grouping Tasks Stage Milestones Sentries Markers Manual Activation Rule Required Rule Auto Complete Repetition Rule Extension Reference Extension Elements Extension Attributes Migration between Specification Versions 1.0 to 1.1 Forms Embedded Forms Controls Text Inputs Textareas Date Inputs Boolean Inputs Selects Hidden Input Fields File Upload and Download BPMN Event Buttons Javascript The cam-script Directive Available API Participating in the Form Lifecycle Debugging Scripts Generating a Business Key Examples Lifecycle and Events Working with Json Data Working with Java Objects Integrating the Forms SDK Getting a Distribution Bootstrapping AngularJS Integration Full Example Spin Dataformats XML Reading XML Manipulating XML Writing XML Querying XML Mapping XML Configuring XML Handling JSON Reading JSON Writing JSON Querying JSON Mapping JSON Configuring JSON Handling Extending Spin Connectors HTTP Connector SOAP Connector Extending Connect Deployment Descriptors bpm-platform.xml processes.xml Tags <job-executor /> <process-archive /> <process-engine /> Installation Database Schema Remote Engine Distribution Shared Engine Distribution Tomcat Pre-Packaged Distribution Manual Installation Configuration JBoss EAP/WildFly Manual Installation Configuration Docker Spring Boot Web Applications Admin User Management Group Management Tenant Management Authorization Management System Management Configuration Plugins Cockpit Dashboard BPMN Processes Dashboard Process Definition View Process Instance View Failed Jobs Suspension Collapsed Subprocesses DMN Decisions Dashboard Decision Definition View Decision Instance View Deployments Open Tasks Dashboard Extending Configuration Plugins Tasklist Working with Tasklist Dashboard Filters User Assignment Task Lifecycle Plugins Configuration Accessibility Welcome Plugins Configuration Shared Configuration Options Authentication Cookie Security CSRF Prevention HTTP Header Security Examples Notices Update & Migration Rolling Update Camunda Migration Database Database Schema Database Configuration Microsoft SQL Server and Azure SQL Database Configuration MySQL Database Configuration Performance :( Back to top cibseven.org and docs.cibseven.org are part of CIB seven project — Privacy Statement – CIB software GmbH The CIB seven documentation is based on Camunda 7 Docs from Camunda. Some redesign & naming adoptation was made. The content on this site is licensed under a Creative Commons Attribution-ShareAlike 3.0 Unported License.",
    "url": "/manual/latest/user-guide/process-engine/database/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/database/mssql-configuration/index.html",
    "title": "Microsoft SQL Server and Azure SQL Database Configuration | docs.cibseven.org",
    "content": "This section documents the additional database configuration changes necessary to correctly use Microsoft SQL Server or Microsoft Azure SQL databases with CIB seven. It provides guides on: How to set the correct database transaction isolation level. How different Microsoft SQL Server versions are supported in Azure SQL. How Camunda supports Azure SQL. How to configure a database on Azure SQL to be supported by Camunda. To use these guides, you should have a basic understanding of (Microsoft’s) T-SQL syntax. You should also have access to a database administration tool that can interact with your Microsoft database. Transaction Isolation Levels This section applies to the following database types: Microsoft SQL Server Microsoft Azure SQL Microsoft SQL Server and Azure SQL implement the READ_COMMITTED isolation level different than most databases and do not interact well with the process engine’s optimistic locking scheme. As a result you may suffer deadlocks when putting the process engine under high load. If you experience deadlocks in your MSSQL installation, you must execute the following statements in order to enable SNAPSHOT isolation: ALTER DATABASE [process-engine] SET ALLOW_SNAPSHOT_ISOLATION ON ALTER DATABASE [process-engine] SET READ_COMMITTED_SNAPSHOT ON where [process-engine] contains the name of your database. Camunda support for Azure SQL This section applies only to the following Microsoft database products: Azure SQL Managed Instance Azure SQL Database The SQL Server database engine has a Database Compatibility Level setting that provides backward compatibility with earlier versions of SQL Server. This backward compatibility covers Transact-SQL and query optimization behaviors, and can be applied per database. Microsoft’s Azure SQL Managed Instance and Azure SQL Database products always use the latest stable version of the SQL Server database engine. In order to provide backward compatibility with earlier SQL Server versions, the Azure SQL products utilize the Database Compatibility Level setting. Azure SQL compatibility levels supported by Camunda Microsoft associates each SQL Server version with a Database Compatibility Level. You can find a table of the SQL Server versions, and their associated compatibility level values at the Microsoft Alter Compatibility Level page. Camunda supports the Database Compatibility Level values of the currently supported Microsoft SQL Server versions documented in our Supported Database Products section. Configuring a database on Azure SQL It is advised to explicitly set the Database Compatibility Level setting for each database created on Azure SQL. The default value of the Database Compatibility Level setting is updated every time a new SQL Server version is released. If a Database Compatibility Level value isn’t explicitly set on a database, the default value will be used. Using the default value may lead to unexpected behavior, or behavior unsupported by Camunda. To set the Database Compatibility Level to a specific value, execute the following code: ALTER DATABASE [database_name] SET COMPATIBILITY_LEVEL = [compatibility_level] In the code above, [database_name] should be replaced with the name of your database, and [compatibility_level] should be replaced with the Database Compatibility Level value of the SQL Server version you would like to use. You can see a list of all the available values at the Microsoft Alter Compatibility Level page.",
    "url": "/manual/latest/user-guide/process-engine/database/mssql-configuration/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/database/mysql-configuration/index.html",
    "title": "MySQL Database Configuration | docs.cibseven.org",
    "content": "This section documents the supported MySQL configuration. Database Schema The engine’s MySQL database schema does not support milliseconds precision for the column types TIMESTAMP and DATETIME: I.e., a to be stored value is rounded to the next or previous second, e.g., 2021-01-01 15:00:46.731 is rounded to 2021-01-01 15:00:47. Heads Up! The missing millisecond’s precision for date/time values impacts the process engine’s behavior. Please read how to configure the MySQL JDBC Driver to ensure that date/time values are handled correctly. JDBC Driver Configuration Here you can find the MySQL JDBC Driver’s configuration prerequisites to ensure a frictionless behavior of the process engine. Disable sending milliseconds for date/time values Heads Up! This configuration flag is mandatory to avoid unexpected behavior when operating the process engine with MySQL. When sending a date/time value as part of any SQL statement to the database, the MySQL JDBC Driver >= 5.1.23 sends milliseconds. This behavior is problematic since the engine’s MySQL database schema does not support milliseconds precision for date/time values. To ensure correct behavior of the process engine when sending date/time values, make sure to update your MySQL JDBC Driver to a version >= 5.1.37. You can avoid sending milliseconds to the MySQL Server in these versions by setting sendFractionalSeconds=false in your JDBC connection URL. Please find below examples of unwanted behavior that occurs, in case the flag sendFractionalSeconds=false is not provided: When a user performs a task query with due date == 2021-01-01 15:00:46.731, the query returns results equal to 2021-01-01 15:00:46.731. However, since the engine’s database schema does not store milliseconds, no result is returned. When a user sets a due date to a task, the value is rounded to the next or previous second, e.g., 2021-01-01 15:00:46.731 is rounded to 2021-01-01 15:00:47. Please also see the official MySQL documentation.",
    "url": "/manual/latest/user-guide/process-engine/database/mysql-configuration/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/database/performance/index.html",
    "title": "Performance | docs.cibseven.org",
    "content": "This page explains specific performance-related topics of database queries. It does not attempt to provide tools and guidance for general performance analysis and optimization of CIB seven installations. As the impact of the settings discussed here largely depends on the setup and workload of CIB seven, the recommendations may or may not help in your case. Performance improvements are not guaranteed. Task Query The task query is one of the heaviest used and most powerful queries of the process engine API. Due to its rich feature set, it can also become complex in SQL and may perform badly. Disabling CMMN and Standalone Tasks To perform transparent access checks, the task query joins the authorization table (ACT_RU_AUTHORIZATION). For any kind of process-related filters, it joins the process definition table (ACT_RE_PROCDEF). By default, the query uses a left join for these operations. If CMMN and standalone tasks (tasks that are neither related to a BPMN process, nor a CMMN case) are not used, the engine configuration flags cmmnEnabled and standaloneTasksEnabled can be set to false. Then, the left joins are replaced by inner joins which perform better on some databases. See the configuration properties reference for details on these settings.",
    "url": "/manual/latest/user-guide/process-engine/database/performance/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/decisions/bpmn-cmmn/index.html",
    "title": "Invoke Decisions from Processes and Cases | docs.cibseven.org",
    "content": "BPMN & CMMN Integration This section explains how to invoke DMN decision from BPMN and CMMN. BPMN Business Rule Task The BPMN business rule task can reference a deployed decision definition. The decision definition is evaluated when the task is executed. <definitions id=\"taskAssigneeExample\" xmlns=\"http://www.omg.org/spec/BPMN/20100524/MODEL\" xmlns:camunda=\"http://camunda.org/schema/1.0/bpmn\" targetNamespace=\"Examples\"> <process id=\"process\"> <!-- ... --> <businessRuleTask id=\"businessRuleTask\" camunda:decisionRef=\"myDecision\" camunda:mapDecisionResult=\"singleEntry\" camunda:resultVariable=\"result\" /> <!-- ... --> </process> </definitions> For more information on how to reference a decision definition from a business rule task, please refer to the BPMN 2.0 reference. DMN Decision Task The CMMN decision task references a deployed decision definition. The decision definition is invoked when the task is activated. <definitions id=\"definitions\" xmlns=\"http://www.omg.org/spec/CMMN/20151109/MODEL\" xmlns:camunda=\"http://camunda.org/schema/1.0/cmmn\" targetNamespace=\"Examples\"> <case id=\"case\"> <casePlanModel id=\"CasePlanModel_1\"> <planItem id=\"PI_DecisionTask_1\" definitionRef=\"DecisionTask_1\" /> <decisionTask id=\"DecisionTask_1\" decisionRef=\"myDecision\" camunda:mapDecisionResult=\"singleEntry\" camunda:resultVariable=\"result\"> </decisionTask> </casePlanModel> </case> </definitions> For more information on how to reference a decision definition from a decision task, please refer to the CMMN 1.1 reference. The Decision Result The output of the decision, also called decision result, is a complex object of type DmnDecisionResult. Generally, it is a list of key-value pairs. If the decision is implemented as decision table then each entry in the list represents one matched rule. The output entries of this rule are represented by the key-value pairs. The key of a pair is specified by the name of the output. Instead, if the decision is implemented as decision literal expression then the list contains only one entry. This entry represents the expression value and is mapped by the variable name. The type DmnDecisionResult provides methods from the List interface and some convenience methods like getSingleResult() or getFirstResult() to get the result of a matched rule. The rule results provide methods from the Map interface and also convenience methods like getSingleEntry() or getFirstEntry(). If the decision result contains only a single output value (e.g., evaluating a decision literal expression) then the value can be retrieved from the result using the getSingleEntry() method which combines getSingleResult() and getSingleEntry(). For example, the following code returns the output entry with name result of the only matched rule. DmnDecisionResult decisionResult = ...; Object value = decisionResult .getSingleResult() .getEntry(\"result\"); It also provides methods to get typed output entries like getSingleEntryTyped(). Please refer to the User Guide for details about typed values. A complete list of all methods can be found in the Java Docs . The decision result is available in the local scope of the executing task as a transient variable named decisionResult. It can be passed into a variable by using a predefined or a custom mapping of the decision result, if necessary. Predefined Mapping of the Decision Result The engine includes predefined mappings of the decision result for common use cases. The mapping is similar to an output variable mapping. It extracts a value from the decision result which is saved in a process/case variable. The following mappings are available: Mapper Result Is suitable for singleEntry TypedValue decision literal expressions and decision tables with no more than one matching rule and only one output singleResult Map<String, Object> decision tables with no more than one matching rule collectEntries List<Object> decision tables with multiple matching rules and only one output resultList List<Map<String, Object>> decision tables with multiple matching rules and multiple outputs Only the singleEntry mapper returns a typed value that wraps the value of the output entry and additional type information. The other mappers return collections which contain the value of the output entries as normal Java objects without additional type information. Note that the mapper throws an exception if the decision result is not suitable. For example, the singleEntry mapper throws an exception if the decision result contains more than one matched rule. Limitations of Serialization If you are using one of the predefined mappers singleResult, collectEntries or resultList then you should consider the limitations of serialization. To specify the name of the process/case variable to store the result of the mapping, the camunda:resultVariable attribute is used. BPMN: <businessRuleTask id=\"businessRuleTask\" camunda:decisionRef=\"myDecision\" camunda:mapDecisionResult=\"singleEntry\" camunda:resultVariable=\"result\" /> CMMN: <decisionTask id=\"DecisionTask_1\" decisionRef=\"myDecision\" camunda:mapDecisionResult=\"singleEntry\" camunda:resultVariable=\"result\"> Name of the Result Variable The result variable should not have the name decisionResult since the decision result itself is saved in a variable with this name. Otherwise an exception is thrown while saving the result variable. Custom Mapping of the Decision Result Instead of a predefined mapping, a custom decision result mapping can be used to pass the decision result into variables. Limitations of Serialization If you pass a collection or a complex object to a variable then you should consider the limitations of serialization. Custom Mapping to Process Variables If a business rule task is used to invoke a decision inside a BPMN process, then the decision result can be passed into process variables by using an output variable mapping. For example, if the decision result has multiple output values which should be saved in separate process variables this can be done achieved by defining an output mapping on the business rule task. <businessRuleTask id=\"businessRuleTask\" camunda:decisionRef=\"myDecision\"> <extensionElements> <camunda:inputOutput> <camunda:outputParameter name=\"result\"> ${decisionResult.getSingleResult().result} </camunda:outputParameter> <camunda:outputParameter name=\"reason\"> ${decisionResult.getSingleResult().reason} </camunda:outputParameter> </camunda:inputOutput> </extensionElements> </businessRuleTask> In addition to an output variable mapping, the decision result can also be processed by an execution listener, which is attached to the business rule task. <businessRuleTask id=\"businessRuleTask\" camunda:decisionRef=\"myDecision\"> <extensionElements> <camunda:executionListener event=\"end\" delegateExpression=\"${myDecisionResultListener}\" /> </extensionElements> </businessRuleTask> public class MyDecisionResultListener implements ExecutionListener { @Override public void notify(DelegateExecution execution) throws Exception { DmnDecisionResult decisionResult = (DmnDecisionResult) execution.getVariable(\"decisionResult\"); String result = decisionResult.getSingleResult().get(\"result\"); String reason = decisionResult.getSingleResult().get(\"reason\"); // ... } } Custom Mapping to Case Variables If a decision task is used to invoke a decision inside a CMMN case, the decision result can be passed to a case variable by using a case execution listener which is attached to the decision task. <decisionTask id=\"decisionTask\" decisionRef=\"myDecision\"> <extensionElements> <camunda:caseExecutionListener event=\"complete\" class=\"org.cibseven.bpm.example.MyDecisionResultListener\" /> </extensionElements> </decisionTask> public class MyDecisionResultListener implements CaseExecutionListener { @Override public void notify(DelegateCaseExecution caseExecution) throws Exception; DmnDecisionResult decisionResult = (DmnDecisionResult) caseExecution.getVariable(\"decisionResult\"); String result = decisionResult.getSingleResult().get(\"result\"); String reason = decisionResult.getSingleResult().get(\"reason\"); // ... caseExecution.setVariable(\"result\", result); // ... } } Limitations of the Serialization of the Mapping Result The predefined mappings singleResult, collectEntries and resultList map the decision result to Java collections. The implementation of the collections depends on the used JDK and contains untyped values as Objects. When a collection is saved as process/case variable then it is serialized as object value because there is no suitable primitive value type. Depending on the used object value serialization, this can lead to deserialization problems. In case you are using the default built-in object serialization, the variable can not be deserialized if the JDK is updated or changed and contains an incompatible version of the collection class. Otherwise, if you are using another serialization like JSON then you should ensure that the untyped value is deserializable. For example, a collection of date values can not be deserialized using JSON because JSON has no registered mapper for date by default. The same problems can occur by using a custom output variable mapping since DmnDecisionResult has methods that return the same collections as the predefined mappers. Additionally, it is not recommended to save a DmnDecisionResult or a DmnDecisionResultEntries as process/case variable because the underlying implementation can change in a new version of CIB seven. To prevent any of these problems, you should use primitive variables only. Alternatively, you can use a custom object for serialization that you control by yourself. Accessing Variables from Decisions DMN Decision tables and Decision Literal Expressions contain multiple expressions which will be evaluated by the DMN engine. For more information about the expressions of a decision please see our DMN 1.3 reference. These expressions can access all process/case variables which are available in the scope of the calling task. The variables are provided through a read-only variable context. As a shorthand, process/case variables can be directly referenced by name in expressions. For example, if a process variable foo exists, then this variable can be used in an input expression, input entry and output entry of a decision table by its name. <input id=\"input\"> <!-- this input expression will return the value of the process/case variable `foo` --> <inputExpression> <text>foo</text> </inputExpression> </input> The returned value of the process/case variable in the expression will be a normal object and not a typed value. If you want to use the typed value in your expression, you have to get the variable from the variable context. The following snippet does the same as the above example. It gets the variable foo from the variable context and returns its unwrapped value. <input id=\"input\"> <!-- this input expression uses the variable context to get the typed value of the process/case variable `foo` --> <inputExpression> <text> variableContext.resolve(\"foo\").getValue() </text> </inputExpression> </input> Expression Language Integration By default, the DMN engine uses FEEL as expression language for input expressions, input entries, output entries and literal expressions. Please see the DMN engine guide for more information about expression languages. Accessing Beans If the DMN engine is invoked by CIB seven, it uses the same JUEL configuration as the CIB seven engine. Therefore, it is also possible to access Spring and CDI Beans from JUEL expressions in decisions. For more information on this integration, please see the corresponding section in the Spring and CDI guides. Heads-up! Beans cannot be accessed when using FEEL as expression language. Extending the Expression Language Use of Internal API These APIs are not part of the public API and may change in later releases. It is possible to add own functions which can be used inside JUEL expressions. Therefore a new FunctionMapper has to be implemented. The function mapper than has to be added to the process engine configuration after it was initialized. ProcessEngineConfigurationImpl processEngineConfiguration = (ProcessEngineConfigurationImpl) processEngine .getProcessEngineConfiguration(); processEngineConfiguration .getExpressionManager() .addFunctionMapper(new MyFunctionMapper()); This can be done, for example, by creating a process engine plugin. Please note that these functions are available in all JUEL expressions in the platform, not only in DMN decisions.",
    "url": "/manual/latest/user-guide/process-engine/decisions/bpmn-cmmn/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/decisions/configuration/index.html",
    "title": "Configure the DMN engine | docs.cibseven.org",
    "content": "The configuration of the DMN engine is a part of the process engine configuration. It depends on whether you use an application managed or a shared, container managed process engine. Please refer to the Process Engine Bootstrapping for details. This section shows how to configure the DMN engine: Programmatically via Java API Declarative via XML configuration In the examples the default expression language of the input expressions is set to groovy. A list of all possible configurations can be found in the DMN Engine Configuration section. Configure the DMN Engine using Java API First, you need to create a ProcessEngineConfiguration object for the process engine and a DmnEngineConfiguration object for the DMN engine. Now you can configure the DMN engine using the DmnEngineConfiguration object. When you are done, set the object on the ProcessEngineConfiguration and call buildProcessEngine() to create the process engine. // create the process engine configuration ProcessEngineConfigurationImpl processEngineConfiguration = // ... // create the DMN engine configuration DefaultDmnEngineConfiguration dmnEngineConfiguration = (DefaultDmnEngineConfiguration) DmnEngineConfiguration.createDefaultDmnEngineConfiguration(); // configure the DMN engine ... // e.g. set the default expression language for input expressions to `groovy` dmnEngineConfiguration.setDefaultInputExpressionExpressionLanguage(\"groovy\"); // set the DMN engine configuration on the process engine configuration processEngineConfiguration.setDmnEngineConfiguration(dmnEngineConfiguration); // build the process engine which includes the DMN engine processEngineConfiguration.buildProcessEngine(); Configure the DMN Engine using Spring XML Follow the instructions to create a base camunda.cfg.xml XML configuration for the process engine. Add a new configuration bean of class org.cibseven.bpm.dmn.engine.impl.DefaultDmnEngineConfiguration. Configure the DMN engine using the bean and set it as dmnEngineConfiguration property on the processEngineConfiguration bean. <beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"> <bean id=\"processEngineConfiguration\" class=\"org.cibseven.bpm.engine.impl.cfg.StandaloneProcessEngineConfiguration\"> <property name=\"dmnEngineConfiguration\"> <bean class=\"org.cibseven.bpm.dmn.engine.impl.DefaultDmnEngineConfiguration\"> <!-- configure the DMN engine ... --> <!-- e.g. set the default expression language for input expressions to `groovy` --> <property name=\"defaultInputExpressionExpressionLanguage\" value=\"groovy\" /> </bean> </property> </bean> </beans>",
    "url": "/manual/latest/user-guide/process-engine/decisions/configuration/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/decisions/decision-service/index.html",
    "title": "Decision Service in the Process Engine | docs.cibseven.org",
    "content": "The decision service is a part of the process engine’s Services API. It allows to evaluate a deployed decision definition independently from BPMN and CMMN. Evaluating a Decision To evaluate a deployed decision, reference it by id or a combination of key and version. If a key is used but no version is specified then the latest version of decision definition with the given key is evaluated. DecisionService decisionService = processEngine.getDecisionService(); VariableMap variables = Variables.createVariables() .putValue(\"status\", \"bronze\") .putValue(\"sum\", 1000); DmnDecisionResult decisionResult = decisionService .evaluateDecisionByKey(\"decision-key\") .variables(variables) .evaluate(); // alternatively for decision tables only DmnDecisionTableResult decisionResult = decisionService .evaluateDecisionTableByKey(\"decision-key\") .variables(variables) .evaluate(); The Decision Key The key of a decision definition is specified by the id attribute of the decision element in the DMN XML. The different naming is related to the Versioning of Decisions. Since a key can reference multiple versions of a decision definition, the id specifies exactly one version. Passing Data A decision may reference one or more variables. For example, a variable can be referenced in an input expression or an input entry of a decision table. The variables are passed to the decision service as key-value pairs. Each pair specifies the name and the value of a variable. For more information on the different expressions see the DMN 1.3 reference. Authorizations for Evaluating Decisions The user needs the permission CREATE_INSTANCE on the resource DECISION_DEFINITION to evaluate decisions. The resource id of the authorization is the decision definition key. For more information about authorizations please refer to the Authorization Service section. Working with the Decision Result The result of an evaluation is called decision result. The decision result is a complex object of type DmnDecisionResult. Think of it as a list of key-value pairs. If the decision is implemented as decision table then each entry in the list represents one matched rule. The output entries of this rule are represented by the key-value pairs. The key of a pair is specified by the name of the output. Instead, if the decision is implemented as decision literal expression then the list contains only one entry. This entry represents the expression value and is mapped by the variable name. The decision result provides methods from interface List<Map<String, Object>> and some convenience methods. DmnDecisionResult decisionResult = ...; // get the value of the single entry of the only matched rule String singleEntry = decisionResult.getSingleResult().getSingleEntry(); // get the value of the result entry with name 'result' of the only matched rule String result = decisionResult.getSingleResult().getEntry(\"result\"); // get the value of the first entry of the second matched rule String firstValue = decisionResult.get(1).getFirstEntry(); // get a list of all entries with the output name 'result' of all matched rules List<String> results = decisionResult.collectEntries(\"result\"); // shortcut to get the single output entry of the single rule result // - combine getSingleResult() and getSingleEntry() String result = decisionResult.getSingleEntry(); Note that the decision result also provides methods to get typed output entries. A complete list of all methods can be found in the Java Docs . If the decision is implemented as decision table then it can also be evaluated using one of the evaluateDecisionTable methods. In this case, the evaluation returns a DmnDecisionTableResult which is semantically equal and provide the same methods as a DmnDecisionResult. History of Evaluated Decisions When a decision is evaluated, a new history entry of type HistoricDecisionInstance is created which contains the inputs and outputs of the decision. The history can be queried by the history service. List<HistoricDecisionInstance> historicDecisions = processEngine .getHistoryService() .createHistoricDecisionInstanceQuery() .decisionDefinitionKey(\"decision-key\") .includeInputs() .includeOutputs() .list(); For more information about this, please refer to the History for DMN Decisions.",
    "url": "/manual/latest/user-guide/process-engine/decisions/decision-service/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/decisions/history/index.html",
    "title": "History for DMN Decisions | docs.cibseven.org",
    "content": "After a decision definition has been evaluated either from a BPMN process, CMMN case or through the Decision Service, the inputs and outputs are saved in the History of the platform. The history entity is of type HistoricDecisionInstance and has the event type evaluate. For details about the history mechanism as such, refer to the History and Audit Event Log. History Level History level FULL is required. Otherwise, no history for decisions is created. Query for evaluated Decisions The History Service can be used to query for HistoricDecisionInstances. For example, use the following query to get all history entries for a decision definition with key checkOrder ordered by the time when the decision was evaluated. List<HistoricDecisionInstance> historicDecisions = processEngine .getHistoryService() .createHistoricDecisionInstanceQuery() .decisionDefinitionKey(\"checkOrder\") .orderByEvaluationTime() .asc() .list(); Decisions which were evaluated from a BPMN business rule task can be filtered by the process definition id or key and process instance id. HistoryService historyService = processEngine.getHistoryService(); List<HistoricDecisionInstance> historicDecisionInstances = historyService .createHistoricDecisionInstanceQuery() .processDefinitionId(\"processDefinitionId\") .list(); historicDecisionInstances = historyService .createHistoricDecisionInstanceQuery() .processDefinitionKey(\"processDefinitionKey\") .list(); historicDecisionInstances = historyService .createHistoricDecisionInstanceQuery() .processInstanceId(\"processInstanceId\") .list(); Decisions which were evaluated from a CMMN decision task can be filtered by the case definition id or key and case instance id. HistoryService historyService = processEngine.getHistoryService(); List<HistoricDecisionInstance> historicDecisionInstances = historyService .createHistoricDecisionInstanceQuery() .caseDefinitionId(\"caseDefinitionId\") .list(); historicDecisionInstances = historyService .createHistoricDecisionInstanceQuery() .caseDefinitionKey(\"caseDefinitionKey\") .list(); historicDecisionInstances = historyService .createHistoricDecisionInstanceQuery() .caseInstanceId(\"caseInstanceId\") .list(); Note that the inputs and outputs of a decision are not included in the query result by default. Call the methods includeInputs() and includeOutputs() on the query to retrieve the inputs and outputs from the result. List<HistoricDecisionInstance> historicDecisions = processEngine .getHistoryService() .createHistoricDecisionInstanceQuery() .decisionDefinitionKey(\"checkOrder\") .includeInputs() .includeOutputs() .list(); The Historic Decision Instance The HistoricDecisionInstance contains information about a single evaluation of a decision. HistoricDecisionInstance historicDecision = ...; // id of the decision definition String decisionDefinitionId = historicDecision.getDecisionDefinitionId(); // key of the decision definition String decisionDefinitionKey = historicDecision.getDecisionDefinitionKey(); // name of the decision String decisionDefinitionName = historicDecision.getDecisionDefinitionName(); // time when the decision was evaluated Date evaluationTime = historicDecision.getEvaluationTime(); // inputs of the decision (if includeInputs was specified in the query) List<HistoricDecisionInputInstance> inputs = historicDecision.getInputs(); // outputs of the decision (if includeOutputs was specified in the query) List<HistoricDecisionOutputInstance> outputs = historicDecision.getOutputs(); In case the decision was evaluated from a process, information of the process definition, the process instance and the activity is set in the HistoricDecisionInstance. The same applies for decisions evaluated from a case, where the history instance will reference the corresponding case instances. Additionally, if the decision is a decision table with hit policy collect and an aggregator function, then the result of the aggregation can be retrieved by the getCollectResultValue() method. For more information on supported hit policies please see the DMN 1.3 reference. Historic Decision Input Instance The HistoricDecisionInputInstance represents one input of an evaluated decision (e.g., an input clause of a decision table). HistoricDecisionInputInstance input = ...; // id of the input clause String clauseId = input.getClauseId(); // label of the input clause String clauseName = input.getClauseName(); // evaluated value of the input expression Object value = input.getValue(); // evaluated value of the input expression as typed value // which contains type information TypedValue typedValue = input.getTypedValue(); Note that the value may be the result of a type transformation in case the input specifies a type. Historic Decision Output Instance The HistoricDecisionOutputInstance represents one output entry of an evaluated decision. If the decision is implemented as decision table, the HistoricDecisionInstance contains one HistoricDecisionOutputInstance for each output clause and matched rule. HistoricDecisionOutputInstance output = ...; // id of the output clause String clauseId = output.getClauseId(); // label of the output clause String clauseName = output.getClauseName(); // evaluated value of the output entry Object value = output.getValue(); // evaluated value of the output entry as typed value // which contains type information TypedValue typedValue = output.getTypedValue(); // id of matched rule the output belongs to String ruleId = output.getRuleId(); // the position of the rule in the list of matched rules Integer ruleOrder = output.getRuleOrder(); // name of the output clause used as output variable identifier String variableName = output.getVariableName(); Note that the value may be the result of a type transformation in case the output specifies a type. Cockpit You can audit the evaluated decision definitions in the Cockpit webapp.",
    "url": "/manual/latest/user-guide/process-engine/decisions/history/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/decisions/index.html",
    "title": "Decisions in the Process Engine | docs.cibseven.org",
    "content": "CIB seven provides an integration of the Camunda DMN engine to evaluate Business Decisions. This section describes how to deploy Business Decisions modeled as DMN decisions together with other resources to the repository of CIB seven. Deployed decisions can be evaluated using the Services API or they can be referenced in BPMN processes and CMMN cases. Evaluated decisions are saved in the History for auditing and reporting purposes.",
    "url": "/manual/latest/user-guide/process-engine/decisions/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/decisions/repository/index.html",
    "title": "Decisions in the Process Engine Repository | docs.cibseven.org",
    "content": "To evaluate a DMN decision in CIB seven, it has to be part of a Deployment. After a decision has been deployed, it can be referenced by its key and version. The platform supports DMN 1.3 XML files. Deploying a Decision To deploy a DMN decision you can either use the Repository Service or add it to a process application. The platform will recognize all files with a .dmn or .dmn11.xml file extension as DMN resources. Deploying a decision using the Repository Service Use the Repository Service to create a new deployment and add DMN resources to it. The following code, for example, will create a new deployment for a DMN file in the classpath. String resourceName = \"MyDecision.dmn11.xml\"; Deploymnet deployment = processEngine .getRepositoryService() .createDeployment() .addClasspathResource(resourceName) .deploy(); Deploying a decision with a Process Application If you deploy a Process Application, you can add the DMN file to your archive as other resources, like BPMN processes. The DMN files must have a .dmn or .dmn11.xml file extension to be recognized as DMN resource. If your Process Archive is set up to scan for process definitions, it will automatically deploy the DMN definitions too. This is the default. <process-archive name=\"loan-approval\"> <properties> <property name=\"isScanForProcessDefinitions\">true</property> </properties> </process-archive> Otherwise, you have to specify the DMN resources explicitly in the Process Archive <process-archive name=\"loan-approval\"> <resource>bpmn/invoice.bpmn</resource> <resource>dmn/assign-approver.dmn</resource> <properties> <property name=\"isScanForProcessDefinitions\">false</property> </properties> </process-archive> Versioning of Decisions When a DMN resource is deployed to the platform, every supported DMN Decision is transformed into a Decision Definition. A decision definition represents a single DMN decision in the platform. It has, among others, these attributes: id: The unique identifier of the Decision Definition generated by the platform. key: The DMN decision id attribute from the XML file. name: The DMN decision name attribute from the XML file. version: The version of the Decision Definition generated by the platform. The Decision Definition Key The decision definition key is equivalent to the id attribute of the DMN decision in the DMN XML. <?xml version=\"1.0\" encoding=\"UTF-8\"?> <definitions xmlns=\"https://www.omg.org/spec/DMN/20191111/MODEL/\" id=\"definitions\" name=\"definitions\" namespace=\"http://camunda.org/schema/1.0/dmn\"> <decision id=\"my-decision\" name=\"My Decision\"> <decisionTable> <output id=\"output1\"/> </decisionTable> </decision> </definitions> When deploying the above DMN XML file, a decision definition having the following properties is created: id: GENERATED key: my-decision name: My Decision version: 1 The Decision Definition Version When a decision is deployed, it is checked whether a definition with the same key is already deployed. If not, the decision definition is assigned version 1 for this key. If a decision definition with the same key already exists, the newly deployed decision definition will become a new version of the existing one, increasing its version by one. This versioning of decision definitions allows the user to update decisions, but still be able to use previous decision versions if needed. The Decision Definition Id The id of a decision definition is not equivalent to the id attribute of the DMN XML decision. It is generated by the platform as unique identifier. This means a decision definition id directly corresponds to a decision definition key and version combination. Reference a Decision Definition To reference a deployed decision definition in the context of the platform, either the decision definition id or the decision definition key and version is used. If a decision definition key is used but no version is specified, the default is to use the latest version of the decision definition. Versioning of Decision Requirements Graph In addition to the decision definitions, the decision requirements graph (i.e., the definitions element in the XML) of a deployed DMN resource is transformed into a Decision Requirements Definition. It has, among others, these attributes: id: The unique identifier of the Decision Requirements Definition generated by the platform. key: The definitions id attribute from the XML file. name: The definitions name attribute from the XML file. version: The version of the Decision Requirements Definition generated by the platform. Note that the decision requirements definition is only created if the DMN resource contains more than one decision. The Decision Requirements Definition Key The decision requirements definition key is equivalent to the id attribute of the definitions element in the DMN XML. <?xml version=\"1.0\" encoding=\"UTF-8\"?> <definitions xmlns=\"https://www.omg.org/spec/DMN/20191111/MODEL/\" id=\"my-drg\" name=\"My DRG\" namespace=\"http://camunda.org/schema/1.0/dmn\"> <!-- ... --> </definitions> When deploying the above DMN XML file, a decision requirements definition having the following properties is created: id: GENERATED key: my-drg name: My DRG version: 1 The Decision Requirements Definition Version When a decision requirements graph is deployed, it is checked whether a definition with the same key is already deployed. If not, the decision requirements definition is assigned version 1 for this key. If a decision requirements definition with the same key already exists, the newly deployed definition will become a new version of the existing one, increasing its version by one. Note that the versions of the contained decision definitions can be different from the decision requirements definition if they are also deployed inside other DMN resources, as a single decision inside a DMN resource, or added later. Querying the Decision Repository All deployed decision definitions and decision requirements definitions can be queried by the repository service API. Querying Decision Definitions Get a decision definition with the id “decisionDefinitionId”: DecisionDefinition decisionDefinition = processEngine .getRepositoryService() .getDecisionDefinition(\"decisionDefinitionId\"); Query for a decision definition with the key “decisionDefinitionKey” and version 1: DecisionDefinition decisionDefinition = processEngine .getRepositoryService() .createDecisionDefinitionQuery() .decisionDefinitionKey(\"decisionDefinitionKey\") .decisionDefinitionVersion(1) .singleResult(); Query for the latest version of decision definition with the key “decisionDefinitionKey”: DecisionDefinition decisionDefinition = processEngine .getRepositoryService() .createDecisionDefinitionQuery() .decisionDefinitionKey(\"decisionDefinitionKey\") .latestVersion() .singleResult(); Query for all versions of decision definitions with the key “decisionDefinitionKey”: List<DecisionDefinition> decisionDefinitions = processEngine .getRepositoryService() .createDecisionDefinitionQuery() .decisionDefinitionKey(\"decisionDefinitionKey\") .list(); Additionally, the repository service can be used to get the DMN XML file, a DMN model instance or deployed diagram images. RepositoryService repositoryService = processEngine.getRepositoryService(); DmnModelInstance dmnModelInstance = repositoryService .getDmnModelInstance(\"decisionDefinitionId\"); InputStream modelInputStream = repositoryService .getDecisionModel(\"decisionDefinitionId\"); InputStream diagramInputStream = repositoryService .getDecisionDiagram(\"decisionDefinitionId\"); Querying Decision Requirements Definitions The decision requirements definitions can be queried in a similar way to the decision definitions. // query for the latest version of a decision requirements definition by key DecisionRequirementsDefinition decisionRequirementsDefinition = processEngine .getRepositoryService() .createDecisionRequirementsDefinitionQuery() .decisionRequirementsDefinitionKey(key) .latestVersion() .singleResult(); // query for all versions of decision requirements definitions by name List<DecisionRequirementsDefinition> decisionRequirementsDefinitions = processEngine .getRepositoryService() .createDecisionRequirementsDefinitionQuery() .decisionRequirementsDefinitionName(name) .list(); Authorizations for Querying the Decision Repository The user needs the READ permission on the resource DECISION_DEFINITION to query decision definitions. This permission is also required to retrieve decision definitions, decision models and decision diagrams from the repository. The resource id of the authorization is the decision definition key. To query decision requirements definitions, the user needs the READ permission on the resource DECISION_REQUIREMENTS_DEFINITION. The resource id of the authorization is the key of the decision requirements definitions. For more information about authorizations, please refer to the Authorization Service section. Cockpit Deployed decision definitions can be viewed in the Cockpit webapp.",
    "url": "/manual/latest/user-guide/process-engine/decisions/repository/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/delegation-code/index.html",
    "title": "Delegation Code | docs.cibseven.org",
    "content": "Delegation Code allows you to execute external Java code, scripts or evaluate expressions when certain events occur during process execution. There are different types of Delegation Code: Java Delegates can be attached to a BPMN Service Task. Delegate Variable Mapping can be attached to a Call Activity. Execution Listeners can be attached to any event within the normal token flow, e.g., starting a process instance or entering an activity. Task Listeners can be attached to events within the user task lifecycle, e.g., creation or completion of a user task. You can create generic Delegation Code and configure this via the BPMN 2.0 XML using so called Field Injection. Java Delegate To implement a class that can be called during process execution, this class needs to implement the org.cibseven.bpm.engine.delegate.JavaDelegate interface and provide the required logic in the execute method. When process execution arrives at this particular step, it will execute this logic defined in that method and leave the activity in the default BPMN 2.0 way. As an example let’s create a Java class that can be used to change a process variable String to uppercase. This class needs to implement the org.cibseven.bpm.engine.delegate.JavaDelegate interface, which requires us to implement the execute(DelegateExecution) method. It’s this operation that will be called by the engine and which needs to contain the business logic. Process instance information such as process variables and other information can be accessed and manipulated through the DelegateExecution interface (click on the link for a detailed Javadoc of its operations). public class ToUppercase implements JavaDelegate { public void execute(DelegateExecution execution) throws Exception { String var = (String) execution.getVariable(\"input\"); var = var.toUpperCase(); execution.setVariable(\"input\", var); } } Note! Each time a delegation class referencing activity is executed, a separate instance of this class will be created. This means that each time an activity is executed there will be used another instance of the class to call execute(DelegateExecution). The classes that are referenced in the process definition (i.e., by using camunda:class ) are NOT instantiated during deployment. Only when a process execution arrives at the point in the process where the class is used for the first time, an instance of that class will be created. If the class cannot be found, a ProcessEngineException will be thrown. The reason for this is that the environment (and more specifically the classpath) when you are deploying is often different than the actual runtime environment. Activity Behavior Instead of writing a Java Delegate, it is also possible to provide a class that implements the org.cibseven.bpm.engine.impl.pvm.delegate.ActivityBehavior interface. Implementations then have access to the more powerful ActivityExecution that for example also allows to influence the control flow of the process. However, note that this is not a very good practice and should be avoided as much as possible. So, it is advised to only use the ActivityBehavior interface for advanced use cases and if you know exactly what you’re doing. Field Injection It is possible to inject values into the fields of the delegated classes. The following types of injection are supported: Fixed string values Expressions If available, the value is injected through a public setter method on your delegated class, following the Java Bean naming conventions (e.g., field firstName has setter setFirstName(...)). If no setter is available for that field, the value of private member will be set on the delegate (but using private fields is not recommended - see warning below). Regardless of the type of value declared in the process-definition, the type of the setter/private field on the injection target should always be org.cibseven.bpm.engine.delegate.Expression. Private fields cannot always be modified! It does not work with e.g., CDI beans (because you have proxies instead of real objects) or with some SecurityManager configurations. Please always use a public setter-method for the fields you want to have injected! The following code snippet shows how to inject a constant value into a field. Field Injection is supported when using the class or delegateExpression attribute. Note that we need to declare a extensionElements XML element before the actual field injection declarations, which is a requirement of the BPMN 2.0 XML Schema. <serviceTask id=\"javaService\" name=\"Java service invocation\" camunda:class=\"org.cibseven.bpm.examples.bpmn.servicetask.ToUpperCaseFieldInjected\"> <extensionElements> <camunda:field name=\"text\" stringValue=\"Hello World\" /> </extensionElements> </serviceTask> The class ToUpperCaseFieldInjected has a field text which is of type org.cibseven.bpm.engine.delegate.Expression. When calling text.getValue(execution), the configured string value Hello World will be returned. Alternatively, for longs texts (e.g., an inline e-mail) the camunda:string sub element can be used: <serviceTask id=\"javaService\" name=\"Java service invocation\" camunda:class=\"org.cibseven.bpm.examples.bpmn.servicetask.ToUpperCaseFieldInjected\"> <extensionElements> <camunda:field name=\"text\"> <camunda:string> Hello World </camunda:string> </camunda:field> </extensionElements> </serviceTask> To inject values that are dynamically resolved at runtime, expressions can be used. Those expressions can use process variables, CDI or Spring beans. As already noted, a separate instance of the Java class will be created each time the service task is executed. To have dynamic injection of values in fields, you can inject value and method expressions in an org.cibseven.bpm.engine.delegate.Expression which can be evaluated/invoked using the DelegateExecution passed in the execute method. <serviceTask id=\"javaService\" name=\"Java service invocation\" camunda:class=\"org.cibseven.bpm.examples.bpmn.servicetask.ReverseStringsFieldInjected\"> <extensionElements> <camunda:field name=\"text1\"> <camunda:expression>${genderBean.getGenderString(gender)}</camunda:expression> </camunda:field> <camunda:field name=\"text2\"> <camunda:expression>Hello ${gender == 'male' ? 'Mr.' : 'Mrs.'} ${name}</camunda:expression> </camunda:field> </extensionElements> </serviceTask> The example class below uses the injected expressions and resolves them using the current DelegateExecution. public class ReverseStringsFieldInjected implements JavaDelegate { private Expression text1; private Expression text2; public void execute(DelegateExecution execution) { String value1 = (String) text1.getValue(execution); execution.setVariable(\"var1\", new StringBuffer(value1).reverse().toString()); String value2 = (String) text2.getValue(execution); execution.setVariable(\"var2\", new StringBuffer(value2).reverse().toString()); } } Alternatively, you can also set the expressions as an attribute instead of a child-element, to make the XML less verbose. <camunda:field name=\"text1\" expression=\"${genderBean.getGenderString(gender)}\" /> <camunda:field name=\"text2\" expression=\"Hello ${gender == 'male' ? 'Mr.' : 'Mrs.'} ${name}\" /> Note! The injection happens each time the service task is called since a separate instance of the class will be created. When the fields are altered by your code, the values will be re-injected when the activity is executed next time. For the same reasons as mentioned above, field injection should not be (usually) used with Spring beans, which are singletons by default. Otherwise, you may run into inconsistencies due to concurrent modification of the bean fields. Delegate Variable Mapping To implement a class that delegates the input and output variable mapping for a call activity, this class needs to implement the org.cibseven.bpm.engine.delegate.DelegateVariableMapping interface. The implementation must provide the methods mapInputVariables(DelegateExecution, VariableMap) and mapOutputVariables(DelegateExecution, VariableScope). See the following example: public class DelegatedVarMapping implements DelegateVariableMapping { @Override public void mapInputVariables(DelegateExecution execution, VariableMap variables) { variables.putValue(\"inputVar\", \"inValue\"); } @Override public void mapOutputVariables(DelegateExecution execution, VariableScope subInstance) { execution.setVariable(\"outputVar\", \"outValue\"); } } The mapInputVariables method is called before the call activity is executed, to map the input variables. The input variables should be put into the given variables map. The mapOutputVariables method is called after the call activity was executed, to map the output variables. The output variables can be directly set into the caller execution. The behavior of the class loading is similar to the class loading on Java Delegates. Execution Listener Execution listeners allow you to execute external Java code or evaluate an expression when certain events occur during process execution. The events that can be captured are: Start and end of a process instance. Taking a transition. Start and end of an activity. Start and end of a gateway. Start and end of intermediate events. Ending a start event or starting an end event. The following process definition contains 3 execution listeners: <process id=\"executionListenersProcess\"> <extensionElements> <camunda:executionListener event=\"start\" class=\"org.cibseven.bpm.examples.bpmn.executionlistener.ExampleExecutionListenerOne\" /> </extensionElements> <startEvent id=\"theStart\" /> <sequenceFlow sourceRef=\"theStart\" targetRef=\"firstTask\" /> <userTask id=\"firstTask\" /> <sequenceFlow sourceRef=\"firstTask\" targetRef=\"secondTask\"> <extensionElements> <camunda:executionListener> <camunda:script scriptFormat=\"groovy\"> println execution.eventName </camunda:script> </camunda:executionListener> </extensionElements> </sequenceFlow> <userTask id=\"secondTask\"> <extensionElements> <camunda:executionListener expression=\"${myPojo.myMethod(execution.eventName)}\" event=\"end\" /> </extensionElements> </userTask> <sequenceFlow sourceRef=\"secondTask\" targetRef=\"thirdTask\" /> <userTask id=\"thirdTask\" /> <sequenceFlow sourceRef=\"thirdTask\" targetRef=\"theEnd\" /> <endEvent id=\"theEnd\" /> </process> The first execution listener is notified when the process starts. The listener is an external Java-class (like ExampleExecutionListenerOne) and should implement the org.cibseven.bpm.engine.delegate.ExecutionListener interface. When the event occurs (in this case end event) the method notify(DelegateExecution execution) is called. public class ExampleExecutionListenerOne implements ExecutionListener { public void notify(DelegateExecution execution) throws Exception { execution.setVariable(\"variableSetInExecutionListener\", \"firstValue\"); execution.setVariable(\"eventReceived\", execution.getEventName()); } } It is also possible to use a delegation class that implements the org.cibseven.bpm.engine.delegate.JavaDelegate interface. These delegation classes can then be reused in other constructs, such as a delegation for a service task. The second execution listener is called when the transition is taken. Note that the listener element doesn’t define an event, since only take events are fired on transitions. Values in the event attribute are ignored when a listener is defined on a transition. Also it contains a camunda:script child element which defines a script which will be executed as execution listener. Alternatively it is possible to specify the script source code as external resources (see the documentation about script sources of script tasks). The last execution listener is called when activity secondTask ends. Instead of using the class on the listener declaration, a expression is defined instead which is evaluated/invoked when the event is fired. <camunda:executionListener expression=\"${myPojo.myMethod(execution.eventName)}\" event=\"end\" /> Note! The end event triggers under any circumstance in which the activity ends. That includes successful completion of the activity’s business logic, but also interruption and cancellation, for example when an attached boundary event triggers. As with other expressions, execution variables are resolved and can be used. Because the execution implementation object has a property that exposes the event name, it’s possible to pass the event-name to your methods using execution.eventName. Execution listeners also support using a delegateExpression, similar to a service task. <camunda:executionListener event=\"start\" delegateExpression=\"${myExecutionListenerBean}\" /> Task Listener A task listener is used to execute custom Java logic or an expression upon the occurrence of a certain task-related event. It can only be added in the process definition as a child element of a user task. Note that this also must happen as a child of the BPMN 2.0 extensionElements and in the Camunda namespace, since a task listener is a construct specifically for the CIB seven engine. <userTask id=\"myTask\" name=\"My Task\" > <extensionElements> <camunda:taskListener event=\"create\" class=\"org.cibseven.bpm.MyTaskCreateListener\" /> </extensionElements> </userTask> Task Listener Event Lifecycle The execution of Task Listeners is dependent on the order of firing of the following task-related events: The create event fires when the task has been created as a transient object with all task properties. No other task-related event will be fired before the create event. The event allows us to inspect all properties of the task when we receive it in the create listener. The update event occurs when a task property (e.g. assignee, owner, priority, etc.) on an already created task is changed. This includes attributes of a task (e.g. assignee, owner, priority, etc.), as well as dependent entities (e.g. attachments, comments, task-local variables). Note that the initialization of a task does not fire an update event (the task is being created). This also means that the update event will always occur after a create event has already occurred. The assignment event specifically tracks the changes of the Task’s assignee property. The event may be fired on two occasions: When a task with an assignee explicitly defined in the process definition has been created. In this case, the assignment event will be fired after the create event. When an already created task is assigned, i.e. the Task’s assignee property is changed. In this case, the assignment event will follow the update event since changing the assignee property results in an updated task. The assignment event can be used for a more fine grained inspection, when the assignee is actually set. The timeout event occurs when a Timer, associated with this Task Listener, is due. Note that this requires for a Timer to be defined. The timeout event may occur after a Task has been created, and before it has been completed. The complete event occurs when the task is successfully completed and just before the task is deleted from the runtime data. A successful execution of a task’s complete Task Listeners results in an end of the task event lifecycle. The delete event occurs just before the task is deleted from the runtime data, because of: An interrupting Boundary Event; An interrupting Event Subprocess; A Process Instance deletion; A BPMN Error thrown inside a Task Listener. No other event is fired after the delete event since it results in an end of the task event lifecycle. This means that the delete event is mutually exclusive with the complete event. Task Event Chaining The descriptions above lay out the order in which Task Events are fired. However, this order may be disrupted under the following conditions: When calling Task#complete() inside a Task Listener, the complete event will be fired right away. The related Task Listeners will be immediately invoked, after which the remaining Task Listeners for the previous event will be processed. By using the TaskService methods inside a Task Listener, which may cause the firing of additional Task Events. As with the complete event mentioned above, these Task Events will immediately invoke their related Listeners, after which the remaining Task Listeners will be processed. However, it should be noted that the chain of events triggered inside the Task Listener, by the invocation of the TaskService method, will be in the previously described order. By throwing a BPMN Error event inside a Task Listener (e.g. a complete event Task Listener). This would cancel the Task and cause a delete event to be fired. Under the above-mentioned conditions, users should be careful not to accidentally create a Task event loop. Defining a Task Listener A task listener supports the following attributes: event (required): the type of task event on which the task listener will be invoked. Possible events are: create, assignment, update, complete, delete and timeout; Note that the timeout event requires a timerEventDefinition child element in the task listener and will only be fired if the Job Executor is enabled. class: the delegation class that must be called. This class must implement the org.cibseven.bpm.engine.impl.pvm.delegate.TaskListener interface. public class MyTaskCreateListener implements TaskListener { public void notify(DelegateTask delegateTask) { // Custom logic goes here // The task object is persisted in the database after this method has finished } } It is also possible to use Field Injection to pass process variables or the execution to the delegation class. Note that each time a delegation class referencing activity is executed, a separate instance of this class will be created. expression: (cannot be used together with the class attribute): specifies an expression that will be executed when the event happens. It is possible to pass the DelegateTask object and the name of the event (using task.eventName) to the called object as parameters. <camunda:taskListener event=\"create\" expression=\"${myObject.callMethod(task, task.eventName)}\" /> delegateExpression: allows to specify an expression that resolves to an object implementing the TaskListener interface, similar to a service task. <camunda:taskListener event=\"create\" delegateExpression=\"${myTaskListenerBean}\" /> id: a unique identifier of the listener within the scope of the user task, only required if the event is set to timeout. Besides the class, expression and delegateExpression attributes, a camunda:script child element can be used to specify a script as task listener. An external script resource can also be declared with the resource attribute of the camunda:script element (see the documentation about script sources of script tasks). <userTask id=\"task\"> <extensionElements> <camunda:taskListener event=\"create\"> <camunda:script scriptFormat=\"groovy\"> println task.eventName </camunda:script> </camunda:taskListener> </extensionElements> </userTask> Furthermore, a timerEventDefinition child element can be used in conjunction with the event type timeout in order to define the associated timer. The specified delegate will be called by the Job Executor when the timer is due. The execution of the user task will not be interrupted by this. <userTask id=\"task\"> <extensionElements> <camunda:taskListener event=\"timeout\" delegateExpression=\"${myTaskListenerBean}\" id=\"friendly-reminder\" > <timerEventDefinition> <timeDuration xsi:type=\"tFormalExpression\">PT1H</timeDuration> </timerEventDefinition> </camunda:taskListener> </extensionElements> </userTask> Field Injection on Listener When using listeners configured with the class attribute, Field Injection can be applied. This is exactly the same mechanism as described for Java Delegates, which contains an overview of the possibilities provided by field injection. The fragment below shows a simple example process with an execution listener with fields injected: <process id=\"executionListenersProcess\"> <extensionElements> <camunda:executionListener class=\"org.cibseven.bpm.examples.bpmn.executionListener.ExampleFieldInjectedExecutionListener\" event=\"start\"> <camunda:field name=\"fixedValue\" stringValue=\"Yes, I am \" /> <camunda:field name=\"dynamicValue\" expression=\"${myVar}\" /> </camunda:executionListener> </extensionElements> <startEvent id=\"theStart\" /> <sequenceFlow sourceRef=\"theStart\" targetRef=\"firstTask\" /> <userTask id=\"firstTask\" /> <sequenceFlow sourceRef=\"firstTask\" targetRef=\"theEnd\" /> <endEvent id=\"theEnd\" /> </process> The actual listener implementation may look as follows: public class ExampleFieldInjectedExecutionListener implements ExecutionListener { private Expression fixedValue; private Expression dynamicValue; public void notify(DelegateExecution execution) throws Exception { String value = fixedValue.getValue(execution).toString() + dynamicValue.getValue(execution).toString(); execution.setVariable(\"var\", value); } } The class ExampleFieldInjectedExecutionListener concatenates the 2 injected fields (one fixed and the other dynamic) and stores this in the process variable var. @Deployment(resources = { \"org/cibseven/bpm/examples/bpmn/executionListener/ExecutionListenersFieldInjectionProcess.bpmn20.xml\" }) public void testExecutionListenerFieldInjection() { Map<String, Object> variables = new HashMap<String, Object>(); variables.put(\"myVar\", \"listening!\"); ProcessInstance processInstance = runtimeService.startProcessInstanceByKey(\"executionListenersProcess\", variables); Object varSetByListener = runtimeService.getVariable(processInstance.getId(), \"var\"); assertNotNull(varSetByListener); assertTrue(varSetByListener instanceof String); // Result is a concatenation of fixed injected field and injected expression assertEquals(\"Yes, I am listening!\", varSetByListener); } Access Process Engine Services It is possible to access the public API services (RuntimeService, TaskService, RepositoryService …) from the Delegation Code. The following is an example showing how to access the TaskService from a JavaDelegate implementation. public class DelegateExample implements JavaDelegate { public void execute(DelegateExecution execution) throws Exception { TaskService taskService = execution.getProcessEngineServices().taskService(); taskService.createTaskQuery()...; } } Throw BPMN Errors from Delegation Code It is possible to throw BpmnError from delegation code (Java Delegate, Execution and Task Listeners). This is done by using a provided Java exception class from within your Java code (e.g., in the JavaDelegate): public class BookOutGoodsDelegate implements JavaDelegate { public void execute(DelegateExecution execution) throws Exception { try { ... } catch (NotOnStockException ex) { throw new BpmnError(NOT_ON_STOCK_ERROR); } } } Throw BPMN Errors from Listeners When implementing an error catch event, keep in mind that the BpmnError will be caught when they are thrown in normal flow of the following listeners: start and end execution listeners on activity, gateway, and intermediate events take execution listeners on transitions create, assign, and complete task listeners The BpmnError will not be caught for the following listeners: start and end process listeners delete task listeners listeners invoked outside of the normal flow: a process modification is performed which trigger subprocess scope initialization and some of its listeners throws an error a process instance deletion invokes an end listener throwing an error a listener is triggered due to interrupting boundary event execution, e.g message correlation on subprocess invokes end listeners throwing an error Note! Throwing a BpmnError in the delegation code behaves like modelling an error end event. See the reference guide about the details on the behavior, especially the error boundary event. If no error boundary event is found on the scope, the execution is ended. Set Business Key from Delegation Code The option to set a new value of business key to already running process instance is shown in the example below: public class BookOutGoodsDelegate implements JavaDelegate { public void execute(DelegateExecution execution) throws Exception { ... String recalculatedKey = (String) execution.getVariable(\"recalculatedKeyVariable\"); execution.setProcessBusinessKey(recalculatedKey); ... } } Exception codes You can throw a ProcessEngineException from your delegation code and define your custom error code by passing it to the constructor or by calling ProcessEngineException#setCode. Also, you can create a custom exception class that extends the ProcessEngineException: // Defining a custom exception. public class MyException extends ProcessEngineException { public MyException(String message, int code) { super(message, code); } } // Delegation code that throws MyException with a custom error code. public class MyJavaDelegate implements JavaDelegate { @Override public void execute(DelegateExecution execution) { String myErrorMessage = \"My error message.\"; int myErrorCode = 22_222; throw new MyException(myErrorMessage, myErrorCode); } } Setting a custom error code via Delegation Code allows your business logic to react to it by getting the code via ProcessEngineException#getCode when calling Camunda Java API or by evaluating the code property in the response of an erroneous REST API call. If you don’t set any code, the engine assigns 0, which a custom or built-in error code provider can override. Also, you can register your custom exception code provider to assign error codes to exceptions you cannot control via your Delegation Code. Heads-up! A custom error code you define via delegation code has precedence over a custom error code provided by a Custom Code Provider. If your custom error code violates the reserved code range, it will be overridden with 0 unless you disable the built-in code provider.",
    "url": "/manual/latest/user-guide/process-engine/delegation-code/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/deployment-cache/index.html",
    "title": "Deployment Cache | docs.cibseven.org",
    "content": "All process definitions are cached (after they have been parsed) to avoid polling the database every time a process definition is needed and because process definition data doesn’t change. This reduces the latency of referencing the process definitions and thus improves the performance of the system. Customize the maximum Capacity of the Cache If one has many process definitions, the cache might occupy a large amount of memory and the capacity of the working memory may reach its limits. Therefore, after the maximum capacity is reached the least recently used process definition entry is evicted from the cache to satisfy the capacity condition. However, if one still meets out of memory issues, it can be necessary to lower the maximum capacity of the cache. By changing the maximum capacity, the configuration effects all of the following cache components: Process definition Case definition Decision definition Decision requirements definition In the process engine configuration one can specify the maximum capacity of the cache. The default value is 1000. When the process engine is created, this property will be set and all resources will be scanned and deployed accordingly. As an example the maximum capacity could be set to 120 as follows: <bean id=\"processEngineConfiguration\" class=\"org.cibseven.bpm.engine.impl.cfg.StandaloneInMemProcessEngineConfiguration\"> <!-- Your property definitions! --> .... <property name=\"cacheCapacity\" value=\"120\" /> </bean> Note: The same capacity is used for all of the components stated above and it is not possible to set the capacity size individually for each component. Furthermore, in the default cache implementation corresponds the capacity size to the maximum number of elements in the cache that are used. That means, the absolute amount of physical storage (e.g. mega bytes) you use up depends on the size needed for the respective process definitions. Provide a custom Cache Implementation The default implementation of the cache evicts the least recently used entry as soon as the maximum capacity is exceeded. If it is necessary to choose the evicted cache entries by a different criteria, one can provide its own cache implementation. One can do this by implementing the Cache interface from org.cibseven.util.commons package. Let’s assume for example that the following class has been implemented: public class MyCacheImplementation<K, V> implements Cache<K, V> { // implement interface methods and your own cache logic here } Next, one need to plug in MyCacheImplementation into a custom CacheFactory: public class MyCacheFactory extends CacheFactory { @Override public <T> Cache<String, T> createCache(int maxNumberOfElementsInCache) { return new MyCacheImplementation<String, T>(maxNumberOfElementsInCache); } } The factory is used to provide the cache implementation for different cache components such as the process definition or the case definition. Once this is done, one can use the process engine configuration where one can specify a set of resources. When the process engine is created, all those resources will be scanned and deployed. In the given example the custom cache factory could now be deployed as follows: <bean id=\"processEngineConfiguration\" class=\"org.cibseven.bpm.engine.impl.cfg.StandaloneInMemProcessEngineConfiguration\"> <!-- Your property definitions! --> .... <property name=\"cacheFactory\"> <bean class=\"org.cibseven.bpm.engine.test.api.cfg.MyCacheFactory\" /> </property> </bean>",
    "url": "/manual/latest/user-guide/process-engine/deployment-cache/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/deployments/index.html",
    "title": "Deployments | docs.cibseven.org",
    "content": "Before a process (or case, or decision) can be executed by the process engine, it has to be deployed. A deployment is a logical entity that groups multiple resources that are deployed together. Deployments can be made programmatically via Java API or REST API, or declaratively for resources of a Process Application. This section covers advanced deployment concepts. Deployments in a Clustered Scenario Before the process engine starts to perform a deployment, it tries to acquire an exclusive lock on a row in the table ACT_GE_PROPERTY. When the process engine is able to acquire the lock successfully, it starts to deploy and holds the exclusive lock as long as the execution of the deployment take place. If a deployment of the same resources is performed on multiple nodes in a clustered scenario simultaneously, the acquired exclusive lock ensures that duplicate filtering works as expected. Otherwise, parallel deployments may result in multiple versions of the same process definition. Additionally, the exclusive lock ensures that multiple definitions (e.g., process definitions) with the same key don’t get the same version when they are deployed simultaneously, which can lead to failures and unexpected behavior. Note that there is no unique constraint in the database that checks the uniqueness of a definition. In consequence, the exclusive lock enforces a sequential order of deployments. By default, the exclusive lock acquisition is enabled. If this is not desired, it is possible to disable it by setting the process engine configuration flag named deploymentLockUsed to false. H2 Database Note that the H2 database is not supported in a clustered scenario. The process engine creates no exclusive locks because H2 uses table level locks by default, which may cause deadlocks if the deploy command needs to get a new Id using the DbIdGenerator while performing a deployment.",
    "url": "/manual/latest/user-guide/process-engine/deployments/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/diagnostics-data/index.html",
    "title": "Diagnostics data | docs.cibseven.org",
    "content": "Diagnostics data is constantly collected and can be collected only by you. This allows you to access the collected data through the Java and REST APIs of CIB seven. Being able to easily access the collected data is helpful when asking for help in our discussions or when opening issues in our issue tracker as it contains many of the information that are usually necessary to understand your Camunda setup. How to access the data Java API To fetch the collected data via the Java API, you can use the ManagementService class. For example, the following code retrieves the detected JDK vendor and version: ProcessEngine processEngine = ...; ManagementService managementService = processEngine.getManagementService(); TelemetryData telemetryData = managementService.getTelemetryData(); Internals productInternals = telemetryData.getProduct().getInternals(); String jdkVendor = productInternals.getJdk().getVendor(); String jdkVersion = productInternals.getJdk().getVersion(); REST API You can fetch the collected data via the REST API by calling the Get Telemetry Data endpoint. Collected data Below you find the full list of data the diagnostic collector collects, followed by a real-world example. On a conceptual level, they can be categorized into general data, meta/environment data, and usage data. General data The “General Data” category contains information about the process engine: Installation - an id that is stored as process engine configuration property Product name - the name of the product (i.e., CIB seven Runtime) Product version - the version of the process engine (i.e., 1.X.Y) Meta and environment data The “Meta/Environment Data” category contains information about the environmental setup: Database vendor and version Application server vendor and version JDK vendor and version Used CIB seven Web Applications The application server information cannot be obtained in an embedded process engine setup where no web application (e.g. Tasklist, Cockpit, REST application) is deployed and used. In case of Azul Zulu JDK, the vendor will be send as “Oracle Corporation” as it cannot be distinguished programmatically from an Oracle JDK. Usage data The “Usage Data” category contains information about the used features and components of the process engine: Commands count - the count of executed commands after the last retrieved data. It could be from the previous 24 hours if the data have been reported then, and the process engine has not been closed during that time. Whenever the process engine is shutdown, the currently collected data is reported immediately. Metrics count - the collected metrics are number of root process instance executions started, number of activity instances started or also known as flow node instances, and number of executed decision instances and elements. The counts are collected from the start of the engine or the last reported time if the engine is already running for more than 24 hours. Camunda integration - a flag that shows if any of the CIB seven integrations are used: Spring boot starter, CIB seven Platform Run, WildFly subsystem or CIB seven ejb service (e.g. WebSphere/WebLogic Application servers). Example { \"installation\": \"8343cc7a-8ad1-42d4-97d2-43452c0bdfa3\", \"product\": { \"name\": \"CIB seven Runtime\", \"version\": \"7.14.0\", \"edition\": \"community\", \"internals\": { \"database\": { \"vendor\": \"h2\", \"version\": \"1.4.190 (2015-10-11)\" }, \"application-server\": { \"vendor\": \"Wildfly\", \"version\": \"WildFly Full 19.0.0.Final (WildFly Core 11.0.0.Final) - 2.0.30.Final\" }, \"jdk\": { \"version\": \"14.0.2\", \"vendor\": \"Oracle Corporation\" }, \"commands\": { \"StartProcessInstanceCmd\": {\"count\": 40}, \"FetchExternalTasksCmd\": {\"count\": 100} }, \"metrics\": { \"process-instances\": { \"count\": 936 }, \"flow-node-instances\": { \"count\": 6125 }, \"decision-instances\": { \"count\": 140 }, \"executed-decision-elements\": { \"count\": 732 } }, \"data-collection-start-date\": \"2022-11-320T15:53:20.386+0100\", \"camunda-integration\": [ \"spring-boot-starter\", \"camunda-bpm-run\" ], \"license-key\": { \"customer\": \"customer name\", \"type\": \"UNIFIED\", \"valid-until\": \"2022-09-30\", \"unlimited\": false, \"features\": { \"camundaBPM\": \"true\" }, \"raw\": \"customer=customer name;expiryDate=2022-09-30;camundaBPM=true;optimize=false;cawemo=false\" }, \"webapps\": [ \"cockpit\", \"admin\" ] } } } Source code In case you want further details, you can have a look at the implementation of the diagnostics topic in the codebase. The link leads you to the current master version of the feature.",
    "url": "/manual/latest/user-guide/process-engine/diagnostics-data/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/error-handling/index.html",
    "title": "Error Handling | docs.cibseven.org",
    "content": "Error Handling Strategies There are a couple of basic strategies to handle errors and exceptions within processes. The decision which strategy to use depends on: Technical vs. Business Errors: Does the error have some business meaning and causes an alternative process flow (like “item not on stock”) or is it a technical malfunction (like “network currently down”)? Explicit error handling or generic approach: For some situations you want to explicitly model what should happen in case of an error (typically for business errors). For a lot of situations you don’t want to do that but have some generic mechanism which applies for errors, simplifying your process models (typical for technical errors, imagine you would have to model network outage on every task were it might possibly occur? You wouldn’t be able to recognize your business process any more). In the context of the process engine, errors are normally raised as Java exceptions which you have to handle. Let’s have a look at how to handle them. Transaction Rollbacks The standard handling strategy is that exceptions are thrown to the client, meaning that the current transaction is rolled back. This means that the process state is rolled back to the last wait state. This behavior is described in detail in the Transactions in Processes section of the User Guide. Error handling is delegated to the client by the engine. Let’s show this in a concrete example: the user gets an error dialog on the frontend stating that the stock management software is currently not reachable due to network errors. To perform a retry, the user might have to click the same button again. Even if this is often not desired it is still a simple strategy applicable in a lot of situations. Async and Failed Jobs If you don’t want the exception being shown to the user, one option is to make service calls, which might cause an error, async (as described in Transactions in Processes). In that case the exception is stored in the process engine database and the Job in the background is marked as failed (to be more precise, the exception is stored and some retry counter is decremented). In the example above this means that the user will not see an error but an “everything successful” dialog. The exception is stored on the job. Now either a clever retry strategy will automatically re-trigger the job later on (when the network is available again) or an operator needs to have a look at the error and trigger an additional retry. This is shown later in more detail. This strategy is pretty powerful and applied often in real-life projects, however, it still hides the error in the BPMN diagram, so for business errors which you want to be visible in the process diagram, it would be better to use Error Events. Catch Exception and use Data Based XOR-Gateway If you call Java Code which can throw an exception, you can catch the exception within the Java Delegate, CDI Bean or whatsoever. Maybe it is already sufficient to log some information and go on, meaning that you ignore the error. More often you write the result into a process variable and model an XOR-Gateway later in the process flow to take a different path if that error occurs. In that case you model the error handling explicitly in the process model but you make it look like a normal result and not like an error. From a business perspective it is not an error but a result, so the decision should not be made lightly. A rule of thumb is that results can be handled this way, exceptional errors should not. However, the BPMN perspective does not always have to match the technical implementation. Example: We trigger a “check data completeness” task. The Java Service might throw a “DataIncompleteException”. However, if we check for completeness, incomplete data is not an exception, but an expected result, so we prefer to use an XOR-Gateway in the process flow which evaluates a process variable, e.g., “#{dataComplete==false}”. BPMN 2.0 Error Event The BPMN 2.0 error event gives you the possibility to explicitly model errors, tackling the use case of business errors. The most prominent example is the “intermediate catching error event”, which can be attached to the boundary of an activity. Defining a boundary error event makes most sense on an embedded subprocess, a call activity or a Service Task. An error will cause the alternative process flow to be triggered: See the Error Events section of the BPMN 2.0 Implementation Reference and the Throwing Errors from Delegation Code section of the User Guide for more information. BPMN 2.0 Compensation and Business Transactions BPMN 2.0 transactions and compensations allow you to model business transaction boundaries (however, not in a technical ACID manner) and make sure already executed actions are compensated during a rollback. Compensation means to make the effect of the action invisible, e.g. book in goods if you have previously booked out the goods. See the BPMN Compensation event and the BPMN Transaction Subprocess sections of the BPMN 2.0 Implementation Reference for details. Monitoring and Recovery Strategies In case the error occurred, different recovery strategies can be applied. Let the User Retry As mentioned above, the simplest error handling strategy is to throw the exception to the client, meaning that the user has to retry the action himself. How he does that is up to the user, normally reloading the page or clicking again. Retry Failed Jobs If you use Jobs (async), you can leverage Cockpit as monitoring tool to handle failed jobs, in this case no end user sees the exception. Then you normally see failures in cockpit when the retries are depleted (see the Failed Jobs section of the Web Applications for more information). See the Failed Jobs in Cockpit section of the Web Applications for more details. If you don’t want to use Cockpit, you can also find the failed jobs via the API yourself: List<Job> failedJobs = processEngine.getManagementService().createJobQuery().withException().list(); for (Job failedJob : failedJobs) { processEngine.getManagementService().setJobRetries(failedJob.getId(), 1); } Explicit Modeling Of course you can always explicitly model a retry mechanism as pointed out in Where is the retry in BPMN 2.0: We would recommend to limit it to cases where you want to see it in the process diagram for a good reason. We prefer asynchronous continuation, as it doesn’t bloat your process diagram and basically can do the same thing with even less runtime overhead, as “walking” through the modeled loop involves additional action, e.g., writing an audit log. User Tasks for Operations We often see something like this in projects: Actually this is a valid approach in which you assign errors to an operator as User Tasks and model what options he has to solve the problem. However, this is a strange mixture: We want to handle a technical error we but add it to our business process model. Where do we stop? Do we have to model it on every Service Task now? Having a failed jobs list instead of using the “normal” task list feels like a more natural approach for this situation, which is why we normally recommend the other possibility and do not consider this to be best practice. Exception codes Sometimes an API call doesn’t succeed because a problem occurs. The Java programming model uses exceptions to handle these situations. Exceptions that occur on the process engine’s application level are of the type ProcessEngineException . Here are two examples of everyday situations in which the engine throws a ProcessEngineException: You cannot start a process instance since the variable’s value is too long. Two users in parallel complete the same task. You can read the exception message to understand the reason for a ProcessEngineException. However, sometimes the message of the top-level exception is too generic. In these situations, the cause might contain a more insightful exception message. Traversing through exception causes might be tedious. Also, causes are unavailable when an error occurs on the REST API level. While reading the error message might help users to understand the root cause of the problem, evaluating exception messages in an automated way is not a good idea since: The message might change with newer versions. Relying on fragments of the message can be error-prone. This is why we introduced static exception codes your business logic can rely on to determine specific problems and react accordingly. You can access error codes via Java as well as REST API. Built-in codes We identified common situations in which the engine throws an exception and assigned a built-in error code to the exception. You can look up the built-in codes in the Categories, ranges, and codes section. Custom codes Sometimes you may want to assign codes to specific errors Camunda hasn’t covered so far. You can either define custom codes from delegation code or by registering your custom ExceptionCodeProvider. Delegation code Learn more on how to assign a custom error code to an exception in the documentation about Delegation Code. Configuration You can configure the exception error codes feature in your process engine configuration: To disable the exception codes feature entirely, set the flag disableExceptionCode in your process engine configuration to true. To disable the built-in exception code provider, set the flag disableBuiltinExceptionCodeProvider in your process engine configuration to true. Disabling the built-in exception code provider allows overriding the reserved code range with your custom exception codes. Register a Custom Code Provider With the help of a ProcessEnginePlugin you can register a custom ExceptionCodeProvider : engineConfig.setCustomExceptionCodeProvider(new ExceptionCodeProvider() { @Override public Integer provideCode(ProcessEngineException processEngineException) { // Put your business logic here to determine the // error code in case a process engine exception was thrown. return 22_222; } @Override public Integer provideCode(SQLException sqlException) { // Put your business logic here to determine the // error code in case a sql exception was thrown. return 33_333; } }); Heads-up! If your custom error code violates the reserved code range, it will be overridden with 0 unless you disable the built-in code provider. Categories, ranges, and codes In the table below, you will find an overview of all categories, ranges, and codes: Category Range Code Description Safe to retry Fallback 0 All errors with no code assigned. Engine [1, 9999] 1 OptimisticLockingException X Persistence [10000, 19999] 10,000 Deadlock situation occurred. X 10,001 A foreign key constraint was violated. 10,002 The column size is too small. Custom [20000, 39999] E.g., 22,222 E.g., custom JavaDelegate validation error. Reserved code range The codes <= 19,999 and >= 40,000 are reserved for built-in codes. If you disable the built-in code provider, you can also use the reserved code range for your custom codes.",
    "url": "/manual/latest/user-guide/process-engine/error-handling/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/expression-language/index.html",
    "title": "Expression Language | docs.cibseven.org",
    "content": "CIB seven supports the Unified Expression Language (EL), specified by the Jakarta Expression Language 4.0 standard. To do so, it maintains a custom version of the open source JUEL implementation. Note, compared to EL 4.0 this JUEL implementation has the following limitations: Initializing collections directly within expressions (e.g., ${[1,2,3]}) is NOT supported. Lambda expressions (e.g., inline functions ${((x,y)->x+y)(3,4)}) are NOT supported. Referencing static fields (e.g., ${Boolean.TRUE}), static functions (e.g., ${Integer.parseInt(\"123\")}), and enums (e.g., ${Thread.State.TERMINATED}) are NOT supported. The Assignment Operator (A=B), the String Concatenation Operator (A+=B), and the Semicolon Operator (A ; B) are NOT supported. To get more general information about the usage of Expression Language, please read the official documentation. It provides examples that give a good overview of the syntax of expressions. Within CIB seven, EL can be used in many circumstances to evaluate small script-like expressions. The following table provides an overview of the BPMN elements which support usage of EL. BPMN element EL support Service Task, Business Rule Task, Send Task, Message Intermediate Throwing Event, Message End Event, Execution Listener and Task Listener Expression language as delegation code Sequence Flows, Conditional Events Expression language as condition expression All Tasks, All Events, Transaction, Subprocess and Connector Expression language inside an inputOutput parameter mapping Different Elements Expression language as the value of an attribute or element All Flow Nodes, Process Definition Expression language to determine the priority of a job Usage of Expression Language Delegation Code Besides Java code, CIB seven also supports the evaluation of expressions as delegation code. For general information about delegation code, see the corresponding section. Two types of expressions are currently supported: camunda:expression and camunda:delegateExpression. With camunda:expression it is possible to evaluate a value expression or to invoke a method expression. You can use special variables which are available inside an expression or Spring and CDI beans. For more information about variables and Spring, respectively CDI beans, please see the corresponding sections. <process id=\"process\"> <extensionElements> <!-- execution listener which uses an expression to set a process variable --> <camunda:executionListener event=\"start\" expression=\"${execution.setVariable('test', 'foo')}\" /> </extensionElements> <!-- ... --> <userTask id=\"userTask\"> <extensionElements> <!-- task listener which calls a method of a bean with current task as parameter --> <camunda:taskListener event=\"complete\" expression=\"${myBean.taskDone(task)}\" /> </extensionElements> </userTask> <!-- ... --> <!-- service task which evaluates an expression and saves it in a result variable --> <serviceTask id=\"serviceTask\" camunda:expression=\"${myBean.ready}\" camunda:resultVariable=\"myVar\" /> <!-- ... --> </process> The attribute camunda:delegateExpression is used for expressions which evaluate to a delegate object. This delegate object must implement either the JavaDelegate or ActivityBehavior interface. <!-- service task which calls a bean implementing the JavaDelegate interface --> <serviceTask id=\"task1\" camunda:delegateExpression=\"${myBean}\" /> <!-- service task which calls a method which returns delegate object --> <serviceTask id=\"task2\" camunda:delegateExpression=\"${myBean.createDelegate()}\" /> Conditions To use conditional sequence flows or conditional events, expression language is usually used. For conditional sequence flows, a conditionExpression element of a sequence flow has to be used. For conditional events, a condition element of a conditional event has to be used. Both are of the type tFormalExpression. The text content of the element is the expression to be evaluated. Within the expression, some special variables are available which enable access of the current context. To find more information about the available variables, please see the corresponding section. The following example shows usage of expression language as condition of a sequence flow: <sequenceFlow> <conditionExpression xsi:type=\"tFormalExpression\"> ${test == 'foo'} </conditionExpression> </sequenceFlow> For usage of expression language on conditional events, see the following example: <conditionalEventDefinition> <condition type=\"tFormalExpression\">${var1 == 1}</condition> </conditionalEventDefinition> inputOutput Parameters With the Camunda inputOutput extension element you can map an inputParameter or outputParameter with expression language. Inside the expression some special variables are available which enable the access of the current context. To find more information about the available variables please see the corresponding section. The following example shows an inputParameter which uses expression language to call a method of a bean. <serviceTask id=\"task\" camunda:class=\"org.cibseven.bpm.example.SumDelegate\"> <extensionElements> <camunda:inputOutput> <camunda:inputParameter name=\"x\"> ${myBean.calculateX()} </camunda:inputParameter> </camunda:inputOutput> </extensionElements> </serviceTask> External Task Error Handling For External Tasks it is possible to define camunda:errorEventDefinition elements which can be provided with a JUEL expression. The expression is evaluated on ExternalTaskService#complete and ExternalTaskService#handleFailure. If the expression evaluates to true, a BPMN error is thrown which can be caught by an Error Boundary Event. In the scope of an External Task, expressions have access to the ExternalTaskEntity object via the key externalTask which provides getter methods for errorMessage, errorDetails, workerId, retries and more. Examples: How to access the External Task object: <bpmn:serviceTask id=\"myExternalTaskId\" name=\"myExternalTask\" camunda:type=\"external\" camunda:topic=\"myTopic\"> <bpmn:extensionElements> <camunda:errorEventDefinition id=\"myErrorEventDefinition\" errorRef=\"myError\" expression=\"${externalTask.getWorkerId() == 'myWorkerId'}\" /> </bpmn:extensionElements> </bpmn:serviceTask> How to match an error message: <bpmn:serviceTask id=\"myExternalTaskId\" name=\"myExternalTask\" camunda:type=\"external\" camunda:topic=\"myTopic\"> <bpmn:extensionElements> <camunda:errorEventDefinition id=\"myErrorEventDefinition\" errorRef=\"myError\" expression=\"${externalTask.getErrorDetails().contains('myErrorMessage')}\" /> </bpmn:extensionElements> </bpmn:serviceTask> For further details on the functionality of error event definitions in the context of external tasks, consult the External Tasks Guide. Value Different BPMN and CMMN elements allow to specify their content or an attribute value by an expression. Please see the corresponding sections for BPMN and CMMN in the references for more detailed examples. Availability of Variables and Functions Inside Expression Language Process Variables All process variables of the current scope are directly available inside an expression. So a conditional sequence flow can directly check a variable value: <sequenceFlow> <conditionExpression xsi:type=\"tFormalExpression\"> ${test == 'start'} </conditionExpression> </sequenceFlow> Internal Context Variables Depending on the current execution context, special built-in context variables are available while evaluating expressions: Variable Java Type Context execution DelegateExecution Available in a BPMN execution context like a service task, execution listener or sequence flow. task DelegateTask Available in a task context like a task listener. externalTask ExternalTask Available during an external task context activity (e.g. in camunda:errorEventDefinition expressions). caseExecution DelegateCaseExecution Available in a CMMN execution context. authenticatedUserId String The id of the currently authenticated user. Only returns a value if the id of the currently authenticated user has been set through the corresponding methods of the IdentityService. Otherwise it returns null. The following example shows an expression which sets the variable test to the current event name of an execution listener. <camunda:executionListener event=\"start\" expression=\"${execution.setVariable('test', execution.eventName)}\" /> External Context Variables With Spring and CDI If the process engine is integrated with Spring or CDI, it is possible to access Spring and CDI beans inside of expressions. Please see the corresponding sections for Spring and CDI for more information. The following example shows the usage of a bean which implements the JavaDelegate interface as delegateExecution. <serviceTask id=\"task1\" camunda:delegateExpression=\"${myBean}\" /> With the expression attribute any method of a bean can be called. <serviceTask id=\"task2\" camunda:expression=\"${myBean.myMethod(execution)}\" /> Internal Context Functions Special built-in context functions are available while evaluating expressions: Function Return Type Description currentUser() String Returns the user id of the currently authenticated user or null no user is authenticated at the moment. currentUserGroups() List of Strings Returns a list of the group ids of the currently authenticated user or null if no user is authorized at the moment. now() Date Returns the current date as a Java Date object. dateTime() DateTime Returns a Joda-Time DateTime object of the current date. Please see the Joda-Time documentation for all available functions. The following example sets the due date of a user task to the date 3 days after the creation of the task. <userTask id=\"theTask\" name=\"Important task\" camunda:dueDate=\"${dateTime().plusDays(3).toDate()}\"/> Built-In Camunda Spin Functions If the Camunda Spin process engine plugin is activated, the Spin functions S, XML and JSON are also available inside of an expression. See the Data Formats section for a detailed explanation. <serviceTask id=\"task\" camunda:expression=\"${XML(xml).attr('test').value()}\" resultVariable=\"test\" />",
    "url": "/manual/latest/user-guide/process-engine/expression-language/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/external-tasks/index.html",
    "title": "External Tasks | docs.cibseven.org",
    "content": "The process engine supports two ways of executing service tasks: Internal Service tasks: Synchronous invocation of code deployed along with a process application External tasks: Providing a unit of work in a list that can be polled by workers The first option is used when code is implemented as Delegation Code or as a Script. By contrast, external (service) tasks work in a way that the process engine publishes a unit of work to a worker to fetch and complete. We refer to this as the external task pattern. Note that the above distinction does not say whether the actual “business logic” is implemented locally or as a remote service. The Java Delegate invoked by an internal service task may either implement the business logic itself or it may call out to a web/rest service, send a message to another system and so forth. The same is true for an external worker. The worker can implement the business logic directly or again delegate to a remote system. The External Task Pattern The flow of executing external tasks can be conceptually separated into three steps, as depicted in the following image: Process Engine: Creation of an external task instance External Worker: Fetch and lock external tasks External Worker & Process Engine: Complete external task instance When the process engine encounters a service task that is configured to be externally handled, it creates an external task instance and adds it to a list of external tasks (step 1). The task instance receives a topic that identifies the nature of the work to be performed. At a time in the future, an external worker may fetch and lock tasks for a specific set of topics (step 2). To prevent one task being fetched by multiple workers at the same time, a task has a timestamp-based lock that is set when the task is acquired. Only when the lock expires, another worker can fetch the task again. When an external worker has completed the desired work, it can signal the process engine to continue process execution after the service task (step 3). The User Task Analogy External tasks are conceptually very similar to user tasks. When first trying to understand the external task pattern, it can be helpful to think about it in analogy to user tasks: User tasks are created by the process engine and added to a task list. The process engine then waits for a human user to query the list, claim a task and then complete it. External tasks are similar: An external task is created and then added to a topic. An external application then queries the topic and locks the task. After the task is locked, the application can work on it and complete it. The essence of this pattern is that the entities performing the actual work are independent of the process engine and receive work items by polling the process engine’s API. This has the following benefits: Crossing System Boundaries: An external worker does not need to run in the same Java process, on the same machine, in the same cluster or even on the same continent as the process engine. All that is required is that it can access the process engine’s API (via REST or Java). Due to the polling pattern, the worker does not need to expose any interface for the process engine to access. Crossing Technology Boundaries: An external worker does not need to be implemented in Java. Instead, any technology can be used that is most suitable to perform a work item and that can be used to access the process engine’s API (via REST or Java). Specialized Workers: An external worker does not need to be a general purpose application. Each external task instance receives a topic name identifying the nature of the task to perform. Workers can poll tasks for only those topics that they can work on. Fine-Grained Scaling: If there is high load concentrated on service task processing, the number of external workers for the respective topics can be scaled out independently of the process engine. Independent Maintenance: Workers can be maintained independently of the process engine without breaking operations. For example, if a worker for a specific topic has a downtime (e.g., due to an update), there is no immediate impact on the process engine. Execution of external tasks for such workers degrades gracefully: They are stored in the external task list until the external worker resumes operation. Working with External Tasks To work with external tasks they have to be declared in the BPMN XML. At runtime, external task instances can be accessed via Java and REST API. The following explains the API concepts and focuses on the Java API. Often the REST API is more suitable in this context, especially when implementing workers running in different environments with different technologies. BPMN In the BPMN XML of a process definition, a service task can be declared to be performed by an external worker by using the attributes camunda:type and camunda:topic. For example, a service task Validate Address can be configured to provide an external task instance for the topic AddressValidation as follows: <serviceTask id=\"validateAddressTask\" name=\"Validate Address\" camunda:type=\"external\" camunda:topic=\"AddressValidation\" /> It is possible to define the topic name by using an expression instead of a constant value. In addition, other service-task-like elements such as send tasks, business rule tasks, and throwing message events can be implemented with the external task pattern. See the BPMN 2.0 implementation reference for details. Error Event Definitions External tasks allow for the definition of error events that throw a specified BPMN error. This can be done by adding a camunda:errorEventDefinition extension element to the task’s definition. Compared to the bpmn:errorEventDefinition, the camunda:errorEventDefinition elements accept an additional expression attribute which supports any JUEL expression. Within the expression, you have access to the ExternalTaskEntity object via the key externalTask which provides getter methods for errorMessage, errorDetails, workerId, retries and more. The expression is evaluated on invocations of ExternalTaskService#complete and ExternalTaskService#handleFailure. If the expression evaluates to true, the actual method execution is canceled and replaced by throwing the respective BPMN error. This error can be caught by an Error Boundary Event. This implies that the error event definition can be used in success and failure scenarios alike - even if the task was completed successfully, you can still decide to throw a BPMN error. <serviceTask id=\"validateAddressTask\" name=\"Validate Address\" camunda:type=\"external\" camunda:topic=\"AddressValidation\" > <extensionElements> <camunda:errorEventDefinition id=\"addressErrorDefinition\" errorRef=\"addressError\" expression=\"${externalTask.getErrorDetails().contains('address error found')}\" /> </extensionElements> </serviceTask> Further information on the functionality of error event definitions on external tasks can be found in the expression language user guide. Rest API See the REST API documentation for how the API operations can be accessed via HTTP. Long Polling to Fetch and Lock External Tasks Ordinary HTTP requests are immediately answered by the server, regardless of whether the requested information is available or not. This inevitably leads to a situation where the client has to perform multiple recurring requests until the information is available (polling). This approach can obviously be expensive in terms of resources. With the aid of long polling, a request is suspended by the server if no external tasks are available. As soon as new external tasks occur, the request is reactivated and the response is performed. The suspension is limited to a configurable period of time (timeout). Long polling significantly reduces the number of requests and enables using resources more efficiently on both the server and the client side. Please also see the REST API documentation. Unique Worker Request By default, multiple workers can use the same workerId. In order to ensure workerId uniqueness on server-side, the ‘Unique Worker Request’ flag can be activated. This configuration flag effects only long-polling requests and not ordinary ‘Fetch and Lock’ requests. If the ‘Unique Worker Request’ flag is activated, pending requests with the same workerId are cancelled when a new request is received. In order to enable the ‘Unique Worker Request’ flag, the engine-rest/WEB-INF/web.xml file included in the engine-rest artifact needs to be adjusted by setting the context parameter fetch-and-lock-unique-worker-request to true. Please consider the following configuration snippet: <!-- ... --> <context-param> <param-name>fetch-and-lock-unique-worker-request</param-name> <param-value>true</param-value> </context-param> <!-- ... --> Java API The entry point to the Java API for external tasks is the ExternalTaskService. It can be accessed via processEngine.getExternalTaskService(). The following is an example of an interaction which fetches 10 tasks, works on these tasks in a loop and for each task, either completes the task or marks it as failed. List<LockedExternalTask> tasks = externalTaskService.fetchAndLock(10, \"externalWorkerId\") .topic(\"AddressValidation\", 60L * 1000L) .execute(); for (LockedExternalTask task : tasks) { try { String topic = task.getTopicName(); // work on task for that topic ... // if the work is successful, mark the task as completed if(success) { externalTaskService.complete(task.getId(), variables); } else { // if the work was not successful, mark it as failed externalTaskService.handleFailure( task.getId(), \"externalWorkerId\", \"Address could not be validated: Address database not reachable\", 1, 10L * 60L * 1000L); } } catch(Exception e) { //... handle exception } } The following sections address the different interactions with the ExternalTaskService in greater detail. Fetching Tasks In order to implement a polling worker, a fetching operation can be executed by using the method ExternalTaskService#fetchAndLock. This method returns a fluent builder that allows to define a set of topics to fetch tasks for. Consider the following code snippet: List<LockedExternalTask> tasks = externalTaskService.fetchAndLock(10, \"externalWorkerId\") .topic(\"AddressValidation\", 60L * 1000L) .topic(\"ShipmentScheduling\", 120L * 1000L) .execute(); for (LockedExternalTask task : tasks) { String topic = task.getTopicName(); // work on task for that topic ... } This code fetches at most 10 tasks of the topics AddressValidation and ShipmentScheduling. The result tasks are locked exclusively for the worker with id externalWorkerId. Locking means that the task is reserved for this worker for a certain duration beginning with the time of fetching and prevents that another worker can fetch the same task while the lock is valid. If the lock expires and the task has not been completed meanwhile, a different worker can fetch it such that silently failing workers do not block execution indefinitely. The exact duration is given in the single topic fetch instructions: Tasks for AddressValidation are locked for 60 seconds (60L * 1000L milliseconds) while tasks for ShipmentScheduling are locked for 120 seconds (120L * 1000L milliseconds). The lock expiration duration should not be shorter than than the expected execution time. It should also not be too high if that implies a too long timeout until the task is retried in case the worker fails silently. Variables that are required to perform a task can be fetched along with the task. For example, assume that the AddressValidation task requires an address variable. Fetching tasks with this variable could look like: List<LockedExternalTask> tasks = externalTaskService.fetchAndLock(10, \"externalWorkerId\") .topic(\"AddressValidation\", 60L * 1000L).variables(\"address\") .execute(); for (LockedExternalTask task : tasks) { String topic = task.getTopicName(); String address = (String) task.getVariables().get(\"address\"); // work on task for that topic ... } The resulting tasks then contain the current values of the requested variable. Note that the variable values are the values that are visible in the scope hierarchy from the external task’s execution. See the chapter on Variable Scopes and Variable Visibility for details. In order to fetch all variables, call to variables() method should be omitted List<LockedExternalTask> tasks = externalTaskService.fetchAndLock(10, \"externalWorkerId\") .topic(\"AddressValidation\", 60L * 1000L) .execute(); for (LockedExternalTask task : tasks) { String topic = task.getTopicName(); String address = (String) task.getVariables().get(\"address\"); // work on task for that topic ... } In order to enable the deserialization of serialized variables values (typically variables that store custom Java objects), it is necessary to call enableCustomObjectDeserialization(). Otherwise an exception, that the object is not deserialized, is thrown once the serialized variable is retrieved from the variables map. List<LockedExternalTask> tasks = externalTaskService.fetchAndLock(10, \"externalWorkerId\") .topic(\"AddressValidation\", 60L * 1000L) .variables(\"address\") .enableCustomObjectDeserialization() .execute(); for (LockedExternalTask task : tasks) { String topic = task.getTopicName(); MyAddressClass address = (MyAddressClass) task.getVariables().get(\"address\"); // work on task for that topic ... } External Task Prioritization External task prioritization is similar to job prioritization. The same problem exists with starvation which should be considered. For further details, see the section on Job Prioritization. Configure the Process Engine for External Task Priorities This section explains how to enable and disable external task priorities in the configuration. There are two relevant configuration properties which can be set on the process engine configuration: producePrioritizedExternalTasks: Controls whether the process engine assigns priorities to external tasks. The default value is true. If priorities are not needed, the process engine configuration property producePrioritizedExternalTasks can be set to false. In this case, all external tasks receive a priority of 0. For details on how to specify external task priorities and how the process engine assigns them, see the following section on Specifying External Task Priorities. Specify External Task Priorities External task priorities can be specified in the BPMN model as well as overridden at runtime via API. Priorities in BPMN XML External task priorities can be assigned at the process or the activity level. To achieve this, the Camunda extension attribute camunda:taskPriority can be used. For specifying the priority, both constant values and expressions are supported. When using a constant value, the same priority is assigned to all instances of the process or activity. Expressions, on the other hand, allow assigning a different priority to each instance of the process or activity. Expression must evaluate to a number in the Java long range. The concrete value can be the result of a complex calculation and be based on user-provided data (resulting from a task form or other sources). Priorities at the Process Level When configuring external task priorities at the process instance level, the camunda:taskPriority attribute needs to be applied to the bpmn <process ...> element: <bpmn:process id=\"Process_1\" isExecutable=\"true\" camunda:taskPriority=\"8\"> ... </bpmn:process> The effect is that all external tasks inside the process inherit the same priority (unless it is overridden locally). The above example shows how a constant value can be used for setting the priority. This way the same priority is applied to all instances of the process. If different process instances need to be executed with different priorities, an expression can be used: <bpmn:process id=\"Process_1\" isExecutable=\"true\" camunda:taskPriority=\"${order.priority}\"> ... </bpmn:process> In the above example the priority is determined based on the property priority of the variable order. Priorities at the Service Task Level When configuring external task priorities at the service task level, the camunda:taskPriority attribute needs to be applied to the bpmn <serviceTask ...> element. The service task must be an external task with the attribute camunda:type=\"external\". ... <serviceTask id=\"externalTaskWithPrio\" camunda:type=\"external\" camunda:topic=\"externalTaskTopic\" camunda:taskPriority=\"8\"/> ... The effect is that the priority is set for the defined external task (overrides the process taskPriority). The above example shows how a constant value can be used for setting the priority. This way the same priority is applied to the external task in different instances of the process. If different process instances need to be executed with different external task priorities, an expression can be used: ... <serviceTask id=\"externalTaskWithPrio\" camunda:type=\"external\" camunda:topic=\"externalTaskTopic\" camunda:taskPriority=\"${order.priority}\"/> ... In the above example the priority is determined based on the property priority of the variable order. Fetch external task By priority To fetch external tasks based on their priority, the overloaded method ExternalTaskService#fetchAndLock with the parameter usePriority can be used. The method without the boolean parameter returns the external tasks arbitrarily. If the parameter is given, the returned external tasks are ordered descendingly. See the following example which regards the priority of the external tasks: List<LockedExternalTask> tasks = externalTaskService.fetchAndLock(10, \"externalWorkerId\", true) .topic(\"AddressValidation\", 60L * 1000L) .topic(\"ShipmentScheduling\", 120L * 1000L) .execute(); for (LockedExternalTask task : tasks) { String topic = task.getTopicName(); // work on task for that topic ... } By create time External tasks can also be fetched using their createTime in LIFO or FIFO order. This behavior allows clients to optimize their processing and avoid starvation in scenarios where the age of tasks and consumption are not aligned. Method ExternalTaskService#fetchAndLock() can be combined with the following methods to configure the ordering: asc() - Tasks will be sorted using ascending order. The first task (at zero index) will have the earliest time and the last will have the oldest. desc() - Tasks will be sorted using descending order. The first task (at zero index) will have the oldest time and the last will have the earliest. See the following example on fetching tasks by createTime descending : List<LockedExternalTask> tasks = externalTaskService.fetchAndLock() .workerId(\"worker\") .maxTasks(10) .orderByCreateTime().desc() .subscribe() .topic(\"AddressValidation\", 60L * 1000L) .topic(\"ShipmentScheduling\", 120L * 1000L) .execute(); for (LockedExternalTask task : tasks) { String topic = task.getTopicName(); // work on task for that topic ... } External tasks created with engine versions < 7.21.0 will not have the createTime attribute. When using fetch and lock by createTime on them the behavior depends on how your database handles sorting of null values. Multi-level sorting Multiple sorting criteria can be combined when fetching external tasks. For example passing true to the parameter usePriority and selecting an effective sorting value for createTime configuration leads to external tasks being sorted with priority descending first; when two tasks share the same priority, the selected createTime order will be used for sorting the results with priority equality. This is an example demonstration of the above example: Given the following indicative tasks: ExternalTask1 [priority=0, createTime=1] ExternalTask2 [priority=2, createTime=2] ExternalTask3 [priority=0, createTime=3] ExternalTask4 [priority=3, createTime=4] And invocation configuration with priority and createTime sorting: externalTaskService.fetchAndLock() .maxTasks(10) .workerId(\"worker\") .usePriority(true) .orderByCreateTime().desc(); The results would be returned in the following order: ExternalTask4 [priority=3, createTime=4] ExternalTask2 [priority=2, createTime=2] ExternalTask3 [priority=0, createTime=3] ExternalTask1 [priority=0, createTime=1] Note: The createTime field used in the example uses numbers for easing the visual demonstration. In real results, the createTime will be populated using a Date value. Priority will always take precedence over any other sorting property. Completing Tasks After fetching and performing the requested work, a worker can complete an external task by calling the ExternalTaskService#complete method. A worker can only complete tasks that it fetched and locked before. If the task has been locked by a different worker in the meantime, an exception is raised. Error Events External tasks can include error event definitions that can cancel the execution of #complete in case the error event’s expression evaluates to true. In case an error event’s expression evaluation raises an exception, the call to #complete will fail with that same exception. Extending of Locks on External Tasks When an external task is locked by a worker, the lock duration can be extended by calling the method ExternalTaskService#extendLock. A worker can specify the amount of time (in milliseconds) to update the timeout. A lock can only be extended by the worker who owns a lock on the given external task. Reporting Task Failure A worker may not always be able to complete a task successfully. In this case it can report a failure to the process engine by using ExternalTaskService#handleFailure. Like #complete, #handleFailure can only be invoked by the worker possessing the most recent lock for a task. The #handleFailure method takes four additional arguments: errorMessage,errorDetails, retries, retryTimeout. The error message can contain a description of the nature of the problem and is limited to 666 characters. It can be accessed when the task is fetched again or is queried for. The errorDetails can contain the full error description and are unlimited in length. Error details are accessible through the separate method ExternalTaskService#getExternalTaskErrorDetails, based on task id parameter. With retries and retryTimout, workers can specify a retry strategy. When setting retries to a value > 0, the task can be fetched again after retryTimeout expires. When setting retries to 0, a task can no longer be fetched and an incident is created for this task. Consider the following code snippet: List<LockedExternalTask> tasks = externalTaskService.fetchAndLock(10, \"externalWorkerId\") .topic(\"AddressValidation\", 60L * 1000L).variables(\"address\") .execute(); LockedExternalTask task = tasks.get(0); // ... processing the task fails externalTaskService.handleFailure( task.getId(), \"externalWorkerId\", \"Address could not be validated: Address database not reachable\", // errorMessage \"Super long error details\", // errorDetails 1, // retries 10L * 60L * 1000L); // retryTimeout // ... other activities externalTaskService.getExternalTaskErrorDetails(task.getId()); A failure is reported for the locked task such that it can be retried once more after 10 minutes. The process engine does not decrement retries itself. Instead, such a behavior can be implemented by setting the retries to task.getRetries() - 1 when reporting a failure. At the moment when error details are required, they are queried from the service using separate method. Error Events External tasks can include error event definitions that can cancel the execution of #handleFailure in case the error event’s expression evaluates to true. In case an error event’s expression evaluation raises an exception, this expression will be considered as evaluating to false. Reporting BPMN Error See the documentation for Error Boundary Events. For some reason a business error can appear during execution. In this case, the worker can report a BPMN error to the process engine by using ExternalTaskService#handleBpmnError. Like #complete or #handleFailure, it can only be invoked by the worker possessing the most recent lock for a task. The #handleBpmnError method takes one additional argument: errorCode. The error code identifies a predefined error. If the given errorCode does not exist or there is no boundary event defined, the current activity instance simply ends and the error is not handled. See the following example: List<LockedExternalTask> tasks = externalTaskService.fetchAndLock(10, \"externalWorkerId\") .topic(\"AddressValidation\", 60L * 1000L).variables(\"address\") .execute(); LockedExternalTask task = tasks.get(0); // ... business error appears externalTaskService.handleBpmnError( task.getId(), \"externalWorkerId\", \"bpmn-error\", // errorCode \"Thrown BPMN Error during...\", // errorMessage variables); A BPMN error with the error code bpmn-error is propagated. If a boundary event with this error code exists, the BPMN error will be caught and handled. The error message and variables are optional. They can provide additional information for the error. The variables will be passed to the execution if the BPMN error is caught. Querying Tasks A query for external tasks can be made via ExternalTaskService#createExternalTaskQuery. Contrary to #fetchAndLock, this is a reading query that does not set any locks. Managing Operations Additional management operations are ExternalTaskService#unlock, ExternalTaskService#setRetries and ExternalTaskService#setPriority to clear the current lock, to set the retries and to set the priority of an external task. Setting the retries is useful when a task has 0 retries left and must be resumed manually. With the last method the priority can be set to a higher value for more important or to a lower value for less important external tasks. There are also operations ExternalTaskService#setRetriesSync and ExternalTaskService#setRetriesAsync to set retries for multiple external tasks synchronously or asynchronously.",
    "url": "/manual/latest/user-guide/process-engine/external-tasks/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/history/custom-implementation/index.html",
    "title": "Custom implementation | docs.cibseven.org",
    "content": "Provide a custom history backend In order to understand how to provide a custom history backend, it is useful to first look at a more detailed view of the history architecture: Whenever the state of a runtime entity is changed, the core execution component of the process engine fires History Events. In order to make this flexible, the actual creation of the History Events as well as populating the history events with data from the runtime structures is delegated to the History Event Producer. The producer is handed in the runtime data structures (such as an ExecutionEntity or a TaskEntity), creates a new History Event and populates it with data extracted from the runtime structures. The event is next delivered to the History Event Handler which constitutes the History Backend. The drawing above contains a logical component named event transport. This is supposed to represent the channel between the process engine core component producing the events and the History Event Handler. In the default implementation, events are delivered to the History Event Handler synchronously and inside the same JVM. It is however conceptually possible to send the event stream to a different JVM (maybe running on a different machine) and making delivery asynchronous. A good fit might be a transactional message Queue (JMS). Once the event has reached the History Event Handler, it can be processed and stored in some kind of datastore. The default implementation writes events to the History Database so that they can be queried using the History Service. Exchanging the History Event Handler with a custom implementation allows users to plug in a custom History Backend. To do so, two main steps are required: Provide a custom implementation of the HistoryEventHandler interface. Wire the custom implementation in the process engine configuration. Composite History Handling Note that if you provide a custom implementation of the HistoryEventHandler and wire it to the process engine, you override the default DbHistoryEventHandler. The consequence is that the process engine will stop writing to the history database and you will not be able to use the history service for querying the audit log. If you do not want to replace the default behavior but only provide an additional event handler, you can use the class org.cibseven.bpm.engine.impl.history.handler.CompositeHistoryEventHandler that dispatches events to a collection of handlers. Spring Boot Note that providing your custom HistoryEventHandler in a Spring Boot Starter environment works slightly differently. By default, the CIB seven Spring Boot starter uses a CompositeHistoryEventHandler which wraps a list of HistoryEventHandler implementations that you can provide via the customHistoryEventHandlers engine configuration property. If you want to override the default DbHistoryEventHandler, you have to explicitly set the enableDefaultDbHistoryEventHandler engine configuration property to false. Implement a custom history level To provide a custom history level the interface org.cibseven.bpm.engine.impl.history.HistoryLevel has to be implemented. The custom history level implementation then has to be added to the process engine configuration, either by configuration or a process engine plugin. <?xml version=\"1.0\" encoding=\"UTF-8\"?> <beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"> <bean id=\"processEngineConfiguration\" class=\"org.cibseven.bpm.engine.impl.cfg.StandaloneInMemProcessEngineConfiguration\" > <property name=\"customHistoryLevels\"> <list> <bean class=\"org.cibseven.bpm.example.CustomHistoryLevel\" /> </list> </property> </bean> </beans> The custom history level has to provide a unique id and name for the new history level. public int getId() { return 42; } public String getName() { return \"custom-history\"; } If the history level is enabled, the method boolean isHistoryEventProduced(HistoryEventType eventType, Object entity) is called for every history event to determine if the event should be saved to the history. The event types used in the engine can be found in org.cibseven.bpm.engine.impl.history.event.HistoryEventTypes (see Javadocs). The second argument is the entity for which the event is triggered, e.g., a process instance, activity instance or variable instance. If the entity is null the engine tests if the history level in general handles such history events. If the method returns false, the engine will not generate any history events of this type again. This means that if your history level only wants to generate the history event for some instances of an event it must still return true if entity is null. Please have a look at this complete example to get a better overview. Removal time inheritance Historic instances inherit the removal time from the respective historic top-level instance. If the custom history level is configured in a way, so that the historic top-level instance is not written, the removal time is not available. The following historic instances are considered as top-level instances: Batch instance Root process instance Root decision instance User operation logs and custom history level The following implementation is required in order to enable User Operation Logs: public boolean isHistoryEventProduced(HistoryEventType eventType, Object entity) { if (eventType.equals(HistoryEventTypes.USER_OPERATION_LOG)){ return true; } ... }",
    "url": "/manual/latest/user-guide/process-engine/history/custom-implementation/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/history/history-cleanup/index.html",
    "title": "History cleanup | docs.cibseven.org",
    "content": "When used intensively, the process engine can produce a huge amount of historic data. History Cleanup is a feature that removes this data based on configurable time-to-live settings. It deletes: Historic process instances plus all related historic data (e.g., historic variable instances, historic task instances, historic instance permissions, all comments and attachments related to them, etc.) Historic decision instances plus all related historic data (i.e., historic decision input and output instances) Historic case instances plus all related historic data (e.g., historic variable instances, historic task instances, etc.) Historic batches plus all related historic data (historic incidents and job logs) History cleanup can be triggered manually or scheduled on a regular basis. Only camunda-admins have permissions to execute history cleanup manually. Use case example Assume we have a billing process for which we must keep the history trail for ten years for legal compliance reasons. Then we have a holiday application process for which history data is only relevant for a short time. In order to reduce the amount of data we have to store, we want to quickly remove holiday-related data. With history cleanup, we can assign the billing process a history time to live of ten years and the holiday process a history time to live of seven days. History cleanup then makes sure that history data is removed when the time to live has expired. This way, we can selectively keep history data based on its importance for our business. At the same time, we only keep what is necessary in the database. Note: The exact time at which data is removed depends on a couple of configuration settings, for example the selected history cleanup strategy. The underlying concepts and settings are explained in the following sections. Basic concepts Cleanable instances The following elements of Camunda history are cleanable: Process Instances Decision Instances Case Instances Batches Note that cleaning one such instance always removes all dependent history data along with it. For example, cleaning a process instance removes the historic process instance as well as all historic activity instances, historic task instances, etc. Note The history clean up job does not delete historic timer-start-event jobs. The reason being that the responsibility of timer-start-event job is to start a process instance, i.e. it does not belong to a process instance. History Time To Live (TTL) History Time To Live (TTL) defines how long historic data shall remain in the database before it is cleaned up. Process, Case and Decision Instances: TTL can be defined in the XML file of the corresponding definition. This value can furthermore be changed after deployment via Java and REST API. Batches: TTL can be defined in the process engine configuration. See the TTL configuration section for how to set TTL. Instance end time End Time is the time when an instance is no longer active. Process Instances: The time when the instance finishes. Decision Instances: The time when the decision is evaluated. Case Instances: The time when the instance completes. Batches: The time when the batch completes. The end time is persisted in the corresponding instance tables ACT_HI_PROCINST, ACT_HI_CASEINST, ACT_HI_DECINST and ACT_HI_BATCH. Instance removal time Removal Time is the time after which an instance shall be removed. It is computed as removal time = base time + TTL. Base time is configurable and can be either the start or the end time of an instance. In particular, this means: Process Instances: Base time is either the time when the process instance starts or the time at which it finishes. This is configurable. Decision Instances: Base time is the time when the decision is evaluated. Case Instances: The removal time concept is not implemented for case instances. Batches: Base time is either the time when the batch is created or when the batch is completed. This is configurable. For process and decision instances in a hierarchy (e.g. a process instance that is started by another process instance via a BPMN Call Activity), the removal time of all instances is always equal to the removal time of the root instance. The removal time is persisted in all history tables. So in case of a process instance, the removal time is present in ACT_HI_PROCINST as well as the corresponding secondary entries in ACT_HI_ACTINST, ACT_HI_TASKINST etc. See the Removal Time Strategy configuration section for how to configure if the removal time is based on the start or end time of an instance. Cleanup strategies In order to use history cleanup, you must decide for one of the two avialable history cleanup strategies: Removal-Time-based or End-Time-based strategy. The Removal-Time-based strategy is the default strategy and recommended in most scenarios. The following sections describe the strategies and their differences in detail. See the Cleanup Strategy configuration section for how to configure each of the strategies. Removal-time-based strategy The removal-time-based cleanup strategy deletes data for which the removal time has expired. Strengths: Since every history table has a removal time attribute, history cleanup can be done with simple DELETE FROM <TABLE> WHERE REMOVAL_TIME_ < <now> SQL statements. This is much more efficient than end-time-based cleanup. Since removal time is consistent for all instances in a hierarchy, a hierarchy is always cleaned up entirely once the removal time has expired. It cannot happen that instances are removed at different times. Limitations: Can only remove data for which a removal time is set. This is especially not the case for data which has been created with Camunda versions < 7.10.0. Changing the TTL of a definition only applies to history data that is created in the future. It does not dynamically update the removal time of already written history data. However, it is possible to Set a Removal Time via Batch Operations. History data of case instances is not cleaned up. End-time-based strategy The end-time-based cleanup strategy deletes data whose end time plus TTL has expired. In contrast to the removal-time strategy, this is computed whenever history cleanup is performed. Strengths: Changing the TTL of a definition also affects already written history data. Can remove data from any Camunda version. Limitations: End time is only stored in the instances tables (ACT_HI_PROCINST, ACT_HI_CASEINST, ACT_HI_DECINST and ACT_HI_BATCH). To delete data from all history tables, the cleanable instances are first fetched via a SELECT statement. Based on that, DELETE statements are made for each history table. These statements can involve joins. This is less efficient than removal-time-based history cleanup. Instance hierarchies are not cleaned up atomically. Since the individual instances have different end times, they are going to be cleaned up at different times. In consequence, hierarchies can appear partially removed. Historic Instance Permissions are not cleaned up. History Cleanup Jobs are not removed from the historic job log. Cleanup internals History cleanup is implemented via jobs and performed by the job executor. It therefore competes for execution resources with other jobs, e.g. triggering of BPMN timer events. Cleanup execution can be controlled in three ways: Cleanup Window: Determines a time frame in which history cleanup runs. This allows to use the job executor’s resources only when there is little load on your system (e.g. at night time or weekends). Default value: No cleanup window is defined. That means that history cleanup is not performed automatically. Batch Size: Determines how many instances are cleaned up in one cleanup transaction. Default: 500. Degree of Parallelism: Determines how many cleanup jobs can run in parallel. Default: 1 (no parallel execution). See the Cleanup configuration section for how to set each of these values. If there is no cleanable data left, the cleanup job performs exponential backoff between runs to reduce system load. This backoff is limited to a maximum of one hour. Backoff does not apply to manual cleanup runs. If cleanup fails, the job executor’s retry mechanism applies. Once the cleanup job has run out of retries, it is not executed again until one of the following actions is performed: History cleanup is triggered manually The process engine is restarted (this resets the number of job retries to the default value) The number of job retries is increased manually (e.g. via Java or REST API) The history cleanup jobs can be found via the API method HistoryService#findHistoryCleanupJobs. Configuration History Time To Live Required property The history time to live is mandatory, any deployment or re-deployment of any model resource (BPMN, DMN, CMMN) that contains a historyTimeToLive of null will be prevented. Unless explicitly disabled via process engine configuration. To define a default TTL for process definitions and decision definitions if no other value is defined check historyTimeToLive configuration. Process/decision/case definitions Process instances are only cleaned up if their corresponding definition has a valid time to live (TTL). Use the “historyTimeToLive” extension attribute of the process definition to define the TTL for all its instances: <process id=\"oneTaskProcess\" name=\"The One Task Process\" isExecutable=\"true\" camunda:historyTimeToLive=\"5\"> ... </process> TTL can also be defined in ISO-8601 date format. The function only accepts the notation to define the number of days. <process id=\"oneTaskProcess\" name=\"The One Task Process\" isExecutable=\"true\" camunda:historyTimeToLive=\"P5D\"> ... </process> Once deployed, TTL can be updated via Java API: processEngine.getRepositoryService().updateProcessDefinitionHistoryTimeToLive(processDefinitionId, 5); Setting the value to null clears the TTL. The same can be done via REST API. For decision and case definitions, TTL can be defined in a similar way. In case you want to provide an engine-wide default TTL for all process, decision and case definitions, use the “historyTimeToLive” attribute of the process engine configuration. This value is applied as the default whenever new definitions without TTL are deployed. Note that it therefore does not change the TTL of already deployed definitions. Use the API method given above to change TTL in this case. Batches TTL for batches can be defined via attribute of the process engine configuration. <!-- default setting for all batch operations --> <property name=\"batchOperationHistoryTimeToLive\">P5D</property> The batchOperationsForHistoryCleanup property can be configured in Spring based application or via custom Process Engine Plugins. It defines history time to live for each specific historic batch operation. <!-- specific TTL for each operation type --> <property name=\"batchOperationsForHistoryCleanup\"> <map> <entry key=\"instance-migration\" value=\"P10D\" /> <entry key=\"instance-modification\" value=\"P7D\" /> <entry key=\"instance-restart\" value=\"P1D\" /> <entry key=\"instance-deletion\" value=\"P1D\" /> <entry key=\"instance-update-suspension-state\" value=\"P20D\" /> <entry key=\"historic-instance-deletion\" value=\"P4D\" /> <entry key=\"set-job-retries\" value=\"P5D\" /> <entry key=\"set-external-task-retries\" value=\"P5D\" /> <entry key=\"process-set-removal-time\" value=\"P0D\" /> <entry key=\"decision-set-removal-time\" value=\"P0D\" /> <entry key=\"batch-set-removal-time\" value=\"P0D\" /> <entry key=\"set-variables\" value=\"P1D\" /> <entry key=\"correlate-message\" value=\"P2D\" /> <!-- in case of custom batch jobs --> <entry key=\"custom-operation\" value=\"P3D\" /> </map> </property> If the specific TTL is not set for a batch operation type, then the option batchOperationHistoryTimeToLive applies. Job logs A history cleanup is always performed by executing a history cleanup job. As with all other jobs, the history cleanup job will produce events that are logged in the historic job log. By default, those entries will stay in the log indefinitely and cleanup must be configured explicitly. Please note that this only works for the removal-time based history cleanup strategy. The historyCleanupJobLogTimeToLive property can be used to define a TTL for historic job log entries produced by history cleanup jobs. The property accepts values in the ISO-8601 date format. Note that only the notation to define a number of days is allowed. <property name=\"historyCleanupJobLogTimeToLive\">P5D</property> Task metrics The process engine reports runtime metrics to the database that can help draw conclusions about usage, load, and performance of the BPM platform. With every assignment of a user task, the related task worker is stored as a pseudonymized, fixed-length value in the ACT_RU_TASK_METER_LOG table together with a timestamp. Cleanup for this data needs to be configured explicitly if needed. The taskMetricsTimeToLive property can be used to define a TTL for task metrics entries produced by user task assignments. The property accepts values in the ISO-8601 date format. Note that only the notation to define a number of days is allowed. <property name=\"taskMetricsTimeToLive\">P540D</property> Cleanup window For automated history cleanup on a regular basis, a batch window must be configured - the period of time during the day when the cleanup is to run. Use the following engine configuration properties to define a batch window for every day of the week: <property name=\"historyCleanupBatchWindowStartTime\">20:00</property> <property name=\"historyCleanupBatchWindowEndTime\">06:00</property> Cleanup can also be scheduled individually for each day of the week (e.g. run cleanup only on weekends): <!-- default for all weekdays --> <property name=\"historyCleanupBatchWindowStartTime\">20:00</property> <property name=\"historyCleanupBatchWindowEndTime\">06:00</property> <!-- overriding batch window for saturday and sunday --> <property name=\"saturdayHistoryCleanupBatchWindowStartTime\">06:00</property> <property name=\"saturdayHistoryCleanupBatchWindowEndTime\">06:00</property> <property name=\"sundayHistoryCleanupBatchWindowStartTime\">06:00</property> <property name=\"sundayHistoryCleanupBatchWindowEndTime\">06:00</property> By default, no cleanup window is configured. In that case, history cleanup is not performed automatically. See the engine configuration reference for a complete list of all parameters. Cleanup strategy Removal-time-based or end-time-based cleanup can be selected as follows: <property name=\"historyCleanupStrategy\">removalTimeBased</property> Valid values are removalTimeBased and endTimeBased. removalTimeBased is the default. Removal-time strategy Removal time is defined per instance as removal time = base time + TTL. base time can be either the start or end time of the instance in case of process instances. This can be configured in the process engine configuration as follows: <property name=\"historyRemovalTimeStrategy\">end</property> Valid values are start, end and none. end is the default value and the recommended option. start is a bit more efficient when the process engine populates the history tables, because it does not have to make extra UPDATE statements when an instance finishes. Note:: With historyRemovalTimeStrategy set to start, it is possible to delete historic data of running process instances. When a process is started the removal time will be calculated (start+TTL) and will be set for all the activities of the process. As soon as removal time is reached data from historic tables gets cleaned up irrespective of whether the instance is running or completed. This may lead to the removal of the historic data before the process instance is finished resulting in no available history in Cockpit or history tables. A mitigation strategy is to choose a longer TTL value or set historyRemovalTimeStrategy to end. Heads-up! The calculation of the removal time can be enabled independently of the selected cleanup strategy of the process engine. This allows to perform a custom cleanup procedure outside the process engine by leveraging database capabilities (e.g. via table partitioning by removal time). Parallel execution The degree of parallel execution for history cleanup can be defined in the engine configuration as follows: <property name=\"historyCleanupDegreeOfParallelism\">4</property> Valid values are integers from 1 to 8. 1 is the default value. This property specifies the number of jobs used for history cleanup. In consequence, this value determines how many job executor threads and database connections may be busy with history cleanup at once. Choosing a high value can make cleanup faster, but may steal resources from other tasks the engine and database have to perform. Cleanup batch size The number of instances that are removed in one cleanup transaction can be set as follows: <property name=\"historyCleanupBatchSize\">100</property> The default (and maximum) value is 500. Reduce it if you notice transaction timeouts during history cleanup. Clustered cleanup In a multi-engine setup, you can configure whether a specific engine should participate in history cleanup or not. Please make sure that the same cleanup execution configuration (window, batch size, degree of parallelism) is present on all participating nodes. Cleanup execution participation per node Sometimes it is necessary to exclude some nodes in a multi-engine setup from performing history cleanup execution, e. g. to reduce the load on some nodes. You can disable the history cleanup execution for each node with the following flag: <property name=\"historyCleanupEnabled\">false</property> When you exclude a node from executing history cleanup, you don’t need to specify the configuration properties related to the cleanup execution since the particular node ignores them. Please Note: The history cleanup configuration properties that are unrelated to the cleanup execution (e.g., time to live, removal time strategy) still need to be defined among all nodes.",
    "url": "/manual/latest/user-guide/process-engine/history/history-cleanup/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/history/history-configuration/index.html",
    "title": "History configuration | docs.cibseven.org",
    "content": "Choose a history level The history level controls the amount of data the process engine provides via the history event stream. The following settings are available out of the box: NONE: no history events are fired. ACTIVITY: the following events are fired: Process Instance START, UPDATE, END, MIGRATE: fired as process instances are being started, updated, ended and migrated Case Instance CREATE, UPDATE, CLOSE: fired as case instances are being created, updated and closed Activity Instance START, UPDATE, END, MIGRATE: fired as activity instances are being started, updated, ended and migrated Case Activity Instance CREATE, UPDATE, END: fired as case activity instances are being created, updated and ended Task Instance CREATE, UPDATE, COMPLETE, DELETE, MIGRATE: fired as task instances are being created, updated (i.e., re-assigned, delegated etc.), completed, deleted and migrated. AUDIT: in addition to the events provided by history level ACTIVITY, the following events are fired: Variable Instance CREATE, UPDATE, DELETE, MIGRATE: fired as process variables are created, updated, deleted and migrated. The default history backend (DbHistoryEventHandler) writes variable instance events to the historic variable instance database table. Rows in this table are updated as variable instances are updated, meaning that only the last value of a process variable will be available. FULL: in addition to the events provided by history level AUDIT, the following events are fired: Form property UPDATE: fired as form properties are being created and/or updated. The default history backend (DbHistoryEventHandler) writes historic variable updates to the database. This makes it possible to inspect the intermediate values of a process variable using the history service. User Operation Log UPDATE: fired when a user performs an operation like claiming a user task, delegating a user task etc. Incidents CREATE, DELETE, RESOLVE, MIGRATE: fired as incidents are being created, deleted, resolved and migrated Historic Job Log CREATE, FAILED, SUCCESSFUL, DELETED: fired as a job is being created, a job execution failed or was successful or a job was deleted Decision Instance EVALUATE: fired when a decision is evaluated by the DMN engine. Batch START, END: fired as batches are being started and ended Identity links ADD, DELETE: fired when an identity link is being added, deleted or when an assignee of a user task is set or changed and when the owner of a user task is set or changed. Historic External Task Log CREATED, DELETED, FAILED, SUCCESSFUL: fired as an external task has been created, deleted or an external task execution has been reported to fail or succeed. AUTO: The level auto is useful if you are planning to run multiple engines on the same database. In that case, all engines have to use the same history level. Instead of manually keeping your configurations in sync, use the level auto and the engine determines the level already configured in the database automatically. If none is found, the default value audit is used. Keep in mind: If you are planning to use custom history levels, you have to register the custom levels for every configuration, otherwise an exception is thrown. If you need to customize the amount of history events logged, you can provide a custom implementation HistoryEventProducer and wire it in the process engine configuration. In case of specific needs, you can also create a custom history level. Set the history level The history level can be provided as a property in the process engine configuration. Depending on how the process engine is configured, the property can be set using Java code: ProcessEngine processEngine = ProcessEngineConfiguration .createProcessEngineConfigurationFromResourceDefault() .setHistory(ProcessEngineConfiguration.HISTORY_FULL) .buildProcessEngine(); It can also be set using Spring XML or a deployment descriptor (bpm-platform.xml, processes.xml). When using the Camunda Wildfly Subsystem, the property can be set through Wildfly configuration (standalone.xml, domain.xml). <property name=\"history\">audit</property> Note that when using the default history backend, the history level is stored in the database and cannot be changed later. History levels and Cockpit Camunda Cockpit web application works best with History Level set to FULL. “Lower” History Levels will disable certain history-related features. Default history implementation The default history database writes History Events to the appropriate database tables. The database tables can then be queried using the HistoryService or using the REST API. History entities There are the following History entities, which - in contrast to the runtime data - will also remain present in the DB after process and case instances have been completed: HistoricProcessInstances containing information about current and past process instances. HistoricVariableInstances containing information about the latest state a variable held in a process instance. HistoricCaseInstances containing information about current and past case instances. HistoricActivityInstances containing information about a single execution of an activity. HistoricCaseActivityInstances containing information about a single execution of a case activity. HistoricTaskInstances containing information about current and past (completed and deleted) task instances. HistoricDetails containing various kinds of information related to either a historic process instances, an activity instance or a task instance. HistoricIncidents containing information about current and past (i.e., deleted or resolved) incidents. UserOperationLogEntry log entry containing information about an operation performed by a user. This is used for logging actions such as creating a new task, completing a task, etc. HistoricJobLog containing information about the job execution. The log provides details about the lifecycle of a job. HistoricDecisionInstance containing information about a single evaluation of a decision, including the input and output values. HistoricBatch containing information about current and past batches. HistoricIdentityLinkLog containing information about current and past (added, deleted, assignee is set or changed and owner is set or changed) identity links. HistoricExternalTaskLog containing information about the external log. The log provides details about the lifecycle of an external task. State of HistoricProcessInstances For every process instance process engine will create single record in history database and will keep updating this record during process execution. Every HistoricProcessInstance record can get one of the following states assigned: ACTIVE - running process instance SUSPENDED - suspended process instances COMPLETED - completed through normal end event EXTERNALLY_TERMINATED - terminated externally, for instance through REST API INTERNALLY_TERMINATED - terminated internally, for instance by terminating boundary event Among them following states can be triggered externally, for example through REST API or Cockpit: ACTIVE, SUSPENDED, EXTERNALLY_TERMINATED. Query history The HistoryService exposes the methods createHistoricProcessInstanceQuery(), createHistoricVariableInstanceQuery(), createHistoricCaseInstanceQuery(), createHistoricActivityInstanceQuery(), createHistoricCaseActivityInstanceQuery(), createHistoricDetailQuery(), createHistoricTaskInstanceQuery(), createHistoricIncidentQuery(), createUserOperationLogQuery(), createHistoricJobLogQuery(), createHistoricDecisionInstanceQuery(), createHistoricBatchQuery(), createHistoricExternalTaskLogQuery and createHistoricIdentityLinkLogQuery() which can be used for querying history. Below are a few examples which show some of the possibilities of the query API for history. Full description of the possibilities can be found in the Javadocs, in the org.cibseven.bpm.engine.history package. HistoricProcessInstanceQuery Get the ten HistoricProcessInstances that are finished and that took the most time to complete (the longest duration) of all finished processes with definition ‘XXX’. historyService.createHistoricProcessInstanceQuery() .finished() .processDefinitionId(\"XXX\") .orderByProcessInstanceDuration().desc() .listPage(0, 10); HistoricCaseInstanceQuery Get the ten HistoricCaseInstances that are closed and that took the most time to be closed (the longest duration) of all closed cases with definition ‘XXX’. historyService.createHistoricCaseInstanceQuery() .closed() .caseDefinitionId(\"XXX\") .orderByCaseInstanceDuration().desc() .listPage(0, 10); HistoricActivityInstanceQuery Get the last HistoricActivityInstance of type ‘serviceTask’ that has been finished in any process that uses the processDefinition with id ‘XXX’. historyService.createHistoricActivityInstanceQuery() .activityType(\"serviceTask\") .processDefinitionId(\"XXX\") .finished() .orderByHistoricActivityInstanceEndTime().desc() .listPage(0, 1); HistoricCaseActivityInstanceQuery Get the last HistoricCaseActivityInstance that has been finished in any case that uses the caseDefinition with id ‘XXX’. historyService.createHistoricCaseActivityInstanceQuery() .caseDefinitionId(\"XXX\") .finished() .orderByHistoricCaseActivityInstanceEndTime().desc() .listPage(0, 1); HistoricVariableInstanceQuery Get all HistoricVariableInstances from a finished process instance with id ‘XXX’, ordered by variable name. historyService.createHistoricVariableInstanceQuery() .processInstanceId(\"XXX\") .orderByVariableName().desc() .list(); HistoricDetailQuery The next example gets all variable-updates that have been done in process with id ‘123’. Only HistoricVariableUpdates will be returned by this query. Note that it’s possible for a certain variable name to have multiple HistoricVariableUpdate entries, one for each time the variable was updated in the process. You can use orderByTime (the time the variable update was done) or orderByVariableRevision (revision of runtime variable at the time of updating) to find out in what order they occurred. historyService.createHistoricDetailQuery() .variableUpdates() .processInstanceId(\"123\") .orderByVariableName().asc() .list() The next example gets all variable updates that were performed on the task with id ‘123’. This returns all HistoricVariableUpdates for variables that were set on the task (task local variables), and NOT on the process instance. historyService.createHistoricDetailQuery() .variableUpdates() .taskId(\"123\") .orderByVariableName().asc() .list() HistoricTaskInstanceQuery Get the ten HistoricTaskInstances that are finished and that took the most time to complete (the longest duration) of all tasks. historyService.createHistoricTaskInstanceQuery() .finished() .orderByHistoricTaskInstanceDuration().desc() .listPage(0, 10); Get HistoricTaskInstances that are deleted with a delete reason that contains ‘invalid’ and that were last assigned to user ‘jonny’. historyService.createHistoricTaskInstanceQuery() .finished() .taskDeleteReasonLike(\"%invalid%\") .taskAssignee(\"jonny\") .listPage(0, 10); HistoricIncidentQuery Query for all resolved incidents: historyService.createHistoricIncidentQuery() .resolved() .list(); UserOperationLogQuery Query for all operations performed by user ‘jonny’: historyService.createUserOperationLogQuery() .userId(\"jonny\") .listPage(0, 10); HistoricJobLogQuery Query for successful historic job logs: historyService.createHistoricJobLogQuery() .successLog() .list(); HistoricDecisionInstanceQuery Get all HistoricDecisionInstances from a decision with key ‘checkOrder’ ordered by the time when the decision was evaluated. historyService.createHistoricDecisionInstanceQuery() .decisionDefinitionKey(\"checkOrder\") .orderByEvaluationTime() .asc() .list(); Get all HistoricDecisionInstances from decisions that were evaluated during the execution of the process instance with id ‘XXX’. The HistoricDecisionInstances contains the input values on which the decision was evaluated and the output values of the matched rules. historyService.createHistoricDecisionInstanceQuery() .processInstanceId(\"XXX\") .includeInputs() .includeOutputs() .list(); HistoricBatchQuery Get all historic process instance migration batches ordered by id. historyService.createHistoricBatchQuery() .type(Batch.TYPE_PROCESS_INSTANCE_MIGRATION) .orderById().desc() .list(); HistoricIdentityLinkLogQuery Query for all identity links that are related to the user ‘demo’. historyService.createHistoricIdentityLinkLogQuery() .userId(\"demo\") .list(); HistoricExternalTaskLogQuery Query for failed historic external task logs: historyService.createHistoricExternalTaskLogQuery() .failureLog() .list(); History report You can use the reports section to retrieve custom statistics and reports. Currently, we support the following kinds of reports: Instance Duration Report Task Report Finished Instance Report Instance duration report Retrieves a report about the duration of completed process instances, grouped by a specified period. These reports include the maximum, minimum and average duration of all completed process instances, which were started in the specified period. The following code snippet retrieves a report for every month since the engine was started: historyService .createHistoricProcessInstanceReport() .duration(PeriodUnit.MONTH); The supported periods so far are MONTH and QUARTER from org.cibseven.bpm.engine.query.PeriodUnit. To narrow down the report query, one can use the following methods from HistoricProcessInstanceReport: startedBefore: Only takes historic process instances into account that were started before a given date. startedAfter: Only takes historic process instances into account that were started after a given date. processDefinitionIdIn: Only takes historic process instances into account for given process definition ids. processDefinitionKeyIn: Only takes historic process instances into account for given process definition keys. where startedBefore and startedAfter use java.util.Date (deprecated) or java.util.Calendar objects for the input. For instance, one could query for all historic process instances which were started before now and get their duration: Calendar calendar = Calendar.getInstance(); historyService.createHistoricProcessInstanceReport() .startedBefore(calendar.getTime()) .duration(PeriodUnit.MONTH); Task report Retrieves a report of completed tasks. For the task report there are two possible report types: count and duration. If you use the method countByProcessDefinitionKey or countByTaskName in the end of your report query, the report contains a list of completed task counts where an entry contains the task name, the definition key of the task, the process definition id, the process definition key, the process definition name and the count of how many tasks were completed for the specified key in a given period. The methods countByProcessDefinitionKey and countByTaskName then group the count reports according the criterion ‘definition key’ or ’task name’. To retrieve a task count report grouped by the task name, one could execute the following query: historyService .createHistoricTaskInstanceReport() .countByTaskName(); If the report type is set to duration, the report contains a minimum, maximum and average duration value of all completed task instances in a given period. historyService .createHistoricTaskInstanceReport() .duration(PeriodUnit.MONTH); The supported period times and the confinement of the query works analogously to Instance Duration Report. Finished instance report Retrieves a report of finished process, decision or case instances. The report helps the user to tune the history time to live for definitions. They can see a summary of the historic data which can be cleaned after history cleanup. The output fields are definition id, key, name, version, count of the finished instances and count of the ‘cleanable’ instances. historyService .createHistoricFinishedProcessInstanceReport() .list(); historyService .createHistoricFinishedDecisionInstanceReport() .list(); historyService .createHistoricFinishedCaseInstanceReport() .list(); Partially sorting history events by their occurrence Sometimes you want to sort history events in the order in which they occurred. Please note that timestamps cannot be used for that. Most history events contain a timestamp which marks the point in time at which the action signified by the event occurred. However, this timestamp can, in general, not be used for sorting the history events. The reason is that the process engine can be run on multiple cluster nodes: on a single machine, the clock may change due to network sync at runtime, in a cluster, events happening in a single process instance may be generated on different nodes among which the clock may not be synced accurately down to nanoseconds. To work around this, the CIB seven engine generates sequence numbers which can be used to partially sort history events by their occurrence. At a BPMN level this means that instances of concurrent activities (example: activities on different parallel branches after a parallel gateway) cannot be compared to each other. Instances of activities that are part of happens-before relation at the BPMN level will be ordered in respect to that relation. Example: List<HistoricActivityInstance> result = historyService .createHistoricActivityInstanceQuery() .processInstanceId(\"someProcessInstanceId\") .orderPartiallyByOccurrence() .asc() .list(); Please note the returned list of historic activity instances in the example is only partially sorted, as explained above. It guarantees that related activity instances are sorted by their occurrence. The ordering of unrelated activity instances is arbitrary and is not guaranteed.",
    "url": "/manual/latest/user-guide/process-engine/history/history-configuration/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/history/index.html",
    "title": "History | docs.cibseven.org",
    "content": "The History Event Stream provides audit information about executed process instances. The process engine maintains the state of running process instances inside the database. This includes writing (1.) the state of a process instance to the database as it reaches a wait state and reading (2.) the state as process execution continues. We call this database the runtime database. In addition to maintaining the runtime state, the process engine creates an audit log providing audit information about executed process instances. We call this event stream the history event stream (3.). The individual events which make up this event stream are called History Events and contain data about executed process instances, activity instances, changed process variables and so forth. In the default configuration, the process engine will simply write (4.) this event stream to the history database. The HistoryService API allows querying this database (5.). The history database and the history service are optional components; if the history event stream is not logged to the history database or if the user chooses to log events to a different database, the process engine is still able to work and it is still able to populate the history event stream. This is possible because the BPMN 2.0 Core Engine component does not read state from the history database. It is also possible to configure the amount of data logged, using the historyLevel setting in the process engine configuration. Since the process engine does not rely on the presence of the history database for generating the history event stream, it is possible to provide different backends for storing the history event stream. The default backend is the DbHistoryEventHandler which logs the event stream to the history database. It is possible to exchange the backend and provide a custom storage mechanism for the history event log.",
    "url": "/manual/latest/user-guide/process-engine/history/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/history/user-operation-log/index.html",
    "title": "User operation log | docs.cibseven.org",
    "content": "The user operation log contains entries for many API operations and can be used for auditing purposes. It provides data on what kind of operations are performed as well as details on the changes involved in the operation. Operations are logged when the operation is performed in the context of a logged in user. To use the operation log, the process engine history level must be set to FULL. Write log entries regardless of user authentication context If it is desired that operations are logged regardless whether they are performed in the context of a logged in user or not, then the process engine configuration flag named restrictUserOperationLogToAuthenticatedUsers can be set to false. Access the user operation log The user operation log can be accessed via the Java API. The history service can be used to execute a UserOperationLogQuery by calling historyService.createUserOperationLogQuery().execute(). The query can be restricted with various filtering options. The query is also exposed in the REST API. User operation log entries The log consists of operations and entries. An operation corresponds to one performed action and consists of multiple entries, at least one. Entries contain the detailed changes being part of the operation. When making a user operation log query, the returned entities are of type UserOperationLogEntry, corresponding to entries. All entries of one operation are linked by an operation id. A user operation log entry has the following properties: Operation ID: A generated id that uniquely identifies a performed operation. Multiple log entries that are part of one operation reference the same operation ID. Operation Type: The name of the performed operation. Available operation types are listed in the interface org.cibseven.bpm.engine.history.UserOperationLogEntry . Note that one operation can consist of multiple types, for example a cascading API operation is one user operation, but is split into multiple types of operations. Entity Type: An identifier of the type of the entity that was addressed by the operation. Available entity types are listed in the class org.cibseven.bpm.engine.EntityTypes . Like the operation type, one operation may address more than one type of entity. Category: The name of the category the operation is associated with. Available categories are listed in the interface org.cibseven.bpm.engine.history.UserOperationLogEntry . For example, all task related runtime operations like claiming and completing tasks fall into the category TaskWorker . Annotation: An arbitrary text annotation set by a user for auditing reasons. Multiple log entries that belong to an operation have the same annotation. Entity IDs: A job log entry contains the entity IDs that serve to identify the entities addressed by the operation. For example, an operation log entry on a task contains the id of the task as well as the id of the process instance the task belongs to. As a second example, a log entry for suspending all process instances of a process definition does not contain individual process instance IDs but only the process definition ID. User ID: The ID of the user who performed the operation. Timestamp: The time at which the operation was performed. Changed Property: A user operation may change multiple properties. For example, suspension of a process instance changes the suspension state property. A log entry is created for each changed property involved in an operation. Old Property Value: The previous value of the changed property. A null value either indicates that the property was previously null or is not known. New Property Value: The new value of the changed property. Annotation of user operation logs User Operation Logs are helpful to audit manual operations. To make it obvious why a certain operation was performed, sometimes it is not enough to only log technical information (e. g. timestamp, operation type, etc.) but also add an annotation that puts the operation in the right business context. You can directly pass an annotation for the following operations: Process Instance Modification You can also set an annotation to an operation log which is already present: An annotation can be set and cleared via Java API: String operationId = historyService.createUserOperationLogQuery() .singleResult() .getOperationId(); String annotation = \"Instances restarted due to wrong turn\"; historyService.setAnnotationForOperationLogById(operationId, annotation); historyService.clearAnnotationForOperationLogById(operationId); Please note: Annotations are present on all entries that belong to an operation log. Please also see the REST API reference for setting and clearing annotations. Glossary of operations logged in the user operation log The following describes the operations logged in the user operation log and the entries that are created as part of it: Entity Type Operation Type Category Properties Task Assign TaskWorker assignee: The id of the user who was assigned to the task Claim TaskWorker assignee: The id of the user who claimed the task Complete TaskWorker delete: The new delete state, true Create TaskWorker No additional property is logged Delegate TaskWorker When delegating a task, three log entries are created, containing one of the following properties: delegation: The resulting delegation state, PENDING owner: The original owner of the task assignee: The user this task has been assigned to Delete TaskWorker delete: The new delete state, true Resolve TaskWorker delegation: The resulting delegation state, RESOLVED SetOwner TaskWorker owner: The new owner of the task SetPriority TaskWorker priority: The new priority of the task Update TaskWorker The manually changed property of a task, where manually means that a property got directly changed. Claiming a task via the TaskService wouldn't be logged with an update entry, but setting the assignee directly would be. One of the following is possible: description: The new description of the task owner: The new owner of the task assignee: The new assignee to the task dueDate: The new due date of the task DeleteHistory Operator nrOfInstances: the amount of decision instances that were deleted async: by default false since the operation can only be performed synchronously ProcessInstance Create Operator No additional property is logged Activate Operator suspensionState: The new suspension state, active Delete Operator In case of regular operation: No additional property is logged In case of batch operation: nrOfInstances: the amount of process instances that were deleted async: true if operation was performed asynchronously as a batch, false if operation was performed synchronously deleteReason: the reason for deletion type: history in case of deletion of historic process instances ModifyProcessInstance Operator nrOfInstances: The amount of process instances modified async: true if modification was performed asynchronously as a batch, false if modification was performed synchronously processDefinitionVersion: The version of the process definition Suspend Operator suspensionState: The new suspension state, suspended Migrate Operator processDefinitionId: The id of the process definition that instances are migrated to nrOfInstances: The amount of process instances migrated nrOfVariables: The amount of set variables. Only present when variables were set async: true if migration was performed asynchronously as a batch, false if migration was performed synchronously RestartProcessInstance Operator nrOfInstances: The amount of process instances restarted async: true if restart was performed asynchronously as a batch, false if restart was performed synchronously DeleteHistory Operator nrOfInstances: the amount of process instances that were deleted async: true if operation was performed asynchronously as a batch, false if operation was performed synchronously deleteReason: the reason for deletion. This property exists only if the operation was performed asynchronously CreateIncident Operator incidentType: The type of incident that was created configuration: The configuration of the incident that was created Resolve Operator incidentId: The id of the incident that was resolved SetRemovalTime Operator async: true if operation was performed asynchronously as a batch nrOfInstances: The amount of updated instances removalTime: The date of which an instance shall be removed mode: CALCULATED_REMOVAL_TIME if the removal time was calculated, ABSOLUTE_REMOVAL_TIME if the removal time was set explicitly, CLEARED_REMOVAL_TIME if the removal time was cleared hierarchical: true if the removal time was set across the hiearchy, false if the hierarchy was neglected SetVariables Operator async: true if operation was performed asynchronously as a batch nrOfInstances: The amount of affected instances nrOfVariables: The amount of set variables CorrelateMessage Operator async: true if operation was performed asynchronously as a batch nrOfInstances: The amount of affected instances nrOfVariables: The amount of set variables messageName: The name of the correlated message Incident SetAnnotation Operator incidentId: the id of the annotated incident ClearAnnotation Operator incidentId: the id of the annotated incident IdentityLink AddUserLink TaskWorker candidate: The new candidate user associated DeleteUserLink TaskWorker candidate: The previously associated user AddGroupLink TaskWorker candidate: The new group associated DeleteGroupLink TaskWorker candidate: The previously associated group Attachment AddAttachment TaskWorker name: The name of the added attachment DeleteAttachment TaskWorker name: The name of the deleted attachment JobDefinition ActivateJobDefinition Operator suspensionState: the new suspension state active SetPriority Operator overridingPriority: the new overriding job priority. Is null, if the priority was cleared. SuspendJobDefinition Operator suspensionState: the new suspension state suspended ProcessDefinition ActivateProcessDefinition Operator suspensionState: the new suspension state active SuspendProcessDefinition Operator suspensionState: the new suspension state suspended Delete Operator cascade: if the value is set to true, then all instances including history are also deleted. UpdateHistoryTimeToLive Operator historyTimeToLive: the new history time to live. DecisionDefinition UpdateHistoryTimeToLive Operator historyTimeToLive: the new history time to live. decisionDefinitionId: the id of the decision definition whose history time to live is updated. decisionDefinitionKey: the key of the decision definition whose history time to live is updated. Evaluate Operator decisionDefinitionId: the id of the decision definition that was evaluated. decisionDefinitionKey: the key of the decision definition that was evaluated. CaseDefinition UpdateHistoryTimeToLive Operator historyTimeToLive: the new history time to live. caseDefinitionKey: the key of the case definition whose history time to live is updated. Job ActivateJob Operator suspensionState: the new suspension state active SetPriority Operator priority: the new priority of the job SetJobRetries Operator retries: the new number of retries nrOfInstances: the number of jobs that were updated. async: true if operation was performed asynchronously as a batch, false if operation was performed synchronously SuspendJob Operator suspensionState: the new suspension state suspended async: true if operation was performed asynchronously as a batch, false if operation was performed synchronously Execute Operator No additional property is logged Delete Operator No additional property is logged SetDueDate Operator duedate: the new due date of the job RecalculateDueDate Operator creationDateBased: if the value is set to true, the new due date was calculated based on the creation date of the job. Otherwise, it was calculated using the date the recalcuation took place. duedate: the new due date of the job CreateHistoryCleanupJobs Operator immediatelyDue: true if the operation was performed immediately, false if the operation was scheduled regularly Variable ModifyVariable Operator/TaskWorker No additional property is logged RemoveVariable Operator/TaskWorker No additional property is logged SetVariable Operator/TaskWorker No additional property is logged DeleteHistory Operator In case of single operation: name: the name of the variable whose history was deleted In case of list operation by process instance: No additional property is logged Deployment Create Operator duplicateFilterEnabled: if the value is set to true, then during the creation of the deployment the given resources have been checked for duplicates in the set of previous deployments. Otherwise, the duplicate filtering has been not executed. deployChangedOnly: this property is only logged when duplicateFilterEnabled is set to true. If the property value is set to true then only changed resources have been deployed. Otherwise, all resources are redeployed if any resource has changed. Delete Operator cascade: if the value is set to true, then all instances including history are also deleted. Batch ActivateBatch Operator suspensionState: the new suspension state active SuspendBatch Operator suspensionState: the new suspension state suspended Delete Operator cascadeToHistory: true if historic data related to the batch job is deleted as well, false if only the runtime data is deleted. DeleteHistory Operator No additional property is logged SetRemovalTime Operator async: true if operation was performed asynchronously as a batch nrOfInstances: The amount of updated instances removalTime: The date of which an instance shall be removed mode: CALCULATED_REMOVAL_TIME if the removal time was calculated, ABSOLUTE_REMOVAL_TIME if the removal time was set explicitly, CLEARED_REMOVAL_TIME if the removal time was cleared ExternalTask SetExternalTaskRetries Operator retries: the new number of retries nrOfInstances: the amount of external tasks that were updated async: true if operation was performed asynchronously as a batch, false if operation was performed synchronously SetPriority Operator priority: the new priority Unlock Operator No additional property is logged DecisionInstance DeleteHistory Operator nrOfInstances: the amount of decision instances that were deleted async: true if operation was performed asynchronously as a batch, false if operation was performed synchronously deleteReason: the reason for deletion. This property exists only if operation was performed asynchronously SetRemovalTime Operator async: true if operation was performed asynchronously as a batch nrOfInstances: The amount of updated instances removalTime: The date of which an instance shall be removed mode: CALCULATED_REMOVAL_TIME if the removal time was calculated, ABSOLUTE_REMOVAL_TIME if the removal time was set explicitly, CLEARED_REMOVAL_TIME if the removal time was cleared hierarchical: true if the removal time was set across the hiearchy, false if the hierarchy was neglected CaseInstance DeleteHistory Operator nrOfInstances: The amount of case instances that were deleted. Only present if executed in bulk delete. Metrics Delete Operator timestamp: The date for which all metrics older than that have been deleted. Only present if specified by the user. reporter: The reporter for which all metrics reported by it have been deleted. Only present if specified by the user. TaskMetrics Delete Operator timestamp: The date for which all task metrics older than that have been deleted. Only present if specified by the user. OperationLog SetAnnotation Operator operationId: the id of the annotated operation log ClearAnnotation Operator operationId: the id of the annotated operation log Filter Create TaskWorker filterId: the id of the filter that been created Update TaskWorker filterId: the id of the filter that been updated Delete TaskWorker filterId: the id of the filter that been deleted User Create Admin userId: the id of the user that has been created Update Admin userId: the id of the user that has been updated Delete Admin userId: the id of the user that has been deleted Unlock Admin userId: the id of the user that has been unlocked Group Create Admin groupId: the id of the group that has been created Update Admin groupId: the id of the group that has been updated Delete Admin groupId: the id of the group that has been deleted Tenant Create Admin tenantId: the id of the tenant that has been created Update Admin tenantId: the id of the tenant that has been updated Delete Admin tenantId: the id of the tenant that has been deleted Group membership Create Admin userId: the id of the user that has been added to the group groupId: the id of the group that the user has been added to Delete Admin userId: the id of the user that has been deleted from the group groupId: the id of the group that the user has been deleted from TenantMembership Create Admin tenantId: the id of the tenant that the group or user was associated with userId: the id of the user that has been associated with the tenant. Is not present if the groupId is set groupId: the id of the group that has been associated with the tenant. Is not present if the userId is set Delete Admin tenantId: the id of the tenant that the group or user has been deleted from userId: the id of the user that has been deleted from the tenant. Is not present if the groupId is set groupId: the id of the group that has been deleted from the tenant. Is not present if the userId is set Authorization Create Admin permissions: the list of permissions that has been granted or revoked permissionBits: the permissions bit mask that is persisted with the authorization type: the type of authorization, can be either 0 (GLOBAL), 1 (GRANT) or 2 (REVOKE) resource: the name of the resource type resourceId: The id of the resource. Can be '*' if granted or revoked for all instances of the resource type. userId: The id of the user the authorization is bound to. Can be '*' if granted or revoked for all users. Is not present when groupId is set. groupId: The id of the group the authorization is bound to. Is not present when userId is set. Update Admin permissions: the list of permissions that has been granted or revoked permissionBits: the permissions bit mask that is persisted with the authorization type: the type of authorization, can be either 0 (GLOBAL), 1 (GRANT) or 2 (REVOKE) resource: the name of the resource type resourceId: The id of the resource. Can be '*' if granted or revoked for all instances of the resource type. userId: The id of the user the authorization is bound to. Can be '*' if granted or revoked for all users. Is not present when groupId is set. groupId: The id of the group the authorization is bound to. Is not present when userId is set. Delete Admin permissions: the list of permissions that has been granted or revoked permissionBits: the permissions bit mask that is persisted with the authorization type: the type of authorization, can be either 0 (GLOBAL), 1 (GRANT) or 2 (REVOKE) resource: the name of the resource type resourceId: The id of the resource. Can be '*' if granted or revoked for all instances of the resource type. userId: The id of the user the authorization is bound to. Can be '*' if granted or revoked for all users. Is not present when groupId is set. groupId: The id of the group the authorization is bound to. Is not present when userId is set. Property Create Admin name: the name of the property that was created Update Admin name: the name of the property that was updated Delete Admin name: the name of the property that was deleted",
    "url": "/manual/latest/user-guide/process-engine/history/user-operation-log/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/id-generator/index.html",
    "title": "Id Generators | docs.cibseven.org",
    "content": "All persistent entities managed by the process engine (Process Instances, Tasks, …) have unique Ids. These Ids uniquely identify an individual task, process instance, etc. When these entities are persisted to the database, the ids are used as primary keys in the corresponding database tables. Out of the box, the process engine provides two Id generator implementations. The Database Id Generator The Database Id Generator is implemented using a sequence Generator on top of the ACT_GE_PROPERTY table. This id generator is good for debugging and testing since it generates human readable ids. The Database Id Generator should never be used in production since it cannot handle high levels of concurrency. The UUID Generator The StrongUuidGenerator uses a UUID generator which uses the Java UUID Generator (JUG) library internally. Always use the StrongUuidGenerator for production setups. In the Camunda Full Distributions, the StrongUuidGenerator is preconfigured and the default Id Generator used by the process engine. If you use an embedded process engine configuration and configure the process engine using Spring, you need to add the following lines to the Spring configuration to enable the StrongUuidGenerator: <bean id=\"processEngineConfiguration\" class=\"org.cibseven.bpm.engine.impl.cfg.StandaloneInMemProcessEngineConfiguration\"> [...] <property name=\"idGenerator\"> <bean class=\"org.cibseven.bpm.engine.impl.persistence.StrongUuidGenerator\" /> </property> </bean> Additionally, you need the following maven dependency: <dependency> <groupId>com.fasterxml.uuid</groupId> <artifactId>java-uuid-generator</artifactId> <scope>provided</scope> <version>3.1.2</version> </dependency>",
    "url": "/manual/latest/user-guide/process-engine/id-generator/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/identity-service/index.html",
    "title": "Identity Service | docs.cibseven.org",
    "content": "The identity service is an API abstraction over various user/group repositories. The basic entities are User: a user identified by a unique Id Group: a group identified by a unique Id Membership: the relationship between users and groups Tenant: a tenant identified by a unique Id Tenant Membership: the relationship between tenants and users/groups Example: User demoUser = processEngine.getIdentityService() .createUserQuery() .userId(\"demo\") .singleResult(); CIB seven distinguishes between read-only and writable user repositories. A read-only user repository provides read-only access to the underlying user/group database. A writable user repository allows write access to the user database which includes creating, updating and deleting users and groups. To provide a custom identity provider implementation, the following interfaces can be implemented: org.cibseven.bpm.engine.impl.identity.ReadOnlyIdentityProvider org.cibseven.bpm.engine.impl.identity.WritableIdentityProvider Custom Whitelist for User, Group and Tenant IDs User, Group and Tenant IDs can be matched against a Whitelist Pattern to determine if the provided ID is acceptable or not. The default (global) Regular Expression pattern to match against is \"[a-zA-Z0-9]+|camunda-admin\" i.e. any combination of alphanumeric values or ‘camunda-admin’. If your organisation allows the usage of additional characters (ex.: special characters), the ProcessEngineConfiguration propery generalResourceWhitelistPattern should be set with the appropriate pattern in the engine’s configuration file. Standard Java Regular Expression syntax can be used. For example, to accept any character, the following property value can be used: <property name=\"generalResourceWhitelistPattern\" value=\".+\"/> The definition of different patterns for User, Group and Tenant IDs is possible by using the appropriate configuration propery: <property name=\"userResourceWhitelistPattern\" value=\"[a-zA-Z0-9-]+\" /> <property name=\"groupResourceWhitelistPattern\" value=\"[a-zA-Z]+\" /> <property name=\"tenantResourceWhitelistPattern\" value=\".+\" /> Note that if a certain pattern isn’t defined (ex. the tenant whitelist pattern), the general pattern will be used, either the default one (\"[a-zA-Z0-9]+|camunda-admin\") or one defined in the configuration file. The Database Identity Service The database identity service uses the process engine database for managing users and groups. This is the default identity service implementation used if no alternative identity service implementation is provided. The database identity service implements both ReadOnlyIdentityProvider and WritableIdentityProvider providing full CRUD functionality in Users, Groups and Memberships. The LDAP Identity Service The LDAP identity service provides read-only access to an LDAP-based user/group repository. The identity service provider is implemented as a Process Engine Plugin and can be added to the process engine configuration. In that case it replaces the default database identity service. To use the LDAP identity service, the camunda-identity-ldap.jar library has to be added to the classloader of the process engine. Please import the CIB seven BOM to ensure correct versions for every CIB seven project. <dependency> <groupId>org.cibseven.bpm.identity</groupId> <artifactId>cibseven-identity-ldap</artifactId> </dependency> Activate the LDAP Plugin The following is an example of how to configure the LDAP Identity Provider Plugin using Spring XML: <beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"> <bean id=\"processEngineConfiguration\" class=\"org.cibseven.bpm.engine.impl.cfg.StandaloneInMemProcessEngineConfiguration\"> ... <property name=\"processEnginePlugins\"> <list> <ref bean=\"ldapIdentityProviderPlugin\" /> </list> </property> </bean> <bean id=\"ldapIdentityProviderPlugin\" class=\"org.cibseven.bpm.identity.impl.ldap.plugin.LdapIdentityProviderPlugin\"> <property name=\"serverUrl\" value=\"ldap://localhost:3433/\" /> <property name=\"managerDn\" value=\"uid=daniel,ou=office-berlin,o=camunda,c=org\" /> <property name=\"managerPassword\" value=\"daniel\" /> <property name=\"baseDn\" value=\"o=camunda,c=org\" /> <property name=\"userSearchBase\" value=\"\" /> <property name=\"userSearchFilter\" value=\"(objectclass=person)\" /> <property name=\"userIdAttribute\" value=\"uid\" /> <property name=\"userFirstnameAttribute\" value=\"cn\" /> <property name=\"userLastnameAttribute\" value=\"sn\" /> <property name=\"userEmailAttribute\" value=\"mail\" /> <property name=\"userPasswordAttribute\" value=\"userpassword\" /> <property name=\"groupSearchBase\" value=\"\" /> <property name=\"groupSearchFilter\" value=\"(objectclass=groupOfNames)\" /> <property name=\"groupIdAttribute\" value=\"ou\" /> <property name=\"groupNameAttribute\" value=\"cn\" /> <property name=\"groupMemberAttribute\" value=\"member\" /> <property name=\"authorizationCheckEnabled\" value=\"false\" /> </bean> </beans> The following is an example of how to configure the LDAP Identity Provider Plugin in bpm-platform.xml/processes.xml: <process-engine name=\"default\"> <job-acquisition>default</job-acquisition> <configuration>org.cibseven.bpm.engine.impl.cfg.StandaloneProcessEngineConfiguration</configuration> <datasource>java:jdbc/ProcessEngine</datasource> <properties>...</properties> <plugins> <plugin> <class>org.cibseven.bpm.identity.impl.ldap.plugin.LdapIdentityProviderPlugin</class> <properties> <property name=\"serverUrl\">ldap://localhost:4334/</property> <property name=\"managerDn\">uid=jonny,ou=office-berlin,o=camunda,c=org</property> <property name=\"managerPassword\">s3cr3t</property> <property name=\"baseDn\">o=camunda,c=org</property> <property name=\"userSearchBase\"></property> <property name=\"userSearchFilter\">(objectclass=person)</property> <property name=\"userIdAttribute\">uid</property> <property name=\"userFirstnameAttribute\">cn</property> <property name=\"userLastnameAttribute\">sn</property> <property name=\"userEmailAttribute\">mail</property> <property name=\"userPasswordAttribute\">userpassword</property> <property name=\"groupSearchBase\"></property> <property name=\"groupSearchFilter\">(objectclass=groupOfNames)</property> <property name=\"groupIdAttribute\">ou</property> <property name=\"groupNameAttribute\">cn</property> <property name=\"groupMemberAttribute\">member</property> <property name=\"authorizationCheckEnabled\">false</property> </properties> </plugin> </plugins> </process-engine> Administrator Authorization Plugin The LDAP Identity Provider Plugin is usually used in combination with the Administrator Authorization Plugin which allows you to grant administrator authorizations for a particular LDAP User/Group. Multi-Tenancy Currently, the LDPA Identity Service doesn’t support multi-tenancy. That means it is not possible to get tenants from LDAP and the transparent multi-tenancy access restrictions don’t work by default. Configuration Properties of the LDAP Plugin The LDAP Identity Provider provides the following configuration properties: Property Description serverUrl The url of the LDAP server to connect to. managerDn The absolute DN of the manager user of the LDAP directory. managerPassword The password of the manager user of the LDAP directory baseDn The base DN: Identifies the root of the LDAP directory. Is appended to all DN names composed for searching for users or groups. Example: o=camunda,c=org userSearchBase Identifies the node in the LDAP tree under which the plugin should search for users. Must be relative to baseDn. Example: ou=employees userSearchFilter LDAP query string used when searching for users. Example: (objectclass=person) userIdAttribute Name of the user Id property. Example: uid userFirstnameAttribute Name of the firstname property. Example: cn userLastnameAttribute Name of the lastname property. Example: sn userEmailAttribute Name of the email property. Example: mail userPasswordAttribute Name of the password property. Example: userpassword groupSearchBase Identifies the node in the LDAP tree under which the plugin should search for groups. Must be relative to baseDn. Example: ou=roles groupSearchFilter LDAP query string used when searching for groups. Example: (objectclass=groupOfNames) groupIdAttribute Name of the group Id property. Example: ou groupNameAttribute Name of the group Name property. Example: cn groupTypeAttribute Name of the group Type property. Example: cn groupMemberAttribute Name of the member attribute. Example: member acceptUntrustedCertificates Accept of untrusted certificates if LDAP server uses SSL. Warning: We strongly advise against using this property. Better install untrusted certificates to JDK key store. useSsl Set to true if LDAP connection uses SSL. Default: false initialContextFactory Value for the java.naming.factory.initial property. Default: com.sun.jndi.ldap.LdapCtxFactory securityAuthentication Value for the java.naming.security.authentication property. Default: simple usePosixGroups Indicates whether posix groups are used. If true, the connector will use a simple (unqualified) user id when querying for groups by group member instead of the full DN. Default: false allowAnonymousLogin Allows to login anonymously without a password. Default: false Warning: We strongly advise against using this property. You should configure your LDAP to use simple authentication without anonymous login. authorizationCheckEnabled If this property is set to true, then authorization checks are performed when querying for users or groups. Otherwise authorization checks are not performed when querying for users or groups. Default: true Note: If you have a huge amount of LDAP users or groups we advise to set this property to false to improve the performance of the user and group query. sortControlSupported If this property is set to true, then ordering of the search results is enabled. Otherwise orderBy clauses in search queries are simply ignored. Default: false Note: The support of search result ordering is not be implemented by every LDAP server. Make sure that your currently used LDAP Server implements the RFC 2891. pageSize When you define a number higher or equal to 1, pagination is enabled, and results are loaded page per page. Therefore, the query sent to the LDAP Server expects support for the LDAPv3 Control for paged results as defined in RFC 2696. Default: null (no pagination) Note: By default, some LDAP Server implementations refuse to serve an unbounded number of results in one response. Therefore, configuring this property is mandatory to circumvent the limit of results. This parameter does not affect the UI or the number of results returned via Java or REST API since it uses an auto-pagination approach. passwordCheckCatchAuthenticationException When a login attempt fails with an AuthenticationException, by default, the plugin catches this exception and marks the password check as failed. You can choose to set this flag to `false` which will cause the plugin to re-throw the AuthenticationException. This is helpful when you want to register a frontend plugin that reacts to the exception message from the login attempt. Default: true The OAuth2 Identity Service See the Spring Security OAuth2 Integration’s OAuth2 Identity Provider documentation. Throttle login attempts A mechanism exists for preventing subsequent unsuccessful login attempts.The essence of it is that the user is not able to log in for a specific amount of time after unsuccessful login attempts. The amount of time is calculated after each attempt but it is limited by maximum delay time. After a predefined number of unsuccessful attempts, the user will be locked and only an administrator has permissions to unlock them. The mechanism is configurable with the following properties and respective default values. loginMaxAttempts=10 loginDelayFactor=2 loginDelayMaxTime=60 loginDelayBase=3 For more information, please check the process engine’s login properties section. Calculation of the delay is done via the formula: baseTime * factor^(attempt-1). The behaviour with the default configuration will be: 3 seconds delay after the first unsuccessful attempt, 6 seconds after the 2nd attempt, 12 seconds, 24 seconds, 48 seconds, 60 seconds, 60 seconds, etc. After the 10th attempt, if the user fails to login again, the user will be locked. LDAP specifics If you have a LDAP setup on your engine, you need to handle the throttling on the LDAP side. The login mechanism in your system will not be affected by the above properties.",
    "url": "/manual/latest/user-guide/process-engine/identity-service/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/incidents/index.html",
    "title": "Incidents | docs.cibseven.org",
    "content": "Incidents are notable events that happen in the process engine. Such incidents usually indicate some kind of problem related to process execution. Examples of such incidents may be a failed job with depleted retries (retries = 0), indicating that an execution is stuck and manual administrative action is necessary to repair the process instance. If such incidents arise, the process engine fires an internal event which can be handled by a configurable incident handler. In the default configuration, the process engine writes incidents to the process engine database. You may then query the database for different types and kinds of incidents using the IncidentQuery exposed by the RuntimeService: runtimeService.createIncidentQuery() .processDefinitionId(\"someDefinition\") .list(); Incidents are stored in the ACT_RU_INCIDENT database table. If you want to customize the incident handling behavior, it is possible to replace the default incident handlers in the process engine configuration and provide custom implementations (see below). Incident Types There are different types of incidents. Currently the process engine supports the following incidents: failedJob: is raised when automatic retries for a job (timer or asynchronous continuation) have been depleted. The incident indicates that the corresponding execution is stuck and will not continue automatically. Administrative action is necessary. The incident is resolved when the job is manually executed or when the retries for the corresponding job are set to a value > 0. failedExternalTask: is raised when a worker of an External Task reports a failure and the given retries are set to a value <= 0. The incident indicates that the corresponding external task is stuck and will not be fetched by a worker. Administrative action is necessary to reset the retries. It is possible to create custom incidents of any type with the Java API. Creating and Resolving Custom Incidents An incident of any type can be created by calling RuntimeService#createIncident … runtimeService.createIncident(\"someType\", \"someExecution\", \"someConfiguration\", \"someMessage\"); … or directly DelegateExecution#createIncident. delegateExecution.createIncident(\"someType\", \"someConfiguration\", \"someMessage\"); Custom incidents must always be related to an existing Execution. An incident of any type, except for failedJob and failedExternalTask, can be resolved by calling RuntimeService#resolveIncident. Incidents can be created and resolved through the REST API as well. (De-)Activate Incidents The process engine allows you to configure whether certain incidents should be raised or not, based on the incident type. The following properties are available in the org.cibseven.bpm.engine.ProcessEngineConfiguration class: createIncidentOnFailedJobEnabled: indicates whether Failed Job incidents should be raised or not. Implement Custom Incident Handlers Incident Handlers are responsible for handling incidents of a certain type (see Incident Types ). An Incident Handler implements the following interface: public interface IncidentHandler { String getIncidentHandlerType(); Incident handleIncident(IncidentContext context, String message); void resolveIncident(IncidentContext context); void deleteIncident(IncidentContext context); } The handleIncident method is called when a new incident is created. The resolveIncident method is called when an incident is resolved. If you want to provide a custom incident handler implementation you can replace one or multiple incident handlers using the following method: org.cibseven.bpm.engine.impl.cfg.ProcessEngineConfigurationImpl.setCustomIncidentHandlers(List<IncidentHandler>) An example of a custom incident handler could be a handler which extends the default behavior by sending an email to an administrator whenever an incident of type failedJob occurs. However, just adding the custom incident handler overwrites the default behavior with the custom incident handlers behavior. As a consequence, the default incident handler is not executed anymore. If the default behavior should be executed as well, then the custom incident handler also needs to invoke the default incident handler, which includes using internal API. Use of Internal API Please be aware that this API is not part of the public API and may change in later releases. Composite Incident Handlers By default, an incident can only be handled by one handler with a same type. Composite incident handlers allow defining one main and multiple sub handlers. Only the result from the “main” incident handler will be returned. To enable composite incident handlers, configure the following property: <property name=\"compositeIncidentHandlersEnabled\" value=\"true\" /> If you want to provide multiple incident handlers, you can add them using the following method: org.cibseven.bpm.engine.impl.cfg.ProcessEngineConfigurationImpl.setCustomIncidentHandlers(List<IncidentHandler>) All additional incident handlers will be added as sub handlers to the CompositeIncidentHandler for the same handler type. By default, the main handler is DefaultIncidentHandler. To override the main handler, create a CompositeIncidentHandler with your own main IncidentHandler and initialize the incident handlers in the engine configuration before setting up the engine. See javadoc for more details Composite Incident Handler .",
    "url": "/manual/latest/user-guide/process-engine/incidents/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/index.html",
    "title": "Process Engine | docs.cibseven.org",
    "content": "Docs Get Started CIB seven Security cibseven.org CIB seven 1.1 Introduction Download Licenses Implemented Standards Architecture Overview Supported Environments Extensions Third-Party Libraries CIB seven License Book Public API User Guide Process Engine Process Engine Bootstrapping Process Engine API Process Engine Concepts Process Variables Process Instance Modification Process Instance Restart Delegation Code Expression Language Scripting Templating Custom Code & Security External Tasks Connectors Process Versioning Process Instance Migration Database Database Schema Database Configuration Microsoft SQL Server and Azure SQL Database Configuration MySQL Database Configuration Performance History History configuration User operation log History cleanup Custom implementation Deployment Cache Password Hashing Password Policy Transactions in Processes The Job Executor Multi-Tenancy Id Generators Metrics Incidents Process Engine Plugins Identity Service Authorization Service Deployments Process Diagram Visualization Time zones Decisions Configuration Repository Decision Service Decisions in BPMN & CMMN History Batch Batch operations Error Handling Diagnostics data Process Applications The Process Application class The processes.xml Deployment Descriptor Process Application Event Listeners Process Application Resource Access Maven Project Templates (Archetypes) Runtime Container Integration CIB seven Services JNDI Bindings for CIB seven Services Apache Tomcat WildFly Job Execution with Managed Resources CIB seven Run Spring Framework Integration Bootstrapping Transactions Deployment Spring Bean Resolving Testing Spring Boot Integration Version Compatibility Configuration REST API Web Applications Process Applications Spring Eventing Bridge Developing and Testing Spring Security OAuth2 Integration Quarkus Integration Version Compatibility Configuration Engine CDI Integration Resource Deployments CDI and Java EE Integration JTA Transaction Integration Expression Resolving Contextual Programming Model Built-In Beans CDI Event Bridge Testing Assert Examples Model API BPMN Model API Read a Model Create a Model Delegation Code Fluent Builder API Repository Service Extension Elements CMMN Model API Read a Model Create a Model Delegation Code Repository Service Extension Elements Limitations DMN Model API Read a Model Create a Model Repository Service Extension Attributes Data Formats (XML, JSON, Other) Configuring Spin Integration Data Formats in Processes XML JSON User Task Forms JSF Task Forms DMN Engine Embed Evaluate Decisions Expressions FEEL Engine Type Handling Custom Functions Spin Integration Legacy Behavior Data Types Testing Logging Security Instructions External Task Client Spring Boot Starter Version Compatibility Reference REST API Overview Configure Authentication Usage with a Pre-Built Distribution Embed the API Hypertext Application Language (HAL) Variables in the REST API Date Format OpenAPI Specification ↗ Javadoc ↗ BPMN 2.0 Tasks Service Task Send Task User Task Business Rule Task Script Task Receive Task Manual Task Task Markers Gateways Data-based Exclusive Gateway (XOR) Conditional and Default Sequence Flows Parallel Gateway Inclusive Gateway Event-based Gateway Events Start Events None Events Message Events Timer Events Error Events Escalation Events Signal Events Cancel and Compensation Events Conditional Events Link Events Terminate Events Subprocess Embedded Subprocess Call Activity Event Subprocess Transaction Subprocess Extension Reference Extension Elements Extension Attributes DMN 1.3 Decision Table Input Output Rule Hit Policy Decision Literal Expression Decision Requirements Graph FEEL Legacy FEEL Reference Data Types Language Elements Extension Reference Extension Attributes CMMN 1.1 Classic vs Fluent API CMMN Concepts Plan Items and Item Definitions Plan Item Lifecycles Entry and Exit Criteria Tasks Human Task Process Task Case Task Decision Task Grouping Tasks Stage Milestones Sentries Markers Manual Activation Rule Required Rule Auto Complete Repetition Rule Extension Reference Extension Elements Extension Attributes Migration between Specification Versions 1.0 to 1.1 Forms Embedded Forms Controls Text Inputs Textareas Date Inputs Boolean Inputs Selects Hidden Input Fields File Upload and Download BPMN Event Buttons Javascript The cam-script Directive Available API Participating in the Form Lifecycle Debugging Scripts Generating a Business Key Examples Lifecycle and Events Working with Json Data Working with Java Objects Integrating the Forms SDK Getting a Distribution Bootstrapping AngularJS Integration Full Example Spin Dataformats XML Reading XML Manipulating XML Writing XML Querying XML Mapping XML Configuring XML Handling JSON Reading JSON Writing JSON Querying JSON Mapping JSON Configuring JSON Handling Extending Spin Connectors HTTP Connector SOAP Connector Extending Connect Deployment Descriptors bpm-platform.xml processes.xml Tags <job-executor /> <process-archive /> <process-engine /> Installation Database Schema Remote Engine Distribution Shared Engine Distribution Tomcat Pre-Packaged Distribution Manual Installation Configuration JBoss EAP/WildFly Manual Installation Configuration Docker Spring Boot Web Applications Admin User Management Group Management Tenant Management Authorization Management System Management Configuration Plugins Cockpit Dashboard BPMN Processes Dashboard Process Definition View Process Instance View Failed Jobs Suspension Collapsed Subprocesses DMN Decisions Dashboard Decision Definition View Decision Instance View Deployments Open Tasks Dashboard Extending Configuration Plugins Tasklist Working with Tasklist Dashboard Filters User Assignment Task Lifecycle Plugins Configuration Accessibility Welcome Plugins Configuration Shared Configuration Options Authentication Cookie Security CSRF Prevention HTTP Header Security Examples Notices Update & Migration Rolling Update Camunda Migration Process Engine Process Engine Bootstrapping Process Engine API Process Engine Concepts Process Variables Process Instance Modification Process Instance Restart Delegation Code Expression Language Scripting Templating Custom Code & Security External Tasks Connectors Process Versioning Process Instance Migration Database History Deployment Cache Password Hashing Password Policy Transactions in Processes The Job Executor Multi-Tenancy Id Generators Metrics Incidents Process Engine Plugins Identity Service Authorization Service Deployments Process Diagram Visualization Time zones Decisions Batch Error Handling Diagnostics data :( Back to top cibseven.org and docs.cibseven.org are part of CIB seven project — Privacy Statement – CIB software GmbH The CIB seven documentation is based on Camunda 7 Docs from Camunda. Some redesign & naming adoptation was made. The content on this site is licensed under a Creative Commons Attribution-ShareAlike 3.0 Unported License.",
    "url": "/manual/latest/user-guide/process-engine/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/metrics/index.html",
    "title": "Metrics | docs.cibseven.org",
    "content": "The process engine reports runtime metrics to the database that can help draw conclusions about usage, load, and performance of CIB seven. Metrics are reported in the database tables ACT_RU_METER_LOG and ACT_RU_TASK_METER_LOG. Single metric entries in ACT_RU_METER_LOG consist of a metric identifier, a value as natural number in the Java long range that the metric took in a certain timespan and a name identifying the metric reporter. Task metric entries in ACT_RU_TASK_METER_LOG comprise a fixed-length, pseudonymized assignee value and the point in time it was assigned at. There is a set of built-in metrics that are reported by default. Built-in Metrics The following table describes the built-in metrics. The identifiers of all built-in metrics are available as constants of the class org.cibseven.bpm.engine.management.Metrics . Category Identifier Description BPMN Execution root-process-instance-start* The number of root process instance executions started. This is also known as Process Instances (PI). A root process instance has no parent process instance, i.e. it is a top-level execution. activity-instance-start* The number of flow node instances (activity instances) started (FNI). activity-instance-end The number of flow node instances (activity instances) ended. DMN Execution executed-decision-instances* The number of evaluated decision instances (DI). A decision instance is a DMN decision table or a DMN Literal Expression. executed-decision-elements* The number of decision elements executed during evaluation of DMN decision tables. For one table, this is calculated as the number of clauses multiplied by the number of rules. Job Executor job-successful The number of jobs successfully executed. job-failed The number of jobs that failed to execute and that were submitted for retry. Every failed attempt to execute a job is counted. job-acquisition-attempt The number of job acquisition cycles performed. job-acquired-success The number of jobs that were acquired and successfully locked for execution. job-acquired-failure The number of jobs that were acquired but could not be locked for execution due to another job executor locking/executing the jobs in parallel. job-execution-rejected The number of successfully acquired jobs submitted for execution that were rejected due to saturated execution resources. This is an indicator that the execution thread pool's job queue is full. job-locked-exclusive The number of exclusive jobs that are immediately locked and executed. Task Metrics unique-task-workers* The number of task users (TU) that have served as assignees. History Clean up history-cleanup-removed-process-instances The number of process instances removed by history clean up. history-cleanup-removed-case-instances The number of case instances removed by history clean up. history-cleanup-removed-decision-instances The number of decision instances removed by history clean up. history-cleanup-removed-batch-operations The number of batch operations removed by history clean up. history-cleanup-removed-task-metrics The number of task metrics removed by history clean up. Querying Metrics can be queried by making a MetricsQuery offered by the ManagementService. For example, the following query retrieves the number of all executed activity instances throughout the entire history of reporting: long numCompletedActivityInstances = managementService .createMetricsQuery() .name(Metrics.ACTIVTY_INSTANCE_START) .sum(); The metrics query offers filters #startDate(Date date) and #endDate(Date date) to restrict the collected metrics to a certain timespan. In addition, by using the filter #reporter(String reporterId) the results can be restricted to metrics collected by a specific reporter. This option can be useful when configuring more than one engine against the same database, for example in a cluster setup. Task metrics can be queried by using the getUniqueTaskWorkerCount method offered by the ManagementService. This method accepts optional Date values for startTime and endTime to restrict the metric to a certain timespan. For example, the following statement retrieves the number of all unique task workers until now: long numUniqueTaskWorkers = managementService.getUniqueTaskWorkerCount(null, null); Configuration Metrics Reporter The process engine flushes the collected metrics to the runtime database tables in an interval of 15 minutes. The behavior of metrics reporting can be changed by replacing the dbMetricsReporter instance of the process engine configuration. For example, to change the reporting interval, a process engine plugin replacing the reporter can be employed: public class MetricsConfigurationPlugin implements ProcessEnginePlugin { public void preInit(ProcessEngineConfigurationImpl processEngineConfiguration) { } public void postInit(ProcessEngineConfigurationImpl processEngineConfiguration) { DbMetricsReporter metricsReporter = new DbMetricsReporter(processEngineConfiguration.getMetricsRegistry(), processEngineConfiguration.getCommandExecutorTxRequired()); metricsReporter.setReportingIntervalInSeconds(5); processEngineConfiguration.setDbMetricsReporter(metricsReporter); } public void postProcessEngineBuild(ProcessEngine processEngine) { } } Note Task metric entries are created on every assignment of a user task. This behavior cannot be modified and is not in the responsibility of the metrics reporter. Reporter Identifier Metrics are reported with an identifier of the reporting party. This identifier allows to attribute reports to individual engine instances when making a metrics query. For example in a cluster, load metrics can be related to individual cluster nodes. By default the process engine generates a reporter id as <local IP>$<engine name>. The generation can be customized by implementing the interface org.cibseven.bpm.engine.impl.history.event.HostnameProvider and setting the engine property hostnameProvider to an instance of that class. Heads Up! The org.cibseven.bpm.engine.impl.metrics.MetricsReporterIdProvider interface and the corresponding metricsReporterIdProvider engine property have been deprecated. Disable Reporting By default, all built-in metrics are reported. For the configuration via XML file (e.g. standalone.xml or bpm-platform.xml) you can disable reporting by adding the properties: <property name=\"metricsEnabled\">false</property> <property name=\"taskMetricsEnabled\">false</property> If you are directly accessing the Java API, you can disable the metrics reporting by using the engine configuration flags isMetricsEnabled and isTaskMetricsEnabled and set them to false.",
    "url": "/manual/latest/user-guide/process-engine/metrics/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/multi-tenancy/index.html",
    "title": "Multi-Tenancy | docs.cibseven.org",
    "content": "Multi-Tenancy regards the case in which a single CIB seven installation should serve more than one tenant. For each tenant, certain guarantees of isolation should be made. For example, one tenant’s process instances should not interfere with those of another tenant. Multi-Tenancy can be achieved in two different ways. One way is to use one process engine per tenant. The other way is to use just one process engine and associate the data with tenant identifiers. The two ways differ from each other in the level of data isolation, the effort of maintenance and the scalability. A combination of both ways is also possible. Single Process Engine With Tenant-Identifiers Multi-Tenancy can be achieved with one process engine which uses tenant identifiers (i.e., tenant-ids). The data of all tenants is stored in one table (same database and schema). Isolation is provided by the means of a tenant identifier that is stored in a column. The tenant identifier is specified on the deployment and is propagated to all data that is created from the deployment (e.g., process definitions, process instances, tasks, etc.). To access the data for a specific tenant, the process engine allows to filter queries by a tenant identifier or specify a tenant identifier for a command (e.g., create a process instance). Additionally, the process engine provides transparent access restrictions in combination with the Identity Service that allows to omit the tenant identifier. Note that transparent tenant separation is not implemented for all APIs. For example, with the deployment API, a tenant can deploy a process for another tenant. Therefore it is not a supported usecase to expose such API endpoints directly to tenants. Instead, custom access checking logic should be built on top of the Camunda API. It is also possible for all tenants to share the same process and decision definitions without deploying them for each tenant. Shared definitions can simplify management of the deployments in case of a larger amount of tenants. Examples Find examples on GitHub that show how to use tenant-identifiers with Embedded Process Engine Shared Process Engine Deploy Definitions for a Tenant To deploy definitions for a single tenant, the tenant identifier has to be set on the deployment. The given identifier is propagated to all definitions of the deployment so that they belong to the tenant. If no tenant identifier is set then the deployment and its definitions belong to all tenants. In this case, all tenants can access the deployment and the definitions. See this section to read more about how to use shared definitions. Specify the Tenant Identifier via Java API When a deployment is created using the Repository Service, the tenant identifier can be set on the DeploymentBuilder . repositoryService .createDeployment() .tenantId(\"tenant1\") .addZipInputStream(inputStream) .deploy() Specify the Tenant Identifier via Deployment Descriptor In case of a process application, the deployment is specified by a processes.xml Deployment Descriptor. Since the descriptor can contain multiple process-archives (i.e., deployments), the tenant identifier can be set on each process-archive as tenantId attribute. <process-application xmlns=\"http://www.camunda.org/schema/1.0/ProcessApplication\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <process-archive tenantId=\"tenant1\"> <process-engine>default</process-engine> <properties> <property name=\"isDeleteUponUndeploy\">false</property> <property name=\"isScanForProcessDefinitions\">true</property> </properties> </process-archive> </process-application> Specify the Tenant Identifier via Spring Configuration When the Automatic Resource Deployment of the Spring Framework Integration is used, the tenant identifier can be specified in the Process Engine Configuration as deploymentTenantId property. <bean id=\"processEngineConfiguration\" class=\"org.cibseven.bpm.engine.spring.SpringProcessEngineConfiguration\"> <property name=\"deploymentResources\"> <array> <value>classpath*:/org/cibseven/bpm/engine/spring/test/autodeployment/autodeploy.*.cmmn</value> <value>classpath*:/org/cibseven/bpm/engine/spring/test/autodeployment/autodeploy.*.bpmn20.xml</value> </array> </property> <property name=\"deploymentTenantId\" value=\"tenant1\" /> </bean> Versioning of Tenant-Specific Definitions When a definition is deployed for a tenant then it is assigned a version which is independent from definitions of other tenants. For example, if a new process definition is deployed for two tenants then both definitions are assigned the version 1. The versioning within one tenant works like the versioning of definitions that belong to no tenant. Query Data of a Tenant The process engine queries of tenant-specific data (e.g., Deployment Query, Process Definition Query) allows to filter by one or more tenant identifiers. If no identifier is set then the result contains the data of all tenants. Note that the transparent access restrictions of tenants can influence the result of a query if a user is not allowed to see the data of a tenant. Query Deployments of a Tenant To find the deployments of specific tenants, the tenant identifiers have to be passed to tenantIdIn on the DeploymentQuery. List<Deployment> deployments = repositoryService .createDeploymentQuery() .tenantIdIn(\"tenant1\", \"tenant2\") .orderByTenantId() .asc() .list(); In case of shared definitions, it can be useful to filter by deployments which belong to no tenant by calling withoutTenantId(). List<Deployment> deployments = repositoryService .createDeploymentQuery() .withoutTenantId() .list(); It is also possible to filter by deployments which belong to a specific tenant or no tenant by calling includeDeploymentsWithoutTenantId(). List<Deployment> deployments = repositoryService .createDeploymentQuery() .tenantIdIn(\"tenant1\") .includeDeploymentsWithoutTenantId() .list(); Query Definitions of a Tenant Similar to the DeploymentQuery, the definition queries allow to filter by one or more tenants and by definitions which belong to no tenant. List<ProcessDefinition> processDefinitions = repositoryService .createProcessDefinitionQuery() .tenantIdIn(\"tenant1\") .includeProcessDefinitionsWithoutTenantId(); .list(); Run Commands for a Tenant When a definition is deployed for multiple tenants, a command can be ambiguous (e.g., start a process instance by key). If such a command is executed, a ProcessEngineException is thrown. To run the command successfully, the tenant identifier has to be passed to the command. Note that the transparent access restrictions of tenants can omit the tenant identifier if a user is only allowed to see one of the definitions. Create a Process Instance To create an instance by key of a process definition which is deployed for multiple tenants, the tenant identifier has to be passed to the ProcessInstantiationBuilder . runtimeService .createProcessInstanceByKey(\"key\") .processDefinitionTenantId(\"tenant1\") .execute(); Correlate a Message The Message API can be used to correlate a message to one or all tenants. In case a message can correlate to definitions or executions of multiple tenants, the tenant identifier has to be passed to the MessageCorrelationBuilder . Otherwise, a MismatchingMessageCorrelationException is thrown. runtimeService .createMessageCorrelation(\"messageName\") .tenantId(\"tenant1\") .correlate(); To correlate a message to all tenants, pass no tenant identifier to the builder and call correlateAll(). runtimeService .createMessageCorrelation(\"messageName\") .correlateAll(); Send a Signal The Signal API can be used to deliver a signal to one or all tenants. Pass the tenant identifier to the SignalEventReceivedBuilder to deliver the signal to a specific tenant. If no identifier is passed then the signal is delivered to all tenants. runtimeService .createSignalEvent(\"signalName\") .tenantId(\"tenant1\") .send(); When a signal is thrown within a process (i.e., intermediate signal event or signal end event) then the signal is delivered to definitions and executions which belong to the same tenant as the calling execution or no tenant. Create a Case Instance To create an instance by key of a case definition which is deployed for multiple tenants, the tenant identifier has to be passed to the CaseInstanceBuilder . caseService .withCaseDefinitionByKey(\"key\") .caseDefinitionTenantId(\"tenant1\") .execute(); Evaluate a Decision Table To evaluate a decision table by key which is deployed for multiple tenants, the tenant identifier has to be passed to the DecisionEvaluationBuilder . decisionService .evaluateDecisionTableByKey(\"key\") .decisionDefinitionTenantId(\"tenant1\") .evaluate(); Transparent Access Restrictions for Tenants When integrating CIB seven into an application, it can be cumbersome to pass the tenant Id to each CIB seven API call. Since such an application usually also has a concept of an “authenticated user”, it is possible to set the list of tenant ids when setting the authentication: try { identityService.setAuthentication(\"mary\", asList(\"accounting\"), asList(\"tenant1\")); // All API calls executed here have \"tenant1\" transparently set as tenantId } finally { identityService.clearAuthentication(); } In the above example, all API calls executed between setAuthentication(...) and clearAuthentication() are transparently executed with the list of provided tenant Ids. Query Example The following query try { identityService.setAuthentication(\"mary\", asList(\"accounting\"), asList(\"tenant1\")); repositoryService.createProcessDefinitionQuery().list(); } finally { identityService.clearAuthentication(); } Is equivalent to repositoryService.createProcessDefinitionQuery() .tenantIdIn(\"tenant1\") .includeProcessDefinitionsWithoutTenantId() .list(); Task Access Example For other commands like complete(), the transparent access check ensures that the authenticated user does not access resources by other tenants: try { identityService.setAuthentication(\"mary\", asList(\"accounting\"), asList(\"tenant1\")); // throws an exception if task has tenant id other than \"tenant1\" taskService.complete(\"someTaskId\"); } finally { identityService.clearAuthentication(); } Getting a user’s Tenant Ids from the Identity Service The process engine’s Identity Service can be used to manage users, groups and tenants as well as their relationships. The following example shows how to retrieve the lists of groups and tenants for a given user and then use these lists when setting the authentication: List<Tenant> groups = identityService.createGroupQuery() .userMember(userId) .list(); List<Tenant> tenants = identityService.createTenantQuery() .userMember(userId) .includingGroupsOfUser(true) .list(); try { identityService.setAuthentication(userId, groups, tenants); // get all tasks visible to user. taskService.createTaskQuery().list(); } finally { identityService.clearAuthentication(); } LDAP Identity Service The above example only works with the Database Identity Service (i.e., the default implementation). The LDAP Identity Service doesn’t support tenants. CIB seven Rest API and Web Applications The CIB seven Rest API and the web applications Cockpit and Tasklist support the transparent access restrictions. When a user logs in then he only sees and can only access the data (e.g., process definitions) that belongs to one of his tenants. Tenants and their memberships can be managed in the Admin web application. Disable the Transparent Access Restrictions The transparent access restrictions are enabled by default. To disable the restrictions, set the tenantCheckEnabled property in the ProcessEngineConfiguration to false. Additionally, it is also possible to disable the restrictions for a single command (e.g., for a maintenance task). Use the CommandContext to disable and enable the restrictions for the current command. commandContext.disableTenantCheck(); // e.g., do maintenance tasks over all tenants commandContext.enableTenantCheck(); Note that the restrictions can’t be enabled for a command if they are disabled in the ProcessEngineConfiguration. Access all Tenants as Administrator The admin user or users who are a member of the admin group can access the data of all tenants, even if they don’t belong to the tenants. This is useful for an administrator of a multi-tenancy application as they must manage the data of all tenants. Define admin users by making them a member of the group camunda-admin or with the help of the Admin Authorization Plugin. The Admin Authorization Plugin allows granting admin privileges to a custom user or group. Shared Definitions for all Tenants In section Deploy Definitions for a Tenant it is explained how to deploy a Process Definition or a Decision Definition for a particular tenant. The result is that the definition is only visible to the tenant for whom it was deployed but not to other tenants. This is useful if tenants have different processes and decisions. However, there are also many situations where all tenants should share the same definitions. In such situations it is desirable to deploy a definition only once, in a way that it is visible to all tenants. Then, when a new instance is created by a particular tenant, it should be only visible to that tenant (and administrators of course). This can be achieved by a usage pattern we call “Shared Definitions”. By the term usage pattern we mean that it is not a feature of Camunda per se but rather a specific way to use it to achieve the desired behavior. Example You can find an example on GitHub that shows how to use shared definitions. Deploy a Shared Definition Deploying a shared definition is just a “regular” deployment not assigning a Tenant Id to the deployment: repositoryService .createDeployment() .addClasspathResource(\"processes/default/mainProcess.bpmn\") .addClasspathResource(\"processes/default/subProcess.bpmn\") .deploy(); Include Shared Definitions in a Query Often in an application, we want to present a list of “available” process definitions to the user. In a multi tenancy context with shared resources we want the list to include definitions with the following properties: tenant id is the current user’s tenant id, tenant id is null => process is a shared resource. To achieve this with a query, the query needs to restrict on the list of the user’s tenant ids (by calling tenantIdIn(...)) and include definitions without a tenant id (includeProcessDefinitionsWithoutTenantId()). Or, looking at it the other way around: exclude all definitions which have a tenant id which is different from the current user’s tenant id(s). Example: repositoryService.createProcessDefinitionQuery() .tenantIdIn(\"someTenantId\") .includeProcessDefinitionsWithoutTenantId() .list(); Instantiate a Shared Definition When creating (starting) a new process instance, the tenant id of the process definition is propagated to the process instance. Shared resources do not have a tenant id which means that no tenant id is propagated automatically. To have the tenant id of the user who starts the process instances assigned to the process instance, an implementation of the TenantIdProvider SPI needs to be provided. The TenantIdProvider receives a callback when an instance of a process definition, case definition or decision definition is created. It can then assign a tenant id to the newly created instance (or not). The following example shows how to assign a tenant id to an instance based on the current authentication: public class CustomTenantIdProvider implements TenantIdProvider { @Override public String provideTenantIdForProcessInstance(TenantIdProviderProcessInstanceContext ctx) { return getTenantIdOfCurrentAuthentication(); } @Override public String provideTenantIdForCaseInstance(TenantIdProviderCaseInstanceContext ctx) { return getTenantIdOfCurrentAuthentication(); } @Override public String provideTenantIdForHistoricDecisionInstance(TenantIdProviderHistoricDecisionInstanceContext ctx) { return getTenantIdOfCurrentAuthentication(); } protected String getTenantIdOfCurrentAuthentication() { IdentityService identityService = Context.getProcessEngineConfiguration().getIdentityService(); Authentication currentAuthentication = identityService.getCurrentAuthentication(); if (currentAuthentication != null) { List<String> tenantIds = currentAuthentication.getTenantIds(); if (tenantIds.size() == 1) { return tenantIds.get(0); } else if (tenantIds.isEmpty()) { throw new IllegalStateException(\"no authenticated tenant\"); } else { throw new IllegalStateException(\"more than one authenticated tenant\"); } } else { throw new IllegalStateException(\"no authentication\"); } } } To use the TenantIdProvider, it must be set in the Process Engine Configuration, for example using the camunda.cfg.xml: <beans> <bean id=\"processEngineConfiguration\" class=\"org.cibseven.bpm.engine.impl.cfg.StandaloneProcessEngineConfiguration\"> <!-- ... --> <property name=\"tenantIdProvider\" ref=\"tenantIdProvider\" /> </bean> <bean id=\"tenantIdProvider\" class=\"org.cibseven.bpm.CustomTenantIdProvider\"> </beans> In case of a shared process engine, the provider can be set via Process Engine Plugin. Tenant-specific behavior with Call Activities So far, we have seen that shared resources are a useful pattern if tenants have the same process definition. The advantage is that we do not have to deploy the same process definitions once per tenant. Yet, in many real world applications, the situation is somewhat in between: tenants share mostly the same process definitions, but there are some tenant specific variations. A common pattern of how to deal with this is to extract the tenant-specific behavior in a separate process which is then invoked using a call activity. Tenant specific decision logic (i.e., decision tables) using a business rules task are also common. To realize this, the call activity or business rule task needs to select the correct definition to invoke based on the tenant id of the current process instance. The Shared Resources Example shows how to achieve this. See also: Shared Resources Example Called Element Tenant Id Case Tenant Id for call activities. Decision Ref Tenant Id for business rule tasks. One Process Engine Per Tenant Multi-Tenancy can be achieved by providing one process engine per tenant. Each process engine is configured to use a different data source which connects the data of the tenant. The data of the tenants can be stored in different databases, in one database with different schemas or in one schema with different tables. The process engines can run on the same server so that all share the same computational resources such as a data source (when isolating via schemas or tables) or a thread pool for asynchronous job execution. Tutorial You can see the example how to implement multi-tenancy with data isolation by schemas. Configure the Process Engines The process engines can be configured in a configuration file or via Java API. Each engine should have a name that is related to a tenant such that it can be identified based on the tenant. For example, each engine can be named after the tenant it serves. See the Process Engine Bootstrapping section for details. Database Isolation If different tenants should work on entirely different databases, they have to use different JDBC settings or different data sources. Schema or Table Isolation For schema- or table-based isolation, a single data source can be used which means that resources like a connection pool can be shared among multiple engines. To achieve this, the configuration option databaseTablePrefix can be used to configure database access. consider switching on the setting useSharedSqlSessionFactory. The setting controls whether each process engine instance should parse and maintain a local copy of the mybatis mapping files or whether a single, shared copy can be used. Since the mappings require a lot of heap (>30MB), it is recommended to switch this on. This way only one copy needs to be allocated. Considerations for useSharedSqlSessionFactory setting The useSharedSqlSessionFactory setting causes caching of the mybatis sql session factory in a static field, once built. When using this configuration setting, you need to be aware that it can only be used if all process engines which use the setting share the same datasource and transaction factory the reference in the field, once set, is never cleared. This is usually not a problem but if it is, users must clear the field manually by setting it to null explicitly via ProcessEngineConfigurationImpl.cachedSqlSessionFactory = null Job Executor for Multiple Process Engines For background execution of processes and tasks, the process engine has a component called job executor. The job executor periodically acquires jobs from the database and submits them to a thread pool for execution. For all process applications on one server, one thread pool is used for job execution. Furthermore, it is possible to share the acquisition thread between multiple engines. This way, resources are still manageable even when a large amount of process engines are used. See the section The Job Executor and Multiple Process Engines for details. Example Configuration for Schema Isolation Multi-Tenancy settings can be applied in the various ways of configuring a process engine. The following is an example of a bpm-platform.xml file that specifies engines for two tenants that share the same database but work on different schemas: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <bpm-platform xmlns=\"http://www.camunda.org/schema/1.0/BpmPlatform\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.camunda.org/schema/1.0/BpmPlatform http://www.camunda.org/schema/1.0/BpmPlatform\"> <job-executor> <job-acquisition name=\"default\" /> </job-executor> <process-engine name=\"tenant1\"> <job-acquisition>default</job-acquisition> <configuration>org.cibseven.bpm.engine.impl.cfg.StandaloneProcessEngineConfiguration</configuration> <datasource>java:jdbc/ProcessEngine</datasource> <properties> <property name=\"databaseTablePrefix\">TENANT_1.</property> <property name=\"history\">full</property> <property name=\"databaseSchemaUpdate\">true</property> <property name=\"authorizationEnabled\">true</property> <property name=\"useSharedSqlSessionFactory\">true</property> </properties> </process-engine> <process-engine name=\"tenant2\"> <job-acquisition>default</job-acquisition> <configuration>org.cibseven.bpm.engine.impl.cfg.StandaloneProcessEngineConfiguration</configuration> <datasource>java:jdbc/ProcessEngine</datasource> <properties> <property name=\"databaseTablePrefix\">TENANT_2.</property> <property name=\"history\">full</property> <property name=\"databaseSchemaUpdate\">true</property> <property name=\"authorizationEnabled\">true</property> <property name=\"useSharedSqlSessionFactory\">true</property> </properties> </process-engine> </bpm-platform> Deploy Definitions for a Tenant When developing process applications, i.e., process definitions and supplementary code, some processes may be deployed to every tenant’s engine while others are tenant-specific. The processes.xml deployment descriptor that is part of every process application offers this kind of flexibility by the concept of process archives. One application can contain any number of process archive deployments, each of which can be deployed to a different process engine with different resources. See the section on the processes.xml deployment descriptor for details. The following is an example that deploys different process definitions for two tenants. It uses the configuration property resourceRootPath that specifies a path in the deployment that contains process definitions to deploy. Accordingly, all the processes under processes/tenant1 on the application’s classpath are deployed to engine tenant1, while all the processes under processes/tenant2 are deployed to engine tenant2. <process-application xmlns=\"http://www.camunda.org/schema/1.0/ProcessApplication\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <process-archive name=\"tenant1-archive\"> <process-engine>tenant1</process-engine> <properties> <property name=\"resourceRootPath\">classpath:processes/tenant1/</property> <property name=\"isDeleteUponUndeploy\">false</property> <property name=\"isScanForProcessDefinitions\">true</property> </properties> </process-archive> <process-archive name=\"tenant2-archive\"> <process-engine>tenant2</process-engine> <properties> <property name=\"resourceRootPath\">classpath:processes/tenant2/</property> <property name=\"isDeleteUponUndeploy\">false</property> <property name=\"isScanForProcessDefinitions\">true</property> </properties> </process-archive> </process-application> Access the Process Engine of a Tenant To access a specific tenant’s process engine at runtime, it has to be identified by its name. The CIB seven engine offers access to named engines in various programming models: Plain Java API: Via the ProcessEngineService any named engine can be accessed. CDI Integration: Named engine beans can be injected out of the box. The built-in CDI bean producer can be specialized to access the engine of the current tenant dynamically. Via JNDI on Wildfly: On Wildfly, every container-managed process engine can be looked up via JNDI. The CIB seven web applications Cockpit, Tasklist and Admin offer tenant-specific views out of the box by switching between different process engines.",
    "url": "/manual/latest/user-guide/process-engine/multi-tenancy/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/password-hashing/index.html",
    "title": "Password Hashing | docs.cibseven.org",
    "content": "This chapter is about how cryptographic password hashing is done in CIB seven. In particular, the hashing algorithm that is being used and the salt generation. If you are not familiar with these topics, we recommend reading the articles about cryptographic hash function, salt and secure password hashing. The Camunda version 7.6 and earlier use the cryptographic hash function SHA-1. Since Camunda version 7.7 the hash function SHA-512 is used. If there is a need for another custom hash function, it is possible to plugin a custom password hashing algorithm in Camunda. At salt generation, a random 16-byte per-user value is created, which is generated with SecureRandom. It is also possible to customize the salt generation if desired. Customize the Hashing Algorithm If it is necessary to use a more secure hash algorithm, you can provide your own implementation. You can do this by implementing the PasswordEncryptor interface from the org.cibseven.bpm.engine.impl.digest package. The interface ensures that all necessary functions for password hashing are implemented. You can have a look at the classes Base64EncodedHashDigest and ShaHashDigest from the org.cibseven.bpm.engine.impl.digest package to see how this is done in Camunda. A template for your own implementation could look as follows: public class MyPasswordEncryptor implements PasswordEncryptor { @Override public String encrypt(String password) { // do something } @Override public boolean check(String password, String encrypted) { // do something } @Override public String hashAlgorithmName() { // This name is used to resolve the algorithm used for the encryption of a password. return \"NAME_OF_THE_ALGORITHM\"; } } Once this is done, you can use the process engine configuration to plug in the custom implementation by the setting the passwordEncryptor property to your custom implementation, e.g., MyPasswordEncryptor. See Process Engine Bootstrapping on where you have to set the property for your Camunda environment. Note that, even if you have already users created with passwords hashed by other algorithms, e.g., old custom algorithms or the Camunda default hash algorithm SHA-512, they can still automatically be resolved by the engine although you have added your custom algorithm afterwards. The property customPasswordChecker is a list of hashing algorithms to be used to check (older) passwords. The Camunda default hashing algorithms are automatically added, so please only add your previous custom passwordEncryptor implementation to that list. Heads Up! Please do not use your own implementation of a hash function, but rather a standard that has been peer reviewed! Customize the Salt generation Similar to the hashing algorithm, the salt generation can be adjusted. First, implement the SaltGenerator interface from the org.cibseven.bpm.engine.impl.digest. This ensures that all necessary functions are implemented. You can have a look at the classes Base64EncodedSaltGenerator and Default16ByteSaltGenerator from the org.cibseven.bpm.engine.impl.digest package to see how this is done in Camunda. A template for your own implementation could look as follows: public class MyCustomSaltGenerator implements SaltGenerator { @Override public String generateSalt() { // do something } } Once this is done, you can use the process engine configuration to plug in the custom implementation by the setting the saltGenerator property to your custom implementation, e.g., MyCustomSaltGenerator. See Process Engine Bootstrapping on where you have to set the property for your Camunda environment.",
    "url": "/manual/latest/user-guide/process-engine/password-hashing/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/password-policy/index.html",
    "title": "Password Policy | docs.cibseven.org",
    "content": "This chapter is about configuring and using a password policy for engine-managed user accounts. A password policy makes sure that only passwords that meet certain criteria are allowed. A policy can consist of any number of rules. Violation of one of the policy’s rules results in an error and the user not being saved. Since version 7.11.0, the engine comes with a standard password policy that is disabled by default and must be configured to use. Note: This only applies to users that are managed within the CIB seven engine. If you use LDAP for your user management a password policy has no effect on these users. Built-In Password Policy The built-in password policy requires all passwords to meet the following criteria: user data (i.e., user id, first name, last name, email) must not be contained minimum length of 10 characters at least 1 upper case character at least 1 lower case character at least 1 digit at least 1 special character Customize the Password Policy You can use the process engine configuration to enable / disable the password policy or plug in a custom policy. See Process Engine Bootstrapping on how to set properties for your Camunda environment. To enable or disable the password policy checks you need to set the enablePasswordPolicy property. If you want to use a custom password policy you can do this by implementing the PasswordPolicy and PasswordPolicyRule interfaces from the org.cibseven.bpm.engine.identity package and provide your implementation to the process engine configuration by setting the passwordPolicy property. public class MyPasswordPolicy implements PasswordPolicy { @Override public List<PasswordPolicyRule> getRules() { // create rules } } public class MyPasswordPolicyRule implements PasswordPolicyRule { @Override public String getPlaceholder() { // This placeholder can be used to display internationalized error messages. return \"PASSWORD_POLICY_RULE_PLACEHOLDER\"; } @Override public Map<String, String> getParameters() { // These parameters can be injected into error messages. } @Override public boolean execute(String candidatePassword, User user) { // validate the candidate password // return true if valid or false if invalid } } By providing a rule placeholder and parameters via getPlaceholder and getParameters a custom front end can display error messages based on the rules and their configuration. (e.g. “The password must at least have a length of X characters” with X being configurable and passed within the parameter map) A rules execute method checks if the entered password meets this rule or not. It is executed when trying to save a user.",
    "url": "/manual/latest/user-guide/process-engine/password-policy/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/process-diagram-api/index.html",
    "title": "Process Diagram Visualization | docs.cibseven.org",
    "content": "A BPMN process diagram is a formidable place to visualize information around your process. We recommend to use JavaScript libraries to display process diagrams and enrich them with additional information. In our web applications Cockpit and Tasklist, we use bpmn.io, a toolkit for rendering BPMN 2.0 process models directly in the browser. It allows adding additional information to the diagram and includes ways for user interaction. Although bpmn.io is still under development, its API is rather stable. The previous JavaScript BPMN renderer can still be found at camunda-bpmn.js, but it is not actively developed anymore. bpmn.io Diagram Renderer To render a process diagram, you need to retrieve the diagram XML via the Java- or REST API. The following example shows how to render the process XML using bpmn.io. For more documentation regarding the annotation of the diagram and user interaction, please refer to the bpmn.io page. var BpmnViewer = require('bpmn-js'); var xml = getBpmnXml(); // get the process xml via REST var viewer = new BpmnViewer({ container: 'body' }); viewer.importXML(xml, function(err) { if (err) { console.log('error rendering', err); } else { console.log('rendered'); } }); Alternatively, you can use the bpmn-viewer widget from the Camunda commons UI.",
    "url": "/manual/latest/user-guide/process-engine/process-diagram-api/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/process-engine-api/index.html",
    "title": "Process Engine API | docs.cibseven.org",
    "content": "Services API The Java API is the most common way of interacting with the engine. The central starting point is the ProcessEngine, which can be created in several ways as described in the configuration section. From the ProcessEngine, you can obtain the various services that contain the workflow/BPM methods. ProcessEngine and the services objects are thread safe. So you can keep a reference to 1 of those for a whole server. ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); RepositoryService repositoryService = processEngine.getRepositoryService(); RuntimeService runtimeService = processEngine.getRuntimeService(); TaskService taskService = processEngine.getTaskService(); IdentityService identityService = processEngine.getIdentityService(); FormService formService = processEngine.getFormService(); HistoryService historyService = processEngine.getHistoryService(); ManagementService managementService = processEngine.getManagementService(); FilterService filterService = processEngine.getFilterService(); ExternalTaskService externalTaskService = processEngine.getExternalTaskService(); CaseService caseService = processEngine.getCaseService(); DecisionService decisionService = processEngine.getDecisionService(); ProcessEngines.getDefaultProcessEngine() will initialize and build a process engine the first time it is called and afterwards always returns the same process engine. Proper creation and closing of all process engines can be done with ProcessEngines.init() and ProcessEngines.destroy(). The ProcessEngines class will scan for all camunda.cfg.xml and activiti.cfg.xml files. For all camunda.cfg.xml files, the process engine will be built in the typical way: ProcessEngineConfiguration .createProcessEngineConfigurationFromInputStream(inputStream) .buildProcessEngine() For all activiti.cfg.xml files, the process engine will be built in the Spring way: first the Spring application context is created and then the process engine is obtained from that application context. All services are stateless. This means that you can easily run CIB seven on multiple nodes in a cluster, each going to the same database, without having to worry about which machine actually executed previous calls. Any call to any service is idempotent regardless of where it is executed. The RepositoryService is probably the first service needed when working with the CIB seven engine. This service offers operations for managing and manipulating deployments and process definitions. Without going into much detail here, a process definition is the Java counterpart of a BPMN 2.0 process. It is a representation of the structure and behavior of each of the steps of a process. A deployment is the unit of packaging within the engine. A deployment can contain multiple BPMN 2.0 XML files and any other resource. The choice of what is included in one deployment is up to the developer. It can range from a single process BPMN 2.0 XML file to a whole package of processes and relevant resources (for example the deployment ‘hr-processes’ could contain everything related to hr processes). The RepositoryService allows to deploy such packages. Deploying a deployment means it is uploaded to the engine, where all processes are inspected and parsed before being stored in the database. From that point on, the deployment is known to the system and any process included in the deployment can now be started. Furthermore, this service allows to Query on deployments and process definitions known to the engine. Suspend and activate process definitions. Suspending means no further operations can be done on them, while activation is the opposite operation. Retrieve various resources such as files contained within the deployment or process diagrams that were automatically generated by the engine. While the RepositoryService is about static information (i.e., data that doesn’t change, or at least not a lot), the RuntimeService is quite the opposite. It deals with starting new process instances of process definitions. As mentioned above, a process definition defines the structure and behavior of the different steps in a process. A process instance is one execution of such a process definition. For each process definition there are typically many instances running at the same time. The RuntimeService is also the service which is used to retrieve and store process variables. This is data specific to the given process instance and can be used by various constructs in the process (e.g., an exclusive gateway often uses process variables to determine which path is chosen to continue the process). The RuntimeService also allows to query on process instances and executions. Executions are a representation of the ’token’ concept of BPMN 2.0. Basically an execution is a pointer pointing to where the process instance currently is. Lastly, the RuntimeService is used whenever a process instance is waiting for an external trigger and the process needs to be continued. A process instance can have various wait states and this service contains various operations to ‘signal’ the instance that the external trigger is received and the process instance can be continued. Tasks that need to be performed by actual human users of the system are core to the process engine. Everything around tasks is grouped in the TaskService, such as Querying tasks assigned to users or groups. Creating new standalone tasks. These are tasks that are not related to a process instances. Manipulating to which user a task is assigned or which users are in some way involved with the task. Claiming and completing a task. Claiming means that someone decided to be the assignee for the task, meaning that this user will complete the task. Completing means ‘doing the work of the tasks’. Typically this is filling in a form of sorts. The IdentityService is pretty simple. It allows the management (creation, update, deletion, querying, …) of groups and users. It is important to understand that the core engine actually doesn’t do any checking on users at runtime. For example, a task could be assigned to any user, but the engine does not verify if that user is known to the system. This is because the engine can also be used in conjunction with services such as LDAP, Active Directory, etc. The FormService is an optional service. This means that the CIB seven engine can be used perfectly without it, without sacrificing any functionality. This service introduces the concept of a start form and a task form. A start form is a form that is shown to the user before the process instance is started, while a task form is the form that is displayed when a user wants to complete a task. You can define these forms in the BPMN 2.0 process definition. This service exposes this data in an easy way to work with. But again, this is optional as forms don’t need to be embedded in the process definition. The HistoryService exposes all historical data gathered by the engine. When executing processes, a lot of data can be kept by the engine (this is configurable) such as process instance start times, who did which tasks, how long it took to complete the tasks, which path was followed in each process instance, etc. This service exposes mainly query capabilities to access this data. The ManagementService is typically not needed when coding custom applications. It allows to retrieve information about the database tables and table metadata. Furthermore, it exposes query capabilities and management operations for jobs. Jobs are used in the engine for various things such as timers, asynchronous continuations, delayed suspension/activation, etc. Later on, these topics will be discussed in more detail. The FilterService allows to create and manage filters. Filters are stored queries like task queries. For example filters are used by Tasklist to filter user tasks. The ExternalTaskService provides access to external task instances. External tasks represent work items that are processed externally and independently of the process engine. The CaseService is like the RuntimeService but for case instances. It deals with starting new case instances of case definitions and managing the lifecycle of case executions. The service is also used to retrieve and update process variables of case instances. The DecisionService allows to evaluate decisions that are deployed to the engine. It is an alternative to evaluate a decision within a business rule task that is independent from a process definition. Java Docs For more detailed information on the service operations and the engine API, see the Java Docs . Query API To query data from the engine there are multiple possibilities: Java Query API: Fluent Java API to query engine entities (like ProcessInstances, Tasks, …). REST Query API: REST API to query engine entities (like ProcessInstances, Tasks, …). Native Queries: Provide own SQL queries to retrieve engine entities (like ProcessInstances, Tasks, …) if the Query API lacks the possibilities you need (e.g., OR conditions). Custom Queries: Use completely customized queries and an own MyBatis mapping to retrieve own value objects or join engine with domain data. SQL Queries: Use database SQL queries for use cases like Reporting. The recommended way is to use one of the Query APIs. The Java Query API allows to program completely typesafe queries with a fluent API. You can add various conditions to your queries (all of which are applied together as a logical AND) and precisely one ordering. The following code shows an example: List<Task> tasks = taskService.createTaskQuery() .taskAssignee(\"kermit\") .processVariableValueEquals(\"orderId\", \"0815\") .orderByDueDate().asc() .list(); You can find more information on this in the Java Docs . Query Maximum Results Limit Querying for results without restricting the maximum number of results or querying for a vast number of results can lead to a high memory consumption or even to out of memory exceptions. With the help of the Query Maximum Results Limit, you can restrict the maximum number of results. This restriction is only enforced in the following cases: an authenticated user performs the query the query API is directly called e. g. via REST API (no enforcement within a process through Delegation Code) Forbidden Performing a query with an unbounded number of results using the #list() method Performing a Paginated Query that exceeds the configured limit of maximum results Performing a query-based synchronous operation that affects more instances than the limit of maximum results (please use a Batch Operation instead) Allowed Performing a query using the Query#unlimitedList method Performing a Paginated Query with a maximum number of results less or equal to the maximum results limit Performing a Native Query since it is not accessible via REST API or Webapps and therefore not likely to be exploited Limitations Performing a statistics query via REST API Performing a called instance query via Webapps (private API) Custom Identity Service Queries When you provide… a custom identity provider implementation by implementing the interface ReadOnlyIdentityProvider or WritableIdentityProvider AND a dedicated implementation of Identity Service Queries (e. g. GroupQuery, TenantQuery, UserQuery) Make sure to return all results without any limitation when calling Query#unlimitedList. The possibility to retrieve an unlimited list is important to make sure that the REST API works appropriately since a few endpoints rely on retrieving unlimited results. Paginated Queries Pagination allows configuring the maximum results retrieved by a query as well as the position (index) of the first result. Please see the following example: List<Task> tasks = taskService.createTaskQuery() .taskAssignee(\"kermit\") .processVariableValueEquals(\"orderId\", \"0815\") .orderByDueDate().asc() .listPage(20, 50); The query shown above retrieves 50 results starting at the result with the index 20. OR Queries The default behavior of the query API links filter criteria together with an AND expression. OR queries enable building queries in which filter criteria are linked together with an OR expression. Heads-up! This functionality is only available for task and process instance queries (runtime & history). The following methods cannot be applied to an OR query: orderBy…(), initializeFormKeys(), withCandidateGroups(), withoutCandidateGroups(), withCandidateUsers(), withoutCandidateUsers(), incidentIdIn(). After calling or(), a chain of several filter criteria could follow. Each filter criterion is linked together with an OR expression. The invocation of endOr() marks the end of the OR query. Calling these two methods is comparable to putting the filter criteria in brackets. List<Task> tasks = taskService.createTaskQuery() .taskAssignee(\"John Munda\") .or() .taskName(\"Approve Invoice\") .taskPriority(5) .endOr() .list(); The query above retrieves all tasks which are assigned to “John Munda” and simultaneously either named “Approve Invoice” or given the fifth degree of priority (assignee = \"John Munda\" AND (name = \"Approve Invoice\" OR priority = 5), Conjunctive Normal Form). Internally the query is translated to the following SQL query (slightly simplified): SELECT DISTINCT * FROM act_ru_task RES WHERE RES.assignee_ = 'John Munda' AND ( Upper(RES.name_) = Upper('Approve Invoice') OR RES.priority_ = 5 ); An arbitrary amount of OR queries can be used at once. When building a query which consists not only of a single OR query but also of filter criteria linked together with an AND expression, the OR query is appended to the criteria chain by a leading AND expression. A filter criterion related to variables can be applied multiple times within the same OR query: List<Task> tasks = taskService.createTaskQuery() .or() .processVariableValueEquals(\"orderId\", \"0815\") .processVariableValueEquals(\"orderId\", \"4711\") .processVariableValueEquals(\"orderId\", \"4712\") .endOr() .list(); Aside from variable related filter criteria, this behavior differs. Whenever a non-variable-filter-criterion is used more than once inside a query, only the value which was applied last is utilized: List<Task> tasks = taskService.createTaskQuery() .or() .taskCandidateGroup(\"sales\") .taskCandidateGroup(\"controlling\") .endOr() .list(); Heads-up! In the query shown above the value “sales” of the filter criterion taskCandidateGroup is replaced by the value “controlling”. To avoid this behavior, filter criteria with a trailing …In could be used e.g.,: taskCandidateGroupIn() tenantIdIn() processDefinitionKeyIn() REST Query API The Java Query API is exposed as REST service as well, see the REST documentation for details. Native Queries Sometimes you need more powerful queries, e.g., queries using an OR operator or restrictions you can not express using the Query API. For these cases, we introduced native queries, which allow you to write your own SQL queries. The return type is defined by the Query object you use and the data is mapped into the correct objects, e.g., Task, ProcessInstance, Execution, etc. Since the query will be fired at the database you have to use table and column names as they are defined in the database schema. This requires some knowledge about the internal data structure and it is recommended to use native queries with care. The table names can be retrieved via the API to keep the dependency as small as possible. List<Task> tasks = taskService.createNativeTaskQuery() .sql(\"SELECT * FROM \" + managementService.getTableName(Task.class) + \" T WHERE T.NAME_ = #{taskName}\") .parameter(\"taskName\", \"aOpenTask\") .list(); long count = taskService.createNativeTaskQuery() .sql(\"SELECT count(*) FROM \" + managementService.getTableName(Task.class) + \" T1, \" + managementService.getTableName(VariableInstanceEntity.class) + \" V1 WHERE V1.TASK_ID_ = T1.ID_\") .count(); Custom Queries For performance reasons it might sometimes be desirable not to query the engine objects but some own value or DTO objects collecting data from different tables - maybe including your own domain classes. Tutorial Performance Tuning with Custom Queries. SQL Queries The table layout is pretty straightforward - we focused on making it easy to understand. Hence it is OK to do SQL queries for e.g., reporting use cases. Just make sure that you do not mess up the engine data by updating the tables without exactly knowing what you are doing.",
    "url": "/manual/latest/user-guide/process-engine/process-engine-api/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/process-engine-bootstrapping/index.html",
    "title": "Process Engine Bootstrapping | docs.cibseven.org",
    "content": "You have a number of options to configure and create a process engine depending on whether you use an application managed or a shared, container managed process engine. Application Managed Process Engine You manage the process engine as part of your application. The following ways exist to configure it: Programmatically via Java API Via XML configuration Via Spring Shared, Container Managed Process Engine A container of your choice (e.g., Tomcat, Wildfly or IBM WebSphere) manages the process engine for you. The configuration is carried out in a container specific way, see Runtime Container Integration for details. ProcessEngineConfiguration Bean The CIB seven engine uses the ProcessEngineConfiguration bean to configure and construct a standalone Process Engine. There are multiple subclasses available that can be used to define the process engine configuration. These classes represent different environments, and set defaults accordingly. It’s a best practice to select the class that matches (most of) your environment to minimize the number of properties needed to configure the engine. The following classes are currently available: org.cibseven.bpm.engine.impl.cfg.StandaloneProcessEngineConfiguration The process engine is used in a standalone way. The engine itself will take care of the transactions. By default the database will only be checked when the engine boots (an exception is thrown if there is no database schema or the schema version is incorrect). org.cibseven.bpm.engine.impl.cfg.StandaloneInMemProcessEngineConfiguration This is a convenience class for unit testing purposes. The engine itself will take care of the transactions. An H2 in-memory database is used by default. The database will be created and dropped when the engine boots and shuts down. When using this, probably no additional configuration is needed (except, for example, when using the job executor or mail capabilities). org.cibseven.bpm.engine.spring.SpringProcessEngineConfiguration To be used when the process engine is used in a Spring environment. See the Spring integration section for more information. org.cibseven.bpm.engine.impl.cfg.JtaProcessEngineConfiguration To be used when the engine runs in standalone mode, with JTA transactions. Bootstrap a Process Engine Using the Java API You can configure the process engine programmatically by creating the right ProcessEngineConfiguration object or by using some pre-defined one: ProcessEngineConfiguration.createStandaloneProcessEngineConfiguration(); ProcessEngineConfiguration.createStandaloneInMemProcessEngineConfiguration(); Now you can call the buildProcessEngine() operation to create a Process Engine: ProcessEngine processEngine = ProcessEngineConfiguration.createStandaloneInMemProcessEngineConfiguration() .setDatabaseSchemaUpdate(ProcessEngineConfiguration.DB_SCHEMA_UPDATE_FALSE) .setJdbcUrl(\"jdbc:h2:mem:my-own-db;DB_CLOSE_DELAY=1000\") .setJobExecutorActivate(true) .buildProcessEngine(); Configure Process Engine Using camunda cfg XML The easiest way to configure your Process Engine is through an XML file called camunda.cfg.xml. Using that you can simply do: ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine() The camunda.cfg.xml must contain a bean that has the id processEngineConfiguration, select the ProcessEngineConfiguration class best suited to your needs: <bean id=\"processEngineConfiguration\" class=\"org.cibseven.bpm.engine.impl.cfg.StandaloneProcessEngineConfiguration\"> This will look for a camunda.cfg.xml file on the classpath and construct an engine based on the configuration in that file. The following snippet shows an example configuration: <beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"> <bean id=\"processEngineConfiguration\" class=\"org.cibseven.bpm.engine.impl.cfg.StandaloneProcessEngineConfiguration\"> <property name=\"jdbcUrl\" value=\"jdbc:h2:mem:camunda;DB_CLOSE_DELAY=1000\" /> <property name=\"jdbcDriver\" value=\"org.h2.Driver\" /> <property name=\"jdbcUsername\" value=\"sa\" /> <property name=\"jdbcPassword\" value=\"\" /> <property name=\"databaseSchemaUpdate\" value=\"true\" /> <property name=\"jobExecutorActivate\" value=\"false\" /> <property name=\"mailServerHost\" value=\"mail.my-corp.com\" /> <property name=\"mailServerPort\" value=\"5025\" /> </bean> </beans> If no resource camunda.cfg.xml is found, the default engine will search for the file activiti.cfg.xml as a fallback. If both are missing, the engine stops and prints an error message about the missing configuration resource. Note that the configuration XML is in fact a Spring configuration. This does not mean that the CIB seven engine can only be used in a Spring environment! We are simply leveraging the parsing and dependency injection capabilities of Spring internally for building up the engine. The ProcessEngineConfiguration object can also be created programmatically using the configuration file. It is also possible to use a different bean id: ProcessEngineConfiguration.createProcessEngineConfigurationFromResourceDefault(); ProcessEngineConfiguration.createProcessEngineConfigurationFromResource(String resource); ProcessEngineConfiguration.createProcessEngineConfigurationFromResource(String resource, String beanName); ProcessEngineConfiguration.createProcessEngineConfigurationFromInputStream(InputStream inputStream); ProcessEngineConfiguration.createProcessEngineConfigurationFromInputStream(InputStream inputStream, String beanName); It is also possible to not use a configuration file and create a configuration based on defaults (see the different supported classes for more information). ProcessEngineConfiguration.createStandaloneProcessEngineConfiguration(); ProcessEngineConfiguration.createStandaloneInMemProcessEngineConfiguration(); All these ProcessEngineConfiguration.createXXX() methods return a ProcessEngineConfiguration that can further be tweaked if needed. After calling the buildProcessEngine() operation, a ProcessEngine is created as explained above. Configure Process Engine in the bpm-platform.xml The bpm-platform.xml file is used to configure CIB seven in the following distributions: Apache Tomcat IBM WebSphere Application Server Oracle WebLogic Application Server The <process-engine ... /> xml tag allows you to define a process engine: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <bpm-platform xmlns=\"http://www.camunda.org/schema/1.0/BpmPlatform\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.camunda.org/schema/1.0/BpmPlatform http://www.camunda.org/schema/1.0/BpmPlatform\"> <job-executor> <job-acquisition name=\"default\" /> </job-executor> <process-engine name=\"default\"> <job-acquisition>default</job-acquisition> <configuration>org.cibseven.bpm.engine.impl.cfg.StandaloneProcessEngineConfiguration</configuration> <datasource>java:jdbc/ProcessEngine</datasource> <properties> <property name=\"history\">full</property> <property name=\"databaseSchemaUpdate\">true</property> <property name=\"authorizationEnabled\">true</property> </properties> </process-engine> </bpm-platform> See the Deployment Descriptor Reference for complete documentation of the syntax of the bpm-platform.xml file. Configure Process Engine in the processes.xml The process engine can also be configured and bootstrapped using the META-INF/processes.xml file. See Section on processes.xml file for details. See the Deployment Descriptor Reference for complete documentation of the syntax of the processes.xml file.",
    "url": "/manual/latest/user-guide/process-engine/process-engine-bootstrapping/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/process-engine-concepts/index.html",
    "title": "Process Engine Concepts | docs.cibseven.org",
    "content": "This section explains some core process engine concepts that are used in both the process engine API and the internal process engine implementation. Understanding these fundamentals makes it easier to use the process engine API. Process Definitions A process definition defines the structure of a process. You could say that the process definition is the process. CIB seven uses BPMN 2.0 as its primary modeling language for modeling process definitions. BPMN 2.0 Reference CIB seven comes with two BPMN 2.0 References: The BPMN 2.0 Modeling Reference introduces the fundamentals of BPMN 2.0 and helps you to get started modeling processes. (Make sure to read the Tutorial as well.) The BPMN 2.0 Implementation Reference covers the implementation of the individual BPMN 2.0 constructs CIB seven. You should consult this reference if you want to implement and execute BPMN processes. In CIB seven you can deploy processes to the process engine in BPMN 2.0 XML format. The XML files are parsed and transformed into a process definition graph structure. This graph structure is executed by the process engine. Query for Process Definitions You can query for all deployed process definitions using the Java API and the ProcessDefinitionQuery made available through the RepositoryService. Example: List<ProcessDefinition> processDefinitions = repositoryService.createProcessDefinitionQuery() .processDefinitionKey(\"invoice\") .orderByProcessDefinitionVersion() .asc() .list(); The above query returns all deployed process definitions for the key invoice ordered by their version property. You can also query for process definitions using the REST API. Keys and Versions The key of a process definition (invoice in the example above) is the logical identifier of the process. It is used throughout the API, most prominently for starting process instances (see section on process instances). The key of a process definition is defined using the id property of the corresponding <process ... > element in the BPMN 2.0 XML file: <process id=\"invoice\" name=\"invoice receipt\" isExecutable=\"true\"> ... </process> If you deploy multiple processes with the same key, they are treated as individual versions of the same process definition by the process engine. Please refer to Process Versioning for details. Suspend Process Definitions Suspending a process definition disables it temporarily, i.e., it cannot be instantiated while it is suspended. The RuntimeService Java API can be used to suspend a process definition. Similarly, you can activate a process definition to undo this effect. Process Instances A process instance is an individual execution of a process definition. The relation of the process instance to the process definition is the same as the relation between Object and Class in Object Oriented Programming (the process instance playing the role of the object and the process definition playing the role of the class in this analogy). The process engine is responsible for creating process instances and managing their state. If you start a process instance which contains a wait state, for example a user task, the process engine must make sure that the state of the process instance is captured and stored inside a database until the wait state is left (the user task is completed). Start a Process Instance The simplest way to start a process instance is by using the startProcessInstanceByKey(...) method offered by the RuntimeService: ProcessInstance instance = runtimeService.startProcessInstanceByKey(\"invoice\"); You may optionally pass in a couple of variables: Map<String, Object> variables = new HashMap<String,Object>(); variables.put(\"creditor\", \"Nice Pizza Inc.\"); ProcessInstance instance = runtimeService.startProcessInstanceByKey(\"invoice\", variables); Process variables are available to all tasks in a process instance and are automatically persisted to the database in case the process instance reaches a wait state. It is also possible to start a process instance using the REST API. Start Process Instances via Tasklist In case you use Tasklist to start process instances, the startableInTasklist option exists to specify which processes are visible for being started by the user. For instance, this could be sensible for a subprocess: if it should only be possible to start the super process but not the subprocess, adjust the process xml file (*.bpmn) as follows: <process id=\"subProcess\" name=\"Process called from Super Process\" isExecutable=\"true\" camunda:isStartableInTasklist=\"false\"> ... </process> Start a Process Instance at Any Set of Activities The startProcessInstanceByKey and startProcessInstanceById methods start the process instance at their default initial activity, which is typically the single blank start event of the process definition. It is also possible to start anywhere in a process instance by using the fluent builder for process instances. The fluent builder can be accessed via the RuntimeService methods createProcessInstanceByKey and createProcessInstanceById. The following starts a process instance before the activity SendInvoiceReceiptTask and the embedded sub process DeliverPizzaSubProcess: ProcessInstance instance = runtimeService.createProcessInstanceByKey(\"invoice\") .startBeforeActivity(\"SendInvoiceReceiptTask\") .setVariable(\"creditor\", \"Nice Pizza Inc.\") .startBeforeActivity(\"DeliverPizzaSubProcess\") .setVariableLocal(\"destination\", \"12 High Street\") .execute(); The fluent builder allows to submit any number of so-called instantiation instructions. When calling execute, the process engine performs these instructions in the order they are specified. In the above example, the engine first starts the task SendInvoiceReceiptTask and executes the process until it reaches a wait state and then starts DeliverPizzaTask and does the same. After these two instructions, the execute call returns. Variables in Return To access the latest variables which was used by the process instance during execution the executeWithVariablesInReturn can be used, instead of the execute method. See the following example: ProcessInstanceWithVariables instance = runtimeService.createProcessInstanceByKey(\"invoice\") .startBeforeActivity(\"SendInvoiceReceiptTask\") .setVariable(\"creditor\", \"Nice Pizza Inc.\") .startBeforeActivity(\"DeliverPizzaSubProcess\") .setVariableLocal(\"destination\", \"12 High Street\") .executeWithVariablesInReturn(); The executeWithVariablesInReturn returns if the process instance ends or reaches a wait state. The returned ProcessInstanceWithVariables object contains the informations of the process instance and the latest variables. Query for Process Instances You can query for all currently running process instances using the ProcessInstanceQuery offered by the RuntimeService: runtimeService.createProcessInstanceQuery() .processDefinitionKey(\"invoice\") .variableValueEquals(\"creditor\", \"Nice Pizza Inc.\") .list(); The above query would select all process instances for the invoice process where the creditor is Nice Pizza Inc.. You can also query for process instances using the REST API. Interact With a Process Instance Once you have performed a query for a particular process instance (or a list of process instances), you may want to interact with it. There are multiple possibilities to interact with a process instance, most prominently: Triggering it (make it continue execution): Through a Message Event Through a Signal Event Canceling it: Using the RuntimeService.deleteProcessInstance(...) method. Starting/Canceling any activity: Using the process instance modification feature If your process uses at least one User Task, you can also interact with the process instance using the TaskService API. Suspend Process Instances Suspending a process instance is helpful, if you want ensure that it is not executed any further. For example, if process variables are in an undesired state, you can suspend the instance and change the variables safely. In detail, suspension means to disallow all actions that change token state (i.e., the activities that are currently executed) of the instance. For example, it is not possible to signal an event or complete a user task for a suspended process instance, as these actions will continue the process instance execution subsequently. Nevertheless, actions like setting or removing variables are still allowed, as they do not change the token state. Also, when suspending a process instance, all tasks belonging to it will be suspended. Therefore, it will no longer be possible to invoke actions that have effects on the task’s lifecycle (i.e., user assignment, task delegation, task completion, …). However, any actions not touching the lifecycle like setting variables or adding comments will still be allowed. A process instance can be suspended by using the suspendProcessInstanceById(...) method of the RuntimeService. Similarly it can be reactivated again. If you would like to suspend all process instances of a given process definition, you can use the method suspendProcessDefinitionById(...) of theRepositoryService and specify the suspendProcessInstances option. Executions If your process instance contains multiple execution paths (like for instance after a parallel gateway, you must be able to differentiate the currently active paths inside the process instance. In the following example, two user tasks receive payment and ship order can be active at the same time. Internally, the process engine creates two concurrent executions inside the process instance, one for each concurrent path of execution. Executions are also created for scopes, for example if the process engine reaches a Embedded Sub Process or in case of Multi Instance. Executions are hierarchical and all executions inside a process instance span a tree, the process instance being the root-node in the tree. Note: the process instance itself is an execution. Executions are variable scopes, meaning that dynamic data can be associated with them. Query for Executions You can query for executions using the ExecutionQuery offered by the RuntimeService: runtimeService.createExecutionQuery() .processInstanceId(someId) .list(); The above query returns all executions for a given process instance. You can also query for executions using the REST API. Activity Instances The activity instance concept is similar to the execution concept but takes a different perspective. While an execution can be imagined as a token moving through the process, an activity instance represents an individual instance of an activity (task, subprocess, …). The concept of the activity instance is thus more state-oriented. Activity instances also span a tree, following the scope structure provided by BPMN 2.0. Activities that are “on the same level of subprocess” (i.e., part of the same scope, contained in the same subprocess) will have their activity instances at the same level in the tree. For example, Activity Instances are used for Process Instance Modification and the Activity Instance Tree in Cockpit. Examples: Process with two parallel user tasks after parallel Gateway: ProcessInstance receive payment ship order Process with two parallel Multi-Instance user tasks after parallel Gateway: ProcessInstance receive payment - Multi-Instance Body receive payment receive payment ship order - Multi-Instance Body ship order Note: a multi-instance activity consists of a multi-instance body and an inner activity. The multi-instance body is a scope around the inner activity and collects the activity instances of the inner activity. User Task inside an embedded subprocess: ProcessInstance Subprocess receive payment Process with thrown compensation event after user task: ProcessInstance cancel order cancel shipping Retrieve an Activity Instance Currently, activity instances can only be retrieved for a process instance: ActivityInstance rootActivityInstance = runtimeService.getActivityInstance(processInstance.getProcessInstanceId()); You can retrieve the activity instance tree using the REST API as well. Identity & Uniqueness Each activity instance is assigned a unique ID. The ID is persistent, if you invoke this method multiple times, the same activity instance IDs will be returned for the same activity instances. (However, there might be different executions assigned, see below) Relation to Executions The Execution concept in the process engine is not completely aligned with the activity instance concept because the execution tree is generally not aligned with the activity / scope concept in BPMN. In general, there is a n-1 relationship between Executions and ActivityInstances, i.e., at a given point in time, an activity instance can be linked to multiple executions. In addition, it is not guaranteed that the same execution that started a given activity instance will also end it. The process engine performs several internal optimizations concerning the compacting of the execution tree which might lead to executions being reordered and pruned. This can lead to situations where a given execution starts an activity instance but another execution ends it. Another special case is the process instance: if the process instance is executing a non-scope activity (for example a user task) below the process definition scope, it will be referenced by both the root activity instance and the user task activity instance. Note: If you need to interpret the state of a process instance in terms of a BPMN process model, it is usually easier to use the activity instance tree as opposed to the execution tree. Jobs and Job Definitions The Camunda process engine includes a component named the Job Executor. The Job Executor is a scheduling component, responsible for performing asynchronous background work. Consider the example of a Timer Event: whenever the process engine reaches the timer event, it will stop execution, persist the current state to the database and create a job to resume execution in the future. A job has a due date which is calculated using the timer expression provided in the BPMN XML. When a process is deployed, the process engine creates a Job Definition for each activity in the process which will create jobs at runtime. This allows you to query information about timers and asynchronous continuations in your processes. Query for jobs Using the management service, you can query for jobs. The following selects all jobs which are due after a certain date: managementService.createJobQuery() .duedateHigherThan(someDate) .list() It is possible to query for jobs using the REST API. Query for Job Definitions Using the management service, you can also query for job definitions. The following selects all job definitions from a specific process definition: managementService.createJobDefinitionQuery() .processDefinitionKey(\"orderProcess\") .list() The result will contain information about all timers and asynchronous continuations in the order process. It is also possible to query for job definitions using the REST API. Suspend and Activate Job Execution Job suspension prevents jobs from being executed. Suspension of job execution can be controlled on different levels: Job Instance Level: individual Jobs can be suspended either directly through the managementService.suspendJob(...) API or transitively when suspending a Process Instance or a Job Definition. Job Definition Level: all instances of a certain Timer or Activity can be suspended. Job suspension by Job Definition allows you to suspend all instances of a certain timer or an asynchronous continuation. Intuitively, this allows you to suspend a certain activity in a process in a way that all process instances will advance until they have reached this activity and then not continue since the activity is suspended. Let’s assume there is a process deployed with key orderProcess, which contains a service task named processPayment. The service task has an asynchronous continuation configured which causes it to be executed by the job executor. The following example shows how you can prevent the processPayment service from being executed: List<JobDefinition> jobDefinitions = managementService.createJobDefinitionQuery() .processDefinitionKey(\"orderProcess\") .activityIdIn(\"processPayment\") .list(); for (JobDefinition jobDefinition : jobDefinitions) { managementService.suspendJobDefinitionById(jobDefinition.getId(), true); }",
    "url": "/manual/latest/user-guide/process-engine/process-engine-concepts/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/process-engine-plugins/index.html",
    "title": "Process Engine Plugins | docs.cibseven.org",
    "content": "The process engine configuration can be extended through process engine plugins. A process engine plugin is an extension to the process engine configuration. A plugin must provide an implementation of the ProcessEnginePlugin interface. Configure Process Engine Plugins Process engine plugins can be configured in the Camunda Deployment Descriptors (bpm-platform.xml/processes.xml), in the Wildfly configuration file (standalone.xml/domain.xml), using Spring Beans XML, in the CIB seven Run YAML configuration files programatically. The following is an example of how to configure a process engine plugin in a bpm-platform.xml file: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <bpm-platform xmlns=\"http://www.camunda.org/schema/1.0/BpmPlatform\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.camunda.org/schema/1.0/BpmPlatform http://www.camunda.org/schema/1.0/BpmPlatform \"> <job-executor> <job-acquisition name=\"default\" /> </job-executor> <process-engine name=\"default\"> <job-acquisition>default</job-acquisition> <configuration>org.cibseven.bpm.engine.impl.cfg.JtaProcessEngineConfiguration</configuration> <datasource>jdbc/ProcessEngine</datasource> <plugins> <plugin> <class>org.cibseven.bpm.engine.MyCustomProcessEnginePlugin</class> <properties> <property name=\"boost\">10</property> <property name=\"maxPerformance\">true</property> <property name=\"actors\">akka</property> </properties> </plugin> </plugins> </process-engine> </bpm-platform> A process engine plugin class must be visible to the classloader which loads the process engine classes. List of Built-In Process Engine Plugins The following is a list of built-in process engine plugins: LDAP Identity Service Plugin Administrator Authorization Plugin Process Application Event Listener Plugin",
    "url": "/manual/latest/user-guide/process-engine/process-engine-plugins/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/process-instance-migration/index.html",
    "title": "Process Instance Migration | docs.cibseven.org",
    "content": "Whenever a new version of a process definition is deployed, existing process instances that run on previous versions are not affected. That means, the new process definition does not apply to them automatically. If process instances are supposed to continue execution on a different process definition, the process instance migration API can be employed. Migration consists of two parts: Creating a migration plan that describes how process instances are to be migrated from one process definition to another Applying the migration plan to a set of process instances A migration plan consists of a set of migration instructions that in essence are mappings between activities of the two process definitions. In particular, it maps an activity of the source process definition, i.e., the definition process instances are migrated from, to an activity of the target process definition, i.e., the definition process instances are migrated to. A migration instruction ensures that an instance of the source activity is migrated into an instance of the target activity. A migration plan is complete when there are instructions for all active source activities. Migration instructions have the purpose to map semantically equivalent activities. In consequence, migration interferes with activity instance state as little as possible which ensures a seamless transition. For example, this means that a migrated user task instance is not re-assigned. From the assignee’s point of view, migration is mostly transparent, so that a task that was started before migration can be completed successfully after migration. The same principle is applied to the other BPMN element types. For cases in which activities are not semantically equivalent, we recommend combining migration with the process instance modification API, e.g., canceling an activity instance before migration and starting a new instance after migration. In the remainder of this section, the following process models are used to illustrate the API and effects of migration unless otherwise noted: Process exampleProcess:1: Process exampleProcess:2: Process Instance Migration by Example We can define a migration plan using the API entrance point RuntimeService#createMigrationPlan. It returns a fluent builder to create a migration plan. For our example, the code looks like: MigrationPlan migrationPlan = processEngine.getRuntimeService() .createMigrationPlan(\"exampleProcess:1\", \"exampleProcess:2\") .mapActivities(\"assessCreditWorthiness\", \"assessCreditWorthiness\") .mapActivities(\"validateAddress\", \"validatePostalAddress\") .mapActivities(\"archiveApplication\", \"archiveApplication\") .build(); The mapActivities invocations each specify a migration instruction and express that instances of the first activity should become instances of the second activity. Let us assume that we have a process instance in the following activity instance state: ProcessInstance ├── Archive Application └── Assess Credit Worthiness └── Validate Address In order to migrate this process instance according to the defined migration plan, the API method RuntimeService#newMigration can be used: MigrationPlan migrationPlan = ...; List<String> processInstanceIds = ...; runtimeService.newMigration(migrationPlan) .processInstanceIds(processInstanceIds) .execute(); The resulting activity instance state is: ProcessInstance ├── Handle Application Receipt │ └── Archive Application └── Assess Credit Worthiness └── Validate Postal Address The following things have happened: An instance of the embedded subprocess Handle Application Receipt was added to reflect the new sub process in exampleProcess:2 The activity instances for Archive Application, Assess Credit Worthiness, and Validate Postal Address have been migrated What does the second point mean in particular? Since there is a migration instruction for these activity instances they are migrated. The entities that comprise this instance are updated to reference the new activity and process definition. Besides that, activity instances, task instances and variable instances are preserved. Before migration, there was a task instance in the tasklist of an accountant to perform the Validate Address activity. After migration, the same task instance still exists and can be completed successfully. It still has the same properties such as assignee or name. From the accountant’s perspective, migration is completely transparent while working on a task. API The following gives a structured overview of the Java API for process instance migration. Note that these operations are also available via REST. Creating a Migration Plan A migration plan can be created by using the API RuntimeService#createMigrationPlan. It defines how migration should be performed. A migration plan contains the IDs of the source and target process definition as well as a list of migration instructions. A migration instruction is a mapping from activities in the source process definition to activities in the target process definition. For example, the following code creates a valid migration plan: MigrationPlan migrationPlan = processEngine.getRuntimeService() .createMigrationPlan(\"exampleProcess:1\", \"exampleProcess:2\") .mapActivities(\"assessCreditWorthiness\", \"assessCreditWorthiness\") .mapActivities(\"validateAddress\", \"validatePostalAddress\") .build(); All activities can be mapped. Migration instructions must map between activities of the same type. Supported activity relationships are: One-to-one relation A migration plan is validated after creation to detect migration instructions that are not supported by the process engine. See the chapter on creation time validation for details. In addition, a migration plan is validated before execution to ensure that it can be applied to a specific process instance. For example, migration instructions for some activity types are only supported for transition instances (i.e., active asynchronous continuations) but not for activity instances. See the chapter on execution time validation for details. Validation Limitations The process engine can only validate that the process model can be migrated. But there are other aspects the user has to care about. You can read more about this in the section about aspects not covered by validation. One-to-One Relation Instruction MigrationPlanBuilder#mapActivities(String sourceActivityId, String targetActivityId) Defining a one-to-one relation instruction means that an instance of the source activity is migrated into an instance of the target activity. Activity instance, task instance and variable instance state is preserved when migration is executed. Updating Event Triggers When migrating events, it is possible to decide whether the corresponding event triggers should be updated or not. See the BPMN-specific considerations on events for details. When generating a migration plan, it is possible to define this setting for generated instructions on User Tasks containing timeout task listeners and between events by using the method updateEventTrigger. For example, the following code generates a migration instruction for a boundary event and updates its event trigger during migration. Conditional Events For conditional events the #updateEventTrigger is mandatory. MigrationPlan migrationPlan = processEngine.getRuntimeService() .createMigrationPlan(\"exampleProcess:1\", \"exampleProcess:2\") .mapActivities(\"userTask\", \"userTask\") .mapActivities(\"boundary\", \"boundary\") .updateEventTrigger() .build(); Set Variables to Process Instances Sometimes it is necessary to add variables after migrating the process instances to a new version of the process definition. For example, when the new process model has a new input mapping which requires a specific variable which isn’t yet present in the migrated process instance. The variables are set to the process instances’ scope. Please see below how to call the Java API: Map<String, Object> variables = Variables.putValue(\"my-variable\", \"my-value\"); MigrationPlan migrationPlan = processEngine.getRuntimeService() .mapEqualActivities() .setVariables(variables) .build(); Known Limitation Currently, it is not possible to set transient variables asynchronously. However, you can set transient variables synchronously. Generating a migration plan In addition to manually specifying all migration instructions, the MigrationPlanBuilder is able to generate migration instructions for all equal activities in the source and target process definitions. This can reduce the effort for creating a migration to only those activities that are not equal. Equality of a pair of activities is defined as follows: They are of the same activity type They have the same ID They belong to the same scope, i.e., their parent BPMN scopes are equal according to this definition. Process definitions are always equal. For example, consider the following code snippet: MigrationPlan migrationPlan = processEngine.getRuntimeService() .createMigrationPlan(\"exampleProcess:1\", \"exampleProcess:2\") .mapEqualActivities() .mapActivities(\"validateAddress\", \"validateProcessAddress\") .build(); It creates generated migration instructions for the equal activities assessCreditWorthiness. It adds an additional mapping from validateAddress to validateProcessAddress. Updating Event Triggers Like for individual instructions, it is possible to specify the event trigger update flag for generated migration instructions by using the updateEventTriggers method. This is equal to calling updateEventTrigger on all event migration instructions which are generated. MigrationPlan migrationPlan = processEngine.getRuntimeService() .createMigrationPlan(\"exampleProcess:1\", \"exampleProcess:2\") .mapEqualActivities() .updateEventTriggers() .build(); Executing a migration plan Migration plans can be applied to a set of process instances of the source process definition by using the API Method RuntimeService#newMigration. The migration can either be executed synchronously (blocking) or asynchronously (non-blocking) using a batch. The following are some reasons to prefer either one or the other: Use synchronous migration if: the number of process instances is small the migration should be atomic, i.e., it should be executed immediately and should fail if at least one process instance cannot be migrated Use asynchronous migration if: the number of process instances is large all process instances should be migrated decoupled from the other instances, i.e., every instance is migrated in its own transaction the migration should be executed by another thread, i.e., the job executor should handle the execution Selecting process instances to migrate Process instances can be selected for migration by either providing a set of process instance IDs or providing a process instance query. It is also possible to specify both, a list of process instance IDs and a query. The process instances to be migrated will then be the union of the resulting sets. List of process instances The process instances which should be migrated by a migration plan can either be specified as a list of the process instance IDs: MigrationPlan migrationPlan = ...; List<String> processInstanceIds = ...; runtimeService.newMigration(migrationPlan) .processInstanceIds(processInstanceIds) .execute(); For a static number of process instances, there is a convenience varargs method: MigrationPlan migrationPlan = ...; ProcessInstance instance1 = ...; ProcessInstance instance2 = ...; runtimeService.newMigration(migrationPlan) .processInstanceIds(instance1.getId(), instance2.getId()) .execute(); Process Instance Query If the instances are not known beforehand, the process instances can be selected by a process instance query: MigrationPlan migrationPlan = ...; ProcessInstanceQuery processInstanceQuery = runtimeService .createProcessInstanceQuery() .processDefinitionId(migrationPlan.getSourceProcessDefinitionId()); runtimeService.newMigration(migrationPlan) .processInstanceQuery(processInstanceQuery) .execute(); Skipping Listeners and Input/Output Mappings During migration, activity instances may end or new activity instances may emerge. Per default, their activities’ execution listeners and input/output mappings are going to be invoked as appropriate. This may not always be the desired behavior. For example, if an execution listener expects the existence of a variable to function properly but that variable does not exist in instances of the source process definition, then skipping listener invocation can be useful. In the API, the two methods #skipCustomListeners and #skipIoMappings can be used for this purpose: MigrationPlan migrationPlan = ...; List<String> processInstanceIds = ...; runtimeService.newMigration(migrationPlan) .processInstanceIds(processInstanceIds) .skipCustomListeners() .skipIoMappings() .execute(); Synchronous migration execution To execute the migration synchronously, the execute method is used. It will block until the migration is completed. MigrationPlan migrationPlan = ...; List<String> processInstanceIds = ...; runtimeService.newMigration(migrationPlan) .processInstanceIds(processInstanceIds) .execute(); Migration is successful if all process instances can be migrated. Confer the chapter on validation to learn which kind of validation is performed before a migration plan is executed. Asynchronous batch migration execution To execute the migration asynchronously, the executeAsync method is used. It will return immediately with a reference to the batch which executes the migration. MigrationPlan migrationPlan = ...; List<String> processInstanceIds = ...; Batch batch = runtimeService.newMigration(migrationPlan) .processInstanceIds(processInstanceIds) .executeAsync(); Using a batch, the process instance migration is split into several jobs which are executed asynchronously. These batch jobs are executed by the job executor. See the batch section for more information. A batch is completed if all batch execution jobs are successfully completed. However, in contrast to the synchronous migration, it is not guaranteed that either all or no process instances are migrated. As the migration is split into several independent jobs, every single job may fail or succeed. If a migration job fails, it is retried by the job executor and if no retries are left, an incident is created. In this case, manual action is necessary to complete the batch migration: The job’s retries can be incremented or the job can be deleted. Deletion cancels migration of the specific instance but does not affect the batch beyond that. Batch migration in a heterogeneous cluster As described in the job executor section of the user guide, the process engine can be used in a heterogeneous cluster where deployments are unevenly distributed across cluster nodes. The deployment-aware job executor only executes jobs for deployments registered with it. In a heterogeneous cluster, this avoids problems with accessing deployment resources. When executing a migration batch, the batch execution jobs are therefore restricted to the job executor that has a registration for the deployment of the source process definition. This introduces the requirement that source and target deployment are registered with the same job executor or else migration may fail when executing custom code (e.g., execution listeners) in the context of the target process. Note that it is also possible to skip the execution of custom code during migration. BPMN-specific API and Effects Depending on the type of the activities a process model contains, migration has varying effects. Tasks User Task When a user task is migrated, all properties of the task instance (i.e., org.cibseven.bpm.engine.task.Task) are preserved apart from the process definition id and task definition key. The task is not reinitialized: Attributes like assignee or name do not change. Timeout Task Listeners User tasks with attached task listeners of event type timeout define persistent event triggers that can be updated or preserved during migration. For the associated timers, the considerations of catching events apply here as well. On migration of the user task, the following semantics are applied: If a timeout task listener is found in the source and target process definition based on its id, its persistent event trigger (i.e. timer) is migrated If a timeout task listener in the source process definition is not found in the target definition based on its id, then its event trigger is deleted during migration If a timeout task listener of the target definition is not the target of a migration instruction, then a new event trigger is initialized during migration Receive Task A receive task defines a persistent event trigger that can be updated or preserved during migration. The considerations for intermediate catch events apply here as well. External Task When an active external task is migrated, all properties of the external task instance (i.e., org.cibseven.bpm.engine.externaltask.ExternalTask) are preserved apart from activity id, process definition key, and process definition id. In particular, this means that attributes like topic and lock state do not change. It is possible to map activities that are implemented as external tasks to each other even if they have different types. For example, an external send task can be mapped to an external service task. Gateways Inclusive & Parallel Gateway Instances of inclusive and parallel gateways represent waiting tokens before the gateway is able to trigger. They can be migrated to a gateway of the same type in the target process by supplying a migration instruction. In addition, the following conditions must hold: The target gateway must have at least the same number of incoming sequence flows as the source gateway There must be a valid migration instruction for the scope in which the gateway is contained in At most one gateway of the source process definition can be mapped to every gateway in the target process definition Event-based Gateway To migrate an event-based gateway instance, a migration instruction to another event-based gateway must be part of the migration plan. In order to migrate the gateway’s event triggers (event subscriptions, jobs), the events following to the gateway can be mapped as well. See the events section for the semantics of instructions between events. Events For all kinds of catching events (start, intermediate, boundary), a migration instruction can be supplied if they define a persistent event trigger. This is the case for message, conditional, timer, and signal events. When mapping events, there are two configuration options: The event trigger remains the same: Even if the target event defines a different trigger (e.g., changed timer configuration), the migrated event instance is triggered according to the source definition. This is the default behavior when calling migrationBuilder.mapActivities(\"sourceTask\", \"targetTask\") The event trigger is updated: The migrated event instance is triggered according to the target definition. This behavior can be specified by calling migrationBuilder.mapActivities(\"sourceTask\", \"targetTask\").updateEventTrigger() Timer Events Using #updateEventTrigger with a timer event does not take into account that a certain amount of time has already elapsed before migration. In consequence, the event trigger is reset according to the target event. Consider the following two processes where the configuration of the boundary event changes: Process timerBoundary:1: Process timerBoundary:2: Specifying the instruction migrationBuilder.mapActivities(\"timer\", \"timer\").updateEventTrigger() is going to reinitialize the timer job. In effect, the boundary event fires ten days after migration. In contrast, if updateEventTrigger is not used, then the timer job configuration is preserved. In effect, it is going to trigger five days after the activity was started regardless of when the migration is performed. Conditional Events The usage of #updateEventTrigger is mandatory for migrating conditional events. The condition is overridden by the condition of the new conditional event. Boundary Event Boundary events can be mapped from the source to the target process definition along with the activity that they are attached to. The following applies: If a boundary event is mapped, its persistent event trigger (for timers, conditionals, messages, and signals) is migrated If a boundary event in the source process definition is not mapped, then its event trigger is deleted during migration If a boundary event of the target definition is not the target of a migration instruction, then a new event trigger is initialized during migration Start Event Start events of event sub processes can be mapped from source to target with similar semantics as boundary events. In particular: If a start event is mapped, its persistent event trigger (for timers, conditionals, messages, and signals) is migrated If a start event in the source process definition is not mapped, then its event trigger is deleted during migration If a start event of the target definition is not the target of a migration instruction, then a new event trigger is initialized during migration Intermediate Catch Event Intermediate catch events must be mapped if a process instance is waiting for that event during migration. Compensation Event Migrating Compensation Events When migrating process instances with active compensation subscriptions, the following rules apply: The corresponding compensation catch events must be mapped After migration, compensation can be triggered from the same migrated scope as before migration or its closest migrated ancestor In order to preserve the variable snapshots of parent scopes, those scopes must be mapped as well. Process instances with active compensation subscriptions can be migrated by mapping the corresponding catching compensation events. This tells the migration API which compensation handler of the source process model corresponds to which handler in the target process model. Consider this source process: And this target process: Assume a process instance in the following state: ProcessInstance └── Assess Credit Worthiness The process instance has a compensation subscription for Archive Application. A valid migration plan must therefore contain a mapping for the compensation boundary event. For example: MigrationPlan migrationPlan = processEngine.getRuntimeService() .createMigrationPlan(\"compensationProcess:1\", \"compensationProcess:2\") .mapActivities(\"archiveApplication\", \"archiveApplication\") .mapActivities(\"compensationBoundary\", \"compensationBoundary\") .build(); After migration, compensation can be triggered from the same scope as before migration (or in case that scope is removed, the closest ancestor scope that migrates). For illustration, consider the following source process: And this target process: When migrating the same process instance state as in the above example, the inner compensation event is not going to trigger compensation of the Archive Application activity but only the outer compensation event. Active Compensation Migrating process instances with active compensation handlers is not supported yet. Adding Compensation Events New compensation boundary events contained in the target process definition only take effect for activity instances that are not started or not finished yet. For example, consider the following two processes: Process compensation:1: Process compensation:2: Furthermore, assume that before migration a process instance is in the following state: ProcessInstance └── Assess Credit Worthiness If this process instance is migrated (with Assess Credit Worthiness being mapped to its equivalent), then triggering compensation afterwards is not going to compensate Archive Application. Subprocess If a migration instruction applies to an embedded/event/transaction sub process, it is migrated to its target sub process in the target process definition. This preserves sub process state such as variables. In case no instruction applies, the instance is cancelled before migration is performed. Should the target process definition contain new sub processes that no existing instance migrates to, then these are instantiated as needed during migration. Embedded/Event/Transaction sub processes can be mapped interchangeably. For example, it is possible to map an embedded sub process to an event sub process. Call Activity Call activities are migrated like any other activity. The called instance, be it a BPMN process or a CMMN case, is not changed. It can be migrated separately. Flow Node Markers Multi-Instance Active multi-instance activities can be migrated if the target activity is multi-instance of the same type (parallel or sequential) the target activity is not a multi-instance activity. Migrating a Multi-instance Activity When migrating instances of a multi-instance activity to another multi-instance activity, the migration plan needs to contain two instructions: One for the inner activity, i.e., the activity that has multi-instance loop characteristics. And another one for the multi-instance body. The body is a BPMN scope that contains the inner activity and that is not visually represented. By convention, it has the id <id of inner activity>#multiInstanceBody. When migrating a multi-instance body and its inner activity, the multi-instance state is preserved. That means, if a parallel multi-instance activity is migrated with two instances out of five being active, then the state is the same after migration. Removing a Multi-Instance Marker If the target activity is not a multi-instance activity, it is sufficient to have an instruction for the inner activity. During migration, the multi-instance variables nrOfInstances, nrOfActiveInstances and nrOfCompletedInstances are removed. The number of inner activity instances is preserved. That means, if there are two out of five active instances before migration, then there are going to be two instances of the target activity after migration. In addition, their loopCounter and collection element variables are kept. Asynchronous Continuations When an asynchronous continuation is active, i.e., the corresponding job has not been completed by the job executor yet, it is represented in the form of a transition instance. For example, this is the case when job execution failed and an incident has been created. For transition instances the mapping instructions apply just like for activity instances. That means, when there is an instruction from activity userTask to activity newUserTask, all transition instances that represent an asynchronous continuation before or after userTask are migrated to newUserTask. In order for this to succeed, the target activity must be asynchronous as well. Limitation with asyncAfter When migrating a transition instance that represents an asynchronous continuation after an activity, migration is only successful if the following limitations hold: If the source activity has no outgoing sequence flow, the target activity must not have more than one outgoing sequence flow If the source activity has outgoing sequence flows, the target activity must have sequence flows with the same IDs or must have not more than one outgoing sequence flow. This also applies if the source activity has a single sequence flow. Operational Semantics In the following, the exact semantics of migration are documented. Reading this section is recommended to fully understand the effects, power, and limitations of process instance migration. Migration Procedure Migration of a process instance follows these steps: Assignment of migration instructions to activity instances Validation of the instruction assignment Cancellation of unmapped activity instances and event handler entities Migration of mapped activity instances and their dependent instances, instantiation of newly introduced BPMN scopes, and handler creation for newly introduced events Assignment of Migration Instructions In the first step, migration instructions are assigned to activity instances of a process instance that is going to be migrated. Validation of Instruction Assignment The created assignment must be executable by the migration logic which is ensured by the validation step. In particular, the following conditions must hold: Exactly one instruction must apply to a leaf activity instance (e.g., user task) At most one instruction must apply to a non-leaf activity instance (e.g., embedded subprocess) The overall assignment must be executable. See the validation chapter for details. Cancellation of Unmapped Activity Instances and Event-Handler Entities Non-leaf activity instances to which no migration instructions apply are cancelled. Event handler entities (e.g., message event subscriptions or timer jobs) are removed when their BPMN elements (e.g., boundary events) are not migrated. Cancellation is performed before any migration instruction is applied, so the process instance is still in the pre-migration state. The semantics are: The activity instance tree is traversed in a bottom-up fashion and unmapped instances are cancelled Activity instance cancellation invokes the activity’s end execution listeners and output variable mappings Migration/Creation of Activity Instances Finally, activity instances are migrated and new ones are created as needed. The semantics are: The activity instance tree is traversed in a top-down fashion If an activity instance is migrated into a BPMN scope to which no parent activity instance is migrated, then a new activity instance is created Creation invokes the activity’s start execution listeners and input variable mappings An activity instance is migrated according to its assigned migration instruction Activity instance migration Migrating an activity instance updates the references to the activity and process definition in the activity instance tree and its execution representation. Furthermore, it migrates or removes dependent instances that belong to the activity instance. Dependent instances are: Variable instances Task instances (for user tasks) Event subscription instances Validation A migration plan is validated at two points in time: When it is created, its instructions are validated for static aspects. When it is applied to a process instance, its instructions are matched to activity instances and this assignment is validated. Validation ensures that none of the limitations stated in this guide lead to an inconsistent process instance state with undefined behavior after migration. Creation Time Validation For an instruction to be valid when a migration plan is created, it has to fulfill the following requirements: It has to map activities of the same type It has to be a one-to-one mapping A migrated activity must remain a descendant of its closest migrating ancestor scope (Hierarchy Preservation) The migration plan adheres to BPMN-element-specific considerations A set variable must not be of type Object AND its serializationFormat must not be application/x-java-serialized-object Validation is skipped when the engine configuration flag javaSerializationFormatEnabled is set to true Please see Process Engine Configuration Reference for more details If validation reports errors, migration fails with a MigrationPlanValidationException providing a MigrationPlanValidationReport object with details on the validation errors. Hierarchy Preservation An activity must stay a descendant of its closest ancestor scope that migrates (i.e., that is not cancelled during migration). Consider the following migration plan for the example processes shown at the beginning of this chapter: MigrationPlan migrationPlan = processEngine.getRuntimeService() .createMigrationPlan(\"exampleProcess:1\", \"exampleProcess:2\") .mapActivities(\"assessCreditWorthiness\", \"handleApplicationReceipt\") .mapActivities(\"validateAddress\", \"validatePostalAddress\") .build(); And a process instance in the following state: ProcessInstance └── Assess Credit Worthiness └── Validate Address The migration plan cannot be applied, because the hierarchy preservation requirement is violated: The activity Validate Address is supposed to be migrated to Validate Postal Address. However, the parent scope Assess Credit Worthiness is migrated to Handle Application Receipt, which does not contain Validate Postal Address. Execution Time Validation When a migration plan is applied to a process instance, it is validated beforehand that the plan is applicable. In particular, the following aspects are checked: Completeness: There must be a migration instruction for every instance of leaf activities (i.e., activities that do not contain other activities) Instruction Applicability: For certain activity types, only transition instances but not activity instances can be migrated If validation reports errors, migration fails with a MigratingProcessInstanceValidationException providing a MigratingProcessInstanceValidationReport object with details on the validation errors. Completeness Migration is only meaningful if a migration instruction applies to every instance of a leaf activity. Assume a migration plan as follows: MigrationPlan migrationPlan = processEngine.getRuntimeService() .createMigrationPlan(\"exampleProcess:1\", \"exampleProcess:2\") .mapActivities(\"archiveApplication\", \"archiveApplication\") .build(); Now consider a process instance in the following activity instance state: ProcessInstance └── Archive Application The plan is complete with respect to this process instance because there is a migration instruction for the activity Archive Application. Now consider another process instance: ProcessInstance ├── Archive Application └── Assess Credit Worthiness └── Validate Address The migration plan is not valid with respect to this instance because there is no instruction that applies to the instance of Validate Address. Instruction Applicability Migration instructions are used to migrate activity instances as well as transition instances (i.e., active asynchronous continuations). Some instructions can only be used to migrate transition instances but not activity instances. In general, activity instances can only be migrated if they are instances of the following element types: Task User Task Receive Task External Task Subprocess Embedded Sub Process Event Sub Process Transaction Sub Process Call Activity Gateways Parallel Gateway Inclusive Gateway Event-based Gateway Events Boundary Event Intermediate Catch Event Misc Multi-instance Body Transition instances can be migrated for any activity type. Aspects Not Covered by Validation Data Consistency Process instances contain data such as variables that are specific to how a process is implemented. Validation cannot ensure that such data is useful in the context of the target process definition. Deserialization of Object Variables Object type variables represent Java objects. That means they have a serialized value along with a Java type name that is used to deserialize the value into a Java object. When migrating between processes of different process applications, it may occur that an Object variable refers to a Java class that does not exist in the process application of the target process. This scenario is not prevented by validation. Accessing the deserialized value may therefore fail after migration. If you end up with unusable Object variables, there are two ways to deal with that situation: Add the missing classes to the target process application Convert the inconsistent variable into a variable for which the Java class is present based on its serialized value",
    "url": "/manual/latest/user-guide/process-engine/process-instance-migration/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/process-instance-modification/index.html",
    "title": "Process Instance Modification | docs.cibseven.org",
    "content": "While the process model contains sequence flows that define in which order activities must be executed, sometimes it is desired to flexibly start an activity again or cancel a running activity. For example, this can be useful when the process model contains an error, such as a wrong sequence flow condition, and running process instances need to be corrected. Use cases for this API may be Repairing process instances in which some steps have to be repeated or skipped Migrating process instances from one version of a process definition to another Testing: Activities can be skipped or repeated for isolated testing of individual process segments To perform such an operation, the process engine offers the process instance modification API that is entered via RuntimeService.createProcessInstanceModification(...) or RuntimeService.createModification(...). This API allows to specify multiple modification instructions in one call by using a fluent builder. In particular, it is possible to: start execution before an activity start execution on a sequence flow leaving an activity cancel a running activity instance cancel all running instances of a given activity set variables with each of the instructions Modification of the own process instance Process instance modification within the same instance is not recommended! An activity which tries to modify its own process instance can cause undefined behavior, which should be avoided. Process Instance Modification by Example As an example, consider the following process model: The model shows a simple process for processing a loan application. Let us assume that a loan application has arrived, the loan application has been evaluated, and it was determined to decline the application. That means, the process instance has the following activity instance state: ProcessInstance Decline Loan Application Now the worker performing the task Decline Loan Application recognizes an error in the evaluation result and comes to the conclusion that the application should be accepted nevertheless. While such flexibility is not modelled as part of the process, process instance modification allows to correct the running process instance. The following API call does the trick: ProcessInstance processInstance = runtimeService.createProcessInstanceQuery().singleResult(); runtimeService.createProcessInstanceModification(processInstance.getId()) .startBeforeActivity(\"acceptLoanApplication\") .cancelAllForActivity(\"declineLoanApplication\") .execute(); This command first starts execution before the activity Accept Loan Application until a wait state - the creation of the user task in this case - is reached. After that, it cancels the running instance of the activity Decline Loan Application. In the worker’s task list, the Decline task has been removed and an Accept task has appeared. The resulting activity instance state is: ProcessInstance Accept Loan Application Let’s assume that a variable called approver must exist when approving the application. This can be accomplished by extending the modification request as follows: ProcessInstance processInstance = runtimeService.createProcessInstanceQuery().singleResult(); runtimeService.createProcessInstanceModification(processInstance.getId()) .startBeforeActivity(\"acceptLoanApplication\") .setVariable(\"approver\", \"joe\") .cancelAllForActivity(\"declineLoanApplication\") .execute(); The added setVariable call ensures that before starting the activity, the specified variable is submitted. Now to some more complex cases. Say that the application was again not ok and the activity Decline Loan Application is active. Now, the worker recognizes that the evaluation process was erroneous and wants to restart it entirely. The following modification instructions represent the modification request to perform this task: It is possible to start the subprocess activities: ProcessInstance processInstance = runtimeService.createProcessInstanceQuery().singleResult(); runtimeService.createProcessInstanceModification(processInstance.getId()) .cancelAllForActivity(\"declineLoanApplication\") .startBeforeActivity(\"assessCreditWorthiness\") .startBeforeActivity(\"registerApplication\") .execute(); to start at the start event of the subprocess: ProcessInstance processInstance = runtimeService.createProcessInstanceQuery().singleResult(); runtimeService.createProcessInstanceModification(processInstance.getId()) .cancelAllForActivity(\"declineLoanApplication\") .startBeforeActivity(\"subProcessStartEvent\") .execute(); to start the subprocess itself: ProcessInstance processInstance = runtimeService.createProcessInstanceQuery().singleResult(); runtimeService.createProcessInstanceModification(processInstance.getId()) .cancelAllForActivity(\"declineLoanApplication\") .startBeforeActivity(\"evaluateLoanApplication\") .execute(); to start the process’ start event: ProcessInstance processInstance = runtimeService.createProcessInstanceQuery().singleResult(); runtimeService.createProcessInstanceModification(processInstance.getId()) .cancelAllForActivity(\"declineLoanApplication\") .startBeforeActivity(\"processStartEvent\") .execute(); Process Instance Modification in JUnit Tests Process instance modification can be very useful in JUnit Tests. You can skip the long part to run through the process from the start to the point you want to test and jump directly to the activity or gateway to test. For this you can start a process instance with a modification and place the token directly inside the process instance. Assume, you want to skip the subprocess Evaluate Loan Application and test the gateway Application OK? with your process variable, you can start the process instance with ProcessInstance processInstance = runtimeService.createProcessInstanceByKey(\"Loan_Application\") .startBeforeActivity(\"application_OK\") .setVariable(\"approved\", true) .execute(); In a JUnit test, you can assert that the processInstance is waiting at ‘Accept Loan Application’, now. Operational Semantics The following sections specify the exact semantics of process instance modification and should be read in order to understand the modification effects in varying circumstances. If not otherwise noted, the following examples refer to the following process model for illustration: Modification Instruction Types The fluent process instance modification builder offers the following instructions to be submitted: startBeforeActivity(String activityId) startBeforeActivity(String activityId, String ancestorActivityInstanceId) startAfterActivity(String activityId) startAfterActivity(String activityId, String ancestorActivityInstanceId) startTransition(String transitionId) startTransition(String transition, String ancestorActivityInstanceId) cancelActivityInstance(String activityInstanceId) cancelTransitionInstance(String transitionInstanceId) cancelAllForActivity(String activityId) Start Before an Activity ProcessInstanceModificationBuilder#startBeforeActivity(String activityId) ProcessInstanceModificationBuilder#startBeforeActivity(String activityId, String ancestorActivityInstanceId) Starting before an activity via startBeforeActivity means that execution is started before entering the activity. The instruction respects an asyncBefore flag, meaning that a job will be created if the activity is asyncBefore. In general, this instruction executes the process model beginning with the specified activity until a wait state is reached. See the documentation on Transactions in Processes for details on wait states. Start After an Activity ProcessInstanceModificationBuilder#startAfterActivity(String activityId) ProcessInstanceModificationBuilder#startAfterActivity(String activityId, String ancestorActivityInstanceId) Starting after an activity via startAfterActivity means that execution is started on the single outgoing sequence flow of the activity. The instruction does not consider the asyncAfter flag of the given activity. If there is more than one outgoing sequence flow or none at all, the instruction fails. If successful, this instruction executes the process model beginning with the sequence flow until a wait state is reached. Start a Transition ProcessInstanceModificationBuilder#startTransition(String transitionId) ProcessInstanceModificationBuilder#startTransition(String transition, String ancestorActivityInstanceId) Starting a transition via startTransition translates to starting execution on a given sequence flow. This can be used in addition to startAfterActivity, when there is more than one outgoing sequence flow. If successful, this instruction executes the process model beginning with the sequence flow until a wait state is reached. Cancel an Activity Instance ProcessInstanceModificationBuilder#cancelActivityInstance(String activityInstanceId) A specific activity instance can be canceled by cancelActivityInstance. This can either be a leaf activity instance, such as an instance of a user task, as well as an instance of a scope higher in the hierarchy, such as an instance of a sub process. See the details on activity instances how to retrieve the activity instances of a process instance. Cancel a Transition Instance ProcessInstanceModificationBuilder#cancelTransitionInstance(String activityInstanceId) Transition instances represent execution flows that are about to enter/leave an activity in the form of an asynchronous continuation. An asynchronous continuation job that has already been created but not yet executed is represented as a transition instance. These instances can be canceled by cancelTransitionInstance. See the details on activity and transition instances how to retrieve the transition instances of a process instance. Cancel All Activity Instances for an Activity ProcessInstanceModificationBuilder#cancelAllForActivity(String activityId) For convenience, it is also possible to cancel all activity and transition instances of a given activity by the instruction cancelAllForActivity. Provide Variables With every instantiating instruction (i.e., startBeforeActivity, startAfterActivity, or startTransition), it is possible to submit process variables. The API offers the methods setVariable(String name, Object value) setVariables(Map<String, Object> variables) setVariableLocal(String name, Object value) setVariablesLocal(Map<String, Object> variables) Variables are set after the necessary scopes for instantiation are created and before the actual execution of the specified element begins. That means, in the process engine history these variables do not appear as if they were set during execution of the specified activity for startBefore and startAfter instructions. Local variables are set on the execution that is about to perform the instruction, i.e., that enters the activity etc. See the variables section of this guide for details on variables and scopes in general. Activity-Instance-based API The process instance modification API is based on activity instances. The activity instance tree of a process instance can be retrieved with the following method: ProcessInstance processInstance = ...; ActivityInstance activityInstance = runtimeService.getActivityInstance(processInstance.getId()); ActivityInstance is a recursive data structure where the activity instance returned by the above method call represents the process instance. The IDs of ActivityInstance objects can be used for cancelation of specific instances or for ancestor selection during instantiation. The interface ActivityInstance has methods getChildActivityInstances and getChildTransitionInstances to drill down in the activity instance tree. For example, assume that the activities Assess Credit Worthiness and Register Application are active. Then the activity instance tree looks as follows: ProcessInstance Evaluate Loan Application Assess Credit Worthiness Register Application Request In code, the Assess and Register activity instances can be retrieved as follows: ProcessInstance processInstance = ...; ActivityInstance activityInstance = runtimeService.getActivityInstance(processInstance.getId()); ActivityInstance subProcessInstance = activityInstance.getChildActivityInstances()[0]; ActivityInstance[] leafActivityInstances = subProcessInstance.getChildActivityInstances(); // leafActivityInstances has two elements; one for each activity It is also possible to directly retrieve all activity instances for a given activity: ProcessInstance processInstance = ...; ActivityInstance activityInstance = runtimeService.getActivityInstance(processInstance.getId()); ActivityInstance assessCreditWorthinessInstances = activityInstance.getActivityInstances(\"assessCreditWorthiness\")[0]; Compared to activity instances, transition instances do not represent active activities but activities that are about to be entered or about to be left. This is the case when jobs for asynchronous continuations exist but have not been executed yet. For an activity instance, child transition instances can be retrieved with the method getChildTransitionInstances and the API for transition instances is similar to that for activity instances. Nested Instantiation Assume a process instance of the above example process where the activity Decline Loan Application is active. Now we submit the instruction to start before the activity Assess Credit Worthiness. When applying this instruction, the process engine makes sure to instantiate all parent scopes that are not active yet. In this case, before starting the activity, the process engine instantiates the Evaluate Loan Application sub process. Where before the activity instance tree was ProcessInstance Decline Loan Application it now is ProcessInstance Decline Loan Application Evaluate Loan Application Assess Credit Worthiness Apart from instantiating these parent scopes, the engine also ensures to register the event subscriptions and jobs in these scopes. For example, consider the following process: Starting the activity Assess Credit Worthiness also registers an event subscription for the message boundary event Cancelation Notice Received such that it is possible to cancel the sub process this way. Ancestor Selection for Instantiation By default, starting an activity instantiates all parent scopes that are not instantiated yet. When the activity instance tree is the following: ProcessInstance Decline Loan Application Then starting Assess Credit Worthiness results in this updated tree: ProcessInstance Decline Loan Application Evaluate Loan Application Assess Credit Worthiness The sub process scope has been instantiated as well. Now assume that the sub process is already instantiated, such as in the following tree: ProcessInstance Evaluate Loan Application Assess Credit Worthiness Starting Assess Credit Worthiness again will start it in the context of the existing sub process instance, such that the resulting tree is: ProcessInstance Evaluate Loan Application Assess Credit Worthiness Assess Credit Worthiness If you want to avoid this behavior and instead want to instantiate the sub process a second time, an id of an ancestor activity instance can be supplied by using the method startBeforeActivity(String activityId, String ancestorActivityInstanceId) - similar methods exist for starting after an activity and starting a transition. The parameter ancestorActivityInstanceId takes the id of an activity instance that is currently active and that belongs to an ancestor activity of the activity to be started. An activity is a valid ancestor, if it contains the activity to be started (either directly, or indirectly with other activities in between). With a given ancestor activity instance id, all scopes in between the ancestor activity and the activity to be started will be instantiated, regardless of whether they are already instantiated. In the example, the following code starts the activity Assess Credit Worthiness with the process instance (being the root activity instance) as the ancestor: ProcessInstance processInstance = ...; ActivityInstance activityInstanceTree = runtimeService.getActivityInstance(processInstance.getId()); runtimeService.createProcessInstanceModification(activityInstanceTree.getId()) .startBeforeActivity(\"assessCreditWorthiness\", processInstance.getId()) .execute(); Then, the resulting activity instance tree is the following: ProcessInstance Evaluate Loan Application Assess Credit Worthiness Evaluate Loan Application Assess Credit Worthiness The sub process was started a second time. Cancelation Propagation Canceling an activity instance propagates to parent activity instances that do not contain other activity instances. This behavior ensures that the process instance is not left in an execution state that makes no sense. This means, when a single activity is active in a sub process and that activity instance is canceled, the sub process is canceled as well. Consider the following activity instance tree: ProcessInstance Decline Loan Application Evaluate Loan Application Assess Credit Worthiness After canceling the activity instance for Assess Credit Worthiness, the tree is: ProcessInstance Decline Loan Application If all instructions have been executed and there is no active activity instance left, the entire process instance is canceled. This would be the case in the example above if both activity instances were canceled, the one for Assess Credit Worthiness and the one for Decline Loan Application. However, the process instance is only canceled after all instructions have been executed. That means, if the process instance has no active activity instances between two instructions the process instance is not immediately canceled. As an example, assume that the activity Decline Loan Application is active. The activity instance tree is: ProcessInstance Decline Loan Application The following modification operation succeeds although the process instance has no active activity instance directly after the cancelation instruction has been executed: ProcessInstance processInstance = ...; runtimeService.createProcessInstanceModification(processInstance.getId()) .cancelAllForActivity(\"declineLoanApplication\") .startBeforeActivity(\"acceptLoanApplication\") .execute(); Instruction Execution Order Modification instructions are always executed in the order they are submitted. Thus, performing the same instructions in a different order can make a difference. Consider the following activity instance tree: ProcessInstance Evaluate Loan Application Assess Credit Worthiness Assume you have the task of canceling the instance of Assess Credit Worthiness and starting the activity Register Application. There are two orderings for these two instructions: Either the cancelation is performed first, or the instantiation is performed first. In the former case, the code looks as follows: ProcessInstance processInstance = ...; runtimeService.createProcessInstanceModification(processInstance.getId()) .cancelAllForActivity(\"assesCreditWorthiness\") .startBeforeActivity(\"registerApplication\") .execute(); Due to cancelation propagation, the sub process instance is canceled when the cancelation instruction is executed only to be re-instantiated when the instantiation instruction is executed. This means, after the modification has been executed, there is a different instance of the Evaluate Loan Application sub process. Any entities associated with the previous instance have been removed, such as variables or event subscriptions. In contrast, consider the case where the instantiation is performed first: ProcessInstance processInstance = ...; runtimeService.createProcessInstanceModification(processInstance.getId()) .startBeforeActivity(\"registerApplication\") .cancelAllForActivity(\"assesCreditWorthiness\") .execute(); Due to the default ancestor selection during instantiation and the fact that cancelation does not propagate to the sub process instance in this case, the sub process instance is the same after modification as it was before. Related entities like variables and event subscriptions are preserved. Start Activities with Interrupting/Canceling Semantics Process instance modification respects any interrupting or canceling semantics of the activities to be started. In particular, starting an interrupting boundary event or an interrupting event sub process will cancel/interrupt the activity it is defined on/in. Consider the following process: Assume that the activity Assess Credit Worthiness is currently active. The event sub process can be started with the following code: ProcessInstance processInstance = ...; runtimeService.createProcessInstanceModification(processInstance.getId()) .startBeforeActivity(\"cancelEvaluation\") .execute(); Since the start event of the Cancel Evaluation sub process is interrupting, it will cancel the running instance of Assess Credit Worthiness. The same happens when the start event of the event subprocess is started via: ProcessInstance processInstance = ...; runtimeService.createProcessInstanceModification(processInstance.getId()) .startBeforeActivity(\"eventSubProcessStartEvent\") .execute(); However, when an activity located in the event sub process is directly started, the interruption is not executed. Consider the following code: ProcessInstance processInstance = ...; runtimeService.createProcessInstanceModification(processInstance.getId()) .startBeforeActivity(\"notifyAccountant\") .execute(); The resulting activity instance tree would be: ProcessInstance Evaluate Loan Application Assess Credit Worthiness Cancel Evaluation Notify Accountant Modify Multi-Instance Activity Instances Modification also works for multi-instance activities. We distinguish in the following between the multi-instance body and the inner activity. The inner activity is the actual activity and has the ID as declared in the process model. The multi-instance body is a scope around this activity that is not represented in the process model as a distinct element. For an activity with id anActivityId, the multi-instance body has by convention the id anActivityId#multiInstanceBody. With this distinction, it is possible to start the entire multi-instance body, as well as start a single inner activity instance for a running parallel multi-instance activity. Consider the following process model: Let’s assume the multi-instance activity is active and has three instances: ProcessInstance Contact Customer - Multi-Instance Body Contact Customer Contact Customer Contact Customer The following modification starts a fourth instance of the Contact Customer activity in the same multi-instance body activity: ProcessInstance processInstance = ...; runtimeService.createProcessInstanceModification(processInstance.getId()) .startBeforeActivity(\"contactCustomer\") .execute(); The resulting activity instance tree is: ProcessInstance Contact Customer - Multi-Instance Body Contact Customer Contact Customer Contact Customer Contact Customer The process engine makes sure to update the multi-instance-related variables nrOfInstances, nrOfActiveInstances, and loopCounter correctly. If the multi-instance activity is configured based on a collection, the collection is not considered when the instruction is executed and the collection element variable will not be populated for the additional instance. Such behavior can be achieved by providing the collection element variable with the instantiation instruction by using the method #setVariableLocal. Now consider the following request: ProcessInstance processInstance = ...; runtimeService.createProcessInstanceModification(processInstance.getId()) .startBeforeActivity(\"contactCustomer#multiInstanceBody\") .execute(); This starts the entire multi-instance body a second time, leading to the following activity instance tree: ProcessInstance Contact Customer - Multi-Instance Body Contact Customer Contact Customer Contact Customer Contact Customer Contact Customer - Multi-Instance Body Contact Customer Contact Customer Contact Customer Asynchronous modification of a process instance It is possible to execute modification of single process instance asynchronous. The modification instructions are the same as the synchronous modification and the syntax of fluent builder is the following: Batch modificationBatch = runtimeService.createProcessInstanceModification(processInstanceId) .cancelActivityInstance(\"exampleActivityId:1\") .startBeforeActivity(\"exampleActivityId:2\") .executeAsync(); This would create a modification batch which will be executed asynchronously. Providing variables is not supported when executing async modification of single process instance. Modification of Multiple Process Instances When there are multiple process instances which fulfill a specific criteria, it is possible to modify them at once using RuntimeService.createModification(...). This method allows to specify the modification instructions and IDs of process instances that should be modified. It is required that the process instances belong to the given process definition. The fluent modification builder offers the following instructions to be submitted: startBeforeActivity(String activityId) startAfterActivity(String activityId) startTransition(String transitionId) cancelAllForActivity(String activityId) Process instances can be selected for modification by either providing a set of process instance IDs or providing a process instance query. It is also possible to specify both, a list of process instance IDs and a query. The process instances to be modified will then be the union of the resulting sets. ProcessInstanceQuery processInstanceQuery = runtimeService.createProcessInstanceQuery(); runtimeService.createModification(\"exampleProcessDefinitionId\") .cancelAllForActivity(\"exampleActivityId:1\") .startBeforeActivity(\"exampleActivityId:2\") .processInstanceIds(processInstanceQuery) .processInstanceIds(\"processInstanceId:1\", \"processInstanceId:2\") .execute(); The modification of multiple process instances can be executed synchronously or asynchronously. For more information about the difference between synchronous and asynchronous execution, please refer to the related section of the user guide. An example for synchronous execution: runtimeService.createModification(\"exampleProcessDefinitionId\") .cancelAllForActivity(\"exampleActivityId:1\") .startBeforeActivity(\"exampleActivityId:2\") .processInstanceIds(\"processInstanceId:1\", \"processInstanceId:2\") .execute(); An example for asynchronous execution: Batch batch = runtimeService.createModification(\"exampleProcessDefinitionId\") .cancelAllForActivity(\"exampleActivityId:1\") .startBeforeActivity(\"exampleActivityId:2\") .processInstanceIds(\"processInstanceId:1\", \"processInstanceId:2\", \"processInstanceId:100\") .executeAsync(); Skip Listener and Input/Output Invocation It is possible to skip invocations of execution and task listeners as well as input/output mappings for the transaction that performs the modification. This can be useful when the modification is executed on a system that has no access to the involved process application deployments and their contained classes. Listener and ioMapping invocations can be skipped by using the modification builder’s method execute(boolean skipCustomListeners, boolean skipIoMappings). Annotation Use the annotation option to pass an arbitrary text annotation for auditing reasons. runtimeService.createProcessInstanceModification(processInstanceId) .cancelAllForActivity(\"declineLoanApplication\") .startBeforeActivity(\"processStartEvent\") .annotation(\"Modified to resolve an error.\") .execute(); It will be visible in User Operation Log for the performed modification. Soundness Checks Process instance modification is a very powerful tool and allows to start and cancel activities at will. Thus, it is easy to create situations that are unreachable by normal process execution. Assume the following process model: Assume that activity Decline Loan Approval is active. With modification, the activity Assess Credit Worthiness can be started. After that activity is completed, execution gets stuck at the joining parallel gateway because no token will ever arrive at the other incoming sequence flow such that the parallel gateway is activated. This is one of the most obvious situations where the process instance cannot continue execution and there are certainly many others, depending on the concrete process model. The process engine is not able to detect modifications that create such situations. It is up to the user of this API to make modifications that do not leave the process instance in an undesired state. However, process instance modification is also the tool to repair these situations :-)",
    "url": "/manual/latest/user-guide/process-engine/process-instance-modification/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/process-instance-restart/index.html",
    "title": "Process Instance Restart | docs.cibseven.org",
    "content": "After a process instance termination, its historic data still exists and can be accessed to restore a process instance, provided that the history level is set to FULL. This can, for example, be useful when termination did not proceed in a desired way. Use cases for this API may be: Restoring the last state of process instances that have been erroneously canceled Restarting process instances after a termination caused by a wrong decision To perform such an operation the process engine offers the process instance restart API, that is entered via RuntimeService.restartProcessInstances(...). This API allows to specify multiple instantiation instructions in one call by using a fluent builder. Note that these operations are also available via REST: Restart Process Instance and Restart Process Instance (async) Process Instance Restart by Example As an example, consider the following process model where the red dots mark active tasks: Let us assume that the process instance has been canceled externally by a worker using the following code: ProcessInstance processInstance = runtimeService.createProcessInstanceQuery().singleResult(); runtimeService.deleteProcessInstance(processInstance.getId(), \"any reason\"); After that, the manager decides to restore the last state of that process instance. runtimeService.restartProcessInstance(processInstance.getProcessDefinitionId()) .startBeforeActivity(\"receivePayment\") .startBeforeActivity(\"shipOrder\") .processInstanceIds(processInstance.getId()) .execute(); The process instance has been restarted with the last set of variables. However, only global variables are set in the restarted process instance. Local variables can be set manually, for example by calling RuntimeService.setVariableLocal(...). Technically, a new process instance has been created. Please note: The ids of the historic and the restarted process instance are different. Operational Semantics In the following, the exact semantics of the process instance restart feature are documented. Reading this section is recommended to fully understand the effects, power and limitations of this feature. Instantiation Instruction Types The fluent process instance restart builder offers the following instructions to be submitted: startBeforeActivity(String activityId) startAfterActivity(String activityId) startTransition(String transitionId) For information about the instruction types, please refer to the similar modification instruction types section. Selecting process instances to restart Process instances can be selected for restart by either providing a set of process instance ids or providing a historic process instance query. It is also possible to specify both, a list of process instance ids and a query. The process instances to be restarted will then be the union of the resulting sets. List of Process Instances The process instances which should be restarted can either be specified as a list of the process instance ids: ProcessDefinition processDefinition = ...; List<String> processInstanceIds = ...; runtimeService.restartProcessInstances(processDefinition.getId()) .startBeforeActivity(\"activity\") .processInstanceIds(processInstanceIds) .execute(); or, for a static number of process instances, there is a convenience varargs method: ProcessDefinition processDefinition = ...; HistoricProcessInstance instance1 = ...; HistoricProcessInstance instance2 = ...; runtimeService.restartProcessInstances(processDefinition.getId()) .startBeforeActivity(\"activity\") .processInstanceIds(instance1.getId(), instance2.getId()) .execute(); Historic Process Instance Query If the instances are not known beforehand, the process instances can be selected by a historic process instance query: HistoricProcessInstanceQuery historicProcessInstanceQuery = historyService .createHistoricProcessInstanceQuery() .processDefinitionId(processDefinition.getId()) .finished(); runtimeService.restartProcessInstances(processDefinition.getId()) .startBeforeActivity(\"activity\") .historicProcessInstanceQuery(historicProcessInstanceQuery) .execute(); Skipping Listeners and Input/Output Mappings It is possible to skip invocations of execution and task listeners as well as input/output mappings for the transaction that performs the restart. This can be useful when the restart is executed on a system that has no access to the involved process application deployments and their contained classes. In the API, the two methods #skipCustomListeners and #skipIoMappings can be used for this purpose: ProcessDefinition processDefinition = ...; List<String> processInstanceIds = ...; runtimeService.restartProcessInstances(processDefinition.getId()) .startBeforeActivity(\"activity\") .processInstanceIds(processInstanceIds) .skipCustomListeners() .skipIoMappings() .execute(); Restarting a Process Instance With the Initial Set of Variables By default, a process instance is restarted with the last set of variables. To alternatively choose the initial set of variables, the initialSetOfVariables method is used. This feature does not only copy the start variables, but will copy the first version of all process variables that have been set in the start activity of the old process instance. ProcessDefinition processDefinition = ...; List<String> processInstanceIds = ...; runtimeService.restartProcessInstances(processDefinition.getId()) .startBeforeActivity(\"activity\") .processInstanceIds(processInstanceIds) .initialSetOfVariables() .execute(); The initial set of variables can not be set if the historic process instance has no unique start activity. In that case, no variables are taken over. Omitting the Business Key of a Historic Process Instance By default, a process instance is restarted with the same business key as the historic process instance. By using the method withoutBusinessKey, the business key of the restarted process instance is not set. ProcessDefinition processDefinition = ...; List<String> processInstanceIds = ...; runtimeService.restartProcessInstances(processDefinition.getId()) .startBeforeActivity(\"activity\") .processInstanceIds(processInstanceIds) .withoutBusinessKey() .execute(); Execution The restart can either be executed synchronously (blocking) or asynchronously (non-blocking) by using a batch . The following are some reasons to prefer either one or the other: Use synchronous execution if: the number of process instances is small the restart should be atomic, i.e., it should be executed immediately and should fail if at least one process instance cannot be restarted Use asynchronous execution if: the number of process instances is large all process instances should be restarted decoupled from the other instances, i.e., every instance is restarted in its own transaction the restart should be executed by another thread, i.e., the job executor should handle the execution Synchronous execution To execute the restart synchronously, the execute method is used. It will block until the restart is completed. ProcessDefinition processDefinition = ...; List<String> processInstanceIds = ...; runtimeService.restartProcessInstances(processDefinition.getId()) .startBeforeActivity(\"activity\") .processInstanceIds(processInstanceIds) .execute(); Restart is successful if all process instances can be restarted. Asynchronous batch execution To execute the restart asynchronously, the executeAsync method is used. It will return immediately with a reference to the batch that executes the restart. ProcessDefinition processDefinition = ...; List<String> processInstanceIds = ...; Batch batch = runtimeService.restartProcessInstances(processDefinition.getId()) .startBeforeActivity(\"activity\") .processInstanceIds(processInstanceIds) .executeAsync(); Using a batch, the process instance restart is split into several jobs which are executed asynchronously. These batch jobs are executed by the job executor. See the batch section for more information. A batch is completed if all batch execution jobs are successfully completed. However, in contrast to the synchronous execution, it is not guaranteed that either all or no process instances are restarted. As the restart is split into several independent jobs, every single job may fail or succeed. If a restart job fails, it is retried by the job executor and, if no retries are left, an incident is created. In this case, manual action is necessary to complete the batch restart: The job’s retries can be incremented or the job can be deleted. Deletion cancels restart of the specific instance but does not affect the batch beyond that.",
    "url": "/manual/latest/user-guide/process-engine/process-instance-restart/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/process-versioning/index.html",
    "title": "Process Versioning | docs.cibseven.org",
    "content": "Versioning of Process Definitions Business Processes are by nature long running. The process instances will maybe last for weeks, or months. In the meantime the state of the process instance is stored to the database. But sooner or later you might want to change the process definition even if there are still running instances. This is supported by the process engine: If you redeploy a changed process definition, you get a new version in the database. Running process instances will continue to run in the version they were started in. New process instances will run in the new version - unless specified explicitly. Support for migrating process instances to new a version is supported within certain limits. You can see different versions in the process definition table and the process instances are linked to this: Multi-Tenancy If you are using multi-tenancy with tenant identifiers then each tenant has its own process definitions which have versions independent from other tenants. See the multi-tenancy section for details. Which Version Will be Used When you start a process instance By key: It starts an instance of the latest deployed version of the process definition with the key. By id: It starts an instance of the deployed process definition with the database id. By using this you can start a specific version. The default and recommended usage is to use startProcessInstanceByKey and always use the latest version: processEngine.getRuntimeService().startProcessInstanceByKey(\"invoice\"); // will use the latest version (2 in our example) If you want to specifically start an instance of an old process definition, use a Process Definition Query to find the correct ProcessDefinition id and use startProcessInstanceById: ProcessDefinition pd = processEngine.getRepositoryService().createProcessDefinitionQuery() .processDefinitionKey(\"invoice\") .processDefinitionVersion(1).singleResult(); processEngine.getRuntimeService().startProcessInstanceById(pd.getId()); When you use BPMN CallActivities you can configure which version is used: <callActivity id=\"callSubProcess\" calledElement=\"checkCreditProcess\" camunda:calledElementBinding=\"latest|deployment|version\" camunda:calledElementVersion=\"17\"> </callActivity> or <callActivity id=\"callSubProcess\" calledElement=\"checkCreditProcess\" camunda:calledElementBinding=\"versionTag\" camunda:calledElementVersionTag=\"ver-tag-1.0.1\"> </callActivity> The options are latest: Use the latest version of the process definition (as with startProcessInstanceByKey). deployment: Use the process definition in the version matching the version of the calling process. This works if they are deployed within one deployment - as they are then always versioned together (see Process Application Deployment for more details). version: Specify the version hard coded in the XML. versionTag: Specify the versionTag hard coded in the XML. Key vs. ID of a Process Definition You might have spotted that two different columns exist in the process definition table with different meanings: Key: The key is the unique identifier of the process definition in the XML, so its value is read from the id attribute in the XML: <bpmn2:process id=\"invoice\" ... Id: The id is the database primary key and an artificial key normally combined out of the key, the version and a generated id (note that the ID may be shortened to fit into the database column, so there is no guarantee that the id is built this way). Version Tag It is possible to tag a process definition with a version tag attribute. This can be done by adding the camunda:versionTag extension attribute to the process: <bpmn2:process camunda:versionTag=\"1.5-patch2\" .. The ProcessDefinition will now provide a versionTag field which you can fetch: ProcessDefinition pd = processEngine.getRepositoryService().createProcessDefinitionQuery() .processDefinitionKey(\"invoice\") .processDefinitionVersion(1).singleResult(); pd.getVersionTag(); or to fetch a list of all deployed process definitions which contain the specified version: List<ProcessDefinition> pdList = processEngine.getRepositoryService().createProcessDefinitionQuery() .versionTag(\"1.5-patch2\") .list(); You can also use versionTagLike to query for a range of versions: List<ProcessDefinition> pdList = processEngine.getRepositoryService().createProcessDefinitionQuery() .versionTagLike(\"1.5-%\") .list(); The following example shows how to start a process instance of the latest process definition for a version tag: ProcessDefinition pd = processEngine.getRepositoryService().createProcessDefinitionQuery() .processDefinitionKey(\"invoice\") .versionTag(\"1.5-patch2\") .orderByVersion(). .desc() .listPage(0,1); processEngine.getRuntimeService().startProcessInstanceById(pd.getId()); Version Tag The version tag is only for tagging and will neither influence the startProcessInstanceByKey nor the startProcessInstanceById behavior. Latest Version The Process Definition version and versionTag are separate properties. When querying with ProcessDefinitionQuery#latestVersion(), the Process Definition with the largest version number is located for a given key. Adding a version tag filter to this query might provide an empty result if the latest Process Definition doesn’t contain the queried version tag. Process Instance Migration By default, when a new process version is deployed, process instances running on previous versions are not affected. Process instance migration can be used to migrate process instances to a new version.",
    "url": "/manual/latest/user-guide/process-engine/process-versioning/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/scripting/index.html",
    "title": "Scripting | docs.cibseven.org",
    "content": "CIB seven supports scripting with JSR-223 compatible script engine implementations. Currently we test the integration for Groovy, JavaScript, JRuby and Jython. To use a scripting engine it is necessary to add the corresponding jar to the classpath. We include GraalVM JavaScript in the pre-packaged CIB seven distributions. Consult JavaScript Considerations for further information. We include Groovy in the pre-packaged CIB seven distributions. The following table provides an overview of the BPMN elements which support the execution of scripts. BPMN element Script support Script Task Script inside a script task Processes, Activities, Sequence Flows, Gateways and Events Script as an execution listener User Tasks Script as a task listener Sequence Flows Script as condition expression of a sequence flow All Tasks, All Events, Transactions, Subprocesses and Connectors Script inside an inputOutput parameter mapping Use Script Tasks With a BPMN 2.0 script task you can add a script to your BPM process (for more information see the BPMN 2.0 reference. The following process is a simple example with a Groovy script task that sums up the elements of an array. <?xml version=\"1.0\" encoding=\"UTF-8\"?> <definitions xmlns=\"http://www.omg.org/spec/BPMN/20100524/MODEL\" targetNamespace=\"http://camunda.org/example\"> <process id=\"process\" isExecutable=\"true\"> <startEvent id=\"start\"/> <sequenceFlow id=\"sequenceFlow1\" sourceRef=\"start\" targetRef=\"task\"/> <scriptTask id=\"task\" name=\"Groovy Script\" scriptFormat=\"groovy\"> <script> <![CDATA[ sum = 0 for ( i in inputArray ) { sum += i } println \"Sum: \" + sum ]]> </script> </scriptTask> <sequenceFlow id=\"sequenceFlow2\" sourceRef=\"task\" targetRef=\"end\"/> <endEvent id=\"end\"/> </process> </definitions> To start the process, a variable inputArray is necessary. Map<String, Object> variables = new HashMap<String, Object>(); variables.put(\"inputArray\", new Integer[]{5, 23, 42}); runtimeService.startProcessInstanceByKey(\"process\", variables); Use Scripts as Execution Listeners Besides Java code and expression language, CIB seven also supports the execution of a script as an execution listener. For general information about execution listeners see the corresponding section. To use a script as an execution listener, a camunda:script element has to be added as a child element of the camunda:executionListener element. During script evaluation, the variable execution is available, which corresponds to the DelegateExecution interface. The following example shows usage of scripts as execution listeners. <process id=\"process\" isExecutable=\"true\"> <extensionElements> <camunda:executionListener event=\"start\"> <camunda:script scriptFormat=\"groovy\"> println \"Process \" + execution.eventName + \"ed\" </camunda:script> </camunda:executionListener> </extensionElements> <startEvent id=\"start\"> <extensionElements> <camunda:executionListener event=\"end\"> <camunda:script scriptFormat=\"groovy\"> println execution.activityId + \" \" + execution.eventName + \"ed\" </camunda:script> </camunda:executionListener> </extensionElements> </startEvent> <sequenceFlow id=\"flow1\" startRef=\"start\" targetRef=\"task\"> <extensionElements> <camunda:executionListener> <camunda:script scriptFormat=\"groovy\" resource=\"org/cibseven/bpm/transition.groovy\" /> </camunda:executionListener> </extensionElements> </sequenceFlow> <!-- ... remaining process omitted --> </process> Use Scripts as Task Listeners Similar to execution listeners, task listeners can also be implemented as scripts. For general information about task listeners see the corresponding section. To use a script as a task listener, a camunda:script element has to be added as a child element of the camunda:taskListener element. Inside the script, the variable task is available, which corresponds to the DelegateTask interface. The following example shows usage of scripts as task listeners. <userTask id=\"userTask\"> <extensionElements> <camunda:taskListener event=\"create\"> <camunda:script scriptFormat=\"groovy\">println task.eventName</camunda:script> </camunda:taskListener> <camunda:taskListener event=\"assignment\"> <camunda:script scriptFormat=\"groovy\" resource=\"org/cibseven/bpm/assignemnt.groovy\" /> </camunda:taskListener> </extensionElements> </userTask> Use Scripts as Conditions As an alternative to expression language, CIB seven allows you to use scripts as conditionExpression of conditional sequence flows. To do that, the language attribute of the conditionExpression element has to be set to the desired scripting language. The script source code is the text content of the element, as with expression language. Another way to specify the script source code is to define an external source as described in the script source section. The following example shows usage of scripts as conditions. The Groovy variable status is a process variable which is available inside the script. <sequenceFlow> <conditionExpression xsi:type=\"tFormalExpression\" language=\"groovy\"> status == 'closed' </conditionExpression> </sequenceFlow> <sequenceFlow> <conditionExpression xsi:type=\"tFormalExpression\" language=\"groovy\" camunda:resource=\"org/cibseven/bpm/condition.groovy\" /> </sequenceFlow> Use Scripts as inputOutput Parameters With the CIB seven inputOutput extension element you can map an inputParameter or outputParameter with a script. The following example process uses the Groovy script from the previous example to assign the Groovy variable sum to the process variable x for a Java delegate. Script Return Value Please note that the last statement of the script is returned. This applies to Groovy, JavaScript and JRuby but not to Jython. If you want to use Jython, your script has to be a single expression like a + b or a > b where a and b are already process variables. Otherwise, the Jython scripting engine will not return a value. <?xml version=\"1.0\" encoding=\"UTF-8\"?> <definitions xmlns=\"http://www.omg.org/spec/BPMN/20100524/MODEL\" xmlns:camunda=\"http://activiti.org/bpmn\" targetNamespace=\"http://camunda.org/example\"> <process id=\"process\" isExecutable=\"true\"> <startEvent id=\"start\"/> <sequenceFlow id=\"sequenceFlow1\" sourceRef=\"start\" targetRef=\"task\"/> <serviceTask id=\"task\" camunda:class=\"org.cibseven.bpm.example.SumDelegate\"> <extensionElements> <camunda:inputOutput> <camunda:inputParameter name=\"x\"> <camunda:script scriptFormat=\"groovy\"> <![CDATA[ sum = 0 for ( i in inputArray ) { sum += i } sum ]]> </camunda:script> </camunda:inputParameter> </camunda:inputOutput> </extensionElements> </serviceTask> <sequenceFlow id=\"sequenceFlow2\" sourceRef=\"task\" targetRef=\"end\"/> <endEvent id=\"end\"/> </process> </definitions> After the script has assigned a value to the sum variable, x can be used inside the Java delegate code. public class SumDelegate implements JavaDelegate { public void execute(DelegateExecution execution) throws Exception { Integer x = (Integer) execution.getVariable(\"x\"); // do something } } The script source code can also be loaded from an external resource in the same way as described for script tasks. <camunda:inputOutput> <camunda:inputParameter name=\"x\"> <camunda:script scriptFormat=\"groovy\" resource=\"org/cibseven/bpm/example/sum.groovy\"/> </camunda:inputParameter> </camunda:inputOutput> Script Engine Caching Whenever the process engine reaches a point where a script has to be executed, the process engine looks for a Script Engine by a language name. The default behavior is that if it is the first request, a new Script Engine is created. If the Script Engine declares to be thread safe, it is also cached. The caching prevents the process engine from creating a new Script Engine for each request for the same script language. By default the caching of Script Engines happens at process application level. Each process application holds an own instance of a Script Engine for a given language. This behavior can be disabled by setting the process engine configuration flag named enableFetchScriptEngineFromProcessApplication to false. Consequently, the Script Engines are cached globally at process engine level and they are shared between each process application. For further details about the process engine configuration flag enableFetchScriptEngineFromProcessApplication, please read the section about referencing process application classes. If it is not desired to cache Script Engines in general, it can be disabled by setting the process engine configuration flag name enableScriptEngineCaching to false. Script Compilation Most script engines compile script source code either to a Java class or to a different intermediary format prior to executing the script. Script engines implementing the Java Compilable interface allow programs to retrieve and cache the script compilation. The default setting of the process engine is to check if a Script Engine supports the compile feature. If true and the caching of Script Engines is enabled, the script engine compiles the script and then caches the compilation result. This prevents the process engine from compiling a script source each time the same script task is executed. By default, compilation of scripts is enabled. If you need to disable script compilation, you can set the process engine configuration flag named enableScriptCompilation to false. Load Script Engine If the process engine configuration flag named enableFetchScriptEngineFromProcessApplication is set to true, it is also possible to load Script Engines from the classpath of the process application. For that, the Script Engine can be packaged as a library within the process application. It is also possible to install the Script Engine globally. In case the Script Engine module should be installed globally and Wildfly is used, it is necessary to add a module dependency to the Script Engine. This can be done by adding a jboss-deployment-structure.xml to the process application, e.g.,: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <jboss-deployment-structure> <deployment> <dependencies> <module name=\"org.apache.groovy.groovy-all\" services=\"import\" /> </dependencies> </deployment> </jboss-deployment-structure> Configure Script Engine Most script engines offer configuration options to adjust their script execution semantics. We provide the following default configurations for supported script engines before executing code on them: Script Engine Default configuration GraalVM JavaScript Configured to allow host acces and host class lookup by setting polyglot.js.allowHostAccess and polyglot.js.allowHostClassLookup to true. Groovy Configured to only hold weak references to Java methods by setting #jsr223.groovy.engine.keep.globals to weak. Besides those default options, you can configure the script engines by any of the following: Set script engine-specific configuration flags in process engine configuration. Provide script engine-specific system properties. Provide a custom implementation of the ScriptEngineResolver interface. Note that for JavaScript execution you might be able to choose the script engine to use depending on your setup. Consult JavaScript Considerations for further information. Process engine flags You can use the following process engine configuration flags to influence the configuration of specific script engines: configureScriptEngineHostAccess - Specifies whether host language resources like classes and their methods are accessible or not. enableScriptEngineLoadExternalResources - Specifies whether external resources can be loaded from file system or not. enableScriptEngineNashornCompatibility - Specifies whether Nashorn compatibility mode is enabled or not. System properties Depending on the script engine, specific system properties can be used to influence the setup of the script engine. Consult the development guides of the script engine you want to configure for further information on available parameters. Note that the supported options can differ between versions of the script engine. You can set system properties either programmatically through System.setProperty(parameter, value) or as JVM arguments, for example upon application start on command line via -Dparameter=value. Most application servers like Wildfly, Tomcat, Websphere, and Weblogic support providing JVM arguments via environment variables JAVA_OPTS or JAVA_OPTIONS. Consult your application server’s documentation to learn how to pass on JVM arguments. CIB seven Run supports setting JVM arguments via the JAVA_OPTS environment variable as well. Custom ScriptEngineResolver You can provide a custom ScriptEngineResolver implementation to configure script engines. Depending on the specifc script engine to configure, you can gain more configuration options with this approach. You can add your custom script engine resolver to the engine configuration with the #setScriptEngineResolver(ScriptEngineResolver) method. You can inherit from the org.cibseven.bpm.engine.impl.scripting.engine.DefaultScriptEngineResolver for starters in case configuring an existing script engine instance is sufficient for you. By overriding the #configureScriptEngines(String, ScriptEngine) method of the DefaultScriptEngineResolver, you can change settings on the script engine instance provided to that method as shown in the following example: public class CustomScriptEngineResolver extends DefaultScriptEngineResolver { public CustomScriptEngineResolver(ScriptEngineManager scriptEngineManager) { super(scriptEngineManager); } protected void configureScriptEngines(String language, ScriptEngine scriptEngine) { super.configureScriptEngines(language, scriptEngine); if (ScriptingEngines.GROOVY_SCRIPTING_LANGUAGE.equals(language)) { // make sure Groovy compiled scripts only hold weak references to java methods scriptEngine.getContext().setAttribute(\"#jsr223.groovy.engine.keep.globals\", \"soft\", ScriptContext.ENGINE_SCOPE); } } } If you need more flexibility in configuring a script engine, you can override a method further up the chain in the script engine creation or provide your own plain implementation of the interface. Have a look at the following example that provides a custom GraalVM JavaScript instance with Nashorn Compatibility Mode enabled: public class CustomScriptEngineResolver extends DefaultScriptEngineResolver { public CustomScriptEngineResolver(ScriptEngineManager scriptEngineManager) { super(scriptEngineManager); } @Override protected void configureGraalJsScriptEngine(ScriptEngine scriptEngine) { // do nothing } @Override protected ScriptEngine getJavaScriptScriptEngine(String language) { return com.oracle.truffle.js.scriptengine.GraalJSScriptEngine.create(null, org.graalvm.polyglot.Context.newBuilder(\"js\") // make sure GraalVM JS can provide access to the host and can lookup classes .allowHostClassLookup(s -> true) // enable Nashorn Compatibility Mode .allowExperimentalOptions(true) .option(\"js.nashorn-compat\", \"true\")); } } Reference Process Application Provided Classes The script can reference to process application provided classes by importing them like in the following groovy script example. import my.process.application.CustomClass sum = new CustomClass().calculate() execution.setVariable('sum', sum) To avoid possible class loading problems during the script execution, it is recommended to set the process engine configuration flag name enableFetchScriptEngineFromProcessApplication to true. Be aware that the process engine flag enableFetchScriptEngineFromProcessApplication is only relevant in a shared engine scenario. Variables Available During Script Execution During the execution of scripts, all process variables visible in the current scope are available. They can be accessed directly by the name of the variable (i.e., sum). This does not apply for JRuby where you have to access the variable as a ruby global variable (prepend with a dollar sign, i.e., $sum) There are also special variables: execution, which is always available if the script is executed in an execution scope (e.g., in a script task) (DelegateExecution ). task, which is available if the script is executed in a task scope (e.g., a task listener) (DelegateTask ). connector, which is available if the script is executed in a connector variable scope (e.g., outputParameter of a camunda:connector) (ConnectorVariableScope ). These variables correspond to the DelegateExecution, DelegateTask or resp. ConnectorVariableScope interface which means that it can be used to get and set variables or access process engine services. // get process variable sum = execution.getVariable('x') // set process variable execution.setVariable('y', x + 15) // get task service and query for task task = execution.getProcessEngineServices().getTaskService() .createTaskQuery() .taskDefinitionKey(\"task\") .singleResult() Accessing Process Engine Services using Scripts CIB seven’s Java API provides access to CIB seven’s process engine services; these services can be accessed using Scripts: Process Engine Services \\ Public Java API of CIB seven Engine Example of creating a BPMN Message that correlates with the message key “work”: execution.getProcessEngineServices().getRuntimeService().createMessageCorrelation(\"work\").correlateWithResult(); Printing to Console using Scripts During the execution of scripts, it might be desired to print to the console due to logging and debugging reasons. Here are examples on how this can be accomplished in the respective language: Groovy: println 'This prints to the console' Java: var system = java.lang.System; system.out.println('This prints to the console'); Script Source The standard way to specify the script source code in the BPMN XML model is to add it directly to the XML file. Nonetheless, CIB seven provides additional ways to specify the script source. If you use another scripting language than Expression Language, you can also specify the script source as an expression which returns the source code to be executed. This way, the source code can, for example, be contained in a process variable. In the following example snippet the process engine will evaluate the expression ${sourceCode} in the current context every time the element is executed. <!-- inside a script task --> <scriptTask scriptFormat=\"groovy\"> <script>${sourceCode}</script> </scriptTask> <!-- as an execution listener --> <camunda:executionListener> <camunda:script scriptFormat=\"groovy\">${sourceCode}</camunda:script> </camunda:executionListener> <!-- as a condition expression --> <sequenceFlow id=\"flow\" sourceRef=\"theStart\" targetRef=\"theTask\"> <conditionExpression xsi:type=\"tFormalExpression\" language=\"groovy\"> ${sourceCode} </conditionExpression> </sequenceFlow> <!-- as an inputOutput mapping --> <camunda:inputOutput> <camunda:inputParameter name=\"x\"> <camunda:script scriptFormat=\"groovy\">${sourceCode}</camunda:script> </camunda:inputParameter> </camunda:inputOutput> You can also specify the attribute camunda:resource on the scriptTask and conditionExpression element, respectively the resource attribute on the camunda:script element. This extension attribute specifies the location of an external resource which should be used as script source code. Optionally, the resource path can be prefixed with an URL-like scheme to specify if the resource is contained in the deployment or classpath. The default behaviour is that the resource is part of the classpath. This means that the first two script task elements in the following examples are equal. <!-- on a script task --> <scriptTask scriptFormat=\"groovy\" camunda:resource=\"org/cibseven/bpm/task.groovy\"/> <scriptTask scriptFormat=\"groovy\" camunda:resource=\"classpath://org/cibseven/bpm/task.groovy\"/> <scriptTask scriptFormat=\"groovy\" camunda:resource=\"deployment://org/cibseven/bpm/task.groovy\"/> <!-- in an execution listener --> <camunda:executionListener> <camunda:script scriptFormat=\"groovy\" resource=\"deployment://org/cibseven/bpm/listener.groovy\"/> </camunda:executionListener> <!-- on a conditionExpression --> <conditionExpression xsi:type=\"tFormalExpression\" language=\"groovy\" camunda:resource=\"org/cibseven/bpm/condition.groovy\" /> <!-- in an inputParameter --> <camunda:inputParameter name=\"x\"> <camunda:script scriptFormat=\"groovy\" resource=\"org/cibseven/bpm/mapX.groovy\" /> </camunda:inputParameter> The resource path can also be specified as an expression which is evaluated on the invocation of the script task. <scriptTask scriptFormat=\"groovy\" camunda:resource=\"${scriptPath}\"/> For more information, see the camunda:resource section of the Custom Extensions chapter. JavaScript Considerations JavaScript code execution is part of the Java Runtime (JRE) with the Nashorn script engine until Java 14 and thus only there available out of the box. We include GraalVM JavaScript in the pre-packaged CIB seven distributions as a replacement regardless of the JRE version. JavaScript code executes on GraalVM JavaScript with preference in the process engine context if this script engine is available. If this script engine cannot be found, the process engine defaults to let the JVM select an appropriate script engine. You can set the default JavaScript engine to use for languages javascript and ecmascript with the process engine configuration property named scriptEngineNameJavaScript. Set this value to nashorn to configure the process engine to use the Nashorn script engine by default. Note that if no script engine related to that value can be found, the process engine does not look for a fallback and throws an exception. Consult the official GraalVM JavaScript Guide for questions around that script engine. It also contains a guide on Migration from Nashorn.",
    "url": "/manual/latest/user-guide/process-engine/scripting/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/securing-custom-code/index.html",
    "title": "Custom Code & Security | docs.cibseven.org",
    "content": "The process engine offers numerous extension points for customization of process behavior by using Java Code, Expression Language, Scripts and Templates. While these extension points allow for great flexibility in process implementation, they open up the possibility to perform malicious actions when in the wrong hands. It is therefore advisable to restrict access to API that allows custom code submission to trusted parties only. The following concepts exist that allow submitting custom code (via Java or REST API): Deployment: Most of the custom logic is submitted with the deployment of a process, case, or decision model. For example, an execution listener invocation is defined in the BPMN 2.0 XML. Queries: Queries offer the ability to include expressions for certain parameters (currently task queries only). This enables users to define reusable queries that can be repeatedly executed and dynamically adapted to changing circumstances. For example, a task query taskService.createTaskQuery().dueBeforeExpression(${now()}).list(); uses an expression to always return the tasks currently due. Camunda Tasklist makes use of this feature in the form of task filters. Only trusted users should be authorized to interact with these endpoints. How access can be restricted is outlined in the next sections. CIB seven in a Trusted Environment When CIB seven is deployed in an environment where only trusted parties can access the system (for example due to firewall policies), no untrusted party can access the APIs for submitting custom code and the following suggestions need not be adhered to. Deployments Access to performing deployments can be restricted by using the authorization infrastructure and activating authentication checks for any endpoint a potentially untrusted party may access. The crucial permission for making deployments is Deployment/Create. Untrusted users should not be granted this permission. Queries Query access cannot be generally restricted with authorizations. Instead, a query’s result is reduced to entities a user is authorized to access. Thus, authorization permissions cannot be used to guard expression evaluation in queries. The process engine configuration offers two flags to toggle expression evaluation in adhoc and stored queries. Adhoc queries are directly submitted queries. For example, taskService.createTaskQuery().list(); creates and executes an adhoc query. In contrast, a stored query is persisted along with a filter and executed when the filter is executed. Expressions in adhoc queries can be disabled by setting the configuration property enableExpressionsInAdhocQueries to false. Accordingly, the property enableExpressionsInStoredQueries disables expressions in stored queries. If an expression is used although expression evaluation is disabled, the process engine raises an exception before evaluating any expression, thereby preventing malicious code from being executed. The following configuration combinations exist: enableExpressionsInAdhocQueries=true, enableExpressionsInStoredQueries=true: Expression evaluation is enabled for any query. Use this setting if all users are trusted. enableExpressionsInAdhocQueries=false, enableExpressionsInStoredQueries=true: Default Setting. Adhoc queries may not use expressions, however filters with expressions can be defined and executed. Access to filter creation can be restricted by the granting the authorization permission Filter/Create. Use this setting if all users authorized to create filters are trusted. enableExpressionsInAdhocQueries=false, enableExpressionsInStoredQueries=false: Expressions are disabled for all queries. Use this setting if none of the above settings can be applied.",
    "url": "/manual/latest/user-guide/process-engine/securing-custom-code/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/templating/index.html",
    "title": "Templating | docs.cibseven.org",
    "content": "CIB seven supports template engines which are implemented as script engines compatible with JSR-223. As a result, templates can be used everywhere where scripts can be used. In community distributions of CIB seven, the following template engine is provided out of the box: FreeMarker The script engine Freemarker wrapper implementation can be found in the cibseven-bpmn-platform repository. The following template engines are provided as optional community extensions: Apache Velocity Saxon XQuery Saxon XSLT The script engine wrapper implementations can be found in the camunda-7-template-engines-jsr223 community hub repository. Install a Template Engine Install a Template Engine for an Embedded Process Engine A template engine must be installed in the same way as a script engine. This means that the template engine must be added to the process engine classpath. When using an embedded process engine, the template engine libraries must be added to the application deployment. When using the process engine in a maven war project, the template engine dependencies must be added as dependencies to the maven pom.xml file: The CIB seven BOM only contains the officially supported freemarker template engine. For the community-driven template engines, please check the Maven coordinates below. <dependencies> <!-- freemarker --> <dependency> <groupId>org.cibseven.template-engines</groupId> <artifactId>cibseven-template-engines-freemarker</artifactId> </dependency> </dependencies> Here are the Maven coordinates of the community extensions for Camunda could be used in CIB seven as well: <dependencies> <!-- saxon xquery --> <dependency> <groupId>org.camunda.community.template.engine</groupId> <artifactId>camunda-7-template-engine-xquery</artifactId> </dependency> <!-- saxon xslt --> <dependency> <groupId>org.camunda.community.template.engine</groupId> <artifactId>camunda-7-template-engine-xslt</artifactId> </dependency> <!-- apache velocity --> <dependency> <groupId>org.camunda.community.template.engine</groupId> <artifactId>camunda-7-template-engine-velocity</artifactId> </dependency> </dependencies> Install a Template Engine for a Shared Process Engine When using a shared process engine, the template engine must be added to the shared process engine classpath. The procedure for this depends on the application server. In Apache Tomcat, the libraries have to be added to the shared lib/ folder. FreeMarker is pre-installed in the CIB seven pre-packaged distribution. Use a Template Engine If the template engine library is in the classpath, you can use templates everywhere in the BPMN process where you can use scripts, for example as a script task or inputOutput mapping. The FreeMarker template engine is part of the CIB seven distribution. Inside the template, all process variables of the BPMN element scope are available. The template can also be loaded from an external resource as described in the script source section. The following example shows a FreeMarker template, of which the result is saved in the process variable text. <scriptTask id=\"templateScript\" scriptFormat=\"freemarker\" camunda:resultVariable=\"text\"> <script> Dear ${customer}, thank you for working with CIB seven ${version}. Greetings, CIB seven developers </script> </scriptTask> In an inputOutput mapping it can be very useful to use an external template to generate the payload of a camunda:connector. <bpmn2:serviceTask id=\"soapTask\" name=\"Send SOAP request\"> <bpmn2:extensionElements> <camunda:connector> <camunda:connectorId>soap-http-connector</camunda:connectorId> <camunda:inputOutput> <camunda:inputParameter name=\"soapEnvelope\"> <camunda:script scriptFormat=\"freemarker\" resource=\"soapEnvelope.ftl\" /> </camunda:inputParameter> <!-- ... remaining connector config omitted --> </camunda:inputOutput> </camunda:connector> </bpmn2:extensionElements> </bpmn2:serviceTask> Use XSLT as Template Engine Use XSLT Template Engine with an embedded process engine When using an embedded process engine, the XSLT template engine library must be added to the application deployment. When using the process engine in a maven war project, the template engine dependency must be added as dependencies to the maven pom.xml file: <dependencies> <!-- XSLT --> <dependency> <groupId>org.camunda.community.template.engine</groupId> <artifactId>camunda-7-template-engine-xslt</artifactId> </dependency> </dependencies> Use XSLT Templates The following is an example of a BPMN ScriptTask used to execute an XSLT Template: <bpmn2:scriptTask id=\"ScriptTask_1\" name=\"convert input\" scriptFormat=\"xslt\" camunda:resource=\"org/cibseven/bpm/example/xsltexample/example.xsl\" camunda:resultVariable=\"xmlOutput\"> <bpmn2:extensionElements> <camunda:inputOutput> <camunda:inputParameter name=\"camunda_source\">${customers}</camunda:inputParameter> </camunda:inputOutput> </bpmn2:extensionElements> </bpmn2:scriptTask> As shown in the example above, the XSL source file can be referenced using the camunda:resource attribute. It may be loaded from the classpath or the deployment (database) in the same way as described for script tasks. The result of the transformation can be mapped to a variable using the camunda:resultVariable attribute. Finally, the input of the transformation must be mapped using the special variable camunda_source using a <camunda:inputParameter ... /> mapping. A full example of the XSLT Template Engine in CIB seven can be found in the examples’ repository.",
    "url": "/manual/latest/user-guide/process-engine/templating/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/the-job-executor/index.html",
    "title": "The Job Executor | docs.cibseven.org",
    "content": "A job is an explicit representation of a task to trigger process execution. A job is created when a timer event or a task marked for asynchronous execution (see transaction boundaries) is approached. Job processing can therefore be separated into three phases: Job Creation Job Acquisition Job Execution While jobs are created during process execution, job acquisition and execution are the job executor’s responsibility. The following diagram illustrates these two steps: Job Executor Activation When using an embedded process engine, by default, the Job Executor is not activated when the process engine boots. Specify <property name=\"jobExecutorActivate\" value=\"true\" /> in the process engine configuration when you want the JobExecutor to be activated upon booting the process engine. When using a shared process engine, the default is reversed: if you do not specify the jobExecutorActivate property on the process engine configuration, the job executor is automatically started. In order to turn it off, you have to explicitly set the property to false: <property name=\"jobExecutorActivate\" value=\"false\" /> Job Executor in a Unit Test For unit testing scenarios it is cumbersome to work with this background component. Therefore the Java API offers to query for (ManagementService.createJobQuery) and execute jobs (ManagementService.executeJob) by hand, which allows to control job execution from within a unit test. Job Creation Jobs are created for a range of purposes by the process engine. The following job types exist: Asynchronous continuations to set transaction boundaries in the process Timer jobs for BPMN timer events Asynchronous handling of BPMN events During creation, jobs can receive a priority for acquisition and execution. Job Prioritization In practice, the amount of jobs processed is seldomly spread evenly across the day. Instead, there are peaks of high load, for example when batch operations are run overnight. In such a situation, the job executor can be temporarily overloaded: the database contains many more jobs than the job executor can handle at a time. Job Prioritization can help cope with these situations in a well-defined matter by defining an order of importance and enabling execution by that order. In general, there are two types of use cases that can be tackled with job prioritization: Anticipating priorities at Design Time: In many cases, a high-load scenario can be anticipated when designing a process model. In these scenarios, it is often important to prioritize job execution according to certain business objectives. Examples: A retail store has casual and VIP customers. In case of high load, it is desired to handle orders of VIP customers with higher priority since their satisfaction is more important to the company’s business goals. A furniture store has human-centric processes for consulting customers in buying furniture as well as non-time-critical processes for delivery. Prioritization can be used to ensure fast response times in the consulting processes, improving user and customer satisfaction. Prioritization as a Response to Runtime Conditions: Some scenarios for high job executor load result from unforeseen conditions at runtime that cannot be dealt with during process design. Temporarily overriding priorities can help deal with these kind of situations gracefully. Example: A service task accesses a web service to process a payment. The payment service encounters an overload and responds very slowly. To avoid occupying all the job executor’s resources with waiting for the service to respond, the respective jobs’ priorities can be temporarily reduced. This way, unrelated process instances and jobs are not slowed down. After the service recovers, the overriding priority can be cleared again. The Job Priority A priority is a natural number in the range of a Java long value. A higher number represents a higher priority. Once assigned, the priority is static, meaning that the process engine will not go through the process of assigning a priority for that job again at any point in the future. Job priorities affect two phases during process execution: job creation and job acquisition. During job creation, a job is assigned a priority. During job acquisition, the process engine can evaluate the given job priorities to order their execution accordingly. That means, jobs are strictly acquired by the order of priorities. A note on Job Starvation In scheduling scenarios, starvation is a typical concern. When high priority jobs are continuously created, it may happen that low priority jobs are never acquired. Performance-wise, acquiring jobs strictly by priority enables the job executor to use indexes for ordering. Solutions like aging that dynamically boost priorities of starving jobs cannot be easily supplemented with an index. In addition, in an environment where the job executor can never catch up to execute all jobs in the job table such that low priority jobs are not executed in a reasonable amount of time, there may be a general issue with overloaded resources. In this case, a solution could be to distribute the work load based on Job Executor priority ranges (see Job Executor priority range) or increase the job executor resources by adding a new node to a cluster. Configure the Process Engine for Job Priorities This section explains how to enable and disable job priorities in the configuration. There are two relevant configuration properties which can be set on the process engine configuration: producePrioritizedJobs: Controls whether the process engine assigns priorities to jobs. The default value is true. If priorities are not needed, the process engine configuration property producePrioritizedJobs can be set to false. In this case, all jobs receive a priority of 0. For details on how to specify job priorities and how the process engine assigns them, see the following section on Specifying Job Priorities. jobExecutorAcquireByPriority: Controls whether jobs are acquired according to their priority. The default value is false which means that it needs to be explicitly enabled. Hint: when enabling this, additional database indexes should be created as well: See the section The Order of Job Acquisition for details. Specify Job Priorities Job priorities can be specified in the BPMN model as well as overridden at runtime via API. Priorities in BPMN XML Job Priorities can be assigned at the process or the activity level. To achieve this the Camunda extension attribute camunda:jobPriority can be used. For specifying the priority, both constant values and expressions are supported. When using a constant value, the same priority is assigned to all instances of the process or activity. Expressions, on the other hand, allow assigning a different priority to each instance of the process or activity. Expression must evaluate to a number in the Java long range. The concrete value can be the result of a complex calculation and be based on user-provided data (resulting from a task form or other sources). Priorities at the Process Level When configuring job priorities at the process instance level, the camunda:jobPriority attribute needs to be applied to the bpmn <process ...> element: <bpmn:process id=\"Process_1\" isExecutable=\"true\" camunda:jobPriority=\"8\"> ... </bpmn:process> The effect is that all activities inside the process inherit the same priority (unless it is overridden locally). See also: Job Priority Precedence Schema. The above example shows how a constant value can be used for setting the priority. This way the same priority is applied to all instances of the process. If different process instances need to be executed with different priorities, an expression can be used: <bpmn:process id=\"Process_1\" isExecutable=\"true\" camunda:jobPriority=\"${order.priority}\"> ... </bpmn:process> In the above example the priority is determined based on the property priority of the variable order. Priorities at the Activity Level When configuring job priorities at the activity level, the camunda:jobPriority attribute needs to be applied to the corresponding bpmn element: <bpmn:serviceTask id=\"ServiceTask_1\" name=\"Prepare Payment\" camunda:asyncBefore=\"true\" camunda:jobPriority=\"100\" /> The effect is that the priority is applied to all instances of the given service task. The priority overrides a process level priority. See also: Job Priority Precedence Schema. When using a constant value, as shown in the above example, the same priority is applied to all instances of the service task. It is also possible to use an expression: <bpmn:serviceTask id=\"ServiceTask_1\" name=\"Schedule Delivery\" camunda:asyncBefore=\"true\" camunda:jobPriority=\"${customer.status == 'VIP' ? 10 : 0}\" /> In the above example the priority is determined based on the property status of the current customer. Resolution Context of Priority Expressions This section explains which context variables and functions are available when evaluating priority expressions. For some general documentation on this, see the corresponding documentation section. All priority expressions are evaluated in the context of an existing execution. This means that variable execution is implicitly defined as well as all of the execution’s variables by their name. The only exceptions are the priority of jobs which lead to the instantiation of a new process instance. Examples: Timer Start Event Asynchronous Signal Start Event Priority Propagation to Called Process Instances When starting a process instance via a call activity, you sometimes want the process instance to “inherit” the priority of the calling process instance. The easiest way to achieve this is by passing the priority using a variable and referencing it using an expression in the called process. See also Call Activity Parameters for details on how to pass variables using call activities. Set Job Definition Priorities via ManagementService API Sometimes job priorities need to be changed at runtime to deal with unforeseen circumstances. For example: consider the service task Process Payment of an order process: the service task invokes some external payment service which may be overloaded and thus respond slowly. The job executor is therefore blocked waiting for responses. Other concurrent jobs with the same or lower priorities cannot proceed, although this is desirable in this exceptional situation. Override Priority by Job Definition While expressions may help in these cases to a certain extent, it is cumbersome to change process data for all involved process instances and to make sure to restore it when the exceptional condition is over. Thus the ManagementService API allows to temporarily set an overriding priority for a job definition. The following operation can be performed to downgrade the priority for all future jobs of a given job definition: // find the job definition JobDefinition jobDefinition = managementService .createJobDefinitionQuery() .activityIdIn(\"ServiceTask_1\") .singleResult(); // set an overriding priority managementService.setOverridingJobPriorityForJobDefinition(jobDefinition.getId(), 0L); Setting an overriding priority makes sure that every new job that is created based on this definition receives the given priority. This setting overrides any priority specified in the BPMN XML. Optionally, the overriding priority can be applied to all the existing jobs of that definition by using the cascade parameter: managementService.setOverridingJobPriorityForJobDefinition(jobDefinition.getId(), 0L, true); Note that this will not lead to preemption of jobs that are currently executed. Reset Priority by Job Definition When the service has recovered from the overload situation, overriding priority can be cleared again as follows: managementService.clearOverridingJobPriorityForJobDefinition(jobDefinition.getId()); From now on, all new jobs receive the priorities specified in the BPMN XML again. Job Priority Precedence Schema The following diagram sums up the precedence of priority sources when a job’s priority is determined: Set Job Priorities via ManagementService API The ManagementService also offers a method to change a single job’s priority via ManagementService#setJobPriority(String jobId, long priority). Job Acquisition Job acquisition is the process of retrieving jobs from the database that are to be executed next. Therefore jobs must be persisted to the database together with properties determining whether a job can be executed. For example, a job created for a timer event may not be executed before the defined time span has passed. Persistence Jobs are persisted to the database, in the ACT_RU_JOB table. This database table has the following columns (among others): ID_ | REV_ | LOCK_EXP_TIME_ | LOCK_OWNER_ | RETRIES_ | DUEDATE_ Job acquisition is concerned with polling this database table and locking jobs. Acquirable Jobs A job is acquirable, i.e., a candidate for execution, if it fulfills all following conditions: it is due, meaning that the value in the DUEDATE_ column is in the past it is not locked, meaning that the value in the LOCK_EXP_TIME_ column is in the past its retries have not been depleted, meaning that the value in the RETRIES_ column is greater than zero. In addition, the process engine has a concept of job suspension. For example, a job gets suspended when the process instance it belongs gets suspended. A job is only acquirable if it is not suspended. Job Acquisition performance optimization To optimize the acquisition of jobs that need to be executed immediately, the DUEDATE_ column is not set (null) and a (positive) null check is added as a condition for acquisition. In case each job must have a DUEDATE_ set, the optimization can be disabled. This can be done by setting the ensureJobDueDateNotNull process engine configuration flag to true. However, any jobs created with a null value for DUEDATE_ before disabling the optimization will not be picked up by the Job Acquisition phase, unless the jobs are explicitly updated with a due date through the Set Due Date Java /REST or Set Retries Java /REST APIs. The Two Phases of Job Acquisition Job acquisition has two phases. In the first phase the job executor queries for a configurable amount of acquirable jobs. If at least one job can be found, it enters the second phase, locking the jobs. Locking is necessary in order to ensure that jobs are executed exactly once. In a clustered scenario, it is customary to operate multiple job executor instances (one for each node) that all poll the same ACT_RU_JOB table. Locking a job ensures that it is only acquired by a single job executor instance. Locking a job means updating its values in the LOCK_EXP_TIME_ and LOCK_OWNER_ columns. The LOCK_EXP_TIME_ column is updated with a timestamp signifying a date that lies in the future. The intuition behind this is that we want to lock the job until that date is reached. The LOCK_OWNER_ column is updated with a value uniquely identifying the current job executor instance. In a clustered scenario this could be a node name uniquely identifying the current cluster node. The situation where multiple job executor instances attempt to lock the same job concurrently is accounted for by using optimistic locking (see REV_ column). After having locked a job, the job executor instance has effectively reserved a time slot for executing the job: once the date written to the LOCK_EXP_TIME_ column is reached it will be visible to job acquisition again. In order to execute the acquired jobs, they are passed to the acquired jobs queue. The Job Order of Job Acquisition By default the job executor does not impose an order in which acquirable jobs are acquired. This means that the job acquisition order depends on the database and its configuration. That’s why job acquisition is assumed to be non-deterministic. The intention for this is to keep the job acquisition query simple and fast. This method of acquiring jobs is not sufficient in all cases, such as: Job Prioritization: When creating prioritized jobs, the job executor must acquire jobs according to the given priorities Job Starvation: In a high load scenario, job starvation is theoretically possible when new jobs are repeatedly created in a rate higher than the job executor can handle. Preferred Handling of Timers: In a high load scenario, timer execution can be delayed to a significantly later point in time than the actual due date. While a due date is not a real-time boundary by which the job is guaranteed to be executed, in some scenarios it may be preferable to acquire timer jobs as soon as they become available to execute. To address the previously described issues, the job acquisition query can be controlled by the process engine configuration properties. Currently, three options are supported: jobExecutorAcquireByPriority. If set to true, the job executor will acquire the jobs with the highest priorities. jobExecutorPreferTimerJobs. If set to true, the job executor will acquire all acquirable timer jobs before other job types. This doesn’t specify an order within types of jobs which are acquired. jobExecutorAcquireByDueDate. If set to true, the job executor will acquire jobs by ascending due date. An asynchronous continuation receives its creation date as due date, so it is immediately executable. Using a combination of these options results in a multi-level ordering. The precedence hierarchy of options is as in the order above: If all three options are active, priorities are the primary, job types the secondary, and due dates the tertiary ordering. This also shows that activating all options is not the optimal solution to the problems of prioritization, starvation, and timer handling. For example, in this case timer jobs are only preferred within one level of priority. Timers with lower priority are acquired after all jobs of higher priorities have been acquired. It is recommended to decide based on the concrete use case which options to activate. For example: For prioritized job execution, only jobExecutorAcquireByPriority should be set to true To execute timer jobs as soon as possible, the two options jobExecutorPreferTimerJobs and jobExecutorAcquireByDueDate should be activated. The job executor will first acquire timer jobs and after that asynchronous continuation jobs. And also sort these jobs within the type ascending by due date. All of these options are set to false by default and should only be activated if required by the use case. The options alter the used job acquisition query and may affect its performance. That’s why we also advise to add an index on the corresponding column(s) of the ACT_RU_JOB table. jobExecutorAcquireByPriority jobExecutorPreferTimerJobs jobExecutorAcquireByDueDate Recommended Index true false false ACT_RU_JOB(PRIORITY_ DESC) false true false ACT_RU_JOB(TYPE_ DESC) false false true ACT_RU_JOB(DUEDATE_ ASC) false true true ACT_RU_JOB(TYPE_ DESC, DUEDATE_ ASC) Job Executor priority range By default, the Job Executor executes all jobs regardless of their priorities. Some jobs might be more important to finish quicker than others, so we assign them priorities and set jobExecutorAcquireByPriority to true as described above. Depending on the workload, the Job Executor might be able to execute all jobs eventually. But if the load is high enough, we might face starvation where a Job Executor is always busy working on high-priority jobs and never manages to execute the lower priority jobs. To prevent this, you can specify a priority range for the job executor by setting values for jobExecutorPriorityRangeMin or jobExecutorPriorityRangeMax (or both). The Job Executor will only acquire jobs that are inside its priority range (inclusive). Both properties are optional, so it is fine only to set one of them. To avoid job starvation, make sure to have no gaps between Job Executor priority ranges. If, for example, Job Executor A has a priority range of 0 to 100 and Job Executor B executes jobs from priority 200 to Long.MAX_VALUE any job that receives a priority of 101 to 199 will never be executed. Job starvation can also occur with batch jobs and history cleanup jobs as both types of jobs also receive priorities (default: 0). You can configure them via their respective properties: batchJobPriority and historyCleanupJobPriority. This feature is particularly useful if you want to separate multiple types of jobs from each other. For example, short-running, urgent jobs with high priority and long-running jobs that are not urgent but should finish eventually. Setting up a Job Executor priority range for both types will ensure that long-running jobs can not block urgent ones. Backoff Strategy The Job Executor uses a backoff strategy to avoid acquisition conflicts in clusters and to reduce the database load when no jobs are due. The second point may result in a delay between job creation and job execution as the job acquisition by default doubles the delay to the next acquisition run. The default maximum wait time is 60 seconds. You can decrease the delay by setting the configuration parameter maxWait to a value lower than 60000 milliseconds. Job Execution Thread Pool Acquired jobs are executed by a thread pool. The thread pool consumes jobs from the acquired jobs queue. The acquired jobs queue is an in-memory queue with a fixed capacity. When an executor starts executing a job, it is first removed from the queue. In the scenario of an embedded process engine, the default implementation for this thread pool is a java.util.concurrent.ThreadPoolExecutor. However, this is not allowed in Java EE environments. There we hook into the application server capabilities of thread management. See the platform-specific information in the Runtime Container Integration section on how this achieved. Failed Jobs Upon failure of job execution, e.g., if a service task invocation throws an exception, a job will be retried a number of times (by default 2 so that the job is tried three times in total). It is not immediately retried and added back to the acquisition queue, but the value of the RETRIES_ column is decreased and the executor unlocks the job. The process engine thus performs bookkeeping for failed jobs. The unlocking also includes erasing the time LOCK_EXP_TIME_ and the owner of the lock LOCK_OWNER_ by setting both entries to null. Subsequently, the failed job will automatically be retried once the job is acquired for execution. Once the number of retries is exhausted (the value of the RETRIES_ column equals 0), the job is not executed any more and the engine stops at this job, signaling that it cannot proceed. While all failed jobs are retried, there is one case in which a job’s retries are not decremented. This is, if a job fails due to an optimistic locking exception. Optimistic Locking is the process engine’s mechanism to resolve conflicting resource updates, for example when two jobs of a process instance are executed in parallel (see the following sections on concurrent job execution). As an optimistic locking exception is no exceptional situation from an operator’s point of view and resolves eventually, it does not cause a retry decrement. If incident creation is enabled for jobs, then once job retries are depleted, an incident is created (see (De-)Activate Incidents). Incidents and historic incidents related to the job can be requested via Java API like this: List<Incident> incidents = engineRule.getRuntimeService() .createIncidentQuery().configuration(jobId).list(); List<HistoricIncident> historicIncidents = engineRule.getHistoryService() .createHistoricIncidentQuery().configuration(jobId).list(); Retry Time Cycle Configuration By default, a failed job will be retried three times and the retries are performed immediately after the failure. In daily business it might be useful to configure a retry strategy, i.e., by setting how often a job is retried and how long the engine should wait until it tries to execute a job again. This configuration can be specified globally in the process engine configuration. <process-engine name=\"default\"> ... <properties> ... <property name=\"failedJobRetryTimeCycle\">R5/PT5M</property> </properties> </process-engine> The configuration follows the ISO_8601 standard for repeating time intervals. In the example, R5/PT5M means that the maximum number of retries is 5 (R5) and the delay of retry is 5 minutes (PT5M). The CIB seven engine allows you to configure this setting for the following specific elements: Activities (tasks, call activities, subprocesses) Events Multi-Instance Activities Use a Custom Job Retry Configuration for Activities As soon as the retry configuration is enabled, it can be applied to tasks, call activities, embedded subprocesses and transactions subprocesses. For instance, the job retry in a task can be configured in the CIB seven engine in the BPMN 2.0 XML as follows: <definitions xmlns:camunda=\"http://camunda.org/schema/1.0/bpmn\"> ... <serviceTask id=\"failingServiceTask\" camunda:asyncBefore=\"true\" camunda:class=\"org.mycompany.FailingDelegate\"> <extensionElements> <camunda:failedJobRetryTimeCycle>R5/PT5M</camunda:failedJobRetryTimeCycle> </extensionElements> </serviceTask> ... </definitions> You can also set an expression as in the retry configuration. For example: <camunda:failedJobRetryTimeCycle>${retryCycle}</camunda:failedJobRetryTimeCycle> The LOCK_EXP_TIME_ is used to define when the job can be executed again, meaning the failed job will automatically be retried once the LOCK_EXP_TIME_ date is expired. Use a Custom Job Retry Configuration for Events The job retries can also be configured for the following events: Timer Start Event Boundary Timer Event Intermediate Timer Catch Event Intermediate Throw Event Similar to tasks, the retries can be configured as an extension element of the event. The following example defines three retries after 5 seconds each for a boundary timer event: <definitions xmlns:camunda=\"http://camunda.org/schema/1.0/bpmn\"> ... <boundaryEvent id=\"BoundaryEvent\" name=\"BoundaryName\" attachedToRef=\"MyActivity\"> <extensionElements> <camunda:failedJobRetryTimeCycle>R3/PT5S</camunda:failedJobRetryTimeCycle> </extensionElements> <outgoing>SequenceFlow_3</outgoing> <timerEventDefinition> <timeDuration>PT10S</timeDuration> </timerEventDefinition> </boundaryEvent> ... </definitions> Reminder: a retry may be required if there are any failures during the transaction which follows the timer. Use a Custom Job Retry Configuration for Multi-Instance Activities If the retry configuration is set for a multi-instance activity then the configuration is applied to the multi-instance body. Additionally, the retries of the inner activities can also be configured using the extension element as child of the multiInstanceLoopCharacteristics element. The following example defines the retries of a multi-instance service task with asynchronous continuation of the multi-instance body and the inner activity. If a failure occur during one of the five parallel instances then the job of the failed instance will be retried up to 3 times with a delay of 5 seconds. In case all instances ended successful and a failure occur during the transaction which follows the task, the job will be retried up to 5 times with a delay of 5 minutes. <definitions xmlns:camunda=\"http://camunda.org/schema/1.0/bpmn\"> ... <serviceTask id=\"failingServiceTask\" camunda:asyncAfter=\"true\" camunda:class=\"org.mycompany.FailingDelegate\"> <extensionElements> <!-- configuration for multi-instance body, e.g. after task ended --> <camunda:failedJobRetryTimeCycle>R5/PT5M</camunda:failedJobRetryTimeCycle> </extensionElements> <multiInstanceLoopCharacteristics isSequential=\"false\" camunda:asyncBefore=\"true\"> <extensionElements> <!-- configuration for inner activities, e.g. before each instance started --> <camunda:failedJobRetryTimeCycle>R3/PT5S</camunda:failedJobRetryTimeCycle> </extensionElements> <loopCardinality>5</loopCardinality> </multiInstanceLoopCharacteristics> </serviceTask> ... </definitions> Retry Intervals The retry time cycle (e.g. R5/PT5M) allows to define the number of retries and an interval when the failed job should be retried. Regardless of the values, the interval is always (at least) 5 minutes. You can configure the list of retry intervals (separated by comma) on a global level or for a specific job configuration. The local configuration takes precedence. Here is an example of a global process engine configuration: <process-engine name=\"default\"> ... <properties> ... <property name=\"failedJobRetryTimeCycle\">PT10M,PT17M,PT20M</property> </properties> </process-engine> The retry times would be three and the behaviour for this example would be the following: A job fails for the first time: the job will be retried in 10 minutes (PT10M is applied). A job fails for the second time: the job will be retried in 17 minutes (PT17M is applied). A job fails for the third time: the job will be retried in 20 minutes (PT20M is applied). A job fails for the fourth time: the job will NOT be retried again and the next due date is in 20 minutes (PT20M is applied again). If the user decides to increase the retry number during retries, the last interval of the list would be applied within the difference between the new value and the size of the list. After that, it would continue with the normal flow as above. The API to increase the number of retries also supports passing a new due date for the job which will determine when the job will be picked up again. This is useful in cases where you want to control when a failed job should be tried again. For example, an incident has been resolved and the job should run as soon as possible instead of waiting for the next retry cycle. In this case, setting the job due date to the current date or a date in the past would make the job executor pick up the job immediately. Custom Retry Configuration You can configure an custom retry configuration by adding the customPostBPMNParseListeners property and specify your custom FailedJobParseListener to the process engine configuration: <bean id=\"processEngineConfiguration\" class=\"org.cibseven.bpm.engine.impl.cfg.StandaloneInMemProcessEngineConfiguration\"> <!-- Your defined properties! --> ... <property name=\"customPostBPMNParseListeners\"> <list> <bean class=\"com.company.impl.bpmn.parser.CustomFailedJobParseListener\" /> </list> </property> ... </bean> Concurrent Job Execution The Job Executor makes sure that jobs from a single process instance are never executed concurrently. Why is this? Consider the following process definition: We have a parallel gateway followed by three service tasks which all perform an asynchronous continuation. As a result of this, three jobs are added to the database. Once such a job is present in the database it can be processed by the job executor. It acquires the jobs and delegates them to a thread pool of worker threads which actually process the jobs. This means that using an asynchronous continuation, you can distribute the work to this thread pool (and in a clustered scenario even across multiple thread pools in the cluster). This is usually a good thing. However it also bears an inherent problem: consistency. Consider the parallel join after the service tasks. When the execution of a service task is completed, we arrive at the parallel join and need to decide whether to wait for the other executions or whether we can move forward. That means, for each branch arriving at the parallel join, we need to take a decision whether we can continue or whether we need to wait for one or more other executions from the other branches. This requires synchronization between the branches of execution. The engine addresses this problem with optimistic locking. Whenever we take a decision based on data that might not be current (because another transaction might modify it before we commit), we make sure to increment the revision of the same database row in both transactions. This way, whichever transaction commits first wins and the other ones fail with an optimistic locking exception. This solves the problem in the case of the process discussed above: if multiple executions arrive at the parallel join concurrently, they all assume that they have to wait, increment the revision of their parent execution (the process instance) and then try to commit. Whichever execution is first will be able to commit and the other ones will fail with an optimistic locking exception. Since the executions are triggered by a job, the job executor will retry to perform the same job after waiting for a certain amount of time and hopefully this time pass the synchronizing gateway. However, while this is a perfectly fine solution from the point of view of persistence and consistency, this might not always be desirable behavior at a higher level, especially if the execution has non-transactional side effects, which will not be rolled back by the failing transaction. For instance, if the book concert tickets service does not share the same transaction as the process engine, we might book multiple tickets if we retry the job. That is why jobs of the same process instance are processed exclusively by default. Exclusive Jobs An exclusive job cannot be performed at the same time as another exclusive job from the same process instance. Consider the process shown in the section above: if the jobs corresponding to the service tasks are treated as exclusive, the job executor will try to avoid that they are executed in parallel. Instead, it will ensure that whenever it acquires an exclusive job from a certain process instance, it also acquires all other exclusive jobs from the same process instance and delegates them to the same worker thread. This enforces sequential execution of these jobs and in most cases avoids optimistic locking exceptions. However, this behavior is a heuristic, meaning that the job executor can only enforce sequential execution of the jobs that are available during lookup time. If a potentially conflicting job is created after that, is currently running or is already scheduled for execution, the job may be processed by another job execution thread in parallel. Exclusive Jobs are the default configuration. All asynchronous continuations and timer events are thus exclusive by default. In addition, if you want a job to be non-exclusive, you can configure it as such using camunda:exclusive=\"false\". For example, the following service task would be asynchronous but non-exclusive. <serviceTask id=\"service\" camunda:expression=\"${myService.performBooking(hotel, dates)}\" camunda:asyncBefore=\"true\" camunda:exclusive=\"false\" /> Is this a good solution? We had some people asking whether it was. Their concern was that it would prevent you from doing things in parallel and would thus be a performance problem. Again, two things have to be taken into consideration: It can be turned off if you are an expert and know what you are doing (and have understood this section). Other than that, it is more intuitive for most users if things like asynchronous continuations and timers just work. Note: one strategy to deal with OptimisticLockingExceptions at a parallel gateway is to configure the gateway to use asynchronous continuations. This way the job executor can be used to retry the gateway until the exception resolves. It is actually not a performance issue. Performance is an issue under heavy load. Heavy load means that all worker threads of the job executor are busy all the time. With exclusive jobs the engine will simply distribute the load differently. Exclusive jobs means that jobs from a single process instance are performed by the same thread sequentially. But consider: you have more than one single process instance. Jobs from other process instances are delegated to other threads and executed concurrently. This means that with exclusive jobs the engine will not execute jobs from the same process instance concurrently but it will still execute multiple instances concurrently. From an overall throughput perspective this is desirable in most scenarios as it usually leads to individual instances being done more quickly. Exclusive Jobs of Process Hierarchies As explained above, the exclusive asynchronous continuation will instruct the job executor to acquire and execute the jobs of a given process instance by one thread. How does exclusive behave when a process contains hierarchies e.g. when multiple parallel subprocesses can be spawned by a root process? By default, the exclusive acquisition & execution is only guaranteed for the jobs that originate from the root process instance. In a multi-instance call activity setting, the subprocess instances that will be spawned can run in parallel despite selecting exclusive asynchronous continuation as depicted in the image below. If there is a use case where the subprocess-jobs should not be performed in parallel across each single process instance, the following configuration can be used: <process-engine name=\"default\"> ... <properties> <property name=\"jobExecutorAcquireExclusiveOverProcessHierarchies\">true</property> ... </properties> </process-engine> The property jobExecutorAcquireExclusiveOverProcessHierarchies is by default set to false. See the property under the Configuration Properties section. Keep in mind that enabling the feature to guarantee exclusive jobs across all subprocesses originating from a root process might have performance implications, especially for process definitions that involve complex and numerous hierarchies. Use the feature in combination with awareness of your process model. The Job Executor and Multiple Process Engines In the case of a single, application-embedded process engine, the job executor setup is the following: There is a single job table that the engine adds jobs to and the acquisition consumes from. Creating a second embedded engine would therefore create another acquisition thread and execution thread-pool. In larger deployments however, this quickly leads to a poorly manageable situation. When running CIB seven on Tomcat or an application server, the platform allows to declare multiple process engines shared by multiple process applications. With respect to job execution, one job acquisition may serve multiple job tables (and thus process engines) and a single thread-pool for execution may be used. This setup enables centralized monitoring of job acquisition and execution. See the platform-specific information in the Runtime Container Integration section on how the thread pooling is implemented on the different platforms. Different job acquisitions can also be configured differently, e.g. to meet business requirements like SLAs. For example, the acquisition’s timeout when no more executable jobs are present can be configured differently per acquisition. To which job acquisition a process engine is assigned can be specified in the declaration of the engine, so either in the processes.xml deployment descriptor of a process application or in the CIB seven descriptor. The following is an example configuration that declares a new engine and assigns it to the job acquisition named default, which is created when the platform is bootstrapped. <process-engine name=\"newEngine\"> <job-acquisition>default</job-acquisition> ... </process-engine> Job acquisitions have to be declared in CIB seven’s deployment descriptor, see the container-specific configuration options. Cluster Setups When running CIB seven in a cluster, there is a distinction between homogeneous and heterogeneous setups. We define a cluster as a set of network nodes that all run CIB seven against the same database (at least for one engine on each node). In the homogeneous case, the same process applications (and thus custom classes like JavaDelegates) are deployed to all of the nodes, as depicted below. In the heterogeneous case, this is not given, meaning that some process applications are only deployed to a part of the nodes. Job Execution in Heterogeneous Clusters A heterogeneous cluster setup as described above poses additional challenges to the job executor. Both platforms declare the same engine, i.e. they run against the same database. This means that jobs will be inserted into the same table. However, in the default configuration the job acquisition thread of node 1 will lock any executable jobs of that table and submit them to the local job execution pool. This means that jobs created in the context of process application B (so on node 2) may be executed on node 1 and vice versa. As the job execution may involve classes that are part of B’s deployment, you are likely going to see a ClassNotFoundExeception or any of the likes. To prevent the job acquisition on node 1 from picking jobs that belong to node 2, the process engine can be configured as deployment aware, by the setting following property in the process engine configuration: <process-engine name=\"default\"> ... <properties> <property name=\"jobExecutorDeploymentAware\">true</property> ... </properties> </process-engine> Now, the job acquisition thread on node 1 will only pick up jobs that belong to deployments made on that node, which solves the problem. Digging a little deeper, the acquisition will only pick up those jobs that belong to deployments that were registered with the engines it serves. Every deployment gets automatically registered. Additionally, one can explicitly register and unregister single deployments with an engine by using the ManagementService methods registerDeploymentForJobExecutor(deploymentId) and unregisterDeploymentForJobExecutor(deploymentId). It also offers a method getRegisteredDeployments() to inspect the currently registered deployments. As this is configurable on engine level, you can also work in a mixed setup, when some deployments are shared between all nodes and some are not. You can assign the globally shared process applications to an engine that is not deployment aware and the others to a deployment aware engine, probably both running against the same database. This way, jobs created in the context of the shared process applications will get executed on any cluster node, while the others only get executed on their respective nodes.",
    "url": "/manual/latest/user-guide/process-engine/the-job-executor/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/time-zones/index.html",
    "title": "Time zones | docs.cibseven.org",
    "content": "Process engine The CIB seven engine uses the default time zone of the JVM when operating with dates: When reading datetime values from BPMN XML In REST responses When reading/writing DateTime values from/to the database Database Database time zone and database sessions time zone are out of scope of the CIB seven engine and must be configured explicitly. However, Timestamp columns in the CIB seven engine are using the TIMESTAMP [WITHOUT TIME ZONE] data type (the name differs in different database servers). For this reason, it is not recommended to change the time zone on the database side once set, since it may lead to an incorrect operation of the CIB seven engine. Daylight Saving Time Timezone information is not saved in the timestamp columns. In order to avoid ambiguous timestamps, it is recommended to use a timezone like UTC as the JVM’s default timezone that is not adjusted for Daylight Saving Time (DST) and therefore cannot produce ambiguous timestamps. If this is not an option in your setting, please consider disabling the JobExecutor during the DST switch in order to avoid unexpected job executions. Camunda Web Applications It is possible to use the Camunda Web Applications in different timezones. All dates are translated to/from the local timezone when working with the UI. Cluster Setup In case the process engine is running in a cluster, all cluster nodes must run in one and the same time zone. In case cluster nodes exist in different time zones, correct behaviour when operating with DateTime values can not be guaranteed.",
    "url": "/manual/latest/user-guide/process-engine/time-zones/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/transactions-in-processes/index.html",
    "title": "Transactions in Processes | docs.cibseven.org",
    "content": "The process engine is a piece of passive Java code which works in the Thread of the client. For instance, if you have a web application allowing users to start a new process instance and a user clicks on the corresponding button, some thread from the application server’s http-thread-pool will invoke the API method runtimeService.startProcessInstanceByKey(...), thus entering the process engine and starting a new process instance. We call this “borrowing the client thread”. On any such external trigger (i.e., start a process, complete a task, signal an execution), the engine runtime will advance in the process until it reaches wait states on each active path of execution. A wait state is a task which is performed later, which means that the engine persists the current execution to the database and waits to be triggered again. For example in case of a user task, the external trigger on task completion causes the runtime to execute the next bit of the process until wait states are reached again (or the instance ends). In contrast to user tasks, a timer event is not triggered externally. Instead it is continued by an internal trigger. That is why the engine also needs an active component, the job executor, which is able to fetch registered jobs and process them asynchronously. Wait States We talked about wait states as transaction boundaries where the process state is stored to the database, the thread returns to the client and the transaction is committed. The following BPMN elements are always wait states: Receive Task User Task Message Message Event Timer Timer Event Signal Signal Event The Event Based Gateway: A special type of the Service Task: External Task Keep in mind that Asynchronous Continuations can add transaction boundaries to other tasks as well. Transaction Boundaries The transition from one such stable state to another stable state is always part of a single transaction, meaning that it succeeds as a whole or is rolled back on any kind of exception occuring during its execution. This is illustrated in the following example: We see a segment of a BPMN process with a user task, a service task and a timer event. The timer event marks the next wait state. Completing the user task and validating the address is therefore part of the same unit of work, so it should succeed or fail atomically. That means that if the service task throws an exception we want to roll back the current transaction, so that the execution tracks back to the user task and the user task is still present in the database. This is also the default behavior of the process engine. In 1, an application or client thread completes the task. In that same thread the engine runtime is now executing the service task and advances until it reaches the wait state at the timer event (2). Then it returns the control to the caller (3) potentially committing the transaction (if it was started by the engine). Asynchronous Continuations Why Asynchronous Continuations? In some cases the synchronous behavior is not desired. Sometimes it is useful to have custom control over transaction boundaries in a process. The most common motivation is the requirement to scope logical units of work. Consider the following process fragment: We are completing the user task, generating an invoice and then sending that invoice to the customer. It can be argued that the generation of the invoice is not part of the same unit of work: we do not want to roll back the completion of the usertask if generating an invoice fails. Ideally, the process engine would complete the user task (1), commit the transaction and return control to the calling application (2). In a background thread (3), it would generate the invoice. This is the exact behavior offered by asynchronous continuations: they allow us to scope transaction boundaries in the process. Configure Asynchronous Continuations Asynchronous Continuations can be configured before and after an activity. Additionally, a process instance itself may be configured to be started asynchronously. An asynchronous continuation before an activity is enabled using the camunda:asyncBefore extension attribute: <serviceTask id=\"service1\" name=\"Generate Invoice\" camunda:asyncBefore=\"true\" camunda:class=\"my.custom.Delegate\" /> An asynchronous continuation after an activity is enabled using the camunda:asyncAfter extension attribute: <serviceTask id=\"service1\" name=\"Generate Invoice\" camunda:asyncAfter=\"true\" camunda:class=\"my.custom.Delegate\" /> Asynchronous instantiation of a process instance is enabled using the camunda:asyncBefore extension attribute on a process-level start event. On instantiation, the process instance will be created and persisted in the database, but execution will be deferred. Also, execution listeners will not be invoked synchronously. This can be helpful in various situations such as heterogeneous clusters, when the execution listener class is not available on the node that instantiates the process. <startEvent id=\"theStart\" name=\"Invoice Received\" camunda:asyncBefore=\"true\" /> Asynchronous Continuations of Multi-Instance Activities A multi-instance activity can be configured for asynchronous continuation like other activities. Declaring asynchronous continuation of a multi-instance activity makes the multi-instance body asynchronous, that means, the process continues asynchronously before the instances of that activity are created or after all instances have ended. Additionally, the inner activity can also be configured for asynchronous continuation using the camunda:asyncBefore and camunda:asyncAfter extension attributes on the multiInstanceLoopCharacteristics element: <serviceTask id=\"service1\" name=\"Generate Invoice\" camunda:class=\"my.custom.Delegate\"> <multiInstanceLoopCharacteristics isSequential=\"false\" camunda:asyncBefore=\"true\"> <loopCardinality>5</loopCardinality> </multiInstanceLoopCharacteristics> </serviceTask> Declaring asynchronous continuation of the inner activity makes each instance of the multi-instance activity asynchronous. In the above example, all instances of the parallel multi-instance activity will be created but their execution will be deferred. This can be useful to take more control over the transaction boundaries of the multi-instance activity or to enable true parallelism in case of a parallel multi-instance activity. Understand Asynchronous Continuations To understand how asynchronous continuations work, we first need to understand how an activity is executed: The above illustration shows how a regular activity which is entered and left by a sequence flow is executed: The “TAKE” listeners are invoked on the sequence flow entering the activity. The “START” listeners are invoked on the activity itself. The behavior of the activity is executed: the actual behavior depends on the type of the activity: in case of a Service Task the behavior consists of invoking Delegation Code, in case of a User Task, the behavior consists of creating a Task instance in the task list etc… The “END” listeners are invoked on the activity. The “TAKE” listeners of the outgoing sequence flow are invoked. Asynchronous Continuations allow putting break points between the execution of the sequence flows and the execution of the activity: The above illustration shows where the different types of asynchronous continuations break the execution flow: An asynchronous continuation BEFORE an activity breaks the execution flow between the invocation of the incoming sequence flow’s TAKE listeners and the execution of the activity’s START listeners. An asynchronous continuation AFTER an activity breaks the execution flow between the invocation of the activity’s END listeners and the outgoing sequence flow’s TAKE listeners. Asynchronous continuations directly relate to transaction boundaries: putting an asynchronous continuation before or after an activity creates a transaction boundary before or after the activity: What’s more, asynchronous continuations are always executed by the Job Executor. Rollback on Exception We want to emphasize that in case of a non handled exception, the current transaction gets rolled back and the process instance is in the last wait state (save point). The following image visualizes that. If an exception occurs when calling startProcessInstanceByKey the process instance will not be saved to the database at all. Reasoning for This Design The above sketched solution normally leads to discussion, as people expect the process engine to stop in case the task caused an exception. Also, other BPM suites often implement every task as a wait state. However, this approach has a couple of advantages: In test cases you know the exact state of the engine after the method call, which makes assertions on process state or service call results easy. In production code the same is true; allowing you to use synchronous logic if required, for example because you want to present a synchronous user experience in the front-end. The execution is plain Java computing which is very efficient in terms of performance. You can always switch to ‘asyncBefore/asyncAfter=true’ if you need different behavior. However, there are consequences which you should keep in mind: In case of exceptions, the state is rolled back to the last persistent wait state of the process instance. It might even mean that the process instance will never be created! You cannot easily trace the exception back to the node in the process causing the exception. You have to handle the exception in the client. Parallel process paths are not executed in parallel in terms of Java Threads, the different paths are executed sequentially, since we only have and use one Thread. Timers cannot fire before the transaction is committed to the database. Timers are explained in more detail later, but they are triggered by the only active part of the Process Engine where we use own Threads: The Job Executor. Hence they run in an own thread which receives the due timers from the database. However, in the database the timers are not visible before the current transaction is visible. So the following timer will never fire: Transaction Integration The process engine can either manage transactions on its own (“Standalone” transaction management) or integrate with a platform transaction manager. Standalone Transaction Management If the process engine is configured to perform standalone transaction management, it always opens a new transaction for each command which is executed. To configure the process engine to use standalone transaction management, use the org.cibseven.bpm.engine.impl.cfg.StandaloneProcessEngineConfiguration: ProcessEngineConfiguration.createStandaloneProcessEngineConfiguration() ... .buildProcessEngine(); The use cases for standalone transaction management are situations where the process engine does not have to integrate with other transactional resources such as secondary datasources or messaging systems. In the Tomcat distribution the process engine is configured using standalone transaction management. Transaction Manager Integration The process engine can be configured to integrate with a transaction manager (or transaction management systems). Out of the box, the process engine supports integration with Spring and JTA transaction management. More information can be found in the following chapters: Section on Spring Transaction Management Section on JTA Transaction Management The use cases for transaction manager integration are situations where the process engine needs to integrate with Transaction focused programming models such as Java EE or Spring (think about transaction scoped JPA entity managers in Java EE), Other transactional resources such as secondary datasources, messaging systems or other transactional middleware like the web services stack. When you configure a transaction manager, make sure that it actually manages the data source that you have configured for the process engine. If that is not the case, the data source works in auto-commit mode. This can lead to inconsistencies in the database, because transaction commits and rollbacks are no longer performed. Transactions and the Process Engine Context When a Process Engine Command is executed, the engine will create a Process Engine Context. The Context caches database entities, so that multiple operations on the same entity do not result in multiple database queries. This also means that the changes to these entities are accumulated and are flushed to the database as soon as the Command returns. However, it should be noted that the current transaction may be committed at a later time. If a Process Engine Command is nested into another Command, i.e. a Command is executed within another command, the default behaviour is to reuse the existing Process Engine Context. This means that the nested Command will have access to the same cached entities and the changes made to them. When the nested Command is to be executed in a new transaction, a new Process Engine Context needs to be created for its execution. In this case, the nested Command will use a new cache for the database entities, independent of the previous (outer) Command cache. This means that, the changes in the cache of one Command are invisible to the other Command and vice versa. When the nested Command returns, the changes are flushed to the database independently of the Process Engine Context of the outer Command. The ProcessEngineContext utility class can be used to declare to the Process Engine that a new Process Engine Context needs to be created in order for the database operations in a nested Process Engine Command to be separated in a new transaction. The following Java code example shows how the class can be used: try { // declare new Process Engine Context ProcessEngineContext.requiresNew(); // call engine APIs execution.getProcessEngineServices() .getRuntimeService() .startProcessInstanceByKey(\"EXAMPLE_PROCESS\"); } finally { // clear declaration for new Process Engine Context ProcessEngineContext.clear(); } Optimistic Locking The CIB seven engine can be used in multi threaded applications. In such a setting, when multiple threads interact with the process engine concurrently, it can happen that these threads attempt to do changes to the same data. For example: two threads attempt to complete the same User Task at the same time (concurrently). Such a situation is a conflict: the task can be completed only once. CIB seven engine uses a well known technique called “Optimistic Locking” (or Optimistic Concurrently Control) to detect and resolve such situations. This section is structured in two parts: The first part introduces Optimistic Locking as a concept. You can skip this section in case you are already familiar with Optimistic Locking as such. The second part explains the usage of Optimistic Locking in Camunda. What is Optimistic Locking? Optimistic Locking (also Optimistic Concurrency Control) is a method for concurrency control, which is used in transaction based systems. Optimistic Locking is most efficient in situations in which data is read more frequently than it is changed. Many threads can read the same data objects at the same time without excluding each other. Consistency is then ensured by detecting conflicts and preventing updates in situations in which multiple threads attempt to change the same data objects concurrently. If such a conflict is detected, it is ensured that only one update succeeds and all others fail. Example Assume we have a database table with the following entry: Id Version Name Address ... 8 1 Steve 3, Workflow Boulevard, Token Town ... ... ... ... ... ... The above table shows a single row holding user data. The user has a unique Id (primary key), a version, a name and a current address. We now construct a situation in which 2 transactions attempt to update this entry, one attempting to change the address, the other one attempting to delete the user. The intended behavior is that once of the transactions succeeds and the other is aborted with an error indicating that a concurrency conflict was detected. The user can then decide to retry the transaction based on the latest state of the data: As you can see in the picture above, Transaction 1 reads the user data, does something with the data, deletes the user and then commits. Transaction 2 starts at the same time and reads the same user data, and also works on the data. When Transaction 2 attempts to update the user address a conflict is detected (since Transaction 1 has already deleted the user). The conflict is detected because the current state of the user data is read when Transaction 2 performs the update. At that time, the concurrent Transaction 1 has already marked the row to be deleted. The database now waits for Transaction 1 to end. After it is ended, Transaction 2 can proceed. At this time, the row does not exist anymore and the update succeeds but reports to have changed 0 rows. An application can react to this and rollback Transaction 2 to prevent other changes made by that transaction to become effective. The application (or the user using it) can further decide whether Transaction 2 should be retried. In our example, the transaction would then not find the user data and report that the user has been deleted. Optimistic Locking vs. Pessimistic Locking Pessimistic Locking works with read locks. A read lock locks a data object on read, preventing other concurrent transactions from reading it as well. This way, conflicts are prevented from occurring. In the example above, Transaction 1 would lock the user data once it reads it. When attempting to read is as well, Transaction 2 is blocked from making progress. Once Transaction 1 completes, Transaction 2 can progress and reads the latest state. This way conflicts are prevented as transactions always exclusively work on the latest state of data. Pessimistic Locking is efficient in situations where writes are as frequent as reads and with high contention. However, since pessimistic locks are exclusive, concurrency is reduced, degrading performance. Optimistic Locking, which detects conflicts rather than preventing them to occur, is therefore preferable in the context of high levels of concurrency and where reads are more frequent than writes. Also, Pessimistic Locking can quickly lead to deadlocks. Further Reading [1] Wikipedia: Optimistic concurrency control [2] Stackoverflow: Optimistic vs. Pessimistic Locking Optimistic Locking in CIB seven CIB seven uses Optimistic Locking for concurrency control. If a concurrency conflict is detected, an exception is thrown and the transaction is rolled back. Conflicts are detected when UPDATE or DELETE statements are executed. The execution of delete or update statements return an affected rows count. If this count is equal to zero, it indicates that the row was previously updated or deleted. In such cases a conflict is detected and an OptimisticLockingException is thrown. The OptimisticLockingException The OptimisticLockingException can be thrown by API methods. Consider the following invocation of the completeTask(...) method: taskService.completeTask(aTaskId); // may throw OptimisticLockingException The above method may throw an OptimisticLockingException in case executing the method call leads to concurrent modification of data. Job execution can also cause an OptimisticLockingException to be thrown. Since this is expected, the execution will be retried. Handling Optimistic Locking exceptions In case the current Command is triggered by the Job Executor, OptimisticLockingExceptions are handled automatically using retries. Since this exception is expected to occur, it does not decrement the retry count. If the current Command is triggered by an external API call, the CIB seven engine rolls back the current transaction to the last save point (wait state). Now the user has to decide how the exception should be handled, if the transaction should be retried or not. Also consider that even if the transaction was rolled back, it may have had non-transactional side effects which have not been rolled back. To control the scope of transactions, explicit save points can be added before and after activities using Asynchronous Continuations. Common Places Where Optimistic Locking Exceptions Are Thrown There a some common places where an OptimisticLockingException can be thrown. For example Competing external requests: completing the same task twice, concurrently. Synchronization points inside a process: Examples are parallel gateway, multi instance, etc. The following model shows a parallel gateway, on which the OptimisticLockingException can occur. There are two user tasks after the opening parallel gateway. The closing parallel gateway, after the user tasks, merges the executions to one. In most cases, one of the user tasks will be completed first. Execution then waits on the closing parallel gateway until the second user task is completed. However, it is also possible that both user tasks are completed concurrently. Say the user task above is completed. The transaction assumes he is the first on the closing parallel gateway. The user task below is completed concurrently and the transaction also assumes he is the first on the closing parallel gateway. Both transactions try to update a row, which indicates that they are the first on the closing parallel gateway. In such cases an OptimisticLockingException is thrown. One of the transactions is rolled back and the other one succeeds to update the row. Optimistic Locking and Non-Transactional Side Effects After the occurrence of an OptimisticLockingException, the transaction is rolled back. Any transactional work will be undone. Non-transactional work like creation of files or the effects of invoking non-transactional web services will not be undone. This can end in inconsistent state. There are several solutions to this problem, the most common one is eventual consolidation using retries. Internal Implementation Details Most of the CIB seven engine database tables contain a column called REV_. This column represents the revision version. When reading a row, data is read at a given “revision”. Modifications (UPDATEs and DELETEs) always attempt to update the revision which was read by the current command. Updates increment the revision. After executing a modification statement, the affected rows count is checked. If the count is 1 it is deduced that the version read was still current when executing the modification. In case the affected rows count is 0, other transaction modified the same data while this transaction was running. This means that a concurrency conflict is detected and this transaction must not be allowed to commit. Subsequently, the transaction is rolled back (or marked rollback-only) and an OptimisticLockingException is thrown.",
    "url": "/manual/latest/user-guide/process-engine/transactions-in-processes/index.html"
  },
  {
    "id": "manual/latest/user-guide/process-engine/variables/index.html",
    "title": "Process Variables | docs.cibseven.org",
    "content": "This section describes the concepts of variables in processes. Variables can be used to add data to process runtime state or, more particular, variable scopes. Various API methods that change the state of these entities allow updating of the attached variables. In general, a variable consists of a name and a value. The name is used for identification across process constructs. For example, if one activity sets a variable named var, a follow-up activity can access it by using this name. The value of a variable is a Java object. Variable Scopes and Variable Visibility All entities that can have variables are called variable scopes. These are executions (which include process instances) and tasks. As described in the Concepts section, the runtime state of a process instance is represented by a tree of executions. Consider the following process model where the red dots mark active tasks: The runtime structure of this process is as follows: There is a process instance with two child executions, each of which has created a task. All these five entities are variable scopes and the arrows mark a parent-child relationship. A variable that is defined on a parent scope is accessible in every child scope unless a child scope defines a variable of the same name. The other way around, child variables are not accessible from a parent scope. Variables that are directly attached to the scope in question are called local variables. Consider the following assignment of variables to scopes: In this case, when working on Task 1 the variables worker and customer are accessible. Note that due to the structure of scopes, the variable worker can be defined twice, so that Task 1 accesses a different worker variable than Task 2. However, both share the variable customer which means that if that variable is updated by one of the tasks, this change is also visible to the other. Both tasks can access two variables each while none of these is a local variable. All three executions have one local variable each. Now let’s say, we set a local variable customer on Task 1: While two variables named customer and worker can still be accessed from Task 1, the customer variable on Execution 1 is hidden, so the accessible customer variable is the local variable of Task 1. In general, variables are accessible in the following cases: Instantiating processes Delivering messages Task lifecycle transitions, such as completion or resolution Setting/getting variables from outside Setting/getting variables in a Delegate Expressions in the process model Scripts in the process model (Historic) Variable queries Set and Retrieve Variables - Overview To set and retrieve variables, the process engine offers a Java API that allows setting of variables from Java objects and retrieving them in the same form. Internally, the engine persists variables to the database and therefore applies serialization. For most applications, this is a detail of no concern. However, sometimes, when working with custom Java classes, the serialized value of a variable is of interest. Imagine the case of a monitoring application that manages many process applications. It is decoupled from those applications’ classes and therefore cannot access custom variables in their Java representation. For these cases, the process engine offers a way to retrieve and manipulate the serialized value. This boils down to two APIs: Java Object Value API: Variables are represented as Java objects. These objects can be directly set as values and retrieved in the same form. This is the more simple API and is the recommended way when implementing code as part of a process application. Typed Value API: Variable values are wrapped in so-called typed values that are used to set and retrieve variables. A typed value offers access to metadata such as the way the engine has serialized the variable and, depending on the type, the serialized representation of the variable. Metadata also contains an information whether a variable is transient or not. As an example, the following code retrieves and sets two integer variables using both APIs: // Java Object API: Get Variable Integer val1 = (Integer) execution.getVariable(\"val1\"); // Typed Value API: Get Variable IntegerValue typedVal2 = execution.getVariableTyped(\"val2\"); Integer val2 = typedVal2.getValue(); Integer diff = val1 - val2; // Java Object API: Set Variable execution.setVariable(\"diff\", diff); // Typed Value API: Set Variable IntegerValue typedDiff = Variables.integerValue(diff); execution.setVariable(\"diff\", typedDiff); The specifics of this code are described in more detail in the sections on the Java Object Value API and the Typed Value API. Setting variables to specific scope There is a possibility to set variables into specific scope from scripts, input\\output mapping, listeners and service tasks. Implementation of this functionality is using activity id in order to identify destination scope and will throw an exception if no scope is located to set a variable. Additionally, once target scope is found, variable will be set locally in it, which means that propagation to the parent scope will not be executed even if destination scope does not have a variable with given id. Here is example usage with script executionListener: <camunda:executionListener event=\"end\"> <camunda:script scriptFormat=\"groovy\"><![CDATA[execution.setVariable(\"aVariable\", \"aValue\",\"aSubProcess\");]]></camunda:script> </camunda:executionListener> Another usage example would be input\\output mapping using DelegateVariableMapping implementation public class SetVariableToScopeMappingDelegate implements DelegateVariableMapping { @Override public void mapInputVariables(DelegateExecution superExecution, VariableMap subVariables) { } @Override public void mapOutputVariables(DelegateExecution superExecution, VariableScope subInstance) { superExecution.setVariable(\"aVariable\",\"aValue\",\"aSubProcess\"); } } here variable will be set locally in “aSubProcess” and not propagated to the parent scope even if variable was not set beforehand locally in “aSubProcess”. Supported Variable Values The process engine supports the following variable value types: Depending on the actual value of a variable, a different type is assigned. Out of the available types, there are nine primitive value types, meaning that they store values of simple standard JDK classes without additional metadata: boolean: Instances of java.lang.Boolean bytes: Instances of byte[] short: Instances of java.lang.Short integer: Instances of java.lang.Integer long: Instances of java.lang.Long double: Instances of java.lang.Double date: Instances of java.util.Date string: Instances of java.lang.String null: null references Primitive values differ from other variable values in that they can be used in API queries such as process instance queries as filtering conditions. The type file can be used to store the contents of a file or input stream along with metadata such as a file name, an encoding, and the MIME type the file contents correspond to. The value type object represents custom Java objects. When such a variable is persisted, its value is serialized according to a serialization procedure. These procedures are configurable and exchangeable. String length restriction string values are stored in the database in a column of type (n)varchar, with a length restriction of 4000 (2000 for Oracle). Depending on the database in use and the configured charset, this length restriction can result in different quantities of real characters. Variable value length is not validated inside the CIB seven engine, but the values are sent to the database ‘as is’ and, in case the length restriction is exceeded, a database level exception will be thrown. If validation is needed, it may be implemented separately and must happen before the Camunda API to set the variables is called. Process variables can be stored in formats like JSON and XML provided by the Camunda Spin plugin. Spin provides serializers for the variables of type object such that Java variables can be persisted in these formats to the database. Furthermore, it is possible to store JSON and XML documents directly as a Spin object by the value types xml and json. Opposed to plain string variables, Spin objects provide a fluent API to perform common operations on such documents like reading and writing properties. Object Value Serialization When an object value is passed to the process engine, a serialization format can be specified to tell the process engine to store the value in a specific format. Based on this format, the engine looks up a serializer. The serializer is able to serialize a Java object to the specified format and deserialize it from a representation in that format. That means, there may be different serializers for different formats and it is possible to implement custom serializers in order to store custom objects in a specific format. The process engine ships one built-in object serializer for the format application/x-java-serialized-object. It is able to serialize Java objects that implement the interface java.io.Serializable and applies standard Java object serialization. The desired serialization format can be specified when setting a variable using the Typed Value API: CustomerData customerData = new CustomerData(); ObjectValue customerDataValue = Variables.objectValue(customerData) .serializationDataFormat(Variables.SerializationDataFormats.JAVA) .create(); execution.setVariable(\"someVariable\", customerDataValue); On top of that, the process engine configuration has an option defaultSerializationFormat that is used when no specific format is requested. This option defaults to application/x-java-serialized-object. Using Custom Objects in Task Forms Note that the built-in serializer converts objects to byte streams that can only be interpreted with the Java class at hand. When implementing task forms that are based on complex objects, a text-based serialization format should be used since Tasklist cannot interpret these byte streams. See the box Serializing Objects to XML and JSON for details on how to integrate serialization formats like XML and JSON. Serializing Objects to XML and JSON The Camunda Spin plugin provides serializers that are capable of serializing object values to XML and JSON. They can be used when it is desired that the serialized objects values can be interpreted by humans or when the serialized value should be meaningful without having the corresponding Java class. When using a pre-built Camunda distribution, Camunda Spin is already preconfigured and you can try these formats without further configuration. Java Object API The most convenient way of working with process variables from Java is to use their Java object representation. Wherever the process engine offers variable access, process variables can be accessed in this representation given that for custom objects the engine is aware of the involved classes. For example, the following code sets and retrieves a variable for a given process instance: com.example.Order order = new com.example.Order(); runtimeService.setVariable(execution.getId(), \"order\", order); com.example.Order retrievedOrder = (com.example.Order) runtimeService.getVariable(execution.getId(), \"order\"); Note that this code sets a variable at the highest possible point in the hierarchy of variable scopes. This means, if the variable is already present (whether in this execution or any of its parent scopes), it is updated. If the variable is not yet present, it is created in the highest scope, i.e. the process instance. If a variable is supposed to be set exactly on the provided execution, the local methods can be used. For example: com.example.Order order = new com.example.Order(); runtimeService.setVariableLocal(execution.getId(), \"order\", order); com.example.Order retrievedOrder = (com.example.Order) runtimeService.getVariable(execution.getId(), \"order\"); com.example.Order retrievedOrder = (com.example.Order) runtimeService.getVariableLocal(execution.getId(), \"order\"); // both methods return the variable Whenever a variable is set in its Java representation, the process engine automatically determines a suitable value serializer or raises an exception if the provided value cannot be serialized. Typed Value API In cases in which it is important to access a variable’s serialized representation or in which the engine has to be hinted to serialize a value in a certain format, the typed-value-based API can be used. In comparison to the Java-Object-based API, it wraps a variable value in a so-called Typed Value. Such a typed value allows richer representation of variable values. In order to easily construct typed values, CIB seven offers the class org.cibseven.bpm.engine.variable.Variables. This class contains static methods that allow creation of single typed values as well as creation of a map of typed values in a fluent way. Primitive Values The following code sets a single String variable by specifying it as a typed value: StringValue typedStringValue = Variables.stringValue(\"a string value\"); runtimeService.setVariable(execution.getId(), \"stringVariable\", typedStringValue); StringValue retrievedTypedStringValue = runtimeService.getVariableTyped(execution.getId(), \"stringVariable\"); String stringValue = retrievedTypedStringValue.getValue(); // equals \"a string value\" Note that with this API, there is one more level of abstraction around the variable value. Thus, in order to access the true value, it is necessary to unwrap the actual value. File Values Of course, for plain String values, the Java-Object-based API is more concise. Let us therefore consider values of richer data structures. Files can be persisted as BLOBs in the database. The file value type allows to store additional metadata such as a file name and a mime type along with it. The following example code creates a file value from a text file: FileValue typedFileValue = Variables .fileValue(\"addresses.txt\") .file(new File(\"path/to/the/file.txt\")) .mimeType(\"text/plain\") .encoding(\"UTF-8\") .create(); runtimeService.setVariable(execution.getId(), \"fileVariable\", typedFileValue); FileValue retrievedTypedFileValue = runtimeService.getVariableTyped(execution.getId(), \"fileVariable\"); InputStream fileContent = retrievedTypedFileValue.getValue(); // a byte stream of the file contents String fileName = retrievedTypedFileValue.getFilename(); // equals \"addresses.txt\" String mimeType = retrievedTypedFileValue.getMimeType(); // equals \"text/plain\" String encoding = retrievedTypedFileValue.getEncoding(); // equals \"UTF-8\" Changing a File Value To change or update a file value, you have to create a new FileValue with the same name and the new content, because all typed values are immutable: InputStream newContent = new FileInputStream(\"path/to/the/new/file.txt\"); FileValue fileVariable = execution.getVariableTyped(\"addresses.txt\"); Variables.fileValue(fileVariable.getName()).file(newContent).encoding(fileVariable.getEncoding()).mimeType(fileVariable.getMimeType()).create(); Object Values Custom Java objects can be serialized with the value type object. Example using the typed value API: com.example.Order order = new com.example.Order(); ObjectValue typedObjectValue = Variables.objectValue(order).create(); runtimeService.setVariableLocal(execution.getId(), \"order\", typedObjectValue); ObjectValue retrievedTypedObjectValue = runtimeService.getVariableTyped(execution.getId(), \"order\"); com.example.Order retrievedOrder = (com.example.Order) retrievedTypedObjectValue.getValue(); This again is equivalent to the Java-Object-based API. However, it is now possible to tell the engine which serialization format to use when persisting the value. For example: ObjectValue typedObjectValue = Variables .objectValue(order) .serializationDataFormat(Variables.SerializationDataFormats.JAVA) .create(); creates a value that gets serialized by the engine’s built-in Java object serializer. Also, a retrieved ObjectValue instance provides additional variable details: // returns true boolean isDeserialized = retrievedTypedObjectValue.isDeserialized(); // returns the format used by the engine to serialize the value into the database String serializationDataFormat = retrievedTypedObjectValue.getSerializationDateFormat(); // returns the serialized representation of the variable; the actual value depends on the serialization format used String serializedValue = retrievedTypedObjectValue.getValueSerialized(); // returns the class com.example.Order Class<com.example.Order> valueClass = retrievedTypedObjectValue.getObjectType(); // returns the String \"com.example.Order\" String valueClassName = retrievedTypedObjectValue.getObjectTypeName(); The serialization details are useful when the calling application does not possess the classes of the actual variable value (i.e. com.example.Order is not known). In these cases, runtimeService.getVariableTyped(execution.getId(), \"order\") will raise an exception since it immediately tries to deserialize the variable value. In such a case, the invocation runtimeService.getVariableTyped(execution.getId(), \"order\", false) can be used. The additional boolean parameter tells the process engine to not attempt deserialization. In this case, the invocation isDeserialized() will return false and invocations like getValue() and getObjectType() will raise exceptions. Calling getValueSerialized() and getObjectTypeName() is a way to access the variable nonetheless. Similarly, it is possible to set a variable from its serialized representation: String serializedOrder = \"...\"; ObjectValue serializedValue = Variables .serializedObjectValue(serializedOrder) .serializationDataFormat(Variables.SerializationDataFormats.JAVA) .objectTypeName(\"com.example.Order\") .create(); runtimeService.setVariableLocal(execution.getId(), \"order\", serializedValue); ObjectValue retrievedTypedObjectValue = runtimeService.getVariableTyped(execution.getId(), \"order\"); com.example.Order retrievedOrder = (com.example.Order) retrievedTypedObjectValue.getValue(); Inconsistent Variable States When setting a serialized variable value, no checking is done whether the structure of the serialized value is compatible with the class the variable value is supposed to be an instance of. When setting the variable from the above example, the supplied serialized value is not validated against the structure of com.example.Order. Thus, an invalid variable value will only be detected when runtimeService#getVariableTyped is called. Java serialization format Be aware that when using a serialized representation of variables, the Java serialization format is forbidden by default. You should either use another format (JSON or XML) or explicitly enable the Java serialization with the help of the javaSerializationFormatEnabled configuration flag. However, please make sure to read the Security Implication first before enabling this. JSON and XML Values The Camunda Spin plugin provides an abstraction for JSON and XML documents that facilitate their processing and manipulation. This is often more convenient than storing such documents as plain string variables. See the documentation on Camunda SPIN for storing JSON documents and storing XML documents for details. Transient variables Declaration of transient variables is possible only through the typed-value-based API. They are not saved into the database and exist only during the current transaction. Every waiting state during an execution of a process instance leads to the loss of all transient variables. This happens typically when e.g. an external service is not currently available, an user task has been reached or the process execution is waiting for a message, a signal or a condition. Please use this feature carefully. Variables of any type can be declared as transient using the Variables class and setting the parameter isTransient to true. // primitive values TypedValue typedTransientStringValue = Variables.stringValue(\"foobar\", true); // object value com.example.Order order = new com.example.Order(); TypedValue typedTransientObjectValue = Variables.objectValue(order, true).create(); // file value TypedValue typedTransientFileValue = Variables.fileValue(\"file.txt\", true) .file(new File(\"path/to/the/file.txt\")) .mimeType(\"text/plain\") .encoding(\"UTF-8\") .create(); Transient variables can be used via REST API, e.g. when starting a new process instance. Set Multiple Typed Values Similar to the Java-Object-based API, it is also possible to set multiple typed values in one API call. The Variables class offers a fluent API to construct a map of typed values: com.example.Order order = new com.example.Order(); VariableMap variables = Variables.createVariables() .putValueTyped(\"order\", Variables.objectValue(order).create()) .putValueTyped(\"string\", Variables.stringValue(\"a string value\")) .putValueTyped(\"stringTransient\", Variables.stringValue(\"foobar\", true)); runtimeService.setVariablesLocal(execution.getId(), \"order\", variables); Interchangeability of APIs Both APIs offer different views on the same entities and can therefore be combined as is desired. For example, a variable that is set using the Java-Object-based API can be retrieved as a typed value and vice versa. As the class VariableMap implements the Map interface, it is also possible to put plain Java objects as well as typed values into this map. Which API should you use? The one that fits your purpose best. When you are certain that you always have access to the involved value classes, such as when implementing code in a process application like a JavaDelegate, then the Java-Object-based API is easier to use. When you need to access value-specific metadata such as serialization formats or to define a variable as transient, then the Typed-Value-based API is the way to go. Input/Output Variable Mapping To improve the reusability of source code and business logic, CIB seven offers input/output mapping of process variables. This can be used for tasks, events and subprocesses. In order to use the variable mapping, the Camunda extension element inputOutput has to be added to the element. It can contain multiple inputParameter and outputParameter elements that specify which variables should be mapped. The name attribute of an inputParameter denotes the variable name inside the activity (a local variable to be created), whereas the name attribute of an outputParameter denotes the variable name outside of the activity. The content of an input/outputParameter specifies the value that is mapped to the corresponding variable. It can be a simple constant string or an expression. An empty body sets the variable to the value null. <camunda:inputOutput> <camunda:inputParameter name=\"x\">foo</camunda:inputParameter> <camunda:inputParameter name=\"willBeNull\"/> <camunda:outputParameter name=\"y\">${x}</camunda:outputParameter> <camunda:outputParameter name=\"z\">${willBeNull == null}</camunda:outputParameter> </camunda:inputOutput> Even complex structures like lists and maps can be used. Both can also be nested. <camunda:inputOutput> <camunda:inputParameter name=\"x\"> <camunda:list> <camunda:value>a</camunda:value> <camunda:value>${1 + 1}</camunda:value> <camunda:list> <camunda:value>1</camunda:value> <camunda:value>2</camunda:value> <camunda:value>3</camunda:value> </camunda:list> </camunda:list> </camunda:inputParameter> <camunda:outputParameter name=\"y\"> <camunda:map> <camunda:entry key=\"foo\">bar</camunda:entry> <camunda:entry key=\"map\"> <camunda:map> <camunda:entry key=\"hello\">world</camunda:entry> <camunda:entry key=\"camunda\">bpm</camunda:entry> </camunda:map> </camunda:entry> </camunda:map> </camunda:outputParameter> </camunda:inputOutput> A script can also be used to provide the variable value. Please see the corresponding section in the scripting chapter for how to specify a script. A simple example of the benefit of input/output mapping is a complex calculation which should be part of multiple processes definitions. This calculation can be developed as isolated delegation code or a script and be reused in every process, even though the processes use a different variable set. An input mapping is used to map the different process variables to the required input parameters of the complex calculation activity. Accordingly, an output mapping allows to utilize the calculation result in the further process execution. In more detail, let us assume such a calculation is implemented by a Java Delegate class org.cibseven.bpm.example.ComplexCalculation. This delegate requires a userId and a costSum variable as input parameters. It then calculates three values, pessimisticForecast, realisticForecast and optimisticForecast, which are different forecasts of the future costs a customer faces. In a first process, both input variables are available as process variables but with different names (id, sum). From the three results, the process only uses realisticForecast which it depends on by the name forecast in follow-up activities. A corresponding input/output mapping looks as follows: <serviceTask camunda:class=\"org.cibseven.bpm.example.ComplexCalculation\"> <extensionElements> <camunda:inputOutput> <camunda:inputParameter name=\"userId\">${id}</camunda:inputParameter> <camunda:inputParameter name=\"costSum\">${sum}</camunda:inputParameter> <camunda:outputParameter name=\"forecast\">${realisticForecast}</camunda:outputParameter> </camunda:inputOutput> </extensionElements> </serviceTask> In a second process, let us assume the costSum variable has to be calculated from properties of three different maps. Also, the process depends on a variable avgForecast as the average value of the three forecasts. In this case, the mapping looks as follows: <serviceTask camunda:class=\"org.cibseven.bpm.example.ComplexCalculation\"> <extensionElements> <camunda:inputOutput> <camunda:inputParameter name=\"userId\">${id}</camunda:inputParameter> <camunda:inputParameter name=\"costSum\"> ${mapA[costs] + mapB[costs] + mapC[costs]} </camunda:inputParameter> <camunda:outputParameter name=\"avgForecast\"> ${(pessimisticForecast + realisticForecast + optimisticForecast) / 3} </camunda:outputParameter> </camunda:inputOutput> </extensionElements> </serviceTask> Multi-instance IO Mapping Input mappings can also be used with multi-instance constructs, in which the mapping is applied for every instance that is created. For example, for a multi-instance subprocess with five instances, the mapping is executed five times and the involved variables are created in each of the five subprocess scopes such that they can be accessed independently. No output mapping for multi-instance constructs The engine does not support output mappings for multi-instance constructs. Every instance of the output mapping would overwrite the variables set by the previous instances and the final variable state would become hard to predict. IO Mapping on canceled activities If an Activity is canceled (e.g. due to throwing a BPMN error), IO mapping is still executed. This can lead to exceptions if the output mapping references variables that do not exist in the scope of the activity at that time. The default behavior is that the engine still tries to execute output mappings on canceled activities and fails with an exception if a variable is not found. By enabling the skipOutputMappingOnCanceledActivities engine configuration flag (i.e. setting it to true) the engine will not perform output mappings on any canceled activity.",
    "url": "/manual/latest/user-guide/process-engine/variables/index.html"
  },
  {
    "id": "manual/latest/user-guide/quarkus-integration/cdi-integration/index.html",
    "title": "Engine CDI Integration | docs.cibseven.org",
    "content": "Quarkus comes with a built-in solution for CDI (short for “Context and Dependency Injection”) called ArC, which is based on the Java CDI 4.0 standard. Quarkus ArC does not entirely cover the CDI 4.0 standard but only implements a subset of it. The CIB seven engine offers CDI 4 integration with the cibseven-engine-cdi-jakarta module. This module is integrated directly into the Quarkus Extension. You can learn more about the features and the programming model at CDI and Java EE Integration. Limitations Since Quarkus ArC does not aim to implement CDI 4.0 fully, you cannot use the full range of features the cibseven-engine-cdi-jakarta module provides. Some features documented under CDI and Java EE Integration are unsupported or only work with restrictions. The limitations and differences are explained in more detail below. Heads-up! Quarkus ArC has more limitations not described in this section, as only those restrictions are highlighted that affect the functionality of the cibseven-engine-cdi-jakarta module. For your individual application development, we highly recommend you consider the limitations and supported features of the Quarkus version you are using. Limited support of JUEL Expression Resolution The cibseven-engine-cdi-jakarta module allows referencing CDI beans and calling methods on CDI beans in model expression properties (e.g., camunda:expression, camunda:delegateExpression, etc.). Quarkus ArC currently doesn’t support the CDI API method javax.enterprise.inject.spi.BeanManager#getELResolver, which the engine uses to resolve method calls on CDI beans. This is why currently, only referencing CDI beans is supported. Examples: Supported Expression: ${myService} Unsupported Expression: ${myService.checkCondition('foo')} Limited support of scopes in the Contextual Programming Model While the cibseven-engine-cdi-jakarta module supports associating a process instance with Conversational Scope or Request Scope, Quarkus ArC only supports the Request Scope. Configure Quarkus to allow setting variables when a @StartProcess annotated method is called The cibseven-engine-cdi-jakarta module allows setting variables when assigning a value to a class field annotated with @ProcessVariableTyped or @ProcessVariable inside a method annotated with @StartProcess, as shown in the following example: @Dependent public class ProcessController { @ProcessVariable String myProcessVariable; @StartProcess(\"keyOfTheProcess\") public void startProcessByKey() { myProcessVariable = \"my-value\"; } } Since Quarkus tries to auto-inject beans into class fields annotated with @Qualifier annotations, the behavior, as shown above, doesn’t work out of the box. Instead, an exception is thrown. However, if you know what you do and can spare the auto-inject behavior, it is possible to disable it. Read more about it in the ArC Configuration Reference. Alternatively, you can set variables within a @StartProcess annotated method programmatically: @Dependent public class ProcessController { String myProcessVariable; @StartProcess(\"keyOfTheProcess\") public void startProcessByKey() { myProcessVariable = \"my-value\"; process.setVariable(\"myProcessVariable\", myProcessVariable); } } @BusinessProcessScoped Beans The cibseven-engine-cdi-jakarta module stores @BusinessProcessScoped beans as process variables in the context of the current process instance. Passivation is unsupported Quarkus does not support Passivation and passivating scopes. When using @BusinessProcessScoped beans, no validation of being serializable and therefore “Passivation Capable” is performed during the startup of the Quarkus application. If your @BusinessProcessScoped beans and their references don’t implement the java.io.Serializable interface, the engine throws an exception during execution when trying to persist the beans as process variables. Destroying Bean Instances is unsupported Programmatically destroying a @BusinessProcessScoped bean instance is currently unsupported. The following API methods will throw an UnsupportedOperationException: javax.enterprise.inject.Instance#destroy io.quarkus.arc.InjectableContext#getState io.quarkus.arc.InjectableContext#destroy io.quarkus.arc.InjectableContext#destroy(Contextual<?> contextual) Task form beans Associating beans with Conversational Scope is currently not supported by Quarkus ArC. Furthermore, Quarkus does not allow to set a different default scope for beans that are outside of the extension’s control. As a result, the following conversational scoped beans are not available in a Quarkus application out of the box: org.cibseven.bpm.engine.cdi.jsf.TaskForm org.cibseven.bpm.engine.cdi.compat.FoxTaskForm org.cibseven.bpm.engine.cdi.compat.CamundaTaskForm In general, you can use these beans in custom JSF forms to interact with the process engine, for example, to render and complete user tasks. To include such functionality in your Quarkus application, provide custom beans with appropriate scopes and functionality. You can learn about the available beans and programming model in the CDI and Java EE Integration.",
    "url": "/manual/latest/user-guide/quarkus-integration/cdi-integration/index.html"
  },
  {
    "id": "manual/latest/user-guide/quarkus-integration/configuration/index.html",
    "title": "Quarkus Extension Configuration | docs.cibseven.org",
    "content": "This section of the Camunda Quarkus extension documentation covers the configuration options for the process engine within a Quarkus application. The documentation on the Camunda Quarkus Extension Configuration is intended for Quarkus application developers. It requires some knowledge on Quarkus CDI support, Quarkus configuration, as well as Camunda Process Engine Configuration properties. Process Engine Configuration An instance of the QuarkusProcessEngineConfiguration class configures the process engine in a Quarkus application. A QuarkusProcessEngineConfiguration instance provides the following defaults: Property name Description Default value jobExecutorActivate The job executor is activated. true transactionsExternallyManaged Transactions are externally managed. true databaseSchemaUpdate The Database Configuration section goes into more details on this propery and the resulting behavior. true idGenerator An instance of StrongUuidGenerator is used. StrongUuidGenerator jdbcUrl, jdbcUsername, jdbcPassword, jdbcDriver No JDBC configuration is present since a Quarkus datasource should be configured and used. null history Camunda Cockpit works best with history level FULL. full Quarkus allows to configure a Quarkus application via a MicroProfile Config source. You can read more about configuring a Quarkus application in the Quarkus configuration page. The Camunda Quarkus extension docs use the application.properties format in the examples, but you can use any supported Quarkus config source. You can set any process engine configuration properties under the quarkus.camunda prefix. The Process Engine Configuration Properties page documents all the available properties. Please convert any property names from camelCase to the kebab-case format, like in the following example: quarkus.camunda.generic-config.cmmn-enabled=false quarkus.camunda.generic-config.dmn-enabled=false quarkus.camunda.generic-config.history=none quarkus.camunda.generic-config.initialize-telemetry=false Programmatic Configuration You can also configure the process engine programmatically, by providing a QuarkusProcessEngineConfiguration CDI bean. @ApplicationScoped public class MyCustomEngineConfig extends QuarkusProcessEngineConfiguration { public MyCustomEngineConfig() { // your custom configuration is done here setProcessEngineName(\"customEngine\"); } } Note that values of properties set in a QuarkusProcessEngineConfiguration instance have a lower ordinal than properties defined in a Quarkus config source. In the above example, a QuarkusProcessEngineConfiguration CDI bean defines “customEngine” as the processEngineName. However, if you define the following in an application.properties file quarkus.camunda.generic-config.process-engine-name=quarkusEngine then “quarkusEngine” will be used as the process engine name since Quarkus config sources have a higher ordinal than a QuarkusProcessEngineConfiguration CDI bean. Job Executor Configuration As with the process engine configuration properties above, you can set any job executor configuration properties under the quarkus.camunda.job-executor prefix. The Job Executor Configuration Properties page documents all the available properties. Convert any property names you intend to use from camelCase to the kebab-case format, like in the following example: quarkus.camunda.job-executor.generic-config.max-jobs-per-acquisition=5 quarkus.camunda.job-executor.generic-config.lock-time-in-millis=500000 quarkus.camunda.job-executor.generic-config.wait-time-in-millis=7000 quarkus.camunda.job-executor.generic-config.max-wait=65000 Quarkus Extension Configuration In addition to the general process engine and job executor configuration properties mentioned in the previous sections, the Camunda Quarkus extension provides some Quarkus-specific configuration properties. They can be set through a Quarkus config source, but not through the QuarkusProcessEngineConfiguration class. You can find all the Quarkus-specific properties in the following table: Prefix Property name Description Default value Data Source quarkus.camunda .datasource Specifies which Quarkus datasource to use. If not defined, the primary Quarkus datasource will be used. For configuring a Quarkus Datasource, have a look on the Quarkus Datasource page. <default> Job Executor quarkus.camunda.job-executor.thread-pool .max-pool-size Sets the maximum number of threads that can be present in the thread pool. 10 .queue-size Sets the size of the queue which is used for holding tasks to be executed. 3 Persistence The Engine Extension integrates with a JDBC Connection Pool and a Jakarta Transaction Manager provided by Quarkus. The latter allows you to integrate your business logic into database transactions of the Engine. Read more about it under JTA Transaction Integration. A datasource is required to run the Camunda process engine. Choose from multiple datasources When multiple datasources are available in your application, you can choose the one the Engine Extension should use by its name via the camunda.datasource configuration property. Consider the example configuration below: quarkus.datasource.engine-datasource.db-kind=oracle quarkus.datasource.engine-datasource.username=my-username quarkus.datasource.engine-datasource.password=my-password quarkus.datasource.engine-datasource.jdbc.url=jdbc:oracle:thin:@localhost:1521:ORCL quarkus.camunda.datasource=engine-datasource Example The following is an example of a Quarkus application.properties file that provides custom values for the process engine configuration, job executor and data source: # process engine configuration quarkus.camunda.generic-config.cmmn-enabled=false quarkus.camunda.generic-config.dmn-enabled=false quarkus.camunda.generic-config.history=none # job executor configuration quarkus.camunda.job-executor.thread-pool.max-pool-size=12 quarkus.camunda.job-executor.thread-pool.queue-size=5 quarkus.camunda.job-executor.generic-config.max-jobs-per-acquisition=5 quarkus.camunda.job-executor.generic-config.lock-time-in-millis=500000 quarkus.camunda.job-executor.generic-config.wait-time-in-millis=7000 quarkus.camunda.job-executor.generic-config.max-wait=65000 quarkus.camunda.job-executor.generic-config.backoff-time-in-millis=5 # custom data source configuration and selection quarkus.datasource.my-datasource.db-kind=h2 quarkus.datasource.my-datasource.username=camunda quarkus.datasource.my-datasource.password=camunda quarkus.datasource.my-datasource.jdbc.url=jdbc:h2:mem:camunda;TRACE_LEVEL_FILE=0;DB_CLOSE_ON_EXIT=FALSE quarkus.camunda.datasource=my-datasource",
    "url": "/manual/latest/user-guide/quarkus-integration/configuration/index.html"
  },
  {
    "id": "manual/latest/user-guide/quarkus-integration/deployments/index.html",
    "title": "Resource Deployments | docs.cibseven.org",
    "content": "This section documents how to perform process engine deployments with a Quarkus application containing an embedded process engine. The documentation assumes some familiarity with Quarkus CDI support and the Camunda DeploymentBuilder API. The CIB seven engine Quarkus Extension only supports programmatic deployments. A user can observe for the CamundaEngineStartupEvent CDI event. The CamundaEngineStartupEvent signals that a process engine has been successfully bootstrapped, and a deployment can be performed. The following example shows how a single process engine deployment can be performed in a Quarkus application: @ApplicationScoped public class MyConfig { @Inject RepositoryService repositoryService; public void createDeployment(@Observes CamundaEngineStartupEvent event) { repositoryService.createDeployment() .addClasspathResource(\"resources/bpmn/simpleProcess.bpmn\") .deploy(); } } However, a Quarkus application doesn’t have to be limited to a single process engine deployment. You can observe for the CamundaEngineStartupEvent in multiple methods, and perform multiple deployments with a finer-grained control over the deployed resources. @ApplicationScoped public class MyConfig { @Inject RepositoryService repositoryService; public void createDeployment1(@Observes CamundaEngineStartupEvent event) { repositoryService.createDeployment() .name(\"deployment-1\") .addClasspathResource(\"resources/bpmn/one/simpleProcess1.bpmn\") .deploy(); } public void createDeployment2(@Observes CamundaEngineStartupEvent event) { repositoryService.createDeployment() .name(\"deployment-2\") .addClasspathResource(\"resources/bpmn/two/simpleProcess2.bpmn\") .deploy(); } }",
    "url": "/manual/latest/user-guide/quarkus-integration/deployments/index.html"
  },
  {
    "id": "manual/latest/user-guide/quarkus-integration/index.html",
    "title": "Quarkus Integration | docs.cibseven.org",
    "content": "The CIB seven engine can be used in a Quarkus application by using the provided Quarkus Extension. Quarkus Extensions add behavior to your Quarkus application by adding dependencies to the classpath. The CIB seven engine Quarkus Extension will pre-configure the Camunda process engine, so it can be easily used in a Quarkus application. If you are not familiar with Quarkus, have a look at the getting started guide. To enable CIB seven engine autoconfiguration, add the following dependency to your pom.xml: <dependency> <groupId>org.cibseven.bpm.quarkus</groupId> <artifactId>cibseven-bpm-quarkus-engine</artifactId> <version>1.1.0</version> </dependency> This will add the CIB seven engine version 1.1.0 to your dependencies. Supported deployment scenarios Camunda supports the following deployment scenario: executable JAR with one embedded process engine. There are other possible variations that might also work, but are not tested by Camunda at the moment.",
    "url": "/manual/latest/user-guide/quarkus-integration/index.html"
  },
  {
    "id": "manual/latest/user-guide/quarkus-integration/version-compatibility/index.html",
    "title": "Quarkus Version Compatibility | docs.cibseven.org",
    "content": "Each version of the CIB seven engine Quarkus Extension is bound to a specific version of CIB seven and Quarkus. Only these default combinations are recommended (and supported) by CIB seven. CIB seven version Quarkus version 7.22.0-cibseven 3.15.x 1.1 3.15.x In case a certain Quarkus version has a bug, you can override the existing Quarkus version by adding the following inside your pom.xml. Note that this new CIB seven/Quarkus version combination should also be supported by CIB seven. <dependencyManagement> <dependencies> ... <dependency> <groupId>io.quarkus.platform</groupId> <artifactId>quarkus-bom</artifactId> <version>${quarkus.framework.version}</version><!-- set correct version here --> <type>pom</type> <scope>import</scope> </dependency> ... </dependencies> </dependencyManagement>",
    "url": "/manual/latest/user-guide/quarkus-integration/version-compatibility/index.html"
  },
  {
    "id": "manual/latest/user-guide/runtime-container-integration/bpm-platform-services/index.html",
    "title": "CIB seven Services | docs.cibseven.org",
    "content": "To inspect the current state of configured process engines and deployed process applications, the class org.cibseven.bpm.BpmPlatform offers access to the ProcessEngineService and the ProcessApplicationService. ProcessEngineService The ProcessEngineService can be accessed by calling BpmPlatform.getProcessEngineService(). It offers access to the default process engine, as well as any process engine by its name as specified in the process engine configuration. It returns ProcessEngine objects from which any services for a specific engine can be accessed. ProcessApplicationService The ProcessApplicationService is accessible via BpmPlatform.getProcessApplicationService(). It provides details on the process application deployments made on the application server it is running on. That means that it does not provide a global view across all nodes in a cluster. Given a process application name, a ProcessApplicationInfo object can be retrieved that contains details on the deployments made by this process application. These correspond to the process archives declared in processes.xml. Furthermore, application-specific properties can be retrieved such as the servlet context path in case of a servlet process application.",
    "url": "/manual/latest/user-guide/runtime-container-integration/bpm-platform-services/index.html"
  },
  {
    "id": "manual/latest/user-guide/runtime-container-integration/index.html",
    "title": "Runtime Container Integration | docs.cibseven.org",
    "content": "Docs Get Started CIB seven Security cibseven.org CIB seven 1.1 Introduction Download Licenses Implemented Standards Architecture Overview Supported Environments Extensions Third-Party Libraries CIB seven License Book Public API User Guide Process Engine Process Engine Bootstrapping Process Engine API Process Engine Concepts Process Variables Process Instance Modification Process Instance Restart Delegation Code Expression Language Scripting Templating Custom Code & Security External Tasks Connectors Process Versioning Process Instance Migration Database Database Schema Database Configuration Microsoft SQL Server and Azure SQL Database Configuration MySQL Database Configuration Performance History History configuration User operation log History cleanup Custom implementation Deployment Cache Password Hashing Password Policy Transactions in Processes The Job Executor Multi-Tenancy Id Generators Metrics Incidents Process Engine Plugins Identity Service Authorization Service Deployments Process Diagram Visualization Time zones Decisions Configuration Repository Decision Service Decisions in BPMN & CMMN History Batch Batch operations Error Handling Diagnostics data Process Applications The Process Application class The processes.xml Deployment Descriptor Process Application Event Listeners Process Application Resource Access Maven Project Templates (Archetypes) Runtime Container Integration CIB seven Services JNDI Bindings for CIB seven Services Apache Tomcat WildFly Job Execution with Managed Resources CIB seven Run Spring Framework Integration Bootstrapping Transactions Deployment Spring Bean Resolving Testing Spring Boot Integration Version Compatibility Configuration REST API Web Applications Process Applications Spring Eventing Bridge Developing and Testing Spring Security OAuth2 Integration Quarkus Integration Version Compatibility Configuration Engine CDI Integration Resource Deployments CDI and Java EE Integration JTA Transaction Integration Expression Resolving Contextual Programming Model Built-In Beans CDI Event Bridge Testing Assert Examples Model API BPMN Model API Read a Model Create a Model Delegation Code Fluent Builder API Repository Service Extension Elements CMMN Model API Read a Model Create a Model Delegation Code Repository Service Extension Elements Limitations DMN Model API Read a Model Create a Model Repository Service Extension Attributes Data Formats (XML, JSON, Other) Configuring Spin Integration Data Formats in Processes XML JSON User Task Forms JSF Task Forms DMN Engine Embed Evaluate Decisions Expressions FEEL Engine Type Handling Custom Functions Spin Integration Legacy Behavior Data Types Testing Logging Security Instructions External Task Client Spring Boot Starter Version Compatibility Reference REST API Overview Configure Authentication Usage with a Pre-Built Distribution Embed the API Hypertext Application Language (HAL) Variables in the REST API Date Format OpenAPI Specification ↗ Javadoc ↗ BPMN 2.0 Tasks Service Task Send Task User Task Business Rule Task Script Task Receive Task Manual Task Task Markers Gateways Data-based Exclusive Gateway (XOR) Conditional and Default Sequence Flows Parallel Gateway Inclusive Gateway Event-based Gateway Events Start Events None Events Message Events Timer Events Error Events Escalation Events Signal Events Cancel and Compensation Events Conditional Events Link Events Terminate Events Subprocess Embedded Subprocess Call Activity Event Subprocess Transaction Subprocess Extension Reference Extension Elements Extension Attributes DMN 1.3 Decision Table Input Output Rule Hit Policy Decision Literal Expression Decision Requirements Graph FEEL Legacy FEEL Reference Data Types Language Elements Extension Reference Extension Attributes CMMN 1.1 Classic vs Fluent API CMMN Concepts Plan Items and Item Definitions Plan Item Lifecycles Entry and Exit Criteria Tasks Human Task Process Task Case Task Decision Task Grouping Tasks Stage Milestones Sentries Markers Manual Activation Rule Required Rule Auto Complete Repetition Rule Extension Reference Extension Elements Extension Attributes Migration between Specification Versions 1.0 to 1.1 Forms Embedded Forms Controls Text Inputs Textareas Date Inputs Boolean Inputs Selects Hidden Input Fields File Upload and Download BPMN Event Buttons Javascript The cam-script Directive Available API Participating in the Form Lifecycle Debugging Scripts Generating a Business Key Examples Lifecycle and Events Working with Json Data Working with Java Objects Integrating the Forms SDK Getting a Distribution Bootstrapping AngularJS Integration Full Example Spin Dataformats XML Reading XML Manipulating XML Writing XML Querying XML Mapping XML Configuring XML Handling JSON Reading JSON Writing JSON Querying JSON Mapping JSON Configuring JSON Handling Extending Spin Connectors HTTP Connector SOAP Connector Extending Connect Deployment Descriptors bpm-platform.xml processes.xml Tags <job-executor /> <process-archive /> <process-engine /> Installation Database Schema Remote Engine Distribution Shared Engine Distribution Tomcat Pre-Packaged Distribution Manual Installation Configuration JBoss EAP/WildFly Manual Installation Configuration Docker Spring Boot Web Applications Admin User Management Group Management Tenant Management Authorization Management System Management Configuration Plugins Cockpit Dashboard BPMN Processes Dashboard Process Definition View Process Instance View Failed Jobs Suspension Collapsed Subprocesses DMN Decisions Dashboard Decision Definition View Decision Instance View Deployments Open Tasks Dashboard Extending Configuration Plugins Tasklist Working with Tasklist Dashboard Filters User Assignment Task Lifecycle Plugins Configuration Accessibility Welcome Plugins Configuration Shared Configuration Options Authentication Cookie Security CSRF Prevention HTTP Header Security Examples Notices Update & Migration Rolling Update Camunda Migration Runtime Container Integration CIB seven Services JNDI Bindings for CIB seven Services Apache Tomcat WildFly Job Execution with Managed Resources :( Back to top cibseven.org and docs.cibseven.org are part of CIB seven project — Privacy Statement – CIB software GmbH The CIB seven documentation is based on Camunda 7 Docs from Camunda. Some redesign & naming adoptation was made. The content on this site is licensed under a Creative Commons Attribution-ShareAlike 3.0 Unported License.",
    "url": "/manual/latest/user-guide/runtime-container-integration/index.html"
  },
  {
    "id": "manual/latest/user-guide/runtime-container-integration/jboss/index.html",
    "title": "The CIB seven WildFly Subsystem | docs.cibseven.org",
    "content": "Installation Guide If you download a full distribution, the CIB seven Wildfly subsystem is readily installed into the application server. Read the installation guide to learn how to install the CIB seven Wildfly subsystem into your Wildfly Server. CIB seven provides advanced integration for Wildfly in the form of a custom Wildfly Subsystem. The most prominent features are: Deploy the process engine as shared Wildfly module. Configure the process engine in standalone.xml / domain.xml and administer it though the JBoss Management System. Process Engines are native JBoss Services with service lifecycles and dependencies. Automatic deployment of BPMN 2.0 processes (through the Process Application API). Use a managed Thread Pool for the Job Executor configured through the CIB seven Subsystem. Configure the Job Executor in standalone.xml/domain.xml The configuration of the thread pool used by the Job Executor is done in the CIB seven subsystem, not in the JBoss Threads subsystem, as it was done before. The thread pool creation and shutdown is now controlled through the CIB seven subsystem. You are able to configure it through the following new configuration elements below the job-executor element of the subsystem XML configuration. Mandatory configuration elements are: <core-threads>3</core-threads> <max-threads>5</max-threads> <queue-length>10</queue-length> Optional configuration elements are: <keepalive-time>10</keepalive-time> (in seconds) <allow-core-timeout>true</allow-core-timeout> Shown values are the default ones. For a complete list of all configuration options, please refer to the Job Executor Configuration. Configure a Process Engine in standalone.xml/domain.xml Using the Camunda Wildfly subsystem, it is possible to configure and manage the process engine through the JBoss Management Model. The most straightforward way is to add the process engine configuration to the standalone.xml file of the Wildfly Server: <subsystem xmlns=\"urn:org.cibseven.bpm.jboss:1.1\"> <process-engines> <process-engine name=\"default\" default=\"true\"> <datasource>java:jboss/datasources/ProcessEngine</datasource> <history-level>full</history-level> <properties> <property name=\"jobExecutorAcquisitionName\">default</property> <property name=\"isAutoSchemaUpdate\">true</property> <property name=\"authorizationEnabled\">true</property> </properties> </process-engine> </process-engines> <job-executor> <core-threads>3</core-threads> <max-threads>5</max-threads> <queue-length>10</queue-length> <job-acquisitions> <job-acquisition name=\"default\"> <properties> <property name=\"lockTimeInMillis\">300000</property> <property name=\"waitTimeInMillis\">5000</property> <property name=\"maxJobsPerAcquisition\">3</property> </properties> </job-acquisition> </job-acquisitions> </job-executor> </subsystem> It should be easy to see that the configuration consists of a single process engine which uses the Datasource java:jboss/datasources/ProcessEngine and is configured to be the default process engine. In addition, the job executor currently uses a single Job Acquisition, also named default. If you start up your Wildfly server with this configuration, it will automatically create the corresponding services and expose them through the management model. For a complete list of all configuration options, please refer to the Process Engine Configuration. Provide a Custom Process Engine Configuration Class It is possible to provide a custom Process Engine Configuration class on a Wildfly Application Server. To this extent, provide the fully qualified classname of the class in the standalone.xml file: <process-engine name=\"default\" default=\"true\"> <datasource>java:jboss/datasources/ProcessEngine</datasource> <configuration>org.my.custom.ProcessEngineConfiguration</configuration> <history-level>full</history-level> <properties> <property name=\"myCustomProperty\">true</property> <property name=\"lockTimeInMillis\">300000</property> <property name=\"waitTimeInMillis\">5000</property> </properties> </process-engine> The class org.my.custom.ProcessEngineConfiguration must be a subclass of org.cibseven.bpm.engine.impl.cfg.JtaProcessEngineConfiguration. The properties map can be used for invoking primitive valued setters (Integer, String, Boolean) that follow the Java Bean conventions. In the case of the example above, the class would provide a method named public void setMyCustomProperty(boolean boolean) { ... } Module dependency of custom configuration class If you configure the process engine in standalone.xml and provide a custom configuration class packaged inside an own module, the camunda-wildfly-subsystem module needs to have a module dependency on the module providing the class. If you fail to do this, you will see the following error log: Caused by: org.cibseven.bpm.engine.ProcessEngineException: Could not load 'foo.bar': the class must be visible from the camunda-wildfly-subsystem module. at org.cibseven.bpm.container.impl.jboss.service.MscManagedProcessEngineController.createProcessEngineConfiguration(MscManagedProcessEngineController.java:187) [camunda-wildfly-subsystem-1.1.0.jar:] at org.cibseven.bpm.container.impl.jboss.service.MscManagedProcessEngineController.startProcessEngine(MscManagedProcessEngineController.java:138) [camunda-wildfly-subsystem-1.1.0.jar:] at org.cibseven.bpm.container.impl.jboss.service.MscManagedProcessEngineController$3.run(MscManagedProcessEngineController.java:126) [camunda-wildfly-subsystem-1.1.0.jar:] Extend a Process Engine Using Process Engine Plugins It is possible to extend a process engine using the process engine plugins concept. You specify the process engine plugins in standalone.xml/domain.xml for each process engine separately as shown below: <subsystem xmlns=\"urn:org.cibseven.bpm.jboss:1.1\"> <process-engines> <process-engine name=\"default\" default=\"true\"> <datasource>java:jboss/datasources/ProcessEngine</datasource> <history-level>full</history-level> <properties> ... </properties> <plugins> <plugin> <class>org.cibseven.bpm.engine.MyCustomProcessEnginePlugin</class> <properties> <property name=\"boost\">10</property> <property name=\"maxPerformance\">true</property> <property name=\"actors\">akka</property> </properties> </plugin> </plugins> </process-engine> </process-engines> ... </subsystem> You have to provide the fully qualified classname between the <class> tags. Additional properties can be specified using the <properties> element. The restrictions which apply for providing a custom process engine configuration class are also valid for process engine plugins: Plugin class must be visible in the classpath for the Camunda subsystem. Properties map can be used for invoking primitive valued setters (Integer, String, Boolean) that follow the Java Bean conventions. Using System Properties To externalize environment specific parts of the configuration, it is possible to reference system properties using Ant-style expressions (i.e., ${PROPERTY_KEY}). Expression resolution is supported for all elements and attributes except for the name attribute on the elements process-engine and job-acquisition. System properties may be set via command line (-Doption). Read more on expressions in the documentation for WildFly. Example <!-- ... --> <plugin> <class>org.cibseven.bpm.engine.impl.plugin.AdministratorAuthorizationPlugin</class> <properties> <property name=\"administratorUserName\">${camunda.administratorUserName}</property> </properties> </plugin> <!-- ... --> Look Up a Process Engine in JNDI The Camunda Wildfly subsystem provides the same JNDI bindings for the ProcessApplicationService and the ProcessEngineService as provided on other containers. In addition, the Camunda Wildfly subsystem creates JNDI Bindings for all managed process engines, allowing us to look them up directly. The global JNDI bindings for process engines follow the pattern java:global/camunda-bpm-platform/process-engine/$PROCESS_ENGINE_NAME If a process engine is named “engine1”, it will be available using the name java:global/camunda-bpm-platform/process-engine/engine1. Note that when looking up the process engine, using a declarative mechanism (like @Resource or referencing the resource in a deployment descriptor) is preferred over a programmatic way. The declarative mechanism makes the application server aware of our dependency on the Process Engine Service and allows it to manage that dependency for us. See also: Managing Service Dependencies. A declarative mechanism like @Resource could be @Resource(mappedName = \"java:global/camunda-bpm-platform/process-engine/$PROCESS_ENGINE_NAME\") Look Up a Process Engine From JNDI Using Spring On Wildfly, Spring users should always create a resource-ref for the process engine in web.xml and then lookup the local name in the java:comp/env/ namespace. For an example, see this Quickstart Manage the Process Engine Through the JBoss Management System To inspect and change the management model, we can use one of the multiple WildFly Management Clients available. Inspect the Configuration It is possible to inspect the configuration using the CLI (Command Line Interface, jboss-cli.bat/sh): You are disconnected at the moment. Type 'connect' to connect to the server or 'help' for the list of supported commands. [disconnected /] connect [standalone@localhost:9999 /] cd /subsystem=camunda-bpm-platform [standalone@localhost:9999 subsystem=camunda-bpm-platform] :read-resource(recursive=true) { \"outcome\" => \"success\", \"result\" => { \"job-executor\" => {\"default\" => { \"thread-pool-name\" => \"job-executor-tp\", \"job-acquisitions\" => {\"default\" => { \"acquisition-strategy\" => \"SEQUENTIAL\", \"name\" => \"default\", \"properties\" => { \"lockTimeInMillis\" => \"300000\", \"waitTimeInMillis\" => \"5000\", \"maxJobsPerAcquisition\" => \"3\" } }} }}, \"process-engines\" => {\"default\" => { \"configuration\" => \"org.cibseven.bpm.container.impl.jboss.config.ManagedJtaProcessEngineConfiguration\", \"datasource\" => \"java:jboss/datasources/ProcessEngine\", \"default\" => true, \"history-level\" => \"full\", \"name\" => \"default\", \"properties\" => { \"jobExecutorAcquisitionName\" => \"default\", \"isAutoSchemaUpdate\" => \"true\" } }} } } Stop the Process Engine Through the JBoss Management System Once the process engine is registered in the JBoss Management Model, it is possible to control it through the management API. For example, you can stop it through the CLI: [standalone@localhost:9999 subsystem=camunda-bpm-platform] cd process-engines=default [standalone@localhost:9999 process-engines=default] :remove {\"outcome\" => \"success\"} This removes the process engine and all dependent services. This means that if you remove a process engine, the application server will stop all deployed applications which use the process engine. Declaring Service Dependencies For this to work, but also to avoid race conditions at deployment time, it is necessary that each application explicitly declares dependencies on the process engines it is using. Start the Process Engine Through the JBoss Management System It is also possible to start a new process engine at runtime: [standalone@localhost:9999 subsystem=camunda-bpm-platform] /subsystem=camunda-bpm-platform/process-engines=my-process-engine/:add(name=my-process-engine,datasource=java:jboss/datasources/ExampleDS) {\"outcome\" => \"success\"} One of the nice features of the Wildfly Management System is that it will Persist any changes to the model in the underlying configuration file. This means that if you start a process engine using the command line interface, the configuration will be added to standalone.xml/domain.xml such that it is available when the server is restarted. Distribute the configuration in the cluster and start / stop the process engine on all servers that are part of the same domain. Use the JBoss JConsole Extensions In some cases, you may find it more convenient to use WildFly’s JConsole extension for starting a process engine. The JConsole plugin allows you to inspect the management model graphically and build operations using a wizard. To start the JBoss JConsole plugin, start the jconsole.bat/sh file provided in the WildFly distribution. More Information in the WildFly Docs. Manage Classpath Dependencies Implicit Module Dependencies Classpath dependencies are automatically managed for you if you use the Process Application API. When using the Camunda Wildfly subsystem, the process engine classes are deployed as WildFly module. The module is named org.cibseven.bpm.camunda-engine and is deployed in the folder $WILDFLY_HOME/modules/org/cibseven/bpm/camunda-engine. By default, the application server will not add this module to the classpath of applications. If an application needs to interact with the process engine, we must declare a module dependency in the application. This can be achieved using either an implicit or an explicit module dependency. Implicit Module Dependencies with the Process Application API When using the Process Application API (i.e., when deploying either a servlet process application or an EJB process application), the Camunda Wildfly subsystem will detect the @ProcessApplication class in the deployment and automatically add a module dependency between the application and the process engine module. As a result, we don’t have to declare the dependency ourselves. It is called an implicit module dependency because it is not explicitly declared but can be derived by inspecting the application and seeing that it provides a @ProcessApplication class. Explicit Module Dependencies If an application does not use the Process Application API but still needs the process engine classes to be added to its classpath, an explicit module dependency is required. Wildfly offers multiple different mechanisms for achieving this. The simplest way is to add a manifest entry to the MANIFEST.MF file of the deployment. The following example illustrates how to generate such a dependency using the maven WAR plugin: <build> ... <plugins> <plugin> <groupId>org.apache.maven.plugins</groupId> <artifactId>maven-war-plugin</artifactId> <configuration> <archive> <manifestEntries> <Dependencies>org.cibseven.bpm.camunda-engine</Dependencies> </manifestEntries> </archive> </configuration> </plugin> </plugins> </build> As a result, the Application Service will add the process engine module to the classpath of the application. Manage Service Dependencies Implicit Service Dependencies Service dependencies are automatically managed for you if you use the Process Application API. The Camunda Wildfly subsystem manages process engines as JBoss Services in the JBoss Module Service Container. For the Module Service Container to provide the process engine service(s) to the deployed applications, it is important that the dependencies are known. Consider the following example: There are three applications deployed and two process engine services exist. Application 1 and Application 2 are using Process Engine 1 and Application 3 is using Process Engine 2. Implicit Service Dependencies When using the Process Application API (i.e., when deploying either a servlet process application or an EJB process application), the Camunda Wildfly subsystem will detect the @ProcessApplication class in the deployment and automatically add a service dependency between the process application component and the process engine module. This ensures that the process engine is available when the process application is deployed. Explicit Service Dependencies If an application does not use the Process Application API but still needs to interact with a process engine, it is important to declare the dependency on the Process Engine Service explicitly. If we fail to declare the dependency, there is no guarantee that the process engine is available to the application. When the application server is started, it will bring up services concurrently. If it is not aware of the dependency between the application and the process engine, the application may start before the process engine, potentially resulting in exceptions if the process engine is accessed from some deployment listener (like a servlet context listener). If the process engine is stopped while the application is deployed, the application server must stop the application as well. The simplest way to add an explicit dependency on the process engine is to bind the process engine in the application’s local naming space. For instance, we can add the following resource reference to the web.xml file of a web application: <resource-ref> <res-ref-name>processEngine/default</res-ref-name> <res-type>org.cibseven.bpm.engine.ProcessEngine</res-type> <mapped-name>java:global/camunda-bpm-platform/process-engine/default</mapped-name> </resource-ref> This way, the global process engine resource java:global/camunda-bpm-platform/process-engine/default is available locally under the name processEngine/default. Since the application server is aware of this dependency, it will make sure the Process Engine Service exists before starting the application and it will stop the application if the process engine is removed. The same effect can be achieved using the @Resource Annotation: @Stateless public class PaComponent { @Resource(mappedName=\"java:global/camunda-bpm-platform/process-engine/default\") private ProcessEngine processEngine; @Produces public ProcessEngine getProcessEngine() { return processEngine; } }",
    "url": "/manual/latest/user-guide/runtime-container-integration/jboss/index.html"
  },
  {
    "id": "manual/latest/user-guide/runtime-container-integration/jndi-bindings-for-bpmn-platform-services/index.html",
    "title": "JNDI Bindings for CIB seven Services | docs.cibseven.org",
    "content": "The CIB seven Services (i.e., Process Engine Service and Process Application Service) are provided via JNDI Bindings with the following JNDI names: Process Engine Service: java:global/camunda-bpm-platform/process-engine/ProcessEngineService!org.cibseven.bpm.ProcessEngineService Process Application Service: java:global/camunda-bpm-platform/process-engine/ProcessApplicationService!org.cibseven.bpm.ProcessApplicationService On JBoss EAP and WildFly, you are able to get any of these CIB seven Services through a JNDI lookup. However, on Apache Tomcat you have to do quite a bit more to be able to do a lookup to get one of these CIB seven Services.",
    "url": "/manual/latest/user-guide/runtime-container-integration/jndi-bindings-for-bpmn-platform-services/index.html"
  },
  {
    "id": "manual/latest/user-guide/runtime-container-integration/job-execution-with-managed-resources/index.html",
    "title": "Job Execution with Managed Resources | docs.cibseven.org",
    "content": "For supported environments, CIB seven provides server modules that integrate the Job Execution with the application server’s managed threadpools. If you are using one of those environments, it is recommended to use the integration provided with it. The descriptions on this page apply to the use case where there is no existing resource-aware implementation provided. In those cases, using managed resources provided by the application server is recommended over using unmanaged resources. In order for the integration to work, a JEE 7+ compliant application server is required. ManagedJobExecutor Integration into application servers without a resource-aware implementation is offered by a specific type of JobExecutor called the ManagedJobExecutor. The purpose of the ManagedJobExecutor is to ensure that job execution within the process engine is correctly controlled by the application server, by using managed resources (primarily: managed threads). In order to facilitate the ManagedJobExecutor, the engine must be configured to use it. For instance, when bootstrapping the engine from Java code, you would create a new instance of the ManagedJobExecutor and provide the resource dependency it has by injecting it from your application server’s environment. The ManagedJobExecutor can then be set as the JobExecutor that the process engine should use. Example usage The following code listing shows the essential configuration performed. @ApplicationScoped public class EngineBuilder { // Inject the ManagedExecutorService from the application server @Resource private ManagedExecutorService managedExecutorService; private ProcessEngine processEngine; private ManagedJobExecutor managedJobExecutor; @PostConstruct public void build() { // Create a new ManagedJobExecutor managedJobExecutor = new ManagedJobExecutor(this.managedExecutorService); // Create a process engine configuration ProcessEngineConfigurationImpl engineConfiguration = ... // Other configuration // Use the ManagedJobExecutor engineConfiguration.setJobExecutor(managedJobExecutor); // Build the process engine processEngine = engineConfiguration.buildProcessEngine(); } @PreDestroy public void stopEngine() { // Ensure the engine and job executor are shutdown as well processEngine.close(); managedJobExecutor.shutdown(); } } Unmanaged resources The example above injects a container managed resource, the ManagedExecutorService, into an object for which the lifecycle is not controlled by the application server (the ManagedJobExecutor which is instantiated with its constructor). This is not a generally recommended practice, because the dependencies that are injected may become unavailable. In this use case however, this approach is chosen because the ManagedJobExecutor relies on the existence of the ManagedExecutorService and this interface was only introduced with JEE7. Earlier versions of JEE could not fulfill this dependency and would fault if the component was activated automatically for all application servers. In order to avoid that the job executor is running on unavailable resources, we recommend to shutdown the job executor via its shutdown() method when the ManagedExecutorService becomes unavailable.",
    "url": "/manual/latest/user-guide/runtime-container-integration/job-execution-with-managed-resources/index.html"
  },
  {
    "id": "manual/latest/user-guide/runtime-container-integration/tomcat/index.html",
    "title": "Apache Tomcat Integration | docs.cibseven.org",
    "content": "JNDI Bindings To use the JNDI Bindings for CIB seven Services on Apache Tomcat you have to add the file META-INF/context.xml to your process application and add the following ResourceLinks (Tomcat 9, Tomcat 10.1): <Context> <ResourceLink name=\"ProcessEngineService\" global=\"global/camunda-bpm-platform/process-engine/ProcessEngineService!org.cibseven.bpm.ProcessEngineService\" type=\"org.cibseven.bpm.ProcessEngineService\" /> <ResourceLink name=\"ProcessApplicationService\" global=\"global/camunda-bpm-platform/process-engine/ProcessApplicationService!org.cibseven.bpm.ProcessApplicationService\" type=\"org.cibseven.bpm.ProcessApplicationService\" /> </Context> These elements are used to create a link to the global JNDI Resources defined in $TOMCAT_HOME/conf/server.xml. Furthermore, declare the dependency on the JNDI binding inside the WEB-INF/web.xml deployment descriptor. <web-app> <resource-ref> <description>Process Engine Service</description> <res-ref-name>ProcessEngineService</res-ref-name> <res-type>org.cibseven.bpm.ProcessEngineService</res-type> <res-auth>Container</res-auth> </resource-ref> <resource-ref> <description>Process Application Service</description> <res-ref-name>ProcessApplicationService</res-ref-name> <res-type>org.cibseven.bpm.ProcessApplicationService</res-type> <res-auth>Container</res-auth> </resource-ref> ... </web-app> Note: You can choose different resource link names for the Process Engine Service and Process Application Service. The resource link name has to match the value inside the <res-ref-name>-element inside the corresponding <resource-ref>-element in WEB-INF/web.xml. We propose the name ProcessEngineService for the Process Engine Service and ProcessApplicationService for the Process Application Service. To do a lookup for a CIB seven Service you have to use the resource link name to get the linked global resource. For example: Process Engine Service: java:comp/env/ProcessEngineService Process Application Service: java:comp/env/ProcessApplicationService If you have declared other resource link names than we proposed, you have to use java:comp/env/$YOUR_RESOURCE_LINK_NAME to do a lookup to get the corresponding CIB seven Service. Job Executor Configuration Tomcat Default Job Executor CIB seven on Apache Tomcat 10.x uses the default job executor. The default job executor uses a ThreadPoolExecutor which manages a thread pool and a job queue. The core pool size, queue size, maximum pool size and keep-alive-time can be configured in the bpm-platform.xml. After configuring job acquisition, it is possible to set the values with the help of a <properties> tag. The correct syntax can be found in the references. All the previously mentioned properties except the queue size can be modified at runtime via the use of a JMX client. Core Pool Size The ThreadPoolExecutor automatically adjusts the size of the thread pool. The number of threads in the thread pool will tend to come to equilibrium with the number of threads set to core pool size. If a new job is presented to the job executor and the total number of threads in the pool is less than core, then a new thread will be created. Hence on initial use, the number of threads in the thread pool will ramp up to the core thread count. The default core pool size is 3. Queue Size The ThreadPoolExecutor includes a job queue for buffering jobs. Once the core number of threads has been reached (and are in use), a new job presented to the job executor will result in the job being added to the ThreadPoolExecutor job queue. The default maximum length of the job queue is 3. Maximum Pool Size If the length of the queue were to exceed the maximum queue size, and the number of threads in the thread pool is less than the maximum pool size, then an additional thread is added to the thread pool. This will continue until the number of threads in the pool is equal to the maximum pool size: The default maximum pool size is 10. KeepAlive If a thread remains idle in the thread pool for longer than the keepalive time, and the number of threads exceeds core pool size, then the thread will be terminated. Hence the pool tends to settle around core thread count. The default keepalive time is 0. Clustered Deployment In a clustered deployment, multiple job executors will work with each other (Note: see Job Execution in Heterogeneous Clusters). On startup, each job executor allocates a UUID which is used for identifying locked job ownership in the job table. Hence in a two node cluster, the job executors may total up to 20 concurrent threads of execution.",
    "url": "/manual/latest/user-guide/runtime-container-integration/tomcat/index.html"
  },
  {
    "id": "manual/latest/user-guide/security/index.html",
    "title": "Security Instructions | docs.cibseven.org",
    "content": "This page provides an overview of how to secure a CIB seven installation. For CIB seven’s security policy, a list of security notices and a guide how to report vulnerabilities, please visit the general security documentation. In order to secure a CIB seven installation, CIB seven itself must be configured correctly and it must be integrated correctly into its environment. This section also identifies areas where we consider security issues to be relevant for the specific CIB seven product and listed those in the subsequent sections. Compliance for those areas is ensured based on common industry best practices and influenced by security requirements of standards like OWASP Top 10 and others Deployment Options and Components There are different ways of using CIB seven and different components are provided: the process engine itself, the REST API, the web applications. Depending on how CIB seven is deployed and which components are used, different security considerations apply. The following list gives a general overview over deployment options and components outlining the main differences from a security point of view. The remainder of this chapter elaborates on the different configuration options. Embedded Java library inside an application: in this case, the CIB seven engine is embedded inside a custom Java Application. Usually the application takes care of securing access to CIB seven’s APIs and the APIs are not directly exposed to an end user. In this case, the application typically takes care of ensuring authentication and preventing access by unauthorized users. Shared Process Engine: in this scenario, the Process Engine is deployed as a container service into an application server such that it can be used by the applications deployed into the same container / server. This case is similar to the embedded Java library case. REST API: the REST API provides access to CIB seven’s core APIs through HTTP. In this case users can directly access CIB seven’s APIs. Usually, it is necessary to configure authentication, authorization and also secure the connection to the REST API using SSL (HTTPS). Web applications (Cockpit, Tasklist, …): similar considerations to the REST API apply. Keep in mind that it is not recommended to use the pre-packaged distribution in production environment rather install the full distribution manually (for example Tomcat manual installation). Security Consideration The pre-packaged distribution is intended for users who want a getting started experience. In case you still want to use it in production, consider un-deploying the invoice application and removing the demo user. Security Configuration inside CIB seven CIB seven provides a number of configuration options which are relevant from a security perspective. Most prominently: authentication, authorization and the control of custom code (scripts) which can be executed on the server. Authentication Authentication controls who can access CIB seven’s APIs and Applications. Do I need Authentication? Authentication is only needed in the following cases: CIB seven’s REST API is used CIB seven’s web applications are used In these cases, direct access to CIB seven’s core APIs is provided over HTTP and authentication must be enabled. By contrast, authentication is generally not done by CIB seven when embedded as a library into an application. In this case the application takes care of authentication itself. Enabling Authentication for the REST API For ease of use by developers, the REST API’s authentication is disabled by default. When deploying the REST API in production, it is therefore required to enable authentication. Check the corresponding section in the REST API documentation. Authentication in the Web Applications For the web applications, authentication is enabled by default, and it is not possible to disable it. Authentication Cache Due to the authentication cache, by default, the following user management actions don’t have an immediate effect on currently active user sessions: A user account is deleted. A tenant/group membership or authorized application is added to or removed from a user account. Heads-up! The user management actions mentioned above can allow the (deleted or unauthorized) user to continue to read sensitive data or perform security-sensitive operations until the authentication cache time to live is due; by default, this is for a maximum of five minutes. To prevent this, you can: Set the time to live to a lower value. Disable the cache entirely (set the time to live to 0), which leads to querying for the authentication information on each REST API request. Note that changing the time to live to a lower value can harm the performance of your database server. Enable authentication logging in the CIB seven web apps It is generally recommended to enable logging of log in attempts (successful and failed) as well as log out events. In CIB seven, you can enable authentication logging in the CIB seven web apps by setting the webappsAuthenticationLoggingEnabled process engine configuration flag to true. All user-initiated log in and log out events will then be logged to the application log using the org.cibseven.bpm.webapp logger. The following events produce log statements: Successful log in with valid credentials Failed log in with wrong password Failed log in with insufficient authorization Failed log in with non-existing username Successful log out Heads-up! Someone could use brute force to produce arbitrary amounts of log statements and potentially reduce disc space available for logging. This could theoretically lead to a denial of service if the logs are stored on the same partition as the application. CIB seven does not handle such cases and the users are responsible to mitigate this risk, e.g. by limiting log in attempts. Internal (database backed) User Management To perform authentication, CIB seven can use two sources: a database or LDAP. When using the database, usernames and passwords are stored inside the ACT_ID_USER table (see documentation on database schema). To protect the passwords stored in the database, CIB seven uses two concepts: hashing: instead of storing the password in plain text, a hash is stored. When authenticating, the same hash is generated from the user’s input and compared against the hash in the database. If both hashes are equal the authentication attempt is successful. CIB seven allows users to configure and customize the hash function used. Please refer the documentation section on password hashing for details. salted hashes to protect the database against rainbow table attacks, CIB seven uses salted hashes. Similar to hashing itself, this function can be configured and extended to a user’s needs. Please refer the documentation section on password hashing for details. LDAP As an alternative to the database, CIB seven can use LDAP for verifying user credentials on authentication. CIB seven has read-only access to LDAP. Authorization Authorization controls what data a user can access and change in CIB seven once authenticated. Authentication is a pre-requisite to authorization. Do I need to enable Authorizations? Similar considerations as for authentication apply. For an in-depth discussion, see the documentation section on authorizations Restricting Data Access with Authorizations Authorizations can be used to restrict a user from accessing a data object (such as a process or a task) and can be used to restrict how the user can interact with such data objects (read-only vs. modifications). Authorizations in CIB seven are very powerful and it is recommended to read the corresponding documentation entry on authorizations. Prevent: Enumerating user accounts by brute-force creating new users Under certain circumstances, an attacker can enumerate user accounts by brute-force creating new users: You don’t centrally manage user accounts (e.g., with the help of LDAP or a custom implementation of WritableIdentityProvider) but instead … … use an account “self-service” approach: Unauthenticated users are allowed to create accounts; i.e., you have implemented a custom REST endpoint which can create users without authentication … an authenticated user has CREATE permission on ANY USER resource to create new user accounts and an untrusted person has access to this account (please see the Authorization Service docs to learn how permissions are granted to resources) As soon as the attacker has obtained information about existing user ids, they can put all their efforts on cracking passwords. Heads-up! We strongly recommend you to use the product with centrally managed user accounts. It is certainly not advisable to manage accounts via the ways mentioned above. We think that the before mentioned scenarios are uncommon for organizations using the CIB seven Runtime. However, we want to inform you about the options to prevent unrecommended usage, which makes the product vulnerable to attacks. Prevent: Bypassing authorizations by reusing leftover user authorizations When you delete a user, related user authorizations are not deleted automatically. Leftover user authorizations are reapplied when creating a new user with the same id, allowing attackers to bypass authorizations. We designed the authorization schema like this because user accounts are usually centrally managed by an external directory service such as LDAP or a custom implementation of the ReadonlyIdentityProvider Java interface. User authorizations cannot be automatically deleted in a technically feasible way since the external directory service does not notify CIB seven when users are deleted. Heads-up! Even if you don’t manage your user accounts through an external directory service, user authorizations are not automatically deleted. To prevent this: Use group instead of user authorizations when possible. Complete tasks that were assigned to to-be-deleted users. Delete user authorizations via Admin web app or APIs. Don’t allow to reuse an id of a deleted user. Spring Security OAuth2 See the Spring Security OAuth2 Integration’s Security Recommendations documentation. Deployments Deployments to the process engine can contain resources that are interpreted like code: BPMN, DMN, CMMN models that the process engine executes on the CIB seven server Scripts and templates in various languages (Javascript, Groovy, Freemarker, …) that the BPMN, DMN, CMMN models reference and that the process engine executes on the CIB seven server Java EL expressions that BPMN, DMN, CMMN models include and that are executed on the CIB seven server Forms that a client application like CIB seven Tasklist renders in the browser of the end user CIB seven does not provide a safe sandbox environment for the execution and rendering of these resources. Attackers that are able to make deployments can effectively perform remote code execution in the CIB seven system. It is therefore critical that only trusted users and systems can make deployments. For example, you can restrict deployment access in the following ways: Using authorizations, administrators grant the CREATE permission on the Deployment resource only to trusted users An application that embeds the CIB seven Java API can choose to not expose the deployment API on untrusted channels (such as to HTTP requests) System administrators ensure that only trusted users have network access to the CIB seven installation See also the user guide section Custom Code & Security for further information. Throttle login attempts The engine gives option to throttle login attempts. The mechanism behind this is enabled by default. You can read more about it under Identity Service in User Guide. Custom Whitelist for User, Group and Tenant IDs To determine if the provided ID is acceptable or not, IDs can be matched against a Whitelist Pattern. You can read more about it under Identity Service in User Guide. Password Policy When using the identity management provided by the engine (i.e., not the LDAP identity management), it is possible to configure a password policy to ensure that all user passwords meet a certain security standard. Since version 7.11, a built-in password policy can be enabled that requires passwords to follow specific rules. However, you can achieve a much higher level of security by implementing a more sophisticated custom password policy (e.g., with the help of [Password Topology Blacklisting] (https://blog.korelogic.com/blog/2014/04/04/pathwell_topologies), also see the [OWASP guide] (https://github.com/OWASP/CheatSheetSeries/blob/7d94e9a29174b8fd76235ca60f47245d1f34df1e/cheatsheets/Authentication_Cheat_Sheet.md#password-complexity) on password complexity). You can find more information on how to enable the base password policy and how to implement a custom password policy in our User Guide. Forms CIB seven offers different types of forms which are primarily used in Tasklist. In the input inside of this forms you can call and execute scripts which allows you to achieve easily your business logic. Please validate this input each time to prevent malicious behaviour. If you don’t want to display form previews and execute the embedded scripts in Cockpit, you can disable it in the configuration. Queries Expressions in Queries Consider disabling execution of expressions in queries. See also: Custom Code & Security Native queries One of the options to query data from the engine is using native queries. Which means to provide own SQL queries to retrieve engine entities if the Query API lacks the possibilities you need. However, use the native queries with care. Please bear in mind of the SQL Injection while using this approach. Maximum Results Limit in Queries Using the REST API or the Webapps querying for results without restricting the maximum number of results or querying for a vast number of results can lead to a high memory consumption or even to out of memory exceptions. You can mitigate the risk of an attack by defining a limit for the maximum number of results (queryMaxResultsLimit) in the process engine configuration. Heads-up! To gain the full feature set of the Webapps, and not suffer any UX degradation due to unavailable data, the queryMaxResultsLimit must be set to 2000. Please see the User Guide to learn more about the Query Maximum Results Limit. CSRF Prevention in the Webapps A CSRF filter is enabled by default, validating each modifying request performed through the webapps. Please also see the detailed overview on how to configure CSRF Prevention. The CSRF Prevention makes use of a cookie. By default, some security-related configurations are present for this cookie. To ensure full security, please consult the documentation about Cookie Security to learn more about it. XML Security CIB seven handles many XML files containing configurations of process engines, definitions of process models and more. In order to mitigate possible vulnerabilities that can be introduced by XML files, the following measures are activated by default: Prevention against XML eXternal Entity (XXE) injections according to OWASP Feature Secure Processing (FSP) of XML files according to Oracle which introduces limits for several XML properties If the limitations on XML files introduced by XXE prevention need to be removed, XXE processing can be enabled via enableXxeProcessing in the process engine configuration. FSP itself can not be disabled in the engine. All properties that are influenced by this can however be configured in the environment via system properties and the jaxp.properties file. See the Oracle documentation on how to determine the right limits and how to set them. Since BPMN schema validation requires external XSD documents, the property http://javax.xml.XMLConstants/property/accessExternalSchema is by default configured to value all, which enables referencing XML schemas by any supported protocol. This can be overridden via the system property javax.xml.accessExternalSchema, however a value set via jaxp.properties does not take effect. HTTP Header Security in Webapps Out-of-the-box the web applications support the following security-related HTTP headers: XSS Protection Content Security Policy Content-Type Options Strict Transport Security (needs to be enabled explicitly) These headers enable browser-side security mechanisms which help to improve the protection against several attacking scenarios. According to your project requirements, some of these headers can be configured more strict or lax. Please see the documentation about the HTTP Header Security to learn more about the several headers, the defaults and how to configure the HTTP headers according to your needs. Variable Values from Untrusted Sources Process variables can be submitted as Java objects using the JDK built-in application/x-java-serialized-object data format, JSON or XML along with a Java class name via the CIB seven REST API and web applications. On server side, they can then be deserialized into Java objects, so that Java code can work with them in a native way. See Spin for details and this REST API endpoint for an example. If an attacker can access these endpoints, they can exploit so-called serialization gadgets, i.e. classes that run vulnerable code during deserialization resulting in remote code execution in the general case. For example, consider a class constructor that makes a REST request based on a field value. An attacker could submit a forged variable value so that during deserialization, when the constructor is called, the application server would make an arbitrary REST request to a destination of the attacker’s choice. For details, see OWASP’s description of Deserialization of untrusted data. Java objects using the JDK built-in application/x-java-serialized-object data format Starting with version 7.9, by default, it is not possible to set variables of type Object AND the data format application/x-java-serialized-object. The behavior can be restored with the process engine configuration flag javaSerializationFormatEnabled. However, please bear in mind that enabling the java serialization format might make the process engine vulnerable against the aforementioned attacking scenario. JSON/XML serialized objects using Spin Therefore, we recommend enabling the whitelisting of allowed Java classes by enabling the property deserializationTypeValidationEnabled in the process engine configuration. With this, the process engine validates the class names of submitted variables against a whitelist of allowed Java class and package names. Any non-whitelisted content is rejected. The default values are safe, but may be too restrictive for your use case. You can use the engine properties deserializationAllowedPackages and deserializationAllowedClasses to extend the default whitelist with package and class names of Java types that you consider save to deserialize in your environment. In case this default behavior needs further adjustment, a custom validator can be implemented and registered in the engine with the engine property deserializationTypeValidator. The provided object needs to be a subtype of org.cibseven.bpm.engine.runtime.DeserializationTypeValidator and offer an implementation of the #validate method. In case you want to rely on allowed package and class names from the engine configuration as well, you can provide a subtype of org.cibseven.bpm.engine.runtime.WhitelistingDeserializationTypeValidator. An implementation of this interface registered as validator will be provided with the defined packages and classes from the engine configuration upon initialization of the engine via #setAllowedClasses and #setAllowedPackages. Jackson Type Whitelisting Spin’s JSON implementation is based on Jackson. If you configure Spin to deserialize polymorphic classes based on type information included in the JSON itself (i.e. where the JSON contains explicit class names), we strongly recommend to additionally enable Jackson’s Whitelisting feature starting with version 2.10. CIB seven’s whitelisting feature does not cover this case. User operation log settings for synchronous operations affecting multiple entities Some of the synchronous APIs can be used to perform actions on multiple entities, potentially affecting large amounts of data. Without constraints, the process engine can create potentially unlimited numbers of user operation log entries. A user operation log entry technically consists of multiple database entries in the ACT_HI_OP_LOG table. The amount of table entries depends on the number of properties logged for the user operation log. Example: A synchronous message correlation will log up to three properties (messageName, nrOfVariables, processInstance) depending on some conditions. A synchronous message correlation operation with 1000 affected process instances would yield 3000 new rows in the user operation log database table. Using the process engine configuration flag logEntriesPerSyncOperationLimit, the number of created entries to the user operation log can be limited for synchronous API calls. By default, one operation log entry is written per API call, regardless of how many entities were affected (default property value is 1). If you choose to change logEntriesPerSyncOperationLimit, select a value that you are certain your system can handle. For more information about the possible values for logEntriesPerSyncOperationLimit, visit the configuration documentation. Currently, the following APIs are affected: Message correlation Security Configuration in the external Environment CIB seven integrates into an environment, most prominently the database and, when using the web applications or the REST API, also a webserver. In order to secure your CIB seven deployment as a whole, the integration is relevant. Database CIB seven stores its data into a relational database. In order to protect access to this data, it must be configured correctly. The documentation section on supported environments provides a list of supported databases. Data encryption To prevent unauthorized access to the data stored in the CIB seven database you must follow best practices around operating the database, including data encryption. Please make sure to consult the manual provided by your database vendor. Securing the database connection To access the database, CIB seven needs to establish a connection. Usually the connection is configured either directly through the JDBC configuration options or through a datasource configured inside the application server. Most database drivers support encrypted connections and transport layer security when connecting to the database. When operating CIB seven and the database in an untrusted network it is recommended to enable these features. Please consider the manuals of your database, database driver and your application server to do so. Securing Database Credentials To establish the connection to the database, the database credentials need to be provided. As opposed to providing the credentials as plain text in a configuration file, some application servers support storing the credentials securely in an encrypted form. In that case, consult the manual of your application server to learn how to use these features. Web Server (applicable when using REST API or Web Applications) When deploying the REST API or the CIB seven web applications, CIB seven is integrated with a third party web server. The documentation section on supported environments provides a list of supported web servers / application servers. It is strongly recommended to consider applying the following configurations. Enabling SSL / HTTPS Configure SSL / HTTPS when deploying the CIB seven REST APIs or web applications. This can be achieved by configuring HTTPS either on the web server itself or through a reverse proxy. Consider disable HTTP and configure HTTPS only for your web applications. Please consult the manual of your web server or reverse proxy for details. Session timeout Setting up the session timeout is usually done via web.xml deployment descriptor. Please consult the Java Servlet specification or manual of your application server. Cookies domain The session cookies domain is configured in web server specific configuration. If you want to set such kind of cookies please consult the manual of your web server for details, e.g. for Tomcat check this docs. Maximum POST size in server (REST API) Restriction of the maximum size in bytes of the POST requests is specific to your web server. Please consult the manual of your web server for details, e.g. for Tomcat server, check this documentation page. Securing Cookies (Web Applications) The container provides the session cookie. Please consult the documentation about Cookie Security to learn what configurations are necessary to ensure full security for the session cookie. Error handling When it comes to error handling, from a security perspective, the top goal is to prevent attackers from obtaining technical details about the system, which for example, a stack trace could reveal (see OWASP’s Improper Error Handling article for more information). In this section, we describe what we do to prevent disclosing technical details about the system. Webapps In the Webapps, a generic default error page is provided when an error occurs. This error page does not include any technical details like stack traces. REST API The REST API only displays the type and a short error message when an error is thrown. Prevent Disclosure of Application Server Internals In the Error handling paragraph, we explain our technical measures not to disclose any technical details about the CIB seven Runtime. However, technical details cannot only be disclosed on the application level, but also by the application server itself. Therefore, it is recommended to configure the application server in a way that no technical details are disclosed when an error occurs on the application server level. The exact configuration and the defaults differ among application servers. Please find below external documentation on how to configure your application server correctly: Tomcat 9.0+ Official Documentation Security Considerations Error Reporter Valve Alternative Resources Securing Tomcat Wildfly 12.0+: Official Documentation Servlet Container Configuration Model Reference JBoss EAP 7.0+: Official Documentation Servlet Container Configuration Model Refernce CIB seven Run/Spring Boot 2.3+ Official Documentation Javadocs about ErrorProperties.IncludeStacktrace Alternative Resources Error Handling on Baeldung",
    "url": "/manual/latest/user-guide/security/index.html"
  },
  {
    "id": "manual/latest/user-guide/spring-boot-integration/configuration/index.html",
    "title": "Process Engine Configuration | docs.cibseven.org",
    "content": "The auto starter uses the org.cibseven.bpm.engine.impl.cfg.ProcessEnginePlugin mechanism to configure the engine. The configuration is divided into sections. These sections are represented by the marker interfaces: org.cibseven.bpm.spring.boot.starter.configuration.CamundaProcessEngineConfiguration org.cibseven.bpm.spring.boot.starter.configuration.CamundaDatasourceConfiguration org.cibseven.bpm.spring.boot.starter.configuration.CamundaHistoryConfiguration org.cibseven.bpm.spring.boot.starter.configuration.CamundaHistoryLevelAutoHandlingConfiguration org.cibseven.bpm.spring.boot.starter.configuration.CamundaJobConfiguration org.cibseven.bpm.spring.boot.starter.configuration.CamundaDeploymentConfiguration org.cibseven.bpm.spring.boot.starter.configuration.CamundaAuthorizationConfiguration org.cibseven.bpm.spring.boot.starter.configuration.CamundaFailedJobConfiguration org.cibseven.bpm.spring.boot.starter.configuration.CamundaMetricsConfiguration Default Configurations The following default and best practice configurations are provided by the starter and can be customized or overridden. DefaultProcessEngineConfiguration Sets the process engine name and automatically adds all ProcessEnginePlugin beans to the configuration. DefaultDatasourceConfiguration Configures the CIB seven data source and enables transaction integration. By default, the primary DataSource and PlatformTransactionManager beans are wired with the process engine configuration. If you want to configure more than one datasource and don’t want to use the @Primary one for the process engine, then you can create a separate data source with name camundaBpmDataSource that will be automatically wired with CIB seven instead. @Bean @Primary @ConfigurationProperties(prefix=\"datasource.primary\") public DataSource primaryDataSource() { return DataSourceBuilder.create().build(); } @Bean(name=\"camundaBpmDataSource\") @ConfigurationProperties(prefix=\"datasource.secondary\") public DataSource secondaryDataSource() { return DataSourceBuilder.create().build(); } If you don’t want to use the @Primary transaction manager, it is possible to create a separate transaction manager with the name camundaBpmTransactionManager that will be wired with the data source used for Camunda (either @Primary or camundaBpmDataSource): @Bean @Primary public PlatformTransactionManager primaryTransactionManager() { return new JpaTransactionManager(); } @Bean(name=\"camundaBpmTransactionManager\") public PlatformTransactionManager camundaTransactionManager(@Qualifier(\"camundaBpmDataSource\") DataSource dataSource) { return new DataSourceTransactionManager(dataSource); } The wired data source and transaction manager beans must match, i.e. make sure that the transaction manager actually manages the CIB seven data source. If that is not the case, the process engine will use auto-commit mode for the data source connection, potentially leading to inconsistencies in the database. DefaultHistoryConfiguration Applies the history configuration to the process engine. If not configured, the history level FULL is used. If you want to use a custom HistoryEventHandler, you just have to provide a bean implementing the interface. @Bean public HistoryEventHandler customHistoryEventHandler() { return new CustomHistoryEventHanlder(); } DefaultHistoryLevelAutoHandlingConfiguration Prefer usage of history-level auto, this configuration adds support for older Camunda versions <= 7.3. To have more control over the handling, you can provide your own org.cibseven.bpm.spring.boot.starter.jdbc.HistoryLevelDeterminator with name historyLevelDeterminator IMPORTANT: The default configuration is applied after all other default configurations using the ordering mechanism. DefaultJobConfiguration Applies the job execution properties to the process engine. To have more control over the execution itself, you can provide your own org.cibseven.bpm.engine.impl.jobexecutor.JobExecutor org.springframework.core.task.TaskExecutor named camundaTaskExecutor beans. IMPORTANT: The job executor is not enabled in the configuration. This is done after the spring context successfully loaded (see org.cibseven.bpm.spring.boot.starter.runlistener). DefaultDeploymentConfiguration If auto deployment is enabled (this is the case by default), all processes found in the classpath are deployed. The resource pattern can be changed using properties (see properties). DefaultAuthorizationConfiguration Applies the authorization configuration to the process engine. If not configured, the camunda default values are used (see properties). Overriding the Default Configuration Provide a bean implementing one of the marker interfaces. For example to customize the datasource configuration: @Configuration public class MyConfiguration { @Bean public static CamundaDatasourceConfiguration camundaDatasourceConfiguration() { return new MyCamundaDatasourceConfiguration(); } } Adding Additional Configurations You just have to provide one or more beans implementing the org.cibseven.bpm.engine.impl.cfg.ProcessEnginePlugin interface (or extend from org.cibseven.bpm.spring.boot.starter.configuration.impl.AbstractCamundaConfiguration). The configurations are applied ordered using the spring ordering mechanism (@Order annotation and Ordered interface). So if you want your configuration to be applied before the default configurations, add a @Order(Ordering.DEFAULT_ORDER - 1) annotation to your class. If you want your configuration to be applied after the default configurations, add a @Order(Ordering.DEFAULT_ORDER + 1) annotation to your class. @Configuration public class MyConfiguration { @Bean @Order(Ordering.DEFAULT_ORDER + 1) public static ProcessEnginePlugin myCustomConfiguration() { return new MyCustomConfiguration(); } } Or, if you have component scan enabled: @Component @Order(Ordering.DEFAULT_ORDER + 1) public class MyCustomConfiguration implements ProcessEnginePlugin { @Override public void preInit(ProcessEngineConfigurationImpl processEngineConfiguration) { //... } ... } or @Component @Order(Ordering.DEFAULT_ORDER + 1) public class MyCustomConfiguration extends AbstractCamundaConfiguration { @Override public void preInit(SpringProcessEngineConfiguration springProcessEngineConfiguration) { //... } ... } CIB seven engine Properties In addition to the bean-based way of overriding process engine configuration properties, it is also possible to set those properties via an application.yaml configuration file. Instructions on how to use it can be found in the Spring Boot Starter Guide. The available properties are as follows: Prefix Property name Description Default value General camunda.bpm .enabled Switch to disable the CIB seven auto-configuration. Use to exclude CIB seven in integration tests. true .process-engine-name Name of the process engine Camunda default value .generate-unique-process-engine-name Generate a unique name for the process engine (format: 'processEngine' + 10 random alphanumeric characters) false .generate-unique-process-application-name Generate a unique Process Application name for every Process Application deployment (format: 'processApplication' + 10 random alphanumeric characters) false .default-serialization-format Default serialization format Camunda default value .history-level CIB seven history level FULL .history-level-default CIB seven history level to use when history-level is auto, but the level can not determined automatically FULL .auto-deployment-enabled If processes should be auto deployed. This is disabled when using the SpringBootProcessApplication true .default-number-of-retries Specifies how many times a job will be executed before an incident is raised 3 .job-executor-acquire-by-priority If set to true, the job executor will acquire the jobs with the highest priorities false .id-generator Configure idGenerator. Allowed values: simple, strong, prefixed. prefixed id generator is like strong, but uses a Spring application name (${spring.application.name}) as the prefix for each id. strong .version Version of the process engine Read only value, e.g., 7.4.0 .formatted-version Formatted version of the process engine Read only value, e.g., (v7.4.0) .deployment-resource-pattern Location for auto deployment classpath*:**/*.bpmn, classpath*:**/*.bpmn20.xml, classpath*:**/*.dmn, classpath*:**/*.dmn11.xml, classpath*:**/*.cmmn, classpath*:**/*.cmmn10.xml, classpath*:**/*.cmmn11.xml Job Execution camunda.bpm.job-execution .enabled If set to false, no JobExecutor bean is created at all. Maybe used for testing. true .deployment-aware If job executor is deployment aware false .core-pool-size Set to value > 1 to activate parallel job execution. 3 .keep-alive-seconds Specifies the time, in milliseconds, for which threads are kept alive when there are no more tasks present. When the time expires, threads are terminated so that the core pool size is reached. 0 .lock-time-in-millis Specifies the time in milliseconds an acquired job is locked for execution. During that time, no other job executor can acquire the job. 300000 .max-jobs-per-acquisition Sets the maximal number of jobs to be acquired at once. 3 .max-pool-size Maximum number of parallel threads executing jobs. 10 .queue-capacity Sets the size of the queue which is used for holding tasks to be executed. 3 .wait-time-in-millis Specifies the wait time of the job acquisition thread in milliseconds in case there are less jobs available for execution than requested during acquisition. If this is repeatedly the case, the wait time is increased exponentially by the factor waitIncreaseFactor. The wait time is capped by maxWait. 5000 .max-wait Specifies the maximum wait time of the job acquisition thread in milliseconds in case there are less jobs available for execution than requested during acquisition. 60000 .backoff-time-in-millis Specifies the wait time of the job acquisition thread in milliseconds in case jobs were acquired but could not be locked. This condition indicates that there are other job acquisition threads acquiring jobs in parallel. If this is repeatedly the case, the backoff time is increased exponentially by the factor waitIncreaseFactor. The time is capped by maxBackoff. With every increase in backoff time, the number of jobs acquired increases by waitIncreaseFactor as well. 0 .max-backoff Specifies the maximum wait time of the job acquisition thread in milliseconds in case jobs were acquired but could not be locked. 0 .backoff-decrease-threshold Specifies the number of successful job acquisition cycles without a job locking failure before the backoff time is decreased again. In that case, the backoff time is reduced by waitIncreaseFactor. 100 .wait-increase-factor Specifies the factor by which wait and backoff time are increased in case their activation conditions are repeatedly met. 2 Datasource camunda.bpm.database .schema-update If automatic schema update should be applied, use one of [true, false, create, create-drop, drop-create] true .type Type of the underlying database. Possible values: h2, mysql, mariadb, oracle, postgres, mssql, db2. Will be automatically determined from datasource .table-prefix Prefix of the CIB seven database tables. Attention: The table prefix will not be applied if you are using schema-update! Camunda default value .schema-name The dataBase schema name Camunda default value .jdbc-batch-processing Controls if the engine executes the jdbc statements as Batch or not. It has to be disabled for some databases. See the user guide for further details. Camunda default value: true Eventing camunda.bpm.eventing .execution Enables eventing of delegate execution events. See the user guide for further details. true .history Enables eventing of history events. See the user guide for further details. true .task Enables eventing of task events. See the user guide for further details. true .skippable Controls if listeners are registered as built-in (false) or are skippable (true). See the user guide for further details. true Management camunda.bpm.management .health.camunda.enabled Enables default CIB seven health indicators true Metrics camunda.bpm.metrics .enabled Enables metrics reporting Camunda default value .db-reporter-activate Enables db metrics reporting Camunda default value Webapp camunda.bpm.webapp .enabled Switch to disable the CIB seven Webapp auto-configuration. true .index-redirect-enabled Registers a redirect from / to CIB seven's bundled index.html. If this property is set to false, the default Spring Boot behaviour is taken into account. true .application-path Changes the application path of the webapp. When setting to /, the legacy behavior of CIB seven Spring Boot Starter <= 3.4.x is restored. /camunda camunda.bpm.webapp.csrf .target-origin Sets the application expected deployment domain. See the user guide for details. Not set .deny-status Sets the HTTP response status code used for a denied request. See the user guide for details. 403 .random-class Sets the name of the class used to generate tokens. See the user guide for details. java.security.SecureRandom .entry-points Sets additional URLs that will not be tested for the presence of a valid token. See the user guide for details. Not set .enable-secure-cookie If set to true, the cookie flag Secure is enabled. false .enable-same-site-cookie If set to false, the cookie flag SameSite is disabled. The default value of the SameSite cookie is LAX and it can be changed via same-site-cookie-option configuration property. true .same-site-cookie-option Can be configured either to STRICT or LAX. Note: Is ignored when enable-same-site-cookie is set to false Cannot be set in conjunction with same-site-cookie-value Not set .same-site-cookie-value A custom value for the cookie property. Note: Is ignored when enable-same-site-cookie is set to false Cannot be set in conjunction with same-site-cookie-option Not set .cookie-name A custom value to change the cookie name. Note: Please make sure to additionally change the cookie name for each webapp (e. g. Cockpit ) separately. XSRF-TOKEN camunda.bpm.webapp.session-cookie .enable-secure-cookie If set to true, the cookie flag Secure is enabled for the Session Cookie. Note: If the Secure flag is set in the cookie by any other means already, this property will not remove it by setting it to false. false .enable-same-site-cookie If set to false, the cookie flag SameSite is disabled. The default value of the SameSite cookie is LAX and it can be changed via same-site-cookie-option configuration property. Note: If the SameSite flag is set in the cookie by any other means already, this property will not adjust or remove it. true .same-site-cookie-option Can be configured either to STRICT or LAX. Note: Is ignored when enable-same-site-cookie is set to false Cannot be set in conjunction with same-site-cookie-value Will not change the value of the SameSite flag if it is set already by any other means Not set .same-site-cookie-value A custom value for the cookie property. Note: Is ignored when enable-same-site-cookie is set to false Cannot be set in conjunction with same-site-cookie-option Will not change the value of the SameSite flag if it is set already by any other means Not set .cookie-name A custom value to configure the name of the session cookie to adjust. JSESSIONID camunda.bpm.webapp.header-security .xss-protection-disabled The header can be entirely disabled if set to true. Allowed set of values is true and false. false .xss-protection-option The allowed set of values: BLOCK: If the browser detects a cross-site scripting attack, the page is blocked completely SANITIZE: If the browser detects a cross-site scripting attack, the page is sanitized from suspicious parts (value 0) Note: Is ignored when .xss-protection-disabled is set to true Cannot be set in conjunction with .xss-protection-value BLOCK .xss-protection-value A custom value for the header can be specified. Note: Is ignored when .xss-protection-disabled is set to true Cannot be set in conjunction with .xss-protection-option 1; mode=block .content-security-policy-disabled The header can be entirely disabled if set to true. Allowed set of values is true and false. false .content-security-policy-value A custom value for the header can be specified. Note: Property is ignored when .content-security-policy-disabled is set to true base-uri 'self' .content-type-options-disabled The header can be entirely disabled if set to true. Allowed set of values is true and false. false .content-type-options-value A custom value for the header can be specified. Note: Property is ignored when .content-security-policy-disabled is set to true nosniff .hsts-disabled Set to false to enable the header. The header is disabled by default. Allowed set of values is true and false. true .hsts-max-age Amount of seconds, the browser should remember to access the webapp via HTTPS. Note: Corresponds by default to one year Is ignored when hstsDisabled is true Cannot be set in conjunction with hstsValue Allows a maximum value of 231-1 31536000 .hsts-include-subdomains-disabled HSTS is additionally to the domain of the webapp enabled for all its subdomains. Note: Is ignored when hstsDisabled is true Cannot be set in conjunction with hstsValue true .hsts-value A custom value for the header can be specified. Note: Is ignored when hstsDisabled is true Cannot be set in conjunction with hstsMaxAge or hstsIncludeSubdomainsDisabled max-age=31536000 camunda.bpm.webapp.auth.cache .ttl-enabled The authentication cache time to live can be entirely disabled if set to false. I. e., authentication information is cached for the lifetime of the HTTP session. Allowed set of values is true and false. true .time-to-live A number of milliseconds, while the web apps reuse the cache for an HTTP session before they recreate it and query for the authentication information again from the database. The allowed set of values: a time duration in milliseconds between 1 and 263-1 0 which effectively leads to querying for the authentication information on each REST API request Note: Ignored when .enabled is set to false 300,000 Authorization camunda.bpm.authorization .enabled Enables authorization Camunda default value .enabled-for-custom-code Enables authorization for custom code Camunda default value .authorization-check-revokes Configures authorization check revokes Camunda default value .tenant-check-enabled Performs tenant checks to ensure that an authenticated user can only access data that belongs to one of his tenants. true Admin User camunda.bpm.admin-user .id The username (e.g., 'admin') - .password The initial password =id .firstName, .lastName, .email Additional (optional) user attributes Defaults to value of 'id' Filter camunda.bpm.filter .create Name of a \"show all\" filter. If set, a new filter is created on start that displays all tasks. Useful for testing on h2 db. - OAuth2 camunda.bpm.oauth2.identity-provider .enabled Enables the OAuth2 identity provider. true .group-name-attribute Enables and configures the OAuth2 Granted Authorities Mapper. - .group-name-delimiter Configures the delimiter used in the OAuth2 Granted Authorities Mapper. It's only used if the configured group-name-attribute contains String value. , (comma) camunda.bpm.oauth2.sso-logout .enabled Activates the client initiated OIDC logout feature. false .post-logout-redirect-uri Configures the URI the user is redirected after SSO logout from the provider. {baseUrl} Generic Properties The method of configuration described above does not cover all process engine properties available. To override any process engine configuration property that is not exposed (i.e. listed above) you can use generic-properties. camunda: bpm: generic-properties: properties: ... Note: Overriding an already exposed property using the generic-properties keyword does not effect the process engine configuration. All exposed properties can only be overridden with their exposed identifier. Examples Override configuration using exposed properties: camunda.bpm: admin-user: id: kermit password: superSecret firstName: Kermit filter: create: All tasks Override configuration using generic properties: camunda: bpm: generic-properties: properties: enable-password-policy: true Session Cookie You can configure the Session Cookie for the Spring Boot application via the application.yaml configuration file. CIB seven Spring Boot Starter versions >= 3.0 (Spring Boot version 2.x) server: servlet: session: cookie: secure: true http-only: true # Not possible for versions before 2.0.3 Further details of the session cookie like the SameSite flag can be configured via camunda.bpm.webapp.session-cookie in the application.yaml. Configuring Spin DataFormats The CIB seven Spring Boot Starter auto-configures the Spin Jackson Json DataFormat when the cibseven-spin-dataformat-json-jackson dependency is detected on the classpath. To include a DataFormatConfigurator for the desired Jackson Java 8 module, the appropriate dependency needs to be included on the classpath as well. Note that cibseven-engine-plugin-spin needs to be included as a dependency as well for the auto-configurators to work. Auto-configuration is currently supported for the following Jackson Java 8 modules: Parameter names (jackson-module-parameter-names) Java 8 Date/time (jackson-datatype-jdk8) Java 8 Datatypes (jackson-datatype-jsr310) Heads Up! The Spin Jackson Json DataFormat auto-configuration is disabled when using cibseven-spin-dataformat-all as a dependency. The cibseven-spin-dataformat-all artifact shades the Jackson libraries, which breaks compatibility with the regular Jackson modules. If usage of cibseven-spin-dataformat-all is necessary, please use the standard method for Spin Custom DataFormat configuration. For example, to provide support for Java 8 Date/time types in Spin, the following dependencies, with their appropriate version tags, will need to be added in the Spring Boot Application’s pom.xml file: <dependencies> <dependency> <groupId>org.cibseven.bpm</groupId> <artifactId>cibseven-engine-plugin-spin</artifactId> </dependency> <dependency> <groupId>org.cibseven.spin</groupId> <artifactId>cibseven-spin-dataformat-json-jackson</artifactId> </dependency> <dependency> <groupId>com.fasterxml.jackson.datatype</groupId> <artifactId>jackson-datatype-jdk8</artifactId> </dependency> </dependencies> Spring Boot also provides some nice configuration properties, to further configure the Jackson ObjectMapper. They can be found here. To provide additional configurations, the following actions need to be performed: Provide a custom implementation of org.cibseven.spin.spi.DataFormatConfigurator; Add the appropriate key-value pair of the fully qualified classnames of the interface and the implementation to the META-INF/spring.factories file; Ensure that the artifact containing the configurator is reachable from Spin’s classloader.",
    "url": "/manual/latest/user-guide/spring-boot-integration/configuration/index.html"
  },
  {
    "id": "manual/latest/user-guide/spring-boot-integration/develop-and-test/index.html",
    "title": "Developing and Testing Spring Boot Applications | docs.cibseven.org",
    "content": "Developing Spring Boot provides Developer Tools which feature options like automatic restart and live reload during the development of an application. Spring Developer Tools and Classloading An additional process engine plugin (ApplicationContextClassloaderSwitchPlugin) will be loaded in case your application is in a development mode: Spring Developer tools (spring-boot-devtools library) are on the class path and the tools are enabled, e.g., the application is started in IDE The plugin ensures exchanging the application context classloader with the classloader used for the process engine to prevent issues during deserialization. Testing Spring offers extensive support for automated testing. This is covered through dedicated mocking packages, test runners and annotations. When testing Spring and Spring Boot applications, a significant amount of time is required to load the ApplicationContext. That is why Spring caches an ApplicationContext after a test is finished. This allows for it to be reused in later tests with the same configuration. Context Caching with Process Engines To use ApplicationContext caching with the Process Engine requires some additional configuration. This is because the Process Engine needs a statically defined name (if no name is defined, “default” is used), which leads to Spring attempting to create multiple ApplicationContexts with Process Engines with the same name. This will cause tests to behave incorrectly, or in the worst case, completely fail to load the ApplicationContext. Using unique Process Engine/Application names To make context caching work properly with Process Engines and Process Applications, they need to have unique names for every different test configuration. When defining a new test configuration, the easiest way to ensure that the new ApplicationContext uses a new Process Engine (and Process Application) is to enable to following properties in your @SpringBootTest annotation: @SpringBootTest( // ...other parameters... properties = { \"camunda.bpm.generate-unique-process-engine-name=true\", // this is only needed if a SpringBootProcessApplication // is used for the test \"camunda.bpm.generate-unique-process-application-name=true\", \"spring.datasource.generate-unique-name=true\", // additional properties... } ) The camunda.bpm.generate-unique-process-engine-name=true property will generate a unique name for the Process Engine (ex. ‘processEngine2Sc4bg2s1g’). The camunda.bpm.generate-unique-process-application-name=true property will generate a unique name for the Process Application (ex. ‘processApplication2Sc4bg2s1g’). This is useful if you want to deploy and test a Process Application multiple times with multiple configurations. The spring.datasource.generate-unique-name=true property will generate a new datasource for each new ApplicationContext. Reused (cached) ApplicationContexts will use the same datasource. Be aware that the generate-unique-process-engine-name and process-engine-name properties are mutually exclusive. Setting them both will result in an exception. If a static accessor needs to be used (e.g. processEngines.getProcessEngine(name)) in a given test, then the following properties can be used: @SpringBootTest( // other parameters properties = { \"camunda.bpm.process-engine-name=foo\", // this is only needed if a SpringBootProcessApplication // is used for the test \"camunda.bpm.generate-unique-process-application-name=true\", \"spring.datasource.generate-unique-name=true\", // additional properties } ) Here, the camunda.bpm.process-engine-name=foo will set (a unique name) “foo” as the Process Engine name. CIB seven Assertions The CIB seven Assertions library is integrated with the CIB seven Spring Boot Starter in order to make testing processes in your Spring Boot application easier. Using Assertions with Context Caching Out of the box, the CIB seven Assertions library tries to use the default engine or the (single) one that is available. Since when using Context Caching multiple engines are used in different contexts, binding the correct Process Engine to the CIB seven Assertions library is required for both caching and assertions to work correctly. This can be done through the following initialization code in the test class: @Autowired ProcessEngine processEngine; @Before public void setUp() { init(processEngine); } This needs to be done in addition to the Unique Process Engine/Application names requirement described in the section above.",
    "url": "/manual/latest/user-guide/spring-boot-integration/develop-and-test/index.html"
  },
  {
    "id": "manual/latest/user-guide/spring-boot-integration/index.html",
    "title": "Spring Boot Integration | docs.cibseven.org",
    "content": "The CIB seven engine can be used in a Spring Boot application by using provided Spring Boot starters. Spring boot starters allow to enable behavior of your spring-boot application by adding dependencies to the classpath. These starters will pre-configure the CIB seven process engine, REST API and Web applications, so they can easily be used in a standalone process application. If you are not familiar with Spring Boot, read the getting started guide. To enable CIB seven auto configuration, add the following dependency to your pom.xml: <dependency> <groupId>org.cibseven.bpm.springboot</groupId> <artifactId>cibseven-bpm-spring-boot-starter</artifactId> <version>1.1.0</version> </dependency> CIB seven relies on Sonatype Nexus Repository to provide all artifacts to users at artifacts.cibseven.org. Since version 1.1.0 all artifacts ara available at Maven Central. Other starters that can be used are: cibseven-bpm-spring-boot-starter-rest cibseven-bpm-spring-boot-starter-webapp cibseven-bpm-spring-boot-starter-external-task-client Requirements CIB seven Spring Boot Starter requires Java 17. Supported deployment scenarios Following deployment scenario is supported by CIB seven: executable JAR with embedded Tomcat and one embedded process engine (plus Webapps when needed) There are other possible variations that might also work, but are not tested by our team at the moment.",
    "url": "/manual/latest/user-guide/spring-boot-integration/index.html"
  },
  {
    "id": "manual/latest/user-guide/spring-boot-integration/process-applications/index.html",
    "title": "Process applications | docs.cibseven.org",
    "content": "By default, the cibseven-spring-boot-starter is configured to use the SpringProcessEngineConfiguration auto deployment feature. Since 1.2.0 you also have the possibility to do so via SpringBootProcessApplication. This disables the SpringProcessEngineConfiguration auto-deploy feature and instead uses the required META-INF/processes.xml as an indicator for resource scanning. This also allows all processes.xml configuration features described here. To use it, just add the @EnableProcessApplication annotation to your Spring Boot application class: @SpringBootApplication @EnableProcessApplication(\"myProcessApplicationName\") public class MyApplication { ... } Some configuration can be done via Spring Boot configuration parameters. Check the list of currently available parameters. Using Deployment Callbacks As when using @EnableProcessApplication we don’t extend the ProcessApplication class, we can’t use @PostDeploy and @PreUndeploy method annotations. Instead these callbacks are provided via Spring event publishing mechanism. So you can use the following event listeners: @EventListener public void onPostDeploy(PostDeployEvent event) { ... } @EventListener public void onPreUndeploy(PreUndeployEvent event) { ... }",
    "url": "/manual/latest/user-guide/spring-boot-integration/process-applications/index.html"
  },
  {
    "id": "manual/latest/user-guide/spring-boot-integration/rest-api/index.html",
    "title": "REST API | docs.cibseven.org",
    "content": "To enable the REST API you can use the following starter in your pom.xml: <dependency> <groupId>org.cibseven.bpm.springboot</groupId> <artifactId>cibseven-bpm-spring-boot-starter-rest</artifactId> <version>1.1.0</version> </dependency> By default the application path is engine-rest, so without any further configuration you can access the api at http://localhost:8080/engine-rest. Because we use jersey, one can use spring boot’s common application properties. For example, to change the application path, use spring.jersey.application-path=myapplicationpath To modify the configuration or register additional resources, one can provide a bean which extends from org.cibseven.bpm.spring.boot.starter.rest.CamundaJerseyResourceConfig: @Component @ApplicationPath(\"/engine-rest\") public class JerseyConfig extends CamundaJerseyResourceConfig { @Override protected void registerAdditionalResources() { register(...); } }",
    "url": "/manual/latest/user-guide/spring-boot-integration/rest-api/index.html"
  },
  {
    "id": "manual/latest/user-guide/spring-boot-integration/spring-security/index.html",
    "title": "Spring Security OAuth2 Integration | docs.cibseven.org",
    "content": "CIB seven provides Spring Security OAuth2 integration with the cibseven-bpm-spring-boot-starter-security library. This library contains the Spring Security and Spring Security OAuth2 dependencies along with configuration classes that integrate Spring Security with CIB seven Webapp’s authentication. This is available both for Spring Boot and CIB seven. CIB seven’s integration comes with multiple components and configurations. In the next sections you can find more details to each of them. Activate OAuth2 Spring Boot In order to enable the Spring Security OAuth2 integration in Spring Boot, add the following dependency to your project: <dependency> <groupId>org.cibseven.bpm.springboot</groupId> <artifactId>cibseven-bpm-spring-boot-starter-security</artifactId> </dependency> CIB seven Run CIB seven Run already contains the required libraries, all you need to do is to activate them. In order to enable the Spring Security OAuth2 integration in CIB seven Run, start Run with an extra --oauth2 argument: ./start.sh --webapps --rest --oauth2 Auto Configuration The CIB seven integration has two default auto configurations. Depending on the OAuth2 client registration in the application properties (spring.security.oauth2.client.registration) either the CamundaSpringSecurityOAuth2AutoConfiguration or the CamundaBpmSpringSecurityDisableAutoConfiguration will be activated. OAuth2 Enabled Configuration Configuration activates if there is OAuth2 client registration configured. This class configures the Spring Security filter chain to secure the CIB seven Webapps. Spring auto configuration class: CamundaSpringSecurityOAuth2AutoConfiguration Spring Security Disabled Auto Configuration Configuration activates if there is no OAuth2 client registration configured. This class configures the Spring Security filter chain to a permit all mode. Spring auto configuration class: CamundaBpmSpringSecurityDisableAutoConfiguration OAuth2 Client Registration For the client registration, please refer to the official Spring Security’s OAuth2 Core Configuration documentation to configure your choice of identity provider. Once there is an OAuth2 client registration configured and the CIB seven Spring Security OAuth2 integration is enabled, the Webapps will use the configured OAuth2 provider for authentication. User Name Mapping CIB seven’s integration uses the name field from Spring Security’s principal object as the User ID in the Webapps. Spring Security by default uses the subject (sub) claim as the principal name. As the User ID in CIB seven is an important part for authorizations, it’s important that the right claim is used. Spring Security provides a way to change the default attribute used for the username. This is the spring.security.oauth2.client.provider.[providerId].user-name-attribute from the above-mentioned OAuth2 Core Configuration. Heads Up! Make sure to correctly configure which token attribute should be used as the User ID. Configuring Initial Authorizations For creating initial authorizations in your application, you have the following options available: The camunda.bpm.admin-user property to create an administrator user with authorizations: camunda.bpm: admin-user: id: demo password: demo firstName: Demo lastName: Demo See CIB seven Engine Properties documentation for more details. The Administrator Authorization Plugin to grant administrator authorizations for a particular OAuth2 user or group. OAuth2 Identity Provider Additionally to the OAuth2 login, CIB seven also provides support to use groups from OAuth2. This is achieved with a custom identity service, called OAuth2IdentityProvider . This is a read-only identity provider that configures user’s groups from the Spring Security’s granted authorities. This identity provider also supports the default CIB seven Database Identity Service as a fallback for authentications for the REST API. The identity provider is activated by default. You can override this with the following properties: camunda.bpm.oauth2: identity-provider: enabled: false See Configuration section for more information. Granted Authorities Mapper We also provide a default granted authorities mapper, that can override the Spring Security authorities, that are by default populated with the scope (scp) claim. This mapper can be enabled with the group-name-attribute property: camunda.bpm.oauth2: identity-provider: enabled: true group-name-attribute: cognito:groups The mapper is only activated if the property is configured. It supports claims with types of collection of Strings and String. If the claim is a String, it will try to split it with a delimiter which is comma by default. You can override the default delimiter with the group-name-delimiter property. See Configuration section for more information. Custom Granted Authorities Mapper Alternatively, you can also define your own GrantedAuthoritiesMapper, if you need more customization. In Spring Boot this can be done by registering your own GrantedAuthoritiesMapper bean. In CIB seven Run a JAR file needs to be built and copied into the userlib folder. This needs to contain a Spring auto configuration with the custom granted authorities mapper bean. Configuration All configuration properties of the identity provider start with the prefix camunda.bpm.oauth2.identity-provider. The following properties are available: Property name Description Default value enabled Enables the OAuth2 identity provider. Enabled by default! true group-name-attribute Enables and configures the OAuth2 Granted Authorities Mapper. - group-name-delimiter Configures the delimiter used in the OAuth2 Granted Authorities Mapper. It's only used if the configured group-name-attribute contains String value. , (comma) Limitations As previously mentioned, this provider is a read-only provider, so creating users, groups or memberships is not available. Due to the fallback to DB Identity Service this provider is still defined as writeable which means the create buttons are still visible on the Admin pages, but are non-functional. OAuth2 doesn’t return information about other users or groups. This means users and even admins can only see their own user and groups on the Admin pages. Furthermore, it only shows groups from OAuth2 and doesn’t show groups configured in CIB seven database. Disabling Identity Provider With the above-mentioned property, the identity provider can be deactivated. Without identity provider OAuth2 is only used for authentication. This means, that the user needs to be also configured with the matching User ID in CIB seven database. If the user is not available or doesn’t have sufficient authorizations, they won’t be able to access the Webapps. Logout We provide support for local and client initiated SSO logout as well. In order to support both logouts, the CIB seven integration also contains a Frontend Plugin that overrides the Webapps default logout behaviour. As a consequence, when the Webapp user clicks on the logout, it invokes Spring’s logout endpoint (/logout) instead of CIB seven. Client Initiated SSO Logout We support client initiated OIDC SSO logout. Please refer Spring’s OpenID Connect 1.0 Client-Initiated Logout section for more information. In order to configure this feature, use the following properties: camunda.bpm.oauth2: sso-logout: enabled: true postLogoutRedirectUri: https://example.org/ Configuration All configuration properties of the identity provider start with the prefix camunda.bpm.oauth2.sso-logout. The following properties are available: Property name Description Default value enabled Activates the client initiated OIDC logout feature. false post-logout-redirect-uri Configures the URI the user is redirected after SSO logout from the provider. {baseUrl} Limitations Currently, it’s not possible to change the default Spring logout endpoint, which is /logout. Security Recommendations CIB seven’s integration heavily relies on Spring Security’s OAuth2 support. If you decide to use OAuth2 for login in CIB seven, we highly recommend to consult and implement the current industry recommended security standards. Additionally, also follow the security recommendations specified by your identity provider. Token Lifetime As OAuth2 works with the exchange of tokens and tokens are valid until the specified expiration (exp), it is inevitable that in a few cases tokens might outlive the main SSO session. Meaning, the user might be already logged out but still have valid tokens on other pages. In order to minimize the risk of this, we recommend the use of short-lived access tokens along with refresh tokens. Refresh tokens can be revoked, and issuing new access tokens require interaction with the provider, which means the user session can be revalidated more frequently. Logging You can switch the level of the following logger to track bean registrations, user authentication or logout, and token authorizations. Logging can be enabled for the package via the following property: logging: level: org.cibseven.bpm.spring.boot.starter.security.oauth2: DEBUG Example In this section we provide an example configuration with OKTA as OIDC provider. Additionally, we also mark and explain a few lines: camunda.bpm.oauth2: sso-logout: # 1 enabled: true postLogoutRedirectUri: https://example.org/ identity-provider: group-name-attribute: okta-groups # 2 spring.security: # 3 oauth2: client: registration: okta: clientId: <clientId> clientSecret: <clientSecret> scope: openid,profile,email,offline_access # 4 provider: okta: issuerUri: <issuerUri> user-name-attribute: preferred_username # 5 Client initiated SSO activated, redirect uri overridden. Identity provider groups loaded from custom okta-groups claim. This also needs to be configured on the provider page in order for the id token to contain the claim. Uses the traditional Spring Security properties. Alternatively, okta-spring-security-oauth2 library and its properties could be used too. Defines the openid,profile,email,offline_access scopes. Scopes are provider dependent. openid is required usually. In case of OKTA, profile and email are useful to access firstname, lastname and email in CIB seven but not mandatory. offline_access activates the refresh_token grant, not mandatory. Configures the preferred_username as the username attribute, which is also used as the CIB seven User ID. Disable Auto Configuration If you wish to use Spring Security but without CIB seven’s integration classes, you can do so by excluding the two auto configuration classes: Either with the @EnableAutoConfiguration annotation: @EnableAutoConfiguration(exclude={ CamundaSpringSecurityOAuth2AutoConfiguration.class, CamundaBpmSpringSecurityDisableAutoConfiguration.class }); Or in the application properties: spring: autoconfigure: exclude: - org.cibseven.bpm.spring.boot.starter.security.oauth2.CamundaSpringSecurityOAuth2AutoConfiguration - org.cibseven.bpm.spring.boot.starter.security.oauth2.CamundaBpmSpringSecurityDisableAutoConfiguration For more information, please refer to Spring’s Disabling Specific Auto-configuration Classes documentation.",
    "url": "/manual/latest/user-guide/spring-boot-integration/spring-security/index.html"
  },
  {
    "id": "manual/latest/user-guide/spring-boot-integration/the-spring-event-bridge/index.html",
    "title": "Spring Eventing Bridge | docs.cibseven.org",
    "content": "The process engine can be hooked-up to the Spring event bus. We call this the “Spring Eventing Bridge”. This allows us to be notified of process events using standard Spring eventing mechanisms. By default, the Spring eventing is enabled by a engine plugin. The eventing is controlled by four camunda.bpm.eventing properties. These are: camunda.bpm.eventing.execution=true camunda.bpm.eventing.history=true camunda.bpm.eventing.task=true camunda.bpm.eventing.skippable=true The first three properties control three event streams for execution, task and history events respectively. The last property camunda.bpm.eventing.skippable is responsible for the registration of the event listeners. If its value is true, the execution of the listners can be skipped via API or in Camunda Cockpit by activating “skip listners” flag. Otherwise, the listeners are registered as built-in listeners and are executed unconditionally. Listeners can subscribe to streams of mutable or immutable event objects. The latter of those are particularly useful in asynchronous listener scenarios - e.g. when using TransactionalEventListener. The mutable event stream objects can be modified multiple times between the creation and the reception of the event the listener has asynchronously subscribed to. Immutable event objects reflect the data at the creation time of the event, regardless of the time they are finally received by the listener. On the execution event stream, DelegateExecutions (mutable) and ExecutionEvents (immutable) can be received. The task event stream offers DelegateTasks (mutable) and TaskEvents (immutable). On the history event stream, only HistoryEvents (mutable) are published. The following example gives an overview of how process events can be received in Spring beans. In doing so, you can implement task and delegate listeners by providing Spring beans with annotated methods instead of implementing the TaskListener and ExecutionListener interfaces. import org.cibseven.bpm.engine.delegate.DelegateExecution; import org.cibseven.bpm.engine.delegate.DelegateTask; import org.cibseven.bpm.engine.impl.history.event.HistoryEvent; import org.springframework.context.event.EventListener; import org.springframework.stereotype.Component; @Component class MyListener { @EventListener public void onTaskEvent(DelegateTask taskDelegate) { // handle mutable task event } @EventListener public void onTaskEvent(TaskEvent taskEvent) { // handle immutable task event } @EventListener public void onExecutionEvent(DelegateExecution executionDelegate) { // handle mutable execution event } @EventListener public void onExecutionEvent(ExecutionEvent executionEvent) { // handle immutable execution event } @EventListener public void onHistoryEvent(HistoryEvent historyEvent) { // handle history event } } If the method, annotated with EventListener returns a non-void result, Spring will throw it as a new event on Spring event bus. This allows to build event handler chains for processing. For more information on eventing, please consult the Spring manual. Specifying event type Spring allows to specify the event delivered to the listener by providing a SpEL condition in the @EventListener annotation. For example, you could register a listener for a task event fired by creating of the user task with a specific task definition key. Here is the code example: @Component class MyTaskListener { @EventListener(condition=\"#taskDelegate.eventName=='create' && #taskDelegate.taskDefinitionKey=='task_confirm'\") public void onTaskEvent(DelegateTask taskDelegate) { // handle task event fired by create of task_confirm task } } Ordering event listeners Event listeners for the same event type can be executed in a specified order. To do so, provide an Order annotation to the event listener: @Component class MyTaskListener { @Order(1) @EventListener public void firstListener(DelegateTask taskDelegate) { // handle task event } @Order(2) @EventListener public void secondListener(DelegateTask taskDelegate) { // handle task event } }",
    "url": "/manual/latest/user-guide/spring-boot-integration/the-spring-event-bridge/index.html"
  },
  {
    "id": "manual/latest/user-guide/spring-boot-integration/version-compatibility/index.html",
    "title": "Spring Boot Version Compatibility | docs.cibseven.org",
    "content": "Each version of the Spring Boot Starter is bound to a specific version of CIB seven and Spring Boot. Only these default combinations are recommended (and supported) by CIB. Other combinations must be thoroughly tested before being used in production. Spring Boot Starter version CIB seven version Spring Boot version 7.22.0-cibseven 1.0 3.3.x (*) 1.1 1.1 3.3.x * For these versions, use the following Maven coordinates: <dependency> <groupId>org.camunda.bpm.springboot</groupId> <artifactId>camunda-bpm-spring-boot-starter-webapp</artifactId> <version>7.22.0-cibseven</version> <!-- set correct version here --> </dependency> Do not forget, that extra repository should be added to settings.xml or to the POM file, since CIB seven is available yet only at artifacts.cibseven.org. <repositories> <repository> <id>mvn-cibseven-public</id> <name>CIB seven Public Repository</name> <url>https://artifacts.cibseven.org/repository/public/</url> </repository> </repositories> Since version 1.1.0 CIB seven is availabale in Maven Central repositories. No extra repository tweaks are required. However you can still use https://artifacts.cibseven.org/ for fetching CIB seven artifacts.",
    "url": "/manual/latest/user-guide/spring-boot-integration/version-compatibility/index.html"
  },
  {
    "id": "manual/latest/user-guide/spring-boot-integration/webapps/index.html",
    "title": "Web applications | docs.cibseven.org",
    "content": "To enable the Web Applications you can use the following starter in your pom.xml: <dependency> <groupId>org.cibseven.bpm.springboot</groupId> <artifactId>cibseven-bpm-spring-boot-starter-webapp</artifactId> <version>1.1.0</version> </dependency> By default the application path is /camunda, so without any further configuration you can access the Webapps under http://localhost:8080/camunda/app/. Configurations You can change the application path with the following configuration property in your application.yaml file: camunda.bpm.webapp.application-path=/my/application/path By default, the starter registers a controller to redirect / to Camunda’s bundled index.html. To disable this, you have to add to your application properties: camunda.bpm.webapp.index-redirect-enabled=false Error Pages The default error handling coming with the Spring Boot (‘whitelabel’ error page) is enabled in the starter. To switch to the Camunda error pages (webjar/META-INF/resources/webjars/camunda/error-XYZ-page.html), please put them to the application folder structure under /src/main/resources/public/error/XYZ.html. Building Custom REST APIs The Camunda Web Applications use a CSRF Prevention Filter that expects a CSRF Token on any modifying request for paths beginning with /camunda/api/ or /camunda/app/. Any modifying requests mapped to these paths will fail, and the current session will be ended if no CSRF Token is present. You can avoid this by registering your resources on different paths or add your resources to the CSRF Prevention Filter Whitelist (via the configuration property camunda.bpm.webapp.csrf.entry-points).",
    "url": "/manual/latest/user-guide/spring-boot-integration/webapps/index.html"
  },
  {
    "id": "manual/latest/user-guide/spring-framework-integration/configuration/index.html",
    "title": "Process Engine Configuration | docs.cibseven.org",
    "content": "You can use a Spring application context XML file to bootstrap the process engine. It is possible to bootstrap both application-managed and container-managed process engines through Spring. Note that you can also use a Spring JavaConfig for bootstrapping instead of XML. Configure an Application-Managed Process Engine The ProcessEngine can be configured as a regular Spring bean. The starting point of the integration is the class org.cibseven.bpm.engine.spring.ProcessEngineFactoryBean. That bean takes a process engine configuration and creates the process engine. This means that the creation and configuration of properties for Spring is the same as documented in the configuration section. For Spring integration the configuration and engine beans will look like this: <bean id=\"processEngineConfiguration\" class=\"org.cibseven.bpm.engine.spring.SpringProcessEngineConfiguration\"> ... </bean> <bean id=\"processEngine\" class=\"org.cibseven.bpm.engine.spring.ProcessEngineFactoryBean\"> <property name=\"processEngineConfiguration\" ref=\"processEngineConfiguration\" /> </bean> Note that the processEngineConfiguration bean uses the SpringProcessEngineConfiguration class. Configure a Container-Managed Process Engine as a Spring Bean If you want the process engine to be registered with the CIB seven ProcessEngineService, you must use org.cibseven.bpm.engine.spring.container.ManagedProcessEngineFactoryBean instead of the ProcessEngineFactoryBean shown in the example above. You will also need to ensure: That none of your webapps include cibseven-webapp*.jar within their own lib folder, this should be at a shared level. That your server.xml contains JNDI entries for the ‘ProcessEngineService’ and ‘ProcessApplicationService’ as below: <!-- Global JNDI resources Documentation at /docs/jndi-resources-howto.html --> <GlobalNamingResources> <Resource name=\"java:global/camunda-bpm-platform/process-engine/ProcessEngineService!org.cibseven.bpm.ProcessEngineService\" auth=\"Container\" type=\"org.cibseven.bpm.ProcessEngineService\" description=\"CIB seven Platform Process Engine Service\" factory=\"org.cibseven.bpm.container.impl.jndi.ProcessEngineServiceObjectFactory\" /> <Resource name=\"java:global/camunda-bpm-platform/process-engine/ProcessApplicationService!org.cibseven.bpm.ProcessApplicationService\" auth=\"Container\" type=\"org.cibseven.bpm.ProcessApplicationService\" description=\"CIB seven Platform Process Application Service\" factory=\"org.cibseven.bpm.container.impl.jndi.ProcessApplicationServiceObjectFactory\" /> ... </GlobalNamingResources> In that case the constructed process engine object is registered with CIB seven and can be referenced for creating process application deployments and exposed through the runtime container integration. Configure a Process Engine Plugin In Spring you can configure a process engine plugin by setting a list value to the processEnginePlugins property of the processEngineConfiguration bean: <bean id=\"processEngineConfiguration\" class=\"org.cibseven.bpm.engine.spring.SpringProcessEngineConfiguration\"> ... <property name=\"processEnginePlugins\"> <list> <bean id=\"spinPlugin\" class=\"org.cibseven.spin.plugin.impl.SpinProcessEnginePlugin\" /> </list> </property> </bean> Using Spring JavaConfig In addition to the Spring application context XML file, you can bootstrap the process engine using Spring JavaConfig. The configuration class can look like this: @Configuration public class ExampleProcessEngineConfiguration { @Bean public DataSource dataSource() { // Use a JNDI data source or read the properties from // env or a properties file. // Note: The following shows only a simple data source // for In-Memory H2 database. SimpleDriverDataSource dataSource = new SimpleDriverDataSource(); dataSource.setDriverClass(org.h2.Driver.class); dataSource.setUrl(\"jdbc:h2:mem:camunda;DB_CLOSE_DELAY=-1\"); dataSource.setUsername(\"sa\"); dataSource.setPassword(\"\"); return dataSource; } @Bean public PlatformTransactionManager transactionManager() { return new DataSourceTransactionManager(dataSource()); } @Bean public SpringProcessEngineConfiguration processEngineConfiguration() { SpringProcessEngineConfiguration config = new SpringProcessEngineConfiguration(); config.setDataSource(dataSource()); config.setTransactionManager(transactionManager()); config.setDatabaseSchemaUpdate(\"true\"); config.setHistory(\"audit\"); config.setJobExecutorActivate(true); return config; } @Bean public ProcessEngineFactoryBean processEngine() { ProcessEngineFactoryBean factoryBean = new ProcessEngineFactoryBean(); factoryBean.setProcessEngineConfiguration(processEngineConfiguration()); return factoryBean; } @Bean public RepositoryService repositoryService(ProcessEngine processEngine) { return processEngine.getRepositoryService(); } @Bean public RuntimeService runtimeService(ProcessEngine processEngine) { return processEngine.getRuntimeService(); } @Bean public TaskService taskService(ProcessEngine processEngine) { return processEngine.getTaskService(); } // more engine services and additional beans ... } Note that you can define your custom beans in the configuration class, in combination with an additional XML file or using component scan. The following example adds a component scan to the configuration class to detect and instantiate all beans in the package “com.example”. @Configuration @ComponentScan(\"com.example\") public class ExampleProcessEngineConfiguration { // ... }",
    "url": "/manual/latest/user-guide/spring-framework-integration/configuration/index.html"
  },
  {
    "id": "manual/latest/user-guide/spring-framework-integration/deployment/index.html",
    "title": "Automatic Resource Deployment | docs.cibseven.org",
    "content": "Spring integration also has a special feature for deploying resources. In the process engine configuration, you can specify a set of resources. When the process engine is created, all those resources will be scanned and deployed. There is filtering in place that prevents duplicate deployments. Only in case the resources have actually changed, new deployments will be deployed to the engine database. This makes sense in a lot of use cases, where the Spring container is rebooted often (e.g., testing). Here’s an example: <bean id=\"processEngineConfiguration\" class=\"org.cibseven.bpm.engine.spring.SpringProcessEngineConfiguration\"> ... <property name=\"deploymentResources\" value=\"classpath*:/mytest/autodeploy.*.bpmn20\" /> <property name=\"deploymentResources\"> <list> <value>classpath*:/mytest/autodeploy.*.bpmn20</value> <value>classpath*:/mytest/autodeploy.*.png</value> </list> </property> </bean> <bean id=\"processEngine\" class=\"org.cibseven.bpm.engine.spring.ProcessEngineFactoryBean\"> <property name=\"processEngineConfiguration\" ref=\"processEngineConfiguration\" /> </bean>",
    "url": "/manual/latest/user-guide/spring-framework-integration/deployment/index.html"
  },
  {
    "id": "manual/latest/user-guide/spring-framework-integration/expressions/index.html",
    "title": "Spring Beans in Processes | docs.cibseven.org",
    "content": "Limit the exposed Spring Beans When using the ProcessEngineFactoryBean, by default, all expressions and scripts in the BPMN processes will also “see” all the Spring beans. It’s possible to limit the beans you want to expose or even expose no beans at all using a map that you can configure. The example below exposes a single bean (printer), available to use under the key printer. To expose NO beans at all, pass an empty map as beans property on the SpringProcessEngineConfiguration. When no beans property is set, all Spring beans in the context will be available. <bean id=\"processEngineConfiguration\" class=\"org.cibseven.bpm.engine.spring.SpringProcessEngineConfiguration\"> ... <property name=\"beans\"> <map> <entry key=\"printer\" value-ref=\"printer\" /> </map> </property> </bean> <bean id=\"printer\" class=\"org.cibseven.bpm.engine.spring.test.transaction.Printer\" /> Using Spring Beans in expressions The exposed beans can be used in expressions. For example, the SpringTransactionIntegrationTest testBasicActivitiSpringIntegration.bpmn20.xml shows how a method on a Spring bean can be invoked using a UEL method expression: <definitions id=\"definitions\" ...> <process id=\"helloProcess\" isExecutable=\"true\"> <startEvent id=\"start\" /> <sequenceFlow id=\"flow1\" sourceRef=\"start\" targetRef=\"print\" /> <serviceTask id=\"print\" camunda:expression=\"#{printer.printMessage(execution)}\" /> <sequenceFlow id=\"flow2\" sourceRef=\"print\" targetRef=\"userTask\" /> <userTask id=\"userTask\" /> <sequenceFlow id=\"flow3\" sourceRef=\"userTask\" targetRef=\"end\" /> <endEvent id=\"end\" /> </process> </definitions> Where Printer looks like this: public class Printer { public void printMessage(ActivityExecution execution) { execution.setVariable(\"myVar\", \"Hello from Printer!\"); } } And the Spring bean configuration (also shown above) looks like this: <beans ...> ... <bean id=\"printer\" class=\"org.cibseven.bpm.engine.spring.test.transaction.Printer\" /> </beans> Expression resolving with the shared process engine In a shared process engine deployment scenario, you have a process engine which dispatches to multiple applications. In this case, there is not a single Spring application context but each application may maintain its own application context. The process engine cannot use a single expression resolver for a single application context but must delegate to the appropriate process application, depending on which process is currently being executed. This functionality is provided by the org.cibseven.bpm.engine.spring.application.SpringProcessApplicationElResolver. This class is a ProcessApplicationElResolver implementation delegating to the local application context. Expression resolving then works in the following way: The shared process engine checks which process application corresponds to the process it is currently executing. It then delegates to that process application for resolving expressions. The process application delegates to the SpringProcessApplicationElResolver which uses the local Spring application context for resolving beans. The SpringProcessApplicationElResolver class is automatically detected if the cibseven-engine-spring module is included as a library of the process application, not as a global library. Using Spring Beans in scripting When using ProcessEngineFactoryBean, all Spring beans are accessible in Groovy, JavaScript, and Jython. For example, the ScriptTaskTest-applicationContext.xml exposes the bean ’testbean': <beans ...> ... <bean id=\"testbean\" class=\"org.cibseven.bpm.engine.spring.test.scripttask.Testbean\" /> </beans> Where Testbean looks like this: @Component public class Testbean { private String name = \"name property of testbean\"; public String getName() { return name; } } Testbean is referenced then form JavaScript: execution.setVariable('foo', testbean.name);",
    "url": "/manual/latest/user-guide/spring-framework-integration/expressions/index.html"
  },
  {
    "id": "manual/latest/user-guide/spring-framework-integration/index.html",
    "title": "Spring Framework Integration | docs.cibseven.org",
    "content": "The CIB seven Spring Framework integration is located inside a maven module and can be added to apache maven-based projects through the following dependency: Please import the CIB seven BOM to ensure correct versions for every CIB seven project. cibseven-engine-spring maven module for Spring Framework 5 <dependency> <groupId>org.cibseven.bpm</groupId> <artifactId>cibseven-engine-spring</artifactId> </dependency> cibseven-engine-spring-6 maven module for Spring Framework 6. <dependency> <groupId>org.cibseven.bpm</groupId> <artifactId>cibseven-engine-spring-6</artifactId> </dependency> The process engine Spring artifact should be added as a library to the process application. The following minimal set of Spring dependencies must be added in the desired version: <properties> <spring.version>X.Y.Z.RELEASE</spring.version> </properties> <dependencyManagement> <dependencies> <dependency> <groupId>org.springframework</groupId> <artifactId>spring-framework-bom</artifactId> <version>${spring.version}</version> <type>pom</type> <scope>import</scope> </dependency> </dependencies> </dependencyManagement> <dependencies> <dependency> <groupId>org.springframework</groupId> <artifactId>spring-context</artifactId> </dependency> <dependency> <groupId>org.springframework</groupId> <artifactId>spring-jdbc</artifactId> </dependency> <dependency> <groupId>org.springframework</groupId> <artifactId>spring-tx</artifactId> </dependency> <dependency> <groupId>org.springframework</groupId> <artifactId>spring-orm</artifactId> </dependency> </dependencies>",
    "url": "/manual/latest/user-guide/spring-framework-integration/index.html"
  },
  {
    "id": "manual/latest/user-guide/spring-framework-integration/testing/index.html",
    "title": "Spring-Based Testing | docs.cibseven.org",
    "content": "When integrating with Spring, business processes can be tested very easily (in scope 2, see Testing Scopes) using the standard Camunda testing facilities. The following example shows how a business process is tested in a typical Spring-based unit test: @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(\"classpath:org/cibseven/bpm/engine/spring/test/junit4/springTypicalUsageTest-context.xml\") public class MyBusinessProcessTest { @Autowired private RuntimeService runtimeService; @Autowired private TaskService taskService; @Autowired @Rule public ProcessEngineRule processEngineRule; @Test @Deployment public void simpleProcessTest() { runtimeService.startProcessInstanceByKey(\"simpleProcess\"); Task task = taskService.createTaskQuery().singleResult(); assertEquals(\"My Task\", task.getName()); taskService.complete(task.getId()); assertEquals(0, runtimeService.createProcessInstanceQuery().count()); } } Note that for this to work, you need to define a ProcessEngineRule bean in the Spring configuration (which is injected by auto-wiring in the example above). <bean id=\"processEngineRule\" class=\"org.cibseven.bpm.engine.test.ProcessEngineRule\"> <property name=\"processEngine\" ref=\"processEngine\" /> </bean>",
    "url": "/manual/latest/user-guide/spring-framework-integration/testing/index.html"
  },
  {
    "id": "manual/latest/user-guide/spring-framework-integration/transactions/index.html",
    "title": "Spring Transaction Integration | docs.cibseven.org",
    "content": "Transaction Integration by Example The following explains the SpringTransactionIntegrationTest of the core codebase step by step. Below is the Spring configuration file that we use in this example (you can find it in SpringTransactionIntegrationTest-context.xml). The section shown below contains the dataSource, transactionManager, processEngine and the process engine services. When passing the DataSource to the SpringProcessEngineConfiguration (using property “dataSource”), the CIB seven engine uses a org.springframework.jdbc.datasource.TransactionAwareDataSourceProxy internally, which wraps the passed DataSource. This is done to make sure the SQL connections retrieved from the DataSource and the Spring transactions play well together. This implies that it’s no longer needed to proxy the dataSource yourself in Spring configuration, although it’s still allowed to pass a TransactionAwareDataSourceProxy into the SpringProcessEngineConfiguration. In this case no additional wrapping will occur. Make sure when declaring a TransactionAwareDataSourceProxy in Spring configuration yourself, that you don’t use it for resources that are already aware of Spring-transactions (e.g., DataSourceTransactionManager and JPATransactionManager need the un-proxied dataSource). <beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-2.5.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.0.xsd\"> <bean id=\"dataSource\" class=\"org.springframework.jdbc.datasource.SimpleDriverDataSource\"> <property name=\"driverClass\" value=\"org.h2.Driver\" /> <property name=\"url\" value=\"jdbc:h2:mem:camunda;DB_CLOSE_DELAY=1000\" /> <property name=\"username\" value=\"sa\" /> <property name=\"password\" value=\"\" /> </bean> <bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"> <property name=\"dataSource\" ref=\"dataSource\" /> </bean> <bean id=\"processEngineConfiguration\" class=\"org.cibseven.bpm.engine.spring.SpringProcessEngineConfiguration\"> <property name=\"dataSource\" ref=\"dataSource\" /> <property name=\"transactionManager\" ref=\"transactionManager\" /> <property name=\"databaseSchemaUpdate\" value=\"true\" /> <property name=\"jobExecutorActivate\" value=\"false\" /> </bean> <bean id=\"processEngine\" class=\"org.cibseven.bpm.engine.spring.ProcessEngineFactoryBean\"> <property name=\"processEngineConfiguration\" ref=\"processEngineConfiguration\" /> </bean> <bean id=\"repositoryService\" factory-bean=\"processEngine\" factory-method=\"getRepositoryService\" /> <bean id=\"runtimeService\" factory-bean=\"processEngine\" factory-method=\"getRuntimeService\" /> <bean id=\"taskService\" factory-bean=\"processEngine\" factory-method=\"getTaskService\" /> <bean id=\"historyService\" factory-bean=\"processEngine\" factory-method=\"getHistoryService\" /> <bean id=\"managementService\" factory-bean=\"processEngine\" factory-method=\"getManagementService\" /> ... </beans> The processEngineConfiguration attributes transactionManager and dataSource must be configured consistently, i.e. the transactionManager bean must actually manage the data source. If that is not the case, the process engine will use auto-commit mode for the data source connection, potentially leading to inconsistencies in the database. The remainder of that Spring configuration file contains the beans and configuration that we’ll use in this particular example: <beans> ... <tx:annotation-driven transaction-manager=\"transactionManager\"/> <bean id=\"userBean\" class=\"org.cibseven.bpm.engine.spring.test.UserBean\"> <property name=\"runtimeService\" ref=\"runtimeService\" /> </bean> <bean id=\"printer\" class=\"org.cibseven.bpm.engine.spring.test.Printer\" /> </beans> First, the application context is created with any of the Spring ways to do that. In this example you could use a classpath XML resource to configure our Spring application context: ClassPathXmlApplicationContext applicationContext = new ClassPathXmlApplicationContext(\"mytest/SpringTransactionIntegrationTest-context.xml\"); or, since it is a test: @ContextConfiguration(\"classpath:mytest/SpringTransactionIntegrationTest-context.xml\") Then we can get the service beans and invoke methods on them. The ProcessEngineFactoryBean will have added an extra interceptor to the services that applies Propagation.REQUIRED transaction semantics on the engine service methods. So, for example, we can use the repositoryService to deploy a process like this: RepositoryService repositoryService = (RepositoryService) applicationContext.getBean(\"repositoryService\"); String deploymentId = repositoryService .createDeployment() .addClasspathResource(\"mytest/hello.bpmn20\") .addClasspathResource(\"mytest/hello.png\") .deploy() .getId(); The other way around also works. In this case, the Spring transaction will be around the userBean.hello() method and the engine service method invocation will join that same transaction. UserBean userBean = (UserBean) applicationContext.getBean(\"userBean\"); userBean.hello(); The UserBean looks like this. Remember from above in the Spring bean configuration we injected the repositoryService into the userBean. public class UserBean { // injected by Spring private RuntimeService runtimeService; @Transactional public void hello() { // here you can do transactional stuff in your domain model // and it will be combined in the same transaction as // the startProcessInstanceByKey to the RuntimeService runtimeService.startProcessInstanceByKey(\"helloProcess\"); } public void setRuntimeService(RuntimeService runtimeService) { this.runtimeService = runtimeService; } } Using Inner Spring Transactions When engine API calls are executed in the Spring context, Spring doesn’t make it transparent to the Process Engine when nested API calls need to be executed in a separate transaction (the Propagation.REQUIRES_NEW transaction behavior). This doesn’t play well with how the Process Engine Context is used to separate transaction data described in detail in Transactions and the Process Engine Context. Due to this, if the inner transaction fails, the changes made by the engine API calls are still committed to the CIB seven database. A solution for this is to explicitly declare to the Process Engine that a new Process Engine Context is to be created, where all the following Engine API calls will store their changes for the database. In case the inner transaction fails, the changes in this new Process Engine Context will be reverted. The Process Engine Context must be declared whenever a Spring Propagation.REQUIRES_NEW inner transaction is defined in an already running transaction. Example In the following code-snippet, we can see a Spring Propagation.REQUIRED transaction, defined on the execute method, and a Spring Propagation.REQUIRES_NEW transaction, defined on the InnerProcessServiceImpl#startInnerProcess method. The InnerProcessServiceImpl#startInnerProcess method is called through the execute method, resulting in an inner transaction.We can also assume that, in the startProcessInstanceByKey engine API call, some custom code continues to execute in the inner transaction, and throws an exception. @Transactional(value = \"transactionManager\", propagation = Propagation.REQUIRED) public void execute(DelegateExecution execution) throws Exception { try { innerProcessService.startInnerProcess(execution); } catch (Exception ex) { // noop } } /* InnerProcessService implementation */ @Service public class InnerProcessServiceImpl implements InnerProcessService { @Override @Transactional(value = \"transactionManager\", propagation = Propagation.REQUIRES_NEW, rollbackFor = {Throwable.class}) public void startInnerProcess(DelegateExecution execution) { execution.getProcessEngineServices() .getRuntimeService() .startProcessInstanceByKey(\"EXAMPLE_PROCESS\"); // custom code continues } } In a case like this one, since Spring doesn’t make the Process Engine aware that the startProcessInstanceByKey engine API call is executed in a new, inner transaction, when the custom code fails, the Spring inner transaction will be rolled back, but the data from the started Process Instance data will be committed with the outer transaction. The described problem can be solved through the static methods of the org.cibseven.bpm.engine.context.ProcessEngineContext class. First, we call the ProcessEngineContext.requiresNew() method to declare that a new Context is required. Finally, we call the ProcessEngineContext.clear() method to clear the declaration for a new Process Engine Context. This is important since a new Process Engine Context will be declared for each following engine API call until the ProcessEngineContext#clear method is called. Using a try-finally block is recommended to ensure that the ProcessEngineContext static methods are called and cleared even in the presence of exceptions. Below, you can find the solution applied to the startProcessInstanceByKey engine API call of the example above: try { // declare new Process Engine Context ProcessEngineContext.requiresNew(); // call engine APIs execution.getProcessEngineServices() .getRuntimeService() .startProcessInstanceByKey(\"EXAMPLE_PROCESS\"); } finally { // clear declaration for new Process Engine Context ProcessEngineContext.clear(); }",
    "url": "/manual/latest/user-guide/spring-framework-integration/transactions/index.html"
  },
  {
    "id": "manual/latest/user-guide/task-forms/index.html",
    "title": "User Task Forms | docs.cibseven.org",
    "content": "There are different types of forms which are primarily used in Tasklist. To implement a task form in your application, you have to connect the form resource with the BPMN 2.0 element in your process diagram. Suitable BPMN 2.0 elements for calling tasks forms are the StartEvent and the UserTask. Forms are referenced using Form Keys or Form References and can either be embedded in Camunda Tasklist or handled by a custom application. Depending on your use-case, different Form Types can be used: Embedded Task Forms allow you to embed custom HTML and JavaScript forms into Tasklist. Camunda Forms offer visual editing of forms in the Camunda Modeler and can be used for less complex forms. Camunda Forms are the only form type that can be referenced either by Form Key or by Form Reference. External Task Forms can be used to link to custom applications. The Form will not be embedded in Tasklist. If no form key is present, a Generic Task Form will be shown. Form Key details Form keys that are used in Tasklist have the structure FORM-TYPE:LOCATION:FORM.NAME. Name Description FORM-TYPE Can be embedded or cibseven-forms depending on the form type. If no type is set, the form will be shown as an External Task Form. LOCATION Can be either deployment or app: deployment: The file is part of your deployment (e.g., by adding it to your process archive or by deploying from the Camunda Modeler), which means that it is stored in the Camunda database. It can then be loaded from there. Note that this allows versioning of your form alongside the process model. app: Add the file to your development project in a folder src/main/webapp/forms. The form file will be packaged into your deployment artifact (typically a WAR archive). During runtime it will be loaded from there. FORM.NAME The file name and path in the deployment, e.g. forms/startFrom.html To configure the form in your process, open the process with the Camunda Modeler and select the desired UserTask or StartEvent. Open the properties panel and enter the Form Key. The relevant XML tag looks like this: <userTask id=\"theTask\" camunda:formKey=\"camunda-forms:deployment:forms/userTask.form\" camunda:candidateUsers=\"John, Mary\" name=\"my Task\"> Embedded Task Forms Embedded task forms are HTML and JavaScript forms. We provide more information about the creation of embedded forms in our Embedded Task Forms Reference. To add an embedded form to your application, simply create an HTML file and refer to it from a UserTask or a StartEvent in your process model. For example, you can create a FORM_NAME.html file containing the relevant content for your form, e.g., a simple form with two input fields: <form role=\"form\" name=\"form\"> <div class=\"form-group\"> <label for=\"customerId-field\">Customer ID</label> <input required cam-variable-name=\"customerId\" cam-variable-type=\"String\" class=\"form-control\" /> </div> <div class=\"form-group\"> <label for=\"amount-field\">Amount</label> <input cam-variable-name=\"amount\" cam-variable-type=\"Double\" class=\"form-control\" /> </div> </form> The form key for this file could be embedded:deployment:FORM_NAME.html or embedded:app:forms/FORM_NAME.html. Camunda Forms Camunda Forms are created as separate files using the Camunda Modeler and can be deployed together with the process models. The form schema is stored in .form files. You can find out how to build Camunda Forms in the Camunda Modeler documentation or refer to the Camunda Forms Reference to explore all configuration options for form elements. Process variables are mapped to form fields where the field’s key matches the variable name. Process variables access Defining forms does not introduce any permissions on process variables. Users can still submit any variables via APIs for form completion like the Submit Task Form REST API. Forms can be used on top of the task completion API to render form fields and validate submitted values. Form Reference With Form References, Camunda Forms provide a flexible way of linking an element in a BPMN diagram to a form. To link a BPMN element (StartEvent or UserTask) to a Camunda Form, you have to specify the Id of the Camunda Form as the camunda:formRef attribute. Additionally, the camunda:formRefBinding attribute specifies which version of the Camunda Form to reference. Valid values are: deployment, which references the Camunda Form with the given key that was deployed with the same deployment as the referencing process. latest, which will refer to the latest deployed version of the Camunda Form. version, which allows you to specify a specific version to be referenced from the BPMN element with the camunda:formRefVersion attribute. <bpmn:userTask id=\"myUserTask\" camunda:formRef=\"formId\" camunda:formRefBinding=\"version\" camunda:formRefVersion=\"1\"> </bpmn:userTask> The attributes camunda:formRef and camunda:formRefVersion can be specified as an expression which will be evaluated on execution of the task or start event. <bpmn:userTask id=\"myUserTask\" camunda:formRef=\"${formId}\" camunda:formRefBinding=\"version\" camunda:formRefVersion=\"${formVersion}\"> </bpmn:userTask> Form Key Aa an alternative to formRef you can reference a Camunda Form file with a deployment or app form key: camunda-forms:deployment:FORM_NAME.form camunda-forms:app:forms/FORM_NAME.form To enter the formKey in the Modeler, you have to select Embedded or External Task Forms as Type in the dropdown. From the form developers point of view, formRef offers more flexibility than formKey as they can be deployed independently from the process model. Process Variable Binding To define a default value for a form field, a process variable with the same name as the form field key needs to be defined. Local variables (e.g. created by defining an Input Parameter for the User Task) take precedence over process variables. The submitted values of a form are returned as variables to the process engine: When a process variable with the same name as the form field key already existed, then its value will be overwritten by the form submission. When the User Task has an Input Parameter defined with the same name as the form field key, then this local variable will be used. In this case, an Output Parameter needs to be defined to map the local variable to a process variable for usage in other process elements. When no variable exists with the same name as the form field key, then a new process variable will be created and gets the value from the submission. Dynamic Components You can bind the available options of some component types (Select, Radio Buttons, Checklist, and Taglist) to a variable. Like this, Camunda Forms show available options dynamically based on process data (variables). To bind a variable to a dynamic component, define its name in Camunda Modeler’s form builder in the Properties Panel under Options Source -> Type -> Input Data -> Dynamic options -> Input values key for the respective component. Camunda Forms support the following variable types that can represent JSON: Json Object with the serializationDataFormat: application/json Camunda Forms store and retrieve user selections for each component in a variable whose name equals the component key. If a variable supposed to store the user selection for multi-select components (Checklist or Taglist) doesn’t exist yet, a new one is created on form submission with the same type as the variable that defines the available options. The format to define available options looks as follows: [ { \"label\": \"Dynamic Value 1\", \"value\": \"dynamicValue1\" }, { \"label\": \"Dynamic Value 2\", \"value\": \"dynamicValue2\" } ] If you are about to prototype your application, you can also use the shortcut format: [\"Dynamic Value 2\", \"Dynamic Value 2\"] Deployment If you want to include your CIB seven Form as part of the deployment, then you need to deploy the .form file in the same deployment as the respective .bpmn diagram - for example using the Camunda Modeler (since Modeler Version 5.0.0). Automatic deployment CIB seven Forms are not automatically deployed as part of a process archive by default. You need to configure it accordingly by adding it as a resource directly or by adding form to the list of additionalResourceSuffixes. Using CIB seven Run, all additional resources - including CIB seven Forms - placed inside the configuration/resources/ directory are automatically deployed. You can also include CIB seven Forms from other deployments by using form references. External Task Forms Using Task Forms outside of CIB seven Tasklist When embedding the process engine into a custom application, you can use any value in the form key property as a reference to your custom form. This way, your front-end can ensure to render the correct form for each user task. If you want to call a task form that is not part of your application, you can add a reference to the desired form. The referenced task form will be configured in a way similar to the embedded task form. Open the properties view and enter FORM_NAME.html as form key. The relevant XML tag looks like this: <userTask id=\"theTask\" camunda:formKey=\"app:FORM_NAME.html\" camunda:candidateUsers=\"John, Mary\" name=\"my Task\"> Tasklist creates the URL by the pattern: \"../..\" + contextPath (of process application) + \"/\" + \"app\" + formKey (from BPMN 2.0 XML) + \"processDefinitionKey=\" + processDefinitionKey + \"&callbackUrl=\" + callbackUrl; When you have completed the task, the call back URL will be called. How To How to add JSF Forms to your process application Other Task Forms These Task forms do not use the form-key attribute to be referenced. They are not recommended for production use and are intended for testing and development purposes. Generic Task Forms The generic form will be used whenever you have not added a dedicated form for a UserTask or a StartEvent. Hit the Add a variable button to add a variable that will be passed to the process instance upon task completion. State a variable name, select the type and enter the desired value. Enter as many variables as you need. After hitting the Complete button, the process instance contains the entered values. Generic task forms can be very helpful during the development stage, so you do not need to implement all task forms before you can run a workflow. For debugging and testing this concept has many benefits as well. You can also retrieve already existing variables of the process instance by clicking the Load Variables button. Generated Task Forms CIB seven Forms or Generated Task Forms? The feature set of CIB seven Forms and Generated Task Forms are similar. For new projects, we recommend to use CIB seven Forms, as they offer more flexibility and are easier to create. The CIB seven process engine supports generating HTML task forms based on Form Data Metadata provided in the BPMN 2.0 XML. Form Data Metadata is a set of BPMN 2.0 vendor extensions provided by CIB seven, allowing you to define form fields directly in the BPMN 2.0 XML: <userTask id=\"usertask\" name=\"Task\"> <extensionElements> <camunda:formData> <camunda:formField id=\"firstname\" label=\"First Name\" type=\"string\"> <camunda:validation> <camunda:constraint name=\"maxlength\" config=\"25\" /> <camunda:constraint name=\"required\" /> </camunda:validation> </camunda:formField> <camunda:formField id=\"lastname\" label=\"Last Name\" type=\"string\"> <camunda:validation> <camunda:constraint name=\"maxlength\" config=\"25\" /> <camunda:constraint name=\"required\" /> </camunda:validation> </camunda:formField> <camunda:formField id=\"dateOfBirth\" label=\"Date of Birth\" type=\"date\" /> </camunda:formData> </extensionElements> </userTask> Form metadata can be graphically edited using the Camunda Modeler. This form would look like this in Tasklist: As you can see, the <camunda:formData ... /> element is provided as a child element of the BPMN <extensionElements> element. Form metadata consists of multiple form fields which represent individual input fields where a user has to provide some value or selection. A form data can have following attributes: AttributeExplanation businessKey Id of a form field that will be marked as cam-business-key Form Fields Process variables access Defining form fields does not introduce any permissions on process variables. Users can still submit any variables via APIs for form completion like the Submit Task Form REST API. Form fields can be used on top of the task completion API to render forms and validate submitted values. A form field can have the following attributes: AttributeExplanation idUnique id of the form field, corresponding to the name of the process variable to which the value of the form field is added when the form is submitted. labelThe label to be displayed next to the form field. type The data type of the form field. The following types are supported out of the box: string long date boolean enum defaultValueValue to be used as a default (pre-selection) for the field. Form Field Validation Validation can be used for specifying frontend and backend validation of form fields. CIB seven provides a set of built-in form field validators and an extension point for plugging in custom validators. Validation can be configured for each form field in the BPMN 2.0 XML: <camunda:formField id=\"firstname\" label=\"First Name\" type=\"string\"> <camunda:validation> <camunda:constraint name=\"maxlength\" config=\"25\" /> <camunda:constraint name=\"required\" /> </camunda:validation> </camunda:formField> As you can see, you can provide a list of validation constraints for each form field. The following built-in validators are supported out of the box: ValidatorExplanation required Applicable to all types. Validates that a value is provided for the form field. Rejects 'null' values and empty strings. <camunda:constraint name=\"required\" /> minlength Applicable to string fields. Validates the minimum length of text content. Accepts 'null' values. <camunda:constraint name=\"minlength\" config=\"4\" /> maxlength Applicable to string fields. Validates the maximum length of text content. Accepts 'null' values. <camunda:constraint name=\"maxlength\" config=\"25\" /> min Applicable to numeric fields. Validates the minimum value of a number. Accepts 'null' values. <camunda:constraint name=\"min\" config=\"1000\" /> max Applicable to numeric fields. Validates the maximum value of a number. Accepts 'null' values. <camunda:constraint name=\"max\" config=\"10000\" /> readonly Applicable to all types. Makes sure no input is submitted for the given form field. <camunda:constraint name=\"readonly\" /> CIB seven supports custom validators. Custom validators are referenced using their fully qualified classname or an expression. Expressions can be used for resolving Spring or CDI @Named beans: <camunda:formField id=\"firstname\" label=\"First Name\" type=\"string\"> <camunda:validation> <camunda:constraint name=\"validator\" config=\"com.asdf.MyCustomValidator\" /> <camunda:constraint name=\"validator\" config=\"${validatorBean}\" /> </camunda:validation> </camunda:formField> The name attribute must be set to “validator” in order to use custom form field validator. A custom validator implements the org.cibseven.bpm.engine.impl.form.validator.FormFieldValidator interface: public class CustomValidator implements FormFieldValidator { public boolean validate(Object submittedValue, FormFieldValidatorContext validatorContext) { // ... do some custom validation of the submittedValue // get access to the current execution DelegateExecution e = validatorContext.getExecution(); // get access to all form fields submitted in the form submit Map<String,Object> completeSubmit = validatorContext.getSubmittedValues(); } } If the process definition is deployed as part of a ProcessApplication deployment, the validator instance is resolved using the process application classloader and / or the process application Spring Application Context / CDI Bean Manager, in case of an expression.",
    "url": "/manual/latest/user-guide/task-forms/index.html"
  },
  {
    "id": "manual/latest/user-guide/task-forms/jsf-task-forms/index.html",
    "title": "JSF Task Forms | docs.cibseven.org",
    "content": "Adding JSF Forms to your Process Application Heads-up! The required CDI beans for this functionality are currently not available in Quarkus applications out of the box. If you add JSF forms as described below, you can easily use them as external task forms. A working example can be found in the examples repository. The BPMN process used for this example is shown in the image below: In this process model we added so called form keys to the Start Event “invoice received”. This is the form the user has to complete to start a new process instance. the User Tasks. These are the forms the user has to complete when completing user tasks that are assigned to him. This is how the forms are referenced in the BPMN 2.0 XML with the camunda:formKey attribute: <startEvent id=\"start\" name=\"invoice received\" camunda:formKey=\"app:sample-start-form.jsf\"/> <userTask id=\"categorize-invoice\" name=\"Categorize Invoice\" camunda:formKey=\"app:sample-task-form-1.jsf\" /> <userTask id=\"file-invoice\" name=\"File Invoice\" camunda:formKey=\"app:sample-task-form-2.jsf\" /> <userTask id=\"acknowledge-categorization\" name=\"Acknowledge Categorization\" camunda:formKey=\"app:acknowledge-form.jsf\" /> Creating Simple User Task Forms Create a JSF page in src/main/webapp/WEB-INF representing a form used for User Tasks. A very simple task form is shown below: <!DOCTYPE HTML> <html lang=\"en\" xmlns=\"http://www.w3.org/1999/xhtml\" xmlns:ui=\"http://java.sun.com/jsf/facelets\" xmlns:h=\"http://java.sun.com/jsf/html\" xmlns:f=\"http://java.sun.com/jsf/core\"> <f:view> <h:head> <f:metadata> <f:event type=\"preRenderView\" listener=\"#{camundaTaskForm.startTaskForm()}\" /> </f:metadata> <title>Task Form: #{task.name}</title> </h:head> <h:body> <h1>#{task.name}</h1> <h:form id=\"someForm\"> <p> Here you would see the actual form to work on the task in a design normally either matching your task list or your business application (or both in the best case). </p> <h:commandButton id=\"complete\" value=\"Task Completed\" action=\"#{camundaTaskForm.completeTask()}\" /> </h:form> </h:body> </f:view> </html> Note that you need cibseven-engine-cdi in order to have the camundaTaskForm bean available. How does this work? If the user clicks on “Start to work on task” in the tasklist, he will follow a link to this form, including the taskId and the callback URL (the URL to access the central tasklist) as GET-Parameters. Accessing this form will trigger the special CDI bean camundaTaskForm which starts a conversation, remembers the callback URL starts the User Task in the process engine, meaning the bean sets the start date and assigns the task to the CDI business process scope (see CDI Integration for details). For that, you just need to add this code block to the beginning of your JSF view: <f:metadata> <f:event type=\"preRenderView\" listener=\"#{camundaTaskForm.startTaskForm()}\" /> </f:metadata> Submit the form by calling the camundaTaskForm bean again, which: Completes the task in the process engine, causing the current token to advance in the process Ends the conversation Triggers a redirect to the callback URL of the tasklist <h:commandButton id=\"complete\" value=\"task completed\" action=\"#{camundaTaskForm.completeTask()}\" /> Note that the command button doesn’t have to be on the same form, you might have a whole wizard containing multiple forms in a row before having the completeTask button. This will work because of the conversation running in the background. Access Process Variables In the forms you can access your own CDI beans as usual and also access the CIB seven CDI beans. This makes it easy to access process variables, e.g., via the processVariables CDI bean: <h:form id=\"someForm\"> <p>Here you would see the actual form to work on the task in some design normally either matching you task list or your business application (or both in the best case).</p> <table> <tr> <td> Process variable <strong>x</strong> (given in in the start form): </td> <td> <h:outputText value=\"#{processVariables['x']}\" /> </td> </tr> <tr> <td> Process variable <strong>y</strong> (added in this task form): </td> <td> <h:inputText value=\"#{processVariables['y']}\" /> </td> </tr> <tr> <td></td> <td> <h:commandButton id=\"complete\" value=\"Task Completed\" action=\"#{camundaTaskForm.completeTask()}\" /> </td> </tr> </table> </h:form> This is rendered to a simple form: The same mechanism can be used to start a new process instance: <!DOCTYPE HTML> <html lang=\"en\" xmlns=\"http://www.w3.org/1999/xhtml\" xmlns:ui=\"http://java.sun.com/jsf/facelets\" xmlns:h=\"http://java.sun.com/jsf/html\" xmlns:f=\"http://java.sun.com/jsf/core\"> <f:view> <f:metadata> <f:event type=\"preRenderView\" listener=\"#{camundaTaskForm.startProcessInstanceByKeyForm()}\" /> </f:metadata> <h:head> <title>Start Process: #{camundaTaskForm.processDefinition.name}</title> </h:head> <h:body> <h1>#{camundaTaskForm.processDefinition.name}</h1> <p>Start a new process instance in version: #{camundaTaskForm.processDefinition.version}</p> <h:form id=\"someForm\"> <p> Here you see the actual form to start a new process instance, normally this would be in some design either matching you task list or your business application (or both in the best case). </p> <table> <tr> <td> Process variable <strong>x</strong>: </td> <td> <h:inputText value=\"#{processVariables['x']}\" /> </td> </tr> <tr> <td></td> <td> <h:commandButton id=\"start\" value=\"Start Process Instance\" action=\"#{camundaTaskForm.completeProcessInstanceForm()}\" /> </td> </tr> </table> </h:form> </h:body> </f:view> </html> If the user clicks on “Start a process instance” in the tasklist and chooses the process your start form is assigned to, he will follow a link to this form, including the processDefinitionKey and the callback URL (the URL to access the central tasklist) as GET-Parameters. Accessing this form will trigger the special CDI bean camundaTaskForm which: Starts a conversation Remembers the callback URL to the centralized tasklist You need to add this code block to the beginning of your JSF view: <f:metadata> <f:event type=\"preRenderView\" listener=\"#{camundaTaskForm.startProcessInstanceByIdForm()}\" /> </f:metadata> Submitting the start form now: Starts the process instance in the process engine Ends the conversation Triggers a redirect to the callback URL of the tasklist <h:commandButton id=\"start\" value=\"Start Process Instance\" action=\"#{camundaTaskForm.completeProcessInstanceForm()}\" /> Note that the command button doesn’t have to be on the same form, you might have a whole wizard containing multiple forms in a row before having the completeProcessInstanceForm button. This will work because of the conversation running in the background. Styling your Task Forms We use Twitter Bootstrap in our tasklist - so best add this to your Process Application as well and you can easily polish your UI: To include CSS and Javascript libraries in your project you can add them to your maven project as dependencies. <dependencies> <!-- ... --> <dependency> <groupId>org.webjars</groupId> <artifactId>bootstrap</artifactId> <version>3.1.1</version> </dependency> </dependencies> To use them, add tags like the following ones to your JSF page. If you have several forms, it may be helpful to create a template that you can refer to from your forms to avoid redundancies.. <h:head> <title>your title</title> <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" /> <!-- CSS Stylesheets --> <h:outputStylesheet library=\"webjars/bootstrap/3.1.1/css\" name=\"bootstrap.css\"/> <h:outputStylesheet library=\"css\" name=\"style.css\"/> <!-- Javascript Libraries --> <h:outputScript type=\"text/javascript\" library=\"webjars/bootstrap/3.1.1/js\" name=\"bootstrap.js\" /> </h:head>",
    "url": "/manual/latest/user-guide/task-forms/jsf-task-forms/index.html"
  },
  {
    "id": "manual/latest/user-guide/testing/assert-examples/index.html",
    "title": "Assert Examples | docs.cibseven.org",
    "content": "Assertions Instance: isActive Assert that a process instance is currently ‘active’, so neither suspended nor ended: assertThat(processInstance).isActive(); Instance: isEnded Assert that a process instance is already ended: assertThat(processInstance).isEnded(); Instance: isNotEnded Assert that a process instance is not ended: assertThat(processInstance).isNotEnded(); Instance: isStarted Assert that a process instance is started: assertThat(processInstance).isStarted(); Instance: isSuspended Assert that a process instance is suspended: assertThat(processInstance).isSuspended(); Instance: hasPassed Assert that a process instance has passed a specified activity: assertThat(processInstance).hasPassed(\"edit\"); Assert that a process instance has passed several specified activities: assertThat(processInstance).hasPassed(\"edit\", \"correct\"); Instance: hasPassedInOrder Assert that a process instance has passed several specified activities exactly in the given order: assertThat(processInstance).hasPassedInOrder(\"edit\", \"review\", \"correct\"); You can even assert that a specific activity has been passed several times: assertThat(processInstance).hasPassedInOrder(\"edit\", \"review\", \"correct\", \"review\", \"correct\", \"review\", \"publish\"); It doesn’t matter whether other activities have been passed in between those specified activities. Everything that matters is that the order is correct. So in the example just given, this more minimalistic assertion would also pass: assertThat(processInstance).hasPassedInOrder(\"edit\", \"review\", \"publish\"); Instance: hasNotPassed Assert that a process instance has not passed a specified activity: assertThat(processInstance).hasNotPassed(\"edit\"); Assert that a process instance has not passed any of several specified activities: assertThat(processInstance).hasNotPassed(\"edit\", \"correct\"); Instance: hasVariables Assert that a process instance holds at least one process variable: assertThat(processInstance).hasVariables(); Assert that a process instance holds - aside potential other variables - one or more specified process variables: assertThat(processInstance) .hasVariables(\"approved\") .hasVariables(\"jobAnnouncementId\", \"approved\"); Instance: hasNoVariables Assert that a process instance holds no process variables at all: assertThat(processInstance).hasNoVariables(); Instance: hasProcessDefinitionKey Assert that a process instance is based on a specific process definition: assertThat(processInstance).hasProcessDefinitionKey(\"myProcessDefinitionKey\"); Instance: hasBusinessKey Assert that a process instance has a specific business key: assertThat(processInstance).hasBusinessKey(\"myBusinessKey\"); Instance: isWaitingAt Assert that a process instance is currently waiting at a specified activity Id: assertThat(processInstance).isWaitingAt(\"edit\"); Assert that a process instance is currently waiting at several specified activity Ids: assertThat(processInstance).isWaitingAt(\"edit\", \"correct\"); Instance: isNotWaitingAt Assert that a process instance is currently NOT waiting at a specified activity Id: assertThat(processInstance).isNotWaitingAt(\"edit\"); Assert that a process instance is currently NOT waiting at several specified activity Ids: assertThat(processInstance).isNotWaitingAt(\"edit\", \"correct\"); Instance: isWaitingAtExactly Assert that a process instance is currently waiting at exactly one specified activity Id: assertThat(processInstance).isWaitingAtExactly(\"edit\"); Assert that a process instance is currently waiting at exactly the several specified activity Ids: assertThat(processInstance).isWaitingAtExactly(\"edit\", \"correct\"); Instance: isWaitingFor Assert that a process instance is currently waiting for a specified message: assertThat(processInstance).isWaitingFor(\"myMessage\"); Assert that a process instance is currently waiting for several specified messages: assertThat(processInstance).isWaitingFor(\"myMessage\", \"yourMessage\"); Instance: isNotWaitingFor Assert that a process instance is currently NOT waiting for a specified message: assertThat(processInstance).isNotWaitingFor(\"myMessage\"); Assert that a process instance is currently NOT waiting for any of several specified messages: assertThat(processInstance).isNotWaitingFor(\"myMessage\", \"yourMessage\"); Definition: hasActiveInstances Assert that a process definition currently has exactly the expected number of ‘active’ (so neither ended nor suspended) instances: assertThat(processDefinition).hasActiveInstances(\"1\"); Job: hasActivityId Assert that a job is based on an activity definition with a specific id: assertThat(job).hasActivityId(\"ServiceTask_1\"); Job: hasDeploymentId Assert that a job has a specific deployment id: assertThat(job).hasDeploymentId(deploymentId); Job: hasDueDate Assert that a job is due at a specific date: assertThat(job).hasDueDate(dueDate); Job: hasId Assert a specific internal id for the job: assertThat(job).hasId(id); Job: hasRetries Assert that a job has a specific number of retries left: assertThat(job).hasRetries(3); Task: isAssignedTo Assert that a specified user is assigned to a task: assertThat(task).isAssignedTo(\"kermit\"); Task: isNotAssigned Assert that a task is currently not assigned to any user: assertThat(task).isNotAssigned(); Task: hasCandidateGroup Assert that a task is is currently waiting to be assigned to a user of the specified candidate group. assertThat(task).hasCandidateGroup(\"human-resources-department\"); Note that (in line with Camunda’s interpretation of the term ‘candidate’) assigned tasks will not pass this assertion. However, the next assertion discussed here, would pass: Task: hasCandidateGroupAssociated Assert the expectation that a task is currently associated to the specified candidate group - no matter whether it is already assigned to a specific user or not. assertThat(task).hasCandidateGroupAssociated(\"human-resources-department\"); Task: hasCandidateUser Assert that a task is currently waiting to be assigned to a specified candidate user: assertThat(task).hasCandidateUser(\"kermit\"); Note that (in line with Camunda’s interpretation of the term ‘candidate’) assigned tasks will not pass this assertion. However, the next assertion discussed here, would pass: Task: hasCandidateUserAssociated Assert the expectation that a task is currently associated to the specified candidate user - no matter whether it is already assigned to a specific user or not. assertThat(task).hasCandidateUserAssociated(\"kermit\"); Task: hasDefinitionKey Assert that a task has the specified definition key (aka the id attribute of the <userTask id=“review-and-approve” …/> element in the process definition BPMN 2.0 XML file): assertThat(task).hasDefinitionKey(\"review-and-approve\"); Task: hasDescription Assert that the task has the specified free text description: assertThat(task).hasDescription(\"Please review and approve the result document.\"); Task: hasDueDate Assert that a task is due at a specified date: assertThat(task).hasDueDate(expectedDueDate); Task: hasFormKey Assert that a task is associated to a specified form (key): assertThat(task).hasFormKey(\"myForm.html\"); Task: hasId Assert that a task has the specified internal id: assertThat(task).hasId(\"1\"); Task: hasName Assert that the task has the specified name: assertThat(task).hasName(\"Review and approve\"); External Task: hasActivityId Assert that the external task has the specified activity id: assertThat(externalTask).hasActivityId(\"review-and-approve\"); External Task: hasTopicName Assert that the external task has the specified topic name: assertThat(externalTask).hasTopicName(\"Review and approve\"); Helpers Finding tasks, events and gateways by name You can map the name of a task, event or a gateway to it’s ID by the means of a static helper method: findId(\"My verbose task name\"); Claiming tasks You can directly claim a task by means of a static helper method: claim(task, \"fozzie\"); Unclaiming tasks You can directly unclaim a task by means of a static helper method: unclaim(task); Completing tasks You can directly complete a task by means of a static helper method: complete(task); Completing tasks and passing process variables You can directly construct a map of process variables by passing a sequence of key/value pairs to the static helper method “withVariables”: Map<String, Object> variables = withVariables(\"documentId\", 5, \"approved\", true); You can therefore e.g. write complete(task, withVariables(\"documentId\", 5, \"approved\", true)); Completing external tasks You can directly complete an external task by means of a static helper method: complete(externalTask); Completing external tasks and passing process variables You can directly construct a map of process variables by passing a sequence of key/value pairs to the static helper method “withVariables”: Map<String, Object> variables = withVariables(\"documentId\", 5, \"approved\", true); You can therefore e.g. write complete(externalTask, withVariables(\"documentId\", 5, \"approved\", true)); Executing jobs You can directly execute a job by means of a static helper method: execute(job()); Creating queries You can directly create queries by means of a static helper methods: TaskQuery taskQuery = taskQuery(); JobQuery jobQuery = jobQuery(); ProcessInstanceQuery processInstanceQuery = processInstanceQuery(); ExecutionQuery executionQuery = executionQuery(); You can therefore e.g. write assertThat(processInstance).task(taskQuery().taskAssignee(\"fozzie\")).hasCandidateGroup(\"human-resources-department\"); Accessing engine and engine API services You can directly access the engine and API services by means of static helper methods: ProcessEngine engine = processEngine(); AuthorizationService authorizationService = authorizationService(); FormService formService = formService(); HistoryService historyService = historyService(); IdentityService identityService = identityService(); ManagementService managementService = managementService(); RepositoryService repositoryService = repositoryService(); RuntimeService runtimeService = runtimeService(); TaskService taskService = taskService(); Making assertions on the only task of an instance You can retrieve a “chained” task assert inspecting the one and only one task currently available in the context of a process instance… assertThat(processInstance).task(); … in order to directly make assertions on it, e.g. assertThat(processInstance).task().isNotAssigned(); Making assertions on a specific task of an instance You can retrieve a “chained” task assert inspecting a very specific task currently available in the context of a process instance… assertThat(processInstance).task(\"edit\"); or assertThat(processInstance).task(taskQuery().taskAssignee(\"fozzie\")); … in order to directly make assertions on it, e.g. assertThat(processInstance).task(\"edit\").isAssignedTo(\"fozzie\"); Making assertions on the only external task of an instance You can retrieve a “chained” external task assert inspecting the one and only one external task currently available in the context of a process instance… assertThat(processInstance).externalTask(); … in order to directly make assertions on it, e.g. assertThat(processInstance).externalTask().hasTopicName(\"editing\"); Making assertions on a specific external task of an instance You can retrieve a “chained” external task assert inspecting a very specific external task currently available in the context of a process instance… assertThat(processInstance).externalTask(\"edit\"); or assertThat(processInstance).externalTask(externalTaskQuery().activityId(\"edit\")); … in order to directly make assertions on it, e.g. assertThat(processInstance).externalTask(\"edit\").hasTopicName(\"editing\"); Making assertions on the only job of an instance You can retrieve a “chained” job assert inspecting the one and only one job currently available in the context of a process instance… assertThat(processInstance).job(); … in order to directly make assertions on it, e.g. assertThat(processInstance).job().hasRetries(0); Making assertions on a specific job of an instance You can retrieve a “chained” job assert inspecting a very specific job currently available in the context of a process instance… assertThat(processInstance).job(\"ServiceTask_1\"); or assertThat(processInstance).job(jobQuery().executionId(executionId)); … in order to directly make assertions on it, e.g. assertThat(processInstance).job(\"ServiceTask_1\").hasRetries(0); Making assertions on the only called process of a super process instance You can retrieve a “chained” process instance assert inspecting the one and only called process instance currently available in the context of a super process instance… assertThat(processInstance).calledProcessInstance(); … in order to directly make assertions on it, e.g. assertThat(processInstance).calledProcessInstance().hasProcessDefinitionKey(\"mySubProcessDefinitionKey\"); Making assertions on a specific called process instance of a super process instance You can retrieve a “chained” process instance assert inspecting a very specific called process instance currently available in the context of a super process instance, either by means of a processDefinitionKey… assertThat(processInstance).calledProcessInstance(\"mySubProcessDefinitionKey\"); or even by means of a more sophisticated processInstanceQuery assertThat(processInstance).calledProcessInstance(processInstanceQuery().processDefinitionKey(\"mySubProcessDefinitionKey\")); … in order to directly make assertions on it, e.g. assertThat(processInstance).calledProcessInstance(\"mySubProcessDefinitionKey\").isNotNull(); Making assertions on the process variables map of an instance You can retrieve a “chained” process variables map assert inspecting all the process variables available in the context of a process instance… assertThat(processInstance).variables(); … in order to directly make assertions on them, e.g. assertThat(processInstance).variables() .hasSize(2).containsEntry(\"approved\", true); You may want to compare that with the other possibility to assert whether a process instance hasVariables (without leaving your current ProcessInstanceAssert). Accessing tasks in the context of a process instance under test You can directly access tasks in the context of the last asserted process instance by means of static helper methods: assertThat(processInstance).isNotNull(); ... Task onlyTaskOflastAssertedProcessInstance = task(); Task someTaskOflastAssertedProcessInstance = task(\"review-and-approve\"); Task sameTaskOflastAssertedProcessInstance = task(taskQuery().taskDefinitionKey(\"review-and-approve\")); You can therefore e.g. write … assertThat(processInstance).task().hasDefinitionKey(\"review-and-approve\"); complete(task(), withVariables(\"documentId\", 5, \"approved\", true)); Furthermore you can directly access tasks in the context of a specified process instance by means of static helper methods: Task onlyTaskOfProcessInstance = task(processInstance); Task someTaskOfProcessInstance = task(\"review-and-approve\", processInstance); Task sameTaskOfProcessInstance = task(taskQuery().taskDefinitionKey(\"review-and-approve\"), processInstance); You can therefore e.g. write … complete(task(\"review-and-approve\", processInstance), withVariables(\"documentId\", 5, \"approved\", true)); Accessing external tasks in the context of a process instance under test You can directly access external tasks in the context of the last asserted process instance by means of static helper methods: assertThat(processInstance).isNotNull(); ... ExternalTask onlyTaskOflastAssertedProcessInstance = externalTask(); ExternalTask someTaskOflastAssertedProcessInstance = externalTask(\"review-and-approve\"); ExternalTask sameTaskOflastAssertedProcessInstance = externalTask(externalTaskQuery().activityId(\"review-and-approve\")); You can therefore e.g. write … assertThat(processInstance).externalTask().hasActivityId(\"review-and-approve\"); complete(externalTask(), withVariables(\"documentId\", 5, \"approved\", true)); Furthermore you can directly access external tasks in the context of a specified process instance by means of static helper methods: ExternalTask onlyTaskOfProcessInstance = externalTask(processInstance); ExternalTask someTaskOfProcessInstance = externalTask(\"review-and-approve\", processInstance); ExternalTask sameTaskOfProcessInstance = externalTask(externalTaskQuery().activityId(\"review-and-approve\"), processInstance); You can therefore e.g. write … complete(externalTask(\"review-and-approve\", processInstance), withVariables(\"documentId\", 5, \"approved\", true)); Accessing jobs in the context of a process instance under test You can directly access jobs in the context of the last asserted process instance by means of static helper methods: assertThat(processInstance).isNotNull(); ... Job onlyJobOflastAssertedProcessInstance = job(); Job someJobOflastAssertedProcessInstance = job(\"publish\"); Job someJobOflastAssertedProcessInstance = job(jobQuery().executionId(executionId)); You can therefore e.g. write … assertThat(processInstance).job(\"publish\").isNotNull(); execute(job(\"publish\")); Furthermore you can directly access jobs in the context of a specified process instance by means of static helper methods: Task onlyJobOfProcessInstance = job(processInstance); Task someJobOfProcessInstance = job(\"publish\", processInstance); Task sameJobOfProcessInstance = job(jobQuery().executable(), processInstance); You can therefore e.g. write … execute(job(\"publish\", processInstance)); Accessing called process instances in the context of a process instance under test You can directly access called process instances in the context of the last asserted process instance by means of static helper methods: assertThat(processInstance).isNotNull(); ... ProcessInstance onlyCalledProcessInstanceOflastAssertedProcessInstance = calledProcessInstance(); ProcessInstance someCalledProcessInstanceOflastAssertedProcessInstance = calledProcessInstance(\"myCalledProcessDefinitionKey\"); ProcessInstance someCalledProcessInstanceOflastAssertedProcessInstance = calledProcessInstance(processInstanceQuery().processDefinitionKey(\"myCalledProcessDefinitionKey\")); You can therefore e.g. write … assertThat(processInstance).isNotNull(); ProcessInstance calledProcessInstance = calledProcessInstance(); Furthermore you can directly access jobs in the context of a specified super process instance by means of static helper methods: ProcessInstance onlyCalledProcessInstanceOfProcessInstance = calledProcessInstance(superProcessInstance); ProcessInstance someCalledProcessInstanceOfProcessInstance = calledProcessInstance(\"myCalledProcessDefinitionKey\", superProcessInstance); ProcessInstance sameCalledProcessInstanceOfProcessInstance = calledProcessInstance(processInstanceQuery().processDefinitionKey(\"myCalledProcessDefinitionKey\"), superProcessInstance); You can therefore e.g. write … ProcessInstance calledProcessInstance = calledProcessInstance(\"myCalledProcessDefinitionKey\", superProcessInstance); Accessing process definitions You can directly access process definitions by means of static helper methods: ProcessDefinition processDefinitionOflastAssertedProcessInstance = processDefinition(); ProcessDefinition processDefinitionOfSpecifiedProcessInstance = processDefinition(processInstance); ProcessDefinition processDefinitionOfSpecifiedProcessDefinitionKey = processDefinition(\"myProcessDefintionKey\"); ProcessDefinition processDefinitionConformingToSpecifiedQuery = processDefinition(processDefinitionQuery().processDefinitionKey(\"myProcessDefintionKey\"); In order to check, whether your last asserted process instance is the only currently running instance of its own process definition you can therefore e.g. write … assertThat(processDefinition()).hasActiveInstances(1);",
    "url": "/manual/latest/user-guide/testing/assert-examples/index.html"
  },
  {
    "id": "manual/latest/user-guide/testing/index.html",
    "title": "Testing | docs.cibseven.org",
    "content": "Testing BPMN processes, CMMN cases (and also DMN decisions) is just as important as testing code. This section explains how to write unit tests and integration tests with CIB seven and explains some best practice and guidelines. Unit Tests CIB seven provides helper classes to write unit tests for JUnit versions 3, 4 and 5. JUnit 5 CIB seven since 1.0 (also includin 7.22.0-cibseven versions) ships with a JUnit 5 extension that provides access to the process engine and services through getter methods. The extensions process engine is configured by the default configuration file called camunda.cfg.xml, which needs to be placed on the classpath. A custom configuration file can be passed to the extension when creating the ProcessEngineExtension object. If you want to use the JUnit 5 ProcessEngineExtension, you need to add the following dependency to your pom.xml file: <dependency> <groupId>org.cibseven.bpm</groupId> <artifactId>cibseven-bpm-junit5</artifactId> <version>1.1.0</version> <scope>test</scope> </dependency> The following code snippets show examples of how to use the extension. Use the @ExtendWith annotation to inject a process engine into a provided field automatically. @ExtendWith(ProcessEngineExtension.class) public class MyBusinessProcessTest { // provide a field where the process engine gets injected ProcessEngine processEngine; @Test @Deployment public void extensionUsageExample() { RuntimeService runtimeService = processEngine.getRuntimeService(); runtimeService.startProcessInstanceByKey(\"extensionUsage\"); TaskService taskService = processEngine.getTaskService(); Task task = taskService.createTaskQuery().singleResult(); assertThat(task.getName()).isEqualTo(\"My Task\"); taskService.complete(task.getId()); assertThat(runtimeService.createProcessInstanceQuery().count()).isEqualTo(0); } } Use the @RegisterExtension to create a referenceable ProcessEngineExtension object which gives you access to more configuration options. public class MyBusinessProcessTest { @RegisterExtension ProcessEngineExtension extension = ProcessEngineExtension.builder() .configurationResource(\"myConfig.xml\") .build(); @Test @Deployment public void extensionUsageExample() { RuntimeService runtimeService = extension.getRuntimeService(); runtimeService.startProcessInstanceByKey(\"extensionUsage\"); TaskService taskService = extension.getTaskService(); Task task = taskService.createTaskQuery().singleResult(); assertThat(task.getName()).isEqualTo(\"My Task\"); taskService.complete(task.getId()); assertThat(runtimeService.createProcessInstanceQuery().count()).isEqualTo(0); } } If you don’t want to create a configuration file, you can configure a process engine programmatically. public class MyBusinessProcessTest { public ProcessEngine myProcessEngine = ProcessEngineConfiguration .createStandaloneInMemProcessEngineConfiguration() .setJdbcUrl(\"jdbc:h2:mem:camunda;DB_CLOSE_DELAY=1000\") .buildProcessEngine(); @RegisterExtension ProcessEngineExtension extension = ProcessEngineExtension .builder() .useProcessEngine(myProcessEngine) .build(); } JUnit 4 Using the JUnit 4 style of writing unit tests, the ProcessEngineRule must be used. Through this rule, the process engine and services are available through getters. This rule will look for the default configuration file on the classpath called camunda.cfg.xml. When constructing the ProcessEngineRule object you can pass a custom configuration file to the rule. Process engines are statically cached over multiple unit tests when using the same configuration resource. The following code snippet shows an example of using the JUnit 4 style of testing and the usage of the ProcessEngineRule. public class MyBusinessProcessTest { @Rule public ProcessEngineRule processEngineRule = new ProcessEngineRule(); @Test @Deployment public void ruleUsageExample() { RuntimeService runtimeService = processEngineRule.getRuntimeService(); runtimeService.startProcessInstanceByKey(\"ruleUsage\"); TaskService taskService = processEngineRule.getTaskService(); Task task = taskService.createTaskQuery().singleResult(); assertThat(task.getName()).isEqualTo(\"My Task\"); taskService.complete(task.getId()); assertThat(runtimeService.createProcessInstanceQuery().count()).isEqualTo(0); } } Our Project Templates for Maven give you a complete running project including a JUnit test out of the box. JUnit 3 In the JUnit 3 style, the ProcessEngineTestCase must be extended. This will make the ProcessEngine and the services available through protected member fields. In the setup() of the test, the processEngine will be initialized by default with the camunda.cfg.xml resource on the classpath. To specify a different configuration file, override the getConfigurationResource() method. Process engines are cached statically over multiple unit tests when the configuration resource is the same. A JUnit 3 style test can look as follows: public class MyBusinessProcessTest extends ProcessEngineTestCase { @Deployment public void testSimpleProcess() { runtimeService.startProcessInstanceByKey(\"simpleProcess\"); Task task = taskService.createTaskQuery().singleResult(); assertThat(task.getName()).isEqualTo(\"My Task\"); taskService.complete(task.getId()); assertThat(runtimeService.createProcessInstanceQuery().count()).isEqualTo(0); } } Deploy Test Resources You can annotate test classes and methods with @Deployment . Before the test is run, a resource file named TestClassName.bpmn20.xml (for a class-level annotation) or TestClassName.testMethod.bpmn20.xml (for a method-level annotation), in the same package as the test class, will be deployed. At the end of the test the deployment will be deleted, including all related process instances, tasks, etc. The @Deployment annotation also supports setting the resource location explicitly. @Deployment(resources = {\"myProcess.bpmn\", \"mySubprocess.bpmn\"}) will pick the files myProcess.bpmn and mySubProcess.bpmn directly from the top of the classpath. Method-level annotations override class-level annotations. See the Javadocs for @Deployment more details. The annotation is supported for JUnit 3 and JUnit 4 style of testing. Specify the required History Level If a test requires a specific history level (e.g., because it uses the HistoryService) then you can annotate the test class or method with @RequiredHistoryLevel and specify the required history level (e.g., “activity”, “full”). Before the test is run, it checks the current history level of the process engine and skip the test if the history level is lower than the specified one. A JUnit 4 style test can look as follows: public class MyBusinessProcessTest { @Rule public ProcessEngineRule processEngineRule = new ProcessEngineRule(); @Test @Deployment @RequiredHistoryLevel(ProcessEngineConfiguration.HISTORY_ACTIVITY) public void ruleUsageExample() { RuntimeService runtimeService = processEngineRule.getRuntimeService(); runtimeService.startProcessInstanceByKey(\"ruleUsage\"); HistoryService historyService = processEngineRule.getHistoryService(); // requires history level >= \"activity\" HistoricVariableInstance variable = historyService .createHistoricVariableInstanceQuery() .singleResult(); assertEquals(\"value\", variable.getValue()); } } The annotation is supported for JUnit 3 and JUnit 4 style of testing. Note that a skipped test is marked as passed for JUnit 3 style tests since JUnit 3 doesn’t support skipping of tests. Debug Unit Tests When using the in-memory H2 database for unit tests, the following instructions allow to easily inspect the data in the engine database during a debugging session. The screenshots here are taken in Eclipse, but the mechanism should be similar for other IDEs. Suppose we have put a breakpoint somewhere in our unit test. In Eclipse this is done by double-clicking in the left border next to the code: If we now run the unit test in debug mode (right-click in test class, select ‘Run as’ and then ‘JUnit test’), the test execution halts at our breakpoint, where we can now inspect the variables of our test as shown in the right upper panel. To inspect the data, open up the ‘Display’ window (if this window isn’t there, open Window->Show View->Other and select Display.) and type (code completion is available) org.h2.tools.Server.createWebServer(\"-web\").start() Select the line you’ve just typed and right-click on it. Now select ‘Display’ (or execute the shortcut instead of right-clicking) Now open up a browser and go to http://localhost:8082, and fill in the JDBC URL to the in-memory database (by default this is jdbc:h2:mem:camunda), and hit the connect button. You can now see the engine database and use it to understand how and why your unit test is executing your process in a certain way. CIB seven Assertions Additional to normal JUnit assertions, CIB seven Assert adds a fluent API for asserting typical scenarios in a process integrating with AssertJ. assertThat(processInstance).isWaitingAt(\"UserTask_InformCustomer\"); assertThat(task()).hasCandidateGroup(\"Sales\").isNotAssigned(); You can find a more extensive guide with examples under Assert Examples. To use CIB seven Assert, add the following dependency to your pom.xml: <dependency> <groupId>org.cibseven.bpm</groupId> <artifactId>cibseven-bpm-assert</artifactId> <version>1.1.0</version> <scope>test</scope> </dependency> Also, you will have to add the AssertJ library to your dependencies. Make sure that the version is correct. You can find the correct version in the compatibility matrix below. <dependency> <groupId>org.assertj</groupId> <artifactId>assertj-core</artifactId> <version>${version.assertJ}</version> <!-- set correct version here --> <scope>test</scope> </dependency> If CIB seven Assert is used in combination with Spring Boot or the CIB seven Spring Boot Starter, the AssertJ dependency will be present in your project already. Assertions Version Compatibility Each version of CIB seven Assert is bound to a specific version of CIB seven and AssertJ. Only these default combinations are recommended (and supported) by CIB seven. Nevertheless, each version of CIB seven Assert can be combined with newer patch versions of the CIB seven engine, though such combinations must be thoroughly tested before being used in production. With CIB seven 1.0 the project was moved into the CIB seven repository and is using the same versioning as CIB seven. CIB seven Assert artifact AssertJ version CIB seven Assert version CIB seven version camunda-bpm-assert 3.25.3 7.22.0-cibseven 7.22.0-cibseven cibseven-bpm-assert 3.25.3 1.1 1.1 Community extensions to support testing There are a couple of well documented and heavily used community extensions that can make testing much more productive and fun. Camunda Scenario Tests Camunda-bpm-assert-scenario enables you to write more robust test suites. The idea is, that you only have to adapt your tests if your process models changes in a way that affects the tested behavior. It concentrates much less on the concrete path through a given process model, but on the external effects the path through the model has. @Test public void testHappyPath() { // \"given\" part of the test when(process.waitsAtUserTask(\"CompleteWork\")).thenReturn( (task) -> task.complete() ); // \"when\" part of the test run(process).startByKey(\"ReadmeProcess\").execute(); // \"then\" part of the test verify(process).hasFinished(\"WorkFinished\"); } Camunda Test Coverage Camunda-bpm-process-test-coverage visualises test process pathes and checks your process model coverage ratio. Running typical JUnit tests leaves html files in the build output. Resolving Beans Without Spring/CDI The Mocks class can be used to make beans available inside the Expression Language or in Script Tasks without the need of any bean manager. Register the bean inside the application: Mocks.register(\"myBean\", new Bean()); Now the named bean is exposed and can be used within the process: <serviceTask id=\"serviceTask\" camunda:expression=\"#{myBean.invokeMethod()}\" /> In the case, that mocked beans must be resolvable during process deployment (e.g. bean expression in timer start event definition), one should make sure, that they are registered before the deployment happens. E.g. when used in combination with @Deployment annotation, beans should not be registered in @Before method, but rather the separate test rule can be created, that registers beans on startup, and chained before ProcessEngineRule. The mocked beans feature should be used for testing purposes only. Beans that are stored with Mocks are exclusively available within the respective storing thread as it is based on ThreadLocal. In most productive environments, it is not possible to access mocked beans during process execution due to the reason that jobs are executed by the multi-threaded Job Executor. Since the Job Executor is disabled in unit test scenarios, the thread of process execution is the same that creates mocked bean instances. Best Practice Write Focused Tests The feature to start a process instance at a set of activities can be used to to create a very specific scenario without much setup. Similarly, certain activities can be skipped by using process instance modification. Scoping Tests BPMN processes, CMMN cases and DMN decisions do not exist in isolation. Consider the example of a BPMN process: firstly, the process itself is executed by the CIB seven engine which requires a database. Next, the process is “not just the process”. It can contain expressions, scripts and often calls out to custom Java classes which may in turn again call out to services, either locally or remotely. To test the process, all these things need to be present, otherwise the test cannot work. Setting all of this up just to run a unit test is expensive. This is why, in practice, it makes sense to apply a concept which we call test scoping. Scoping the test means limiting the amount of infrastructure required to run the test. Things outside of the scope of the test are mocked. Example: Scoping Tests for a Java EE Application This is best explained using an example. Assume you are building a typical Java EE application containing a BPMN process. The process uses Java Expression Language (EL) for conditions, it invokes Java Delegate implementations as CDI beans, these beans may in turn call out to the actual business logic implemented as EJBs. The business logic uses JPA for maintaining additional business objects in a secondary database. It also sends out messages using JMS to interact with external systems and has a nice web UI. The application runs inside a Java EE application server like Wildfly. To test this application, all components, including the application server itself, need to be present and the external systems need to process the JMS messages. This makes it hard to write focused tests. However, by looking at the process itself, we find that there are many aspects of it that we can test without having the complete infrastructure in place. For example, if the process data is present, the Expression Language conditions can usually be tested without any additional infrastructure. This already allows asserting that the process “takes the right turn” at a gateway given a set of input data. Next, if the EJBs are mocked, the delegation logic can be included in such tests as well. This allows asserting that wiring of the delegation logic is correct, that it performs correct data transformation and mapping and that it invokes the business logic with the correct parameters. Given that the CIB seven engine can work with an in-memory database, it now becomes possible to test the BPMN process “in isolation”, as a unit test and assert its local functional correctness. The same principle can be applied to the next “outer layers” of the system, including the business logic and external systems. The following drawing shows a schematic representation of what this looks like for our example of a Java EE application: Three test scopes are defined: Scope 1: Local, functional correctness of the process model with data, conditions and delegation code, usually implemented as a unit test. Scope 2: Integration with business logic inside the runtime container, for Java EE applications usually implemented as an Arquillian-based integration test. Scope 3: Integration with external systems and UI. Note that the above is just an example for a Java EE application, other applications may require different test scopes. However the principle remains the same.",
    "url": "/manual/latest/user-guide/testing/index.html"
  },
  {
    "id": "manual/latest/webapps/admin/authorization-management/index.html",
    "title": "Authorization Management | docs.cibseven.org",
    "content": "Manage authorizations for a variety of resources (e.g., Applications, Groups, Filters). In the following sections you will learn how to use an administrator account with the help of some simple use cases. See Authorization Service for more information about Authorizations. Accessing the Authorization Management menu The Authorization Management menu is only usable by users which are granted with Read permission for authorizations. Grant Basic Permissions In this use case we’ll grant some basic permissions. To start out we’ll need some users and a group. Create two users in the users menu, create a group called support in the groups menu and add the new users to the group in the users menu. Application Access Set the authorizations for the new group and the created users. First you have to define which application the members of your new group have access to. Select the Application menu and create a new Application Authorization rule. The group members should be able to access Tasklist, so add the following rule: Now every member of the group support can use Tasklist. Furthermore, you want one of the new users to get access to Cockpit. Therefore, add a new user-specific rule: This specific rule is only valid for the user ’lemmy’ and provides him with additional authorization for the resource Cockpit. Log in with the new user accounts and test if you can access the desired application. Filter Access Currently the users in the support group can only see the predefined filters in Tasklist. We want the group members to have READ access to another filter, so we create a rule for that filter: The authorizations set here correspond to the authorizations that can be set in the filter settings in Tasklist. The resource ID can be found in the database table ACT_RU_FILTER. See this section for more information about filters. Member Visibility Depending on the users authorization, Tasklist will show you information about your colleagues and groups. Currently you can only see the group folder support but not your colleague. To change that, log in to the admin application as administrator, enter the Users Authorization menu and create the following rules: Now every member of the group support is able to see the new users lemmy and Ozzy. Application-Specific Permissions This use case demonstrates how to give a group access to Cockpit, but restrict them to READ access. We will use the support group that we created in the previous example. To limit the access we have to know which resources are accessible in Cockpit so that we can set the proper permissions for them. Of the predefined resources at the moment this would be: Process Definition Process Instance Task First of all, we have to provide the permission to access Cockpit (also see the Application Access section). For all the resources that are accessible from Cockpit we add READ permission for every resource id (indicated by the asterisk) for the group, e.g., in the screenshot for all process definitions. Now every user of the support group can access Cockpit and see everything that is inside without being able to change anything (unless the user has special permissions himself, because those take precedence over group permissions). Now that we have one group that can see everything in Cockpit, we want to have another group managing one single process. Restrict Process Permissions Not every process has to be managed by every user/group and with regards to different organizational levels, not every group should be aware of every process present in the process engine. Therefore it might be necessary to restrict the access of users/groups to certain processes. In this use case we want to give the group accounting, which we will assume is already present and has access to Cockpit (see Application-Specific Permission and Application Access), full access to the “invoice” process and only to this process. For groups and users to be able to see process definitions they need at least READ permission for the “Process Definition” resource. To see running process instances the same permission is required for the “Process Instance” resource. We grant the accounting group all permissions for the invoice process because they shall be able to manage their process completely. The resource id references the key of the process definition. Now that we know how to grant certain permissions, we might need a second user who serves as an administrator. Create a User with All Permissions During the setup you had to create one administrator account. In a real-world scenario it could be beneficial to have a second administrator account to manage the users. Basically, an administrator is a user with the ALL permission for every possible resource and resource id. For example, to grant the accounting group all permissions for authorizations the following entry has to be made: To create an administrator account, there are several options: If you kept the group camunda-admin in your application, you can add the user to this group. If you use the Administrator Authorization Plugin, you can configure the plugin to grant the user or a certain group all permissions. You can create your own administrator group (also see Groups), grant it all permissions and assign a user to it. Grant one specific user all permissions. Now, after creating a new administrator account, we may want to start working and start processes. Grant Permission to Start Processes from Tasklist Processes are started from Tasklist. For a user or group to be able to start processes we need, again, a certain combination of permissions. In this use case we want to give the accounting group the permission to start the invoice process from Tasklist. To start, we will grant the group access to Tasklist (also see Application Specific Permission. Next, we grant the accounting group the READ and CREATE_INSTANCE permission for the invoice process to be able to see the process definition and create instances in Tasklist. After that, we grant the CREATE permission for process instances. The CREATE permission is necessary for the group to be able to create new process instances. The resource id references the generated process instance ids, therefore we use the asterisk, because we can’t know the generated id in advance. Now that we know how to start a process, we may want to restrict permissions to certain running processes. Grant Permission for Single Process Instance It is possible to restrict a group’s/user’s permissions to a single process instance, i.e., after the process ends, the group/user will not be able to change any other running process instances. We will use the accounting group again in this example. We assume that the group has access to Cockpit (also see Application Access) and that a process with the name and key OrderProcess is present. To enable the group to see the process in Cockpit, we have to grant the READ permission for the process definition. Now we have to get the process instance id from Cockpit. You can find the ids of all running processes after clicking on a process definition name or diagram preview on the Cockpit dashboard. This id then has to be used as the resource id when granting the user all permissions for the Process Instance resource. This will limit the group’s permissions to this running process instance. As with restricting access to a certain process instance, it is also possible to apply similar limitations for a single task. Grant Permission for Single Tasks Since several groups can participate in a process, it could be useful to restrict certain tasks to certain people/groups. For this example, we will reuse the accounting group and the invoice process from the previous sections. At least we need one running instance of the process. First of all, we have to grant the accounting group READ permission for filters so that tasks will be displayed in Tasklist. Next we go into Cockpit and assign the desired task to the accounting group. This will automatically create an entry for the task with the task id as resource id in Admin and grant the READ and UPDATE permissions. Those are the most common use cases for possible combinations of resources, permissions and resource ids.",
    "url": "/manual/latest/webapps/admin/authorization-management/index.html"
  },
  {
    "id": "manual/latest/webapps/admin/configuration/index.html",
    "title": "Configuration | docs.cibseven.org",
    "content": "You can override the default configuration of admin using a central configuration file located in app/admin/scripts/config.js. The following configuration options are available: LDAP If you connect CIB seven with the LDAP identity service, you have read-only access to the users and groups. Create new users and groups via the LDAP system, but not in the admin application. Find more information about how to configure the process engine in order to use the LDAP identity service here. Logo and header color You can change the visual aspects of Admin. The user stylesheet file is located in app/admin/styles/user-styles.css. This file contains CSS, which is loaded into Admin and can override the standard styles. .navbar-brand { /* hides the \"CIB even Admin\" text */ text-indent: -999em; /* put your logo */ background-image: url(./path/to/the/logo.png); /* sets the width to match the logo's width */ width: 80px; } /* changes the header bottom border color */ [cam-widget-header] { border-bottom-color: blue; } Note: you can also change the app name (Admin) and vendor (CIB seven) by changing the app/admin/scripts/config.js configuration file as follow: export default { // … app: { name: 'Admin', vendor: 'Company' } } Localization Admin can be localized. CIB seven maintains English and German translation files. You can find and download community maintained translation files at the Camunda webapp translations repository. The localization of Admin is contained in the app/admin/locales/ directory. This directory contains a separate localization file for every available language. The file name consists of the language code and the suffix .json (e.g., en.json). Admin uses a locale file corresponding to the language settings of the browser. You can set the availableLocales property in the configuration file to provide a list of available locales. Every locale contained in this list must have a locale file in the locales directory with the corresponding language code. If the browser uses a language which is not available, Admin uses the locale defined via the fallbackLocale property in the configuration file: export default { // … \"locales\": { \"availableLocales\": [\"en\", \"de\"], \"fallbackLocale\": \"en\" } } To create a new localization for Admin, copy the provided language file, translate it and save it as new localization file with the corresponding language code. To make the new translation available, add it to the list of available locales in the configuration file. Custom scripts Admin allows you to include arbitrary JavaScript files. This allows you to extend admin with custom code. The script file might contain a custom frontend module. Admin shares the frontend module structure with Cockpit Plugins. Add your files to the customScripts property of the app/admin/scripts/config.js file: export default { // … customScripts: ['custom-module/module.js'] } This includes a custom-module/module.js file. The path is relative to the app/admin folder in the CIB seven webapp .war file. Change CSRF cookie name The default name of the CSRF Cookie is XSRF-TOKEN. When using other applications within the same origin, the CSRF mechanisms could interfere with each other. To avoid the name conflict, change the name of the CSRF cookie in the config.js file as follows: export default { // … csrfCookieName: 'MY-XSRF-TOKEN' } Note: Ensure you also change the CSRF cookie name on server-side. Disable welcome message for new users First-time visitors are shown a message directing them to the CIB seven welcome page. If you do not want this message to be shown, you can disable it by adjusting the config.js as follows: export default { // … disableWelcomeMessage: true } Note: This only affects the Admin login page. For other web apps, adjust the corresponding config file as well. User operation log annotation length The default maximum length of a user operation log annotation is 4000 characters. Some databases have smaller limits. You can change the maximum allowed input length in the config.js file as follows: export default { // … userOperationLogAnnotationLength: 4000 } Note: This only affects the Admin Operation Log. For the Cockpit Operation Log, check out the Cockpit configuration. Task worker metrics The task worker metrics (TW) on the metrics page are displayed by default. You can disable this behavior by adjusting the config.js as follows: export default { // … alwaysShowUniqueTaskWorkerMetrics: false } If disabled, the metrics can still be displayed on-demand via a checkbox. Advanced styles customization In addition to the basic user-styles.css file, you can edit the source style and layout files using less to change the overall appearance of Admin. To customize the interface with less, start by having a look at the variables defined in the following files: node_modules/camunda-commons-ui/node_modules/bootstrap/less/variables.less defines the original Bootstrap variables node_modules/camunda-commons-ui/resources/less/cam-variables.less overrides some Bootstrap variables (above) and add some custom ones Compiling with Grunt From within the cibseven-bpm-webapp directory: grunt build:admin The command will build the front-end assets (of Admin), styles included.",
    "url": "/manual/latest/webapps/admin/configuration/index.html"
  },
  {
    "id": "manual/latest/webapps/admin/group-management/index.html",
    "title": "Group Management | docs.cibseven.org",
    "content": "Groups Menu The Groups menu allows you to add, edit and delete user groups. Besides that you can view the members of groups",
    "url": "/manual/latest/webapps/admin/group-management/index.html"
  },
  {
    "id": "manual/latest/webapps/admin/index.html",
    "title": "Admin | docs.cibseven.org",
    "content": "Along with the Camunda web applications we ship Admin, accessible via http://localhost:8080/camunda/app/admin/. Admin is an application that allows you to configure users and groups via the engine’s Identity Service and authorizations via the engine’s Authorization Service. Furthermore, you can connect Camunda Admin to your LDAP system.",
    "url": "/manual/latest/webapps/admin/index.html"
  },
  {
    "id": "manual/latest/webapps/admin/plugins/index.html",
    "title": "Admin Plugins | docs.cibseven.org",
    "content": "Plugin Compatibility Please note that the code of Admin plugins might need to be migrated when updating CIB seven to a higher version (e.g. CSS styles). Admin uses the concept of plugins to add own functionality without having to extend or hack the Admin web application. For further details about the concepts behind plugins, please read the Cockpit plugins section. Difference between Cockpit and Admin plugins: To publish the plugin with Admin, its class name must be put into a file called org.cibseven.bpm.admin.plugin.spi.AdminPlugin that resides in the directory META-INF/services. The plugin mechanism of Admin does not allow to provide additional SQL queries by using MyBatis mappings. Plugin Points Here you can see the various points at which you are able to add your own plugins. Route Name: admin.route This plugin points properties contain the attribute path, which stands for the hashRoute for this page. This will be rendered when the user navigates in the browser to the url, e.g. #/my-path. properties: { path: \"/my-path\" } Dashboard Name: admin.dashboard.section With CIB seven.5, the Admin webapp gets a dashboard based on plugins similar to the Cockpit dashboard ones. This plugin points properties contain the attributes label and pagePath, which are the heading of the new Section as well as the linked sub-page of the heading. If pagePath is undefined, the label will not be rendered as a link. properties: { label: \"My Plugin\", pagePath: '#/myPage' } You can find examples of Admin dashboard plugins here.",
    "url": "/manual/latest/webapps/admin/plugins/index.html"
  },
  {
    "id": "manual/latest/webapps/admin/system-management/index.html",
    "title": "System Management | docs.cibseven.org",
    "content": "The System Settings menu gives you general information about the process engine. It enables users with system permissions to access certain system information, including diagnostics, metrics. Accessing the System Settings menu The System Settings menu is only usable by users which are granted with All permission for authorizations. Diagnostics The Diagnostics menu allows you to view and copy diagnostics data about your environment or distribution of Camunda. The main purpose of the Diagnostics menu is to increase transparency by giving you easy access to important system diagnostics information. In the event of an issue, this should also improve problem diagnosis by enabling you to quickly understand and share the Camunda environment you are running. Execution Metrics The Execution Metrics menu in Admin displays an approximate number of Flow Nodes Instances (FNI), Executed Decision Elements (EDE), Process Instances (PI) and Decision Instances (DI) processed by the engine and Task Users (TU) that were assigned to a user task by the selected contract start date. The page displays the rolling last 12 months metrics in a chart and table. Legacy metrics (FNI, EDE) are hidden by default, but can be displayed by selecting the Display legacy metrics checkbox. Underneath, it displays all the available annual usage metrics. Annual metrics together with the diagnostics data can be copied to the clipboard by clicking on the button. The copied format consists of two parts as seen below in the example. The second part contains the diagnostics data which provides useful information that helps Camunda to improve support but customers can opt out of sharing it. This part has been truncated in the example. 21/02/2024 up to today - PI: 1,705,434 - DI: 1,709,410 - TU: 3 - FNI: 1,722,414 - EDE: 1,716,683 { \"installation\": \"bf32d0f5-43c6-4be4-b45e-de0ef1a48117\", \"product\": { \"name\": \"Camunda BPM Runtime\", \"version\": \"1.1.0\", \"edition\": \"community\", ... } }",
    "url": "/manual/latest/webapps/admin/system-management/index.html"
  },
  {
    "id": "manual/latest/webapps/admin/tenant-management/index.html",
    "title": "Tenant Management | docs.cibseven.org",
    "content": "Tenants Menu The Tenants menu allows you to add, edit and delete tenants. Besides that you can view which user or group is a member of a tenant. Create a new tenant All you have to do to create a new tenant is: Click the Create new tenant button Type the Tenant Id and Tenant Name in the corresponding input fields Click the Create new Tenant button This creates a new tenant. Add an user to a tenant To add an user to a tenant you have to go to the users account settings and click on the Tenants menu on the left side. In this menu you can click the Add to a tenant button and select the tenants where the user should be a member. Add a group to a tenant To add a group to a tenant you have to go to the group settings and click on the Tenants menu on the left side. In this menu you can click the Add to a tenant button and select the tenants where the group should be a member.",
    "url": "/manual/latest/webapps/admin/tenant-management/index.html"
  },
  {
    "id": "manual/latest/webapps/admin/user-management/index.html",
    "title": "User Management | docs.cibseven.org",
    "content": "Users Menu The Users menu allows you to add, edit and delete user profiles. Furthermore, you can manage group membership and change passwords. My Profile By clicking on your user name in the Users menu, you can access the My Profile menu. In the My Profile menu you can edit your personal account settings, such as: Profile: Change your name or email address. You cannot change the user account ID! Account: Change your password or delete/unlock your account. Be careful, deletion cannot be undone. Groups: This menu lists all groups of which you are member. With administrator rights you can assign your account to the available groups. You can also access the My Profile menu from any of the web applications by clicking on your user name at the top right and selecting My Profile. Initial User Setup If no administrator account is configured, a setup screen will be shown on first access of a process engine through Cockpit or Tasklist . This screen allows you to configure an initial user account with administrator rights. Administrator users are not global but per engine. Thus, you will need to set up an admin user for each separate engine. If you installed the default Camunda webapps and demo content, Camunda was configured with several demo users. The default admin user can be accessed with the following credentials: Username: demo Password: demo Administrator Account Users who belong to the group camunda-admin (default set by the invoice receipt demo process application) have administrator privileges. There must be at least one member in this group, otherwise the initial setup screen appears. Besides user- and groupmanagement, as administrator you are able to define authorization rules for a variety of resources. See the chapter on Authorizations for more details.",
    "url": "/manual/latest/webapps/admin/user-management/index.html"
  },
  {
    "id": "manual/latest/webapps/cockpit/bpmn/dashboard/index.html",
    "title": "Dashboard | docs.cibseven.org",
    "content": "The processes dashboard of Cockpit is the entry point for process monitoring. It comes with a pre-installed plugin, which lets you see deployed process definitions. Additional plugins can be added to the processes dashboard. Deployed Processes With this plugin you can easily observe the state of a process definition. Green and red dots signalize running and failed jobs. At this observing level a red dot signifies that there is at least one process instance or a sub process instance which has an unresolved incident. You can localize the problem by using the process definition view. With the search component above the table, you can search for deployed processes by their name or key. To do so, click in the search box and select the property. Both of these search properties support the ’like’ operator, which allows searching for process definitions where the entered value is a substring of the property value. Furthermore, you can copy a link to the current search query to your clipboard by clicking on the button and you can save search queries to your local browser storage by clicking on the button and inserting a name in the drop-down menu that appears. You can then retrieve the search query by clicking on the button and selecting the chosen name in the drop-down menu. You can also switch to the preview tab which displays the rendered process model of each deployed process. Additionally, you get information about how many instances of the process are currently running and about the process state. Green and red dots signalize running and failed jobs. Click on the model to go to the process definition view. CSV Export for Process Instances Sometimes incidents make it necessary for the Operations Engineer to intervene manually. However, these incidents might not always be solvable from Cockpit if other services or systems are involved. For this case, Cockpit provides a feature to export affected process instances and their process variable values as CSV spreadsheets. The export feature helps to communicate efficiently with other system owners. To trigger the CSV export, search for process instances and customize what properties you want to export by adding or removing columns. Suppose you are only interested in selecting specific process instances; you can checkmark the process instances of interest on the left side or select the whole page by checkmarking the box on the left side in the table header. You can select process instances across multiple pages. In the next step, you can choose a more coarse-grained process instance selection approach. When you are satisfied with your configuration of columns, query criteria, and selection of process instances, click . Clicking the button opens a modal dialog. You can define if you want to export your previous selection of process instances, the currently displayed page, or all pages. Additionally, you can specify process variables by name to enrich the export result with the values of these variables. Heads-up! Exporting all pages is more inefficient than exporting a selection or a single page of process instances and can cause extra load on the database and application server. Also, a more complex query that runs against an unbounded number of rows affects the execution time negatively. For security reasons, you can limit the maximum number of process instances that can be exported via the Query Maximum Results Limit. When clicking Export CSV, the backend crunches the requested data and creates a CSV file. This could take a while, depending on the amounts of process instances you want to export. As soon as the request succeeds, you should see a notification that the CSV creation was successful, and the button changes to Download as CSV. When you click the button, the download of the CSV file starts. Export Result The format of the export result is a file of Comma-separated values (CSV) (opens an external link to Wikipedia). Structure of the Spreadsheet Each row in the spreadsheet represents a process instance, while each property has its dedicated column. The spreadsheet has a dedicated column for each variable property and displays its value in the respective row that matches with the process instance. The spreadsheet displays: A null value as <<NULL>> An unsupported variable value type as <<UNSUPPORTED TYPE>> A non-existing variable as empty cell. Example Limitations You can only export variables with the following value types: boolean string date double, integer, long, short (number types) You can only export the value property of a variable. IN operator Cockpit provides IN operator support when filtering for process instances for the following query criteria: Process instance ID Business key Process definition key Variable value By default, the criteria defined in the search are linked together with a logical AND (conjunctive normal form). Occasionally, you may search for multiple query criterion values. The IN operator allows searching for multiple values where any of the values match. To use the IN operator, select a query criterion that supports the IN operator, and provide the values as a comma-separated list. To adjust the comma-separated list of values, start editing by clicking on the value. You can expand the value in a modal dialog for easier editing by clicking on the button.",
    "url": "/manual/latest/webapps/cockpit/bpmn/dashboard/index.html"
  },
  {
    "id": "manual/latest/webapps/cockpit/bpmn/drilldown/index.html",
    "title": "Collapsed Subprocesses | docs.cibseven.org",
    "content": "Diagrams can contain collapsed subprocesses to hide complexity on multiple levels. You can drill down into collapsed subprocesses with the drilldown icon. Process diagram If you have a collapsed subprocess in your diagram, a drilldown icon will appear in the lower right of the activity. The collapsed shape indicates if there are running child instances or if an incident occurred in a child activity. If you click on the drilldown icon, the diagram will show the contents of the collapsed subprocess. Use the breadcrumbs in the upper left corner of the diagram to navigate back to the parent process. The breadcrumbs show the process hierarchy. Opening an expanded subprocess opens the nearest collapsed subprocess. Migration When migrating collapsed subprocesses, be aware that the collapsed shapes hide other activities. The wizard only displays connections for the current layer. Additionally, collapsed subprocesses can have two badges: Status of the subprocess activity Status of the child activities If a child activity of the collapsed subprocess is not mapped or has an error, an additional badge is shown on the left of the shape.",
    "url": "/manual/latest/webapps/cockpit/bpmn/drilldown/index.html"
  },
  {
    "id": "manual/latest/webapps/cockpit/bpmn/failed-jobs/index.html",
    "title": "Failed Jobs | docs.cibseven.org",
    "content": "Unresolved incidents of a process instance or a sub process instance are indicated by Cockpit as failed jobs. To localize which instance of a process failed, Cockpit allows you to drill down to the unresolved incident by using the process status dots. Hit a red status dot of the affected instance in the Process Definition View to get an overview of all incidents. The Incidents tab in the Detailed Information Panel lists the failed activities with additional information. Furthermore, you have the possibility of going down to the failing instance of a sub process. Retry a Failed Job On the process instance view, you can use the button on the right side to resolve a failed job. A modal dialog opens where you can: Choose whether the previous due date should be kept or set to an absolute date/time of your choice. Select the failed jobs to be retried. After clicking on Retry, the engine will re-trigger the jobs and increment their retry values in the database so the Job Executor can acquire and execute the jobs again.",
    "url": "/manual/latest/webapps/cockpit/bpmn/failed-jobs/index.html"
  },
  {
    "id": "manual/latest/webapps/cockpit/bpmn/index.html",
    "title": "BPMN Processes in Cockpit | docs.cibseven.org",
    "content": "Cockpit allows monitoring of BPMN Processes. The dashboard is the entry point to the BPMN monitoring features. Either select a deployed process definition or search for a process instance. This will either take you to the process definition view or the process instance view.",
    "url": "/manual/latest/webapps/cockpit/bpmn/index.html"
  },
  {
    "id": "manual/latest/webapps/cockpit/bpmn/process-definition-view/index.html",
    "title": "Process Definition View | docs.cibseven.org",
    "content": "The process definition view provides you with information about the definition and the status of a process. On the left side you can easily survey the versions of the process and how many instances of the versions are running. Incidents of all running process instances are displayed together with an instance counter label in the corresponding rendered diagram. So it is easy to locate failed activities in the process. Use the mouse to navigate through the diagram. By pressing the CTRL key while turning the mouse wheel you can zoom in and out. Hold the left mouse button to pan the diagram in the desired direction. Furthermore, you can maximize the diagram view or the detailed information panel by clicking on, respectively, the button or the button, at the bottom left of the diagram view. In the Process Instances tab all running instances are listed in a tabular view. Besides information about start time, business key and state you can select an instance by ID and go down to the process instance view. The Called Process Definitions tab displays the called child processes. You can learn more about navigating called process definitions and this tab in the section about Call Activity Navigation. In the column Called Process Definition the names of the called sub processes are listed. Click on the name to display the process in the process definition view. Please note that a filter called Parent is automatically set for the process so that you only see the instances that belong to the parent process. In the Activity column you can select the instance that is calling the child process. The Job Definitions tab displays the job definitions that are linked to this process definition. Observe the name of the activity, the type of job, the configuration and the state thereof. You can also suspend and re-activate the job definition (see Job Definition Suspension for more information). It is also possible to set the priority of jobs. Filter The filter function on the bottom of the Process Definition View in the Process Instances tab allows you to find certain instances by filtering for variables, business keys, activity IDs or date and time. In addition, you can filter for the process definition version by selecting the version of a process on the left side of the Process Definition View. Beyond that you can combine different filters as logical AND relation. Filter expressions on variables must be specified as variableName OPERATOR value where the operator may be one of the following terms: =, !=, >, >=, <, <=, like. Apart from the like operator, the operator expressions do not have to be separated by spaces. The like operator is for string variables only. You can use % as wildcard in the value expression. String and date values must be properly enclosed in quotes \" \". Complex Data Types Please be aware that this feature does not support complex data types. Furthermore, you can copy a link to the current filter query to your clipboard by clicking on the button and you can save filter queries to your local browser storage by clicking on the button and inserting a name in the drop down menu that appears. You can then retrieve the filter query by clicking on the button and selecting the chosen name in the drop down menu. Runtime View Add a filter to the process definition view. Select a filter for variables, the start date and time, activity ID or the business key of process instances. Business Key Add a filter for process instances by business key. Start Date and Time Add a filter for process instances by start date. Please note that the date must be set in accordance to the ISO 8601 standard. Choose between before and after to filter for instances that were started before or after the given date. For example, click on before to obtain the selection. String variable Add a filter for process instances by filtering for a string value. Please note that you should not encase the value in quotation marks. Boolean variable Add a filter for process instances by filtering for a boolean value. Numeric variable Add a filter for process instances by filtering for a numeric (double, integer, long or short) value. Set Job priority You can change the job priority by overriding the priority specified in the BPMN 2.0 XML. To do so, click on the icon in the Job Definitions tab. In the opened dialog you can override the job priority. If an overridden priority is already set, you can clear it to use the priority specified in the XML again. It is also possible to include existing jobs when changing the priority. By using the button to the right of the process diagram, you can set the job priority of all jobs contained in the process definition at once. Call Activity Navigation You can navigate from a process that contains Call Activities to its respectively called process definitions. Hover over a Call Activity in the BPMN diagram to display a link in the upper right corner of the Call Activity. Limitation When a to be called process is referenced via a process variable or an expression, the called process can only be determined at runtime. For these types of call activities, the diagram shows a greyed out overlay, unless there is currently a process instance running at that call activity. Additionally, you can use the called process definitions tab to get an overview of which call activity calls which process definition. We differentiate between three states: Referenced: the called process definition can be derived without any runtime information. Running and referenced: the called process definition can be derived without any runtime information and a call activity in this process is currently calling it. Running: There is currently a process instance calling this process definition. However, the called process definition can only be resolved at runtime and is only valid for a particular process instance. For more drill down options on call activities you can check out the process instance view.",
    "url": "/manual/latest/webapps/cockpit/bpmn/process-definition-view/index.html"
  },
  {
    "id": "manual/latest/webapps/cockpit/bpmn/process-instance-view/index.html",
    "title": "Process Instance View | docs.cibseven.org",
    "content": "Open the process instance view by selecting a process instance from the process definition view instance list. This view allows you to drill down into a single process instance and explore its running activities as well as the variables, tasks, jobs, etc. Beside the diagram view the process will be displayed as an activity instance tree view. Variables that belong to the instance will be listed in a variables table of the detailed information panel. Now you can select single or multiple (‘ctrl + click’) flow nodes in the interactive BPMN 2.0 diagram or you can select an activity instance within the activity tree view. As diagram, tree view and variables table correspond with each other, the selected flow node will also be selected in the tree and the associated variables will be shown and vice versa. Furthermore, you can maximize the diagram view or the detailed information panel by clicking on the button, respectively the button, at the bottom left of the diagram view. Activity Instance Tree The activity instance tree contains a node for each activity that is currently active in the process instance. It allows you to select activity instances to explore their details. Concurrently, the selected instance will be marked in the rendered process diagram and the corresponding variables will be listed in the detailed information panel. Call Activity Drill Down Call activity instances that call at least one process instance have an overlay on the upper right corner that links to their called process instances. If the call activity instance calls exactly one process instance, then clicking the overlay redirects to the called process instance page. However, if the number of called process instances exceeds one, then clicking the overlay will show the called process instances tab containing only process instances called by the selected call activity instance. Detailed Information Panel Use the detailed information panel to get an overview of the variables, incidents, called process instances, user tasks and external tasks that the process instance contains. In addition to the instance information you can edit variables or change the assignees of user tasks. In the incidents tab you can click on the incident message name, which will open the stacktrace of the selected incident. Furthermore, you can increment the number of retries for a failed job by hitting the button. The user tasks tab allows managing users and groups for selected user tasks. Hit the or button to open the corresponding menu. The jobs tab gives you an overview of all currently active jobs. If the job has a duedate, you can edit the duedate by clicking on the button. A dialogue will open where you can choose to recalculate the duedate based on the current time or its creation time. It is also possible to set a specific duedate. Furthermore, you can suspend or activate a job by pressing the or button respectively. The external tasks tab displays various information about external tasks, such as the External Task Id, the activity, amount of retries, the Worker Id of the external task, lock expiration time, topic name and the set priority. See the external tasks section of the user guide for more information about external tasks. Filter for Variables In the variables tab, you can filter for variables by variable name, activity instance id and variable value by using search pills. You can filter variable values with the type String, Number, or Boolean. To do so, click in the empty search field and select a criterion. Next, fill in the respective values for the search pill. You can combine multiple search pills to narrow down the results. The total amount of results that suit the search query is displayed to the right. Furthermore, you can copy a link to the current search query to your clipboard by clicking on the button and you can save search queries to your local browser storage by clicking on the button and inserting a name in the drop down menu that appears. You can then retrieve the search query by clicking on the button and selecting the chosen name in the drop down menu. Add Variables Hit the button on the right side to add variables to a process instance. You can choose between different data types. Please note that variables will be overwritten if you add a new variable with an existing name. Edit Variables Edit variables in the list of variables by using the symbol. This feature allows you to change the value of variables as well as the type. A validation of the date format and for the value of integers happens on client side. If you enter NULL the variable will be converted to a string type. Cancel a Process Instance In the process instance view you can cancel a single process instance. Hit the button on the right side. In the dialog that appears, you can choose to skip custom listeners and to skip I/O mappings. After you have completed this step, a confirmation dialog appears and the runtime data of the canceled instance is deleted.",
    "url": "/manual/latest/webapps/cockpit/bpmn/process-instance-view/index.html"
  },
  {
    "id": "manual/latest/webapps/cockpit/bpmn/suspension/index.html",
    "title": "Suspension | docs.cibseven.org",
    "content": "In the process definition view and in the process instance view you can suspend the selected process definition or process instance by using the button on the right side. Process Definition Suspension If you suspend the process definition, you prevent the process definition from being instantiated. No further operations can be done while the process definition is in the suspended state. You can simply re-activate the process definition by using the button on the right side. You have the option of suspending/reactivating all process instances of the process definition as well as defining if the process definition (and process instances) should instantly be suspended/reactivated or at a specific time in a confirmation dialog. Find more information about this functionality in the suspending process definitions section of the process engine chapter. Process Instance Suspension If you suspend the process instance, you can prevent the process instance from being executed any further. This includes suspending all tasks included in the process instance. You can simply re-activate the process instance by using the button on the right side. Find more information about this functionality in the suspending process instances section of the process engine chapter. Job Definition Suspension In the Process Definition View you have the option of suspending a job definition. This can be done by using the button displayed in the Action column of the Job Definitions tab at the bottom of the screen. By doing this, you can prevent this job definition from being processed in all process instances of the selected process definition. You can simply re-activate the job definition by using the button in the same Action column. Find more information about this functionality in the suspending and activating job execution section of the user guide.",
    "url": "/manual/latest/webapps/cockpit/bpmn/suspension/index.html"
  },
  {
    "id": "manual/latest/webapps/cockpit/dashboard/index.html",
    "title": "Dashboard | docs.cibseven.org",
    "content": "The dashboard of Cockpit provides a quick overview of running and historic operations as well as details about deployments. At the top of the dashboard you can see a plugin with pie charts that display the amount of running process instances, open incidents and open human tasks. By clicking on the number or a section of the pie chart, you are forwarded to the respective search with preselected query parameters. On the right hand side, you see an overview of deployed process definitions, decision definitions, case definitions and the total number of deployments. Additional plugins can be added to the dashboard. Multi Engine If you are working with more than one engine, you can select the desired engine via a dropdown selection. Cockpit provides all information of the selected engine.",
    "url": "/manual/latest/webapps/cockpit/dashboard/index.html"
  },
  {
    "id": "manual/latest/webapps/cockpit/deployment-view/index.html",
    "title": "Deployment View | docs.cibseven.org",
    "content": "The deployment view of Cockpit shows an overview of all deployments, their resources and the content of these resources. It allows the deletion of existing deployments as well as redeployment of old resources and the creation of new deployments. The content of resources within deployments can be displayed. It is also possible to download single resources from this view. Search Use the search field at the top of the list of deployments to find specific deployments. Similar to the search on the cockpit dashboard and in tasklist, it is possible to search deployments using an array of available criteria. Valid search criteria are unique ID, name (which does not need to be unique across all deployments), time of deployment and source. The deployment source can be provided when a deployment is created. A deployment that is created by the application during startup will have this property set to process application. You can also search for deployments that have no deployment source set using the Source undefined criterion. Furthermore, you can copy a link to the current search query to your clipboard by clicking on the button and you can save search queries to your local browser storage by clicking on the button and inserting a name in the drop down menu that appears. You can then retrieve the search query by clicking on the button and selecting the chosen name in the drop down menu. Independently of the search, ordering for the deployment list can be set using the sorting parameter above the search field. It is possible to order by ID, name and deployment time. Clicking on the arrow on the right side of the sorting criterion changes the ordering (ascending and descending). Delete To delete a deployment, hover over the deployment and click on the deletion icon . In the dialog that appears, you can choose to cascade the deletion (i.e., also delete running and historic process instances) and you can choose to skip custom listeners and I/O mappings. After you have completed this step, the deployment is deleted. Definition Resources For resources that contain definitions (BPMN, DMN and CMMN files), a preview of the diagram or the table is displayed on the right side of the page as well as the version number of the definitions contained in this resource. At the bottom of the page, there is a list of definitions with a link to the respective definition pages.",
    "url": "/manual/latest/webapps/cockpit/deployment-view/index.html"
  },
  {
    "id": "manual/latest/webapps/cockpit/dmn/dashboard/index.html",
    "title": "Dashboard | docs.cibseven.org",
    "content": "The decisions dashboard of Cockpit is the entry point for decision monitoring. It comes with a pre-installed plugin, which lets you see deployed decision definitions. Additional plugins can be added to the decisions dashboard. Deployed Decisions This plugin provides you with a list of deployed decision definitions. You can click on the name of a decision to go to the decision definition view and access more details. Deployed Decision Requirements Definition This plugin provides you with a list of deployed decision requirements definitions. You can click on the name of a decision requirements definition to go to the [decision requirements definition view][decision-requirements-definition-view] and access more details.",
    "url": "/manual/latest/webapps/cockpit/dmn/dashboard/index.html"
  },
  {
    "id": "manual/latest/webapps/cockpit/dmn/decision-definition-view/index.html",
    "title": "Decision Definition View | docs.cibseven.org",
    "content": "On the decision definition view, you can find a table or literal expression of the deployed decision definition. You can change the version of the decision definition in the dropdown menu on the left side. The table or literal expression is then updated accordingly. You can also navigate to the deployment of the selected version that contains the decision definition. Clicking the navigate to deployment button will take you to the deployment view. You can maximize the table view or the detailed information panel by clicking on the button, respectively the button, at the bottom left of the table view. Below the decision table you find a listing of all instances for this definition. You can also search for decision instances which fulfill certain search criteria. To do so, click in the search box and select the parameters to search for. You can also begin typing to find the required parameter faster. You have to specify the value of the selected property to perform the search and you can combine multiple search pills to narrow down the search results. Furthermore, you can copy a link to the current search query to your clipboard by clicking on the button and you can save search queries to your local browser storage by clicking on the button and inserting a name in the drop down menu that appears. You can then retrieve the search query by clicking on the button and selecting the chosen name in the drop down menu. If the decision instance was executed in the context of a process, you can also find the process definition as well as the process instance id that executed that specific decision instance. Clicking on the links takes you to the respective pages. Clicking on the id of the decision instance takes you to the decision instance view.",
    "url": "/manual/latest/webapps/cockpit/dmn/decision-definition-view/index.html"
  },
  {
    "id": "manual/latest/webapps/cockpit/dmn/decision-instance-view/index.html",
    "title": "Decision Instance View | docs.cibseven.org",
    "content": "On the decision instance page you find the table or literal expression of the decision that was executed as well as the values for the input variables and the decision result. The input and output values for this decision instance are shown directly on the table in the corresponding cells as well as in the Inputs and Outputs tabs below the table. Complex variables like Objects, Files and Bytes are not displayed on the table. You have to use the Inputs and Outputs tabs to access the values of these variables. Rules that have matched during the execution of the decision table are highlighted. Furthermore, you can maximize the table view or the detailed information panel by clicking on the button, respectively the button, at the bottom left of the table view.",
    "url": "/manual/latest/webapps/cockpit/dmn/decision-instance-view/index.html"
  },
  {
    "id": "manual/latest/webapps/cockpit/dmn/index.html",
    "title": "DMN Decisions in Cockpit | docs.cibseven.org",
    "content": "Cockpit allows monitoring of DMN Decisions. The dashboard is the entry point to the DMN monitoring features. Select a deployed decision definition to get to the decision definition view. All data that is displayed about decision definitions and decision instances is based on historic data. Unlike process definitions and process instances, there is no runtime data, as decisions are executed instantly without intermediary wait states or save points.",
    "url": "/manual/latest/webapps/cockpit/dmn/index.html"
  },
  {
    "id": "manual/latest/webapps/cockpit/extend/configuration/index.html",
    "title": "Configuration | docs.cibseven.org",
    "content": "You can override the default configuration of Cockpit using a central configuration file located in app/cockpit/scripts/config.js. The following configuration options are available: Logo and Header Color You can change the visual aspects of Cockpit. The user stylesheet file is located in app/cockpit/styles/user-styles.css. This file contains CSS which is loaded into Cockpit and can override the standard styles. /* hides the CIB seven logo */ .app-banner svg { display: none; } .app-banner { /* hides the \"CIB seven Cockpit\" text */ text-indent: 200vw; /* put your logo */ background-image: url(./path/to/the/logo.png); /* sets the width to match the logo's width */ width: 80px; } /* changes the header top border color */ .Header { border-top-color: blue !important; } Note: you can also change the app name (Cockpit) and vendor (CIB seven) by changing the app/cockpit/scripts/config.js configuration file as follow: export default { // … app: { name: 'Operations', vendor: 'Company' }, } Localization Cockpit can be localized. CIB seven maintains English and German translation files. You can find and download community maintained translation files at the Camunda webapp translations repository. The localization of Cockpit is contained in the app/cockpit/locales/ directory. This directory contains a separate localization file for every available language. The file name consists of the language code and the suffix .json (e.g., en.json). Cockpit uses a locale file corresponding to the language settings of the browser. You can set the availableLocales property in the configuration file to provide a list of available locales. Every locale which is contained in this list must have a locale file in the locales directory with the corresponding language code. If the browser uses a language which is not available, Cockpit uses the locale which is defined via the fallbackLocale property in the configuration file: export default { // … \"locales\": { \"availableLocales\": [\"en\", \"de\"], \"fallbackLocale\": \"en\" } } To create a new localization for Cockpit, copy the provided language file, translate it and save it as new localization file with the corresponding language code. To make the new translation available, add it to the list of available locales in the configuration file. Custom Scripts Cockpit allows you to include arbitrary JavaScript files. This allows you to extend Cockpit with custom code. The script file might contain a custom frontend module as described in Cockpit Plugins - Structure of a Frontend Module. Add your files to the customScripts property of the app/cockpit/scripts/config.js file: export default { // … customScripts: ['custom-module/module.js'] }; This includes a custom-module/module.js file. The path is relative to the app/cockpit folder in the CIB seven webapp .war file. You can find a complete example about how to use customScripts to develop a Cockpit Plugin in the CIB seven examples repository. Legacy Custom Scripts Custom Scripts created for CIB seven.13 or earlier can be included using the requireJsConfig property to the app/cockpit/scripts/config.js. You can include these custom scripts using the custom requireJS configuration. export default { // … requireJsConfig: { // names of angular modules defined in your custom script files. // will be added to the 'cam.cockpit.custom' as dependencies ngDeps: ['my.custom.module'], // RequireJS modules to load. deps: ['custom-ng-module'], // RequreJS path definitions paths: { 'custom-ng-module': '../custom-ng-module/script' } } } For more details about legacy Plugins, check out the legacy plugin documentation of Camunda. Please note that this link will take you to the documentation of Camunda 7.13 . BPMN Diagram Viewer (bpmn.js) The diagram viewer (bpmn.js) can be either customized by moddle extensions or additional modules. To extend the BPMN diagram viewer of Cockpit, a bpmnJs property must be added to the app/cockpit/scripts/config.js file. Additional Modules To add modules, the additionalModules property needs to be specified, where each module is registered with its path. The path is relative to the app/cockpit folder in the .war file of the CIB seven Webapp. export default { // … bpmnJs: { additionalModules: [ 'my-custom-module/module' ] } } You can find an example on how to add an additional bpmn.js module to Cockpit in the CIB seven examples repository. Moddle Extensions The BPMN moddle can be extended by adding a moddleExtensions property. Each moddle extension has a unique name (key) and a path (value) to the JSON file of the moddle extension. The path is relative to the app/cockpit folder in the .war file of the CIB seven Webapp. The suffix .json of the file is added automatically and must not be specified. export default { // … bpmnJs: { moddleExtensions: { camunda: 'my-custom-moddle/camunda' } } } skipCustomListeners and skipIoMappings Flags You can configure the skipCustomListeners and the skipIoMappings flag globally for cockpit by adding a skipCustomListeners or skipIoMappings property in app/cockpit/scripts/config.js: export default { skipCustomListeners: { default: true, // default value for skipCustomListeners is true hidden: false // skipCustomListeners checkbox is not hidden }, skipIoMappings: { default: true, // default value for skipIoMappings is true hidden: false // skipIoMappings checkbox is not hidden } }; By default (if not configured), the flag value is true. However, you can set the default value of the flag (true | false) in the default property in the configuration. Moreover, the checkbox to enable/disable the option is by default not hidden in Cockpit. You can set this behaviour by configuring the property hidden (true | false) in the configuration. If the hidden value is configured to be false, then the checkbox will be hidden everywhere in Cockpit. Runtime Activity Instance Metrics (Process Definition) export default { runtimeActivityInstanceMetrics: { display: true } }; By default the activity instance statistics are displayed for the runtime view of the process definition. Hence, the default value of the display flag is true. If the statistics shouldn’t be displayed initially process definition runtime view is opened, the display option needs to be set to false. In any case does the toggle button allow to display/remove the statistics on demand. Historic Activity Instance Metrics export default { historicActivityInstanceMetrics: { adjustablePeriod: true, //select from the default time period: day, week, month, complete period: { unit: 'day' } } }; By default, the adjustablePeriod flag value is true. Setting it to false disables the ability in the process definition history view to manually select the time period for which the activity instances are displayed. the unit property of period allows to specify the default timer period for which the activity instance badges are supposed to be shown. Here it is possible to select form the range of values: today, week,month,complete; Default Filter for the Historic Process Instances Search export default { defaultFilter: { historicProcessDefinitionInstancesSearch: { lastDays: 5, event: 'started' } } }; A default filter can be applied for the historic process instances search on the historic process definition view. Like this, it is possible to reduce the amount of instances which are being retrieved at the same time. It is configurable, for how many days in the past instances are queried based on the start or the end time of historic process instances. The property lastDays specifies the numeric amount of days in the past based on the current time The property event can be either set to ‘started’ or ’ended’ Change CSRF Cookie Name The default name of the CSRF Cookie is XSRF-TOKEN. When using other applications within the same-origin, the CSRF mechanisms could interfere with each other. To avoid the name conflict, you can change the name of the CSRF cookie in the config.js file as follows: export default = { // … csrfCookieName: 'MY-XSRF-TOKEN' }; Note: Please make sure to change the CSRF cookie name also on server-side. Disable Welcome Message for new Users First-time visitors are shown a message directing them to the CIB seven welcome page. If you do not want this message to be shown, you can disable it by adjusting the config.js as follows: export default = { // … disableWelcomeMessage: true }; Note: This does only affect the Cockpit login page. For other webapps, you need to adjust the corresponding config file as well. User Operation Log Annotation Length The default maximum length of a User Operation Log annotation is 4000 characters. Some databases have smaller limits. You can change the maximum allowed input length in the config.js file as follows: export default = { // … userOperationLogAnnotationLength: 4000 }; Note: This does only affect the Cockpit Operation Log. For the Admin Operation Log, check out the Admin Configuration. Preview Deployed Embedded Forms You can view a preview of embedded forms and other HTML files in the Cockpit deployment view. If the HTML has embedded <script> tags, they will be executed, which may have unintended side-effects. You can disable this feature if you don’t trust your deployed HTML files in the config.js file as follows: export default = { // … previewHtml: false };",
    "url": "/manual/latest/webapps/cockpit/extend/configuration/index.html"
  },
  {
    "id": "manual/latest/webapps/cockpit/extend/index.html",
    "title": "Extend and customize Camunda Cockpit | docs.cibseven.org",
    "content": "It is possible to extend and customize Camunda Cockpit.",
    "url": "/manual/latest/webapps/cockpit/extend/index.html"
  },
  {
    "id": "manual/latest/webapps/cockpit/extend/plugins/index.html",
    "title": "Cockpit Plugins | docs.cibseven.org",
    "content": "Cockpit defines a plugin concept to add own functionality without being forced to extend or hack the Cockpit web application. You can add plugins at various plugin points, e.g., the processes dashboard as shown in the following example: The Nature of a Cockpit Plugin A Cockpit plugin is a maven jar project that is included in the Cockpit webapplication as a library dependency. It provides a server-side and a client-side extension to Cockpit. On the server-side, it can extend Cockpit with custom SQL queries and JAX-RS resource classes. Queries (defined via MyBatis) may be used to squeeze additional intel out of an engine database or to execute custom engine operations. JAX-RS resources on the other hand extend the Cockpit API and expose data to the client-side part of the plugin. On the client-side a plugin may include Javascript modules to extend the Cockpit webapplication. Via those modules a plugin provides custom views. File structure The basic skeleton of a Cockpit plugin looks as follows: cockpit-plugin/ ├── src/ | ├── main/ | | ├── java/ | | | └── org/my/plugin/ | | | ├── db/ | | | | └── MyDto.java (5) | | | ├── resource/ | | | | ├── MyPluginRootResource.java (3) | | | | └── ... (4) | | | └── MyPlugin.java (1) | | └── resources/ | | ├── META-INF/services/ | | | └── org.cibseven.bpm.cockpit.plugin.spi.CockpitPlugin (2) | | ├── org/my/plugin/queries/ (6) | | | └── sample.xml | | └── plugin-webapp/MyPlugin/ (7) | | └── app/ | | ├── plugin.js (8) | | ├── plugin.css (9) | | └── ... | └── test/ | ├── java/ | | └── org/my/plugin/ | | └── MyPluginTest.java | └── resources/ | └── camunda.cfg.xml └── pom.xml As runtime relevant resource it defines a plugin main class a META-INF/services entry that publishes the plugin to Cockpit a plugin root JAX-RS resource that wires the server-side API. When you want to include a frontend module in your plugin, you can use AbstractCockpitPluginRootResource as the plug-in resources base class. This allows you to serve static client-side resources under the /static path. Per convention, these resources must reside in a /plugin-webapp/$plugin_id directory absolute to the classpath root. the plugin root resource has to explicitly declare the assets that are allowed to be served via the REST API. You can declare your assets by overriding the AbstractAppPluginRootResource#getAllowedAssets() method in your root resource. Undeclared assets won’t be served. The default implementation contains two predefined assets: app/plugin.js and app/plugin.css. other resources that are part of the server-side API data transfer objects used by the resources mapping files that provide additional Cockpit queries as MyBatis mappings resource directory from which client-side plugin assets are served as static files a js file that exports a frontend module. This file must be named plugin.js and be located in the app directory of the plugin asset directory a css file that contains the style definitions for the client-side plugin. This file must be named plugin.css and be located in the app directory of the plugin asset directory Related Example How to develop a Cockpit plugin Structure of a Frontend Module A frontend module always follows the same structure. This is how a sample plugin.js could look like: export default { id: \"customPlugin\", pluginPoint: \"cockpit.dashboard\", priority: 5, render: container => { container.innerHTML = \"Hello World!\"; } }; This file can also be included standalone as a custom script. Important notes about the structure The default export is either one plugin or an array of plugins. Only the default export will be considered in Cockpit. The render function must not have a return value. Attributes in Detail id: A string which defines this plugin. Should be unique across the application. This can be used to exclude plugins, see Plugin exclusion. pluginPoint: A string which describes where the plugin is rendered. This also defines which parameters are passed into the render function, see the plugin point reference priority: Number, describes in which order the plugins at the same pluginPoint will be mounted. For certain Plugin points (like cockpit.navigation), a negative priority hides the entry in a dropdown. How this is handled depends on the Plugin Point. render: Function, the heart of your Plugin. Arguments are (DOMNode|BPMNioViewerInstance, additionalData (Object)). Using the DOM node, you can render your plugin into the DOM. The second argument contains API endpoints and CSRF cookie information, as well as constants like a processDefinitionId. The api key is always present and contains engine: the engine name CSRFToken: the current CSRF token for your requests baseApi, adminApi, cockpitApi, engineApi: The paths to different API endpoints. The engineApi corresponds to the Rest Api The details of which data is passed into the plugin can be found at the plugin point reference. result: Function, only available in data plugins. Argument is a (Promise). unmount: Optional function which is called when the Plugin is unmounted. Use this to cleanup any listeners you or your Framework might have registered. properties: Optional object which contains all additional configuration for the plugin point, such as labels. Plugin Exclusion (Client Side) You can exclude some plugins from the interface by adding a cam-exclude-plugins attribute to the HTML base tag of the page loading the interface. The content of the attribute is a comma separated list formatted like: <plugin.key>:<feature.id>. If the feature ID is not provided, the whole plugin will be excluded. Excluding a Complete Plugin This example will completely deactivate the action buttons on the right side of the process instance view. <base href=\"/\" cam-exclude-plugins=\"cockpit.processInstance.runtime.action\" /> Excluding a Plugin Feature In this example we deactivate the cancel action in the Cockpit process instance view and disable the job retry action button: <base href=\"/\" cam-exclude-plugins=\"cockpit.processInstance.runtime.action:cancel-process-instance-action, cockpit.processInstance.runtime.action:job-retry-action\" /> Legacy Plugins Plugins created for Camunda 7.13 or earlier can be included for compatibility. To achieve this, simply prefix your Plugin ID with legacy-. The AngularJS module name for the entry module will be cockpit.plugin.legacy-*. Please note that all Plugins with this prefix will be included using the 7.13 plugin mechanism. You cannot create new Plugins with IDs starting with legacy. For more details about legacy Plugins, check out the legacy Plugin documentation for Camunda. Please note that this link will take you to the documentation of Camunda 7.13 . Plugin points In this section you will find all Cockpit plugin points. To configure where you place your plugin, enter the ID into the pluginPoint attribute of you frontend module. Plugin Points describe where a Plugin will be rendered and define which additional data is passed into the second argument of the render function. For more information on creating and configuring your own plugin, please see How to develop a Cockpit plugin. Data Data Plugin Points have a #result function that gets the response data as a promise of a called REST endpoint passed. The #result function is called when the respective HTTP request is performed. The first argument of the #result function is a (Promise). Login Data Name: cockit.login.data REST Endpoint: POST /camunda/api/admin/auth/user/default/login/cockpit When a user clicks on the Login button of the login form, the plugin points #result function is called. Your Login Plugin can react to the data that this data plugin will retrieve. This plugin point is available for all web apps. Just change the canonical app name for the respective webapp (tasklist.login.data, admin.login.data, welcome.login.data). Route Name: cockpit.route This plugin points properties contain the attribute path, which stands for the hashRoute for this page. This will be rendered when the user navigates in the browser to the url, e.g. #/my-path. properties: { path: \"/my-path\" } Navigation Name: cockpit.navigation This plugin point can be used in conjunction with a cockpit.route plugin or for shortcuts to existing pages. Negative priority will hide the entry in a drop-down. This plugin points properties contain the attribute path, which matches the location to highlight the active menu entry when the user is on a certain page. The value can be a regex. If no path is set, the menu entry will never be highlighted. properties: { path: \"/my-path\" } Login Name: cockpit.login The cockpit.login plugin point allows to add your custom views at the place where the web app renders the login form. This plugin point is available for all web apps. Just change the canonical app name for the respective webapp (tasklist.login, admin.login, welcome.login). Dashboard Name: cockpit.dashboard The cockpit.dashboard plugin point will allow to add your custom views at the bottom of the dashboard. Metrics Name: cockpit.dashboard.metrics Processes Dashboard Name: cockpit.processes.dashboard Decisions Dashboard Name: cockpit.decisions.dashboard Cases Dashboard Name: cockpit.cases.dashboard Process Definition Runtime Tab Name: cockpit.processDefinition.runtime.tab This plugin points properties contain the attribute label, which will be rendered in the navigation even when the plugin is not selected. properties: { label: \"My Plugin\" } This additional data is passed into the render function: processDefinitionId Process Instance Runtime Tab Name: cockpit.processInstance.runtime.tab This plugin points properties contain the attribute label, which will be rendered in the navigation even when the plugin is not selected. properties: { label: \"My Plugin\" } This additional data is passed into the render function: processInstanceId Process Definition Runtime Action Name: cockpit.processDefinition.runtime.action This additional data is passed into the render function: processDefinitionId Process Instance Runtime Action Name: cockpit.processInstance.runtime.action This additional data is passed into the render function: processInstanceId Process Definition View Name: cockpit.processDefinition.view Process Instance View Name: cockpit.processInstance.view Process Definition Diagram Overlay Name: cockpit.processDefinition.diagram.plugin Diagram overlay plugins are a little different from other plugins. This plugin point does not receive a DOM node to render into but an instance of the Diagram viewer to create an overlay. export default { id: \"myOverlay\", pluginPoint: \"cockpit.processDefinition.diagram.plugin\", priority: 0, render: (viewer, {processDefinitionId}) => { viewer.get(\"overlays\").add( // ... ) } }; This additional data is passed into the render function: processDefinitionId Process Instance Diagram Overlay Name: cockpit.processInstance.diagram.plugin Diagram overlay plugins are a little different from other plugins. This plugin point does not receive a DOM node to render into but an instance of the Diagram viewer to create an overlay. See Process Definition Diagram Overlay for an example. This additional data is passed into the render function: processInstanceId Job Definition Action Name: cockpit.jobDefinition.action This additional data is passed into the render function: jobDefinitionId Decision Definition Tab Name: cockpit.decisionDefinition.tab This plugin points properties contain the attribute label, which will be rendered in the navigation even when the plugin is not selected. properties: { label: \"My Plugin\" } This additional data is passed into the render function: decisionDefinitionId Decision Definition Action Name: cockpit.decisionDefinition.action This additional data is passed into the render function: decisionDefinitionId Decision Definition Table Name: cockpit.decisionDefinition.table Diagram overlay plugins are a little different from other plugins. This plugin point does not receive a DOM node to render into but an instance of the Diagram viewer to create an overlay. See Process Definition Diagram Overlay for an example. This additional data is passed into the render function: decisionDefinitionId Decision Instance Tab Name: cockpit.decisionInstance.tab This plugin points properties contain the attribute label, which will be rendered in the navigation even when the plugin is not selected. properties: { label: \"My Plugin\" } This additional data is passed into the render function: decisionInstanceId Decision Instance Action Name: cockpit.decisionInstance.action This additional data is passed into the render function: decisionInstanceId Decision Instance Table Name: cockpit.decisionInstance.table Diagram overlay plugins are a little different from other plugins. This plugin point does not receive a DOM node to render into but an instance of the Diagram viewer to create an overlay. See Process Definition Diagram Overlay for an example. This additional data is passed into the render function: decisionInstanceId Case Definition Tab Name: cockpit.caseDefinition.tab This plugin points properties contain the attribute label, which will be rendered in the navigation even when the plugin is not selected. properties: { label: \"My Plugin\" } This additional data is passed into the render function: decisionInstanceId Case Definition Action Name: cockpit.caseDefinition.action This plugin points properties contain the attribute label, which will be rendered in the navigation even when the plugin is not selected. properties: { label: \"My Plugin\" } This additional data is passed into the render function: caseDefinitionId Case Definition Diagram Overlay Name: cockpit.caseDefinition.diagram.overlay Case Definition Diagram Plugin Name: cockpit.caseDefinition.diagram.plugin Diagram overlay plugins are a little different from other plugins. This plugin point does not receive a DOM node to render into but an instance of the Diagram viewer to create an overlay. See Process Definition Diagram Overlay for an example. This additional data is passed into the render function: caseDefinitionId Case Instance Tab Name: cockpit.caseInstance.tab This plugin points properties contain the attribute label, which will be rendered in the navigation even when the plugin is not selected. properties: { label: \"My Plugin\" } This additional data is passed into the render function: caseInstanceId Case Instance Action Name: cockpit.caseInstance.action This additional data is passed into the render function: caseInstanceId Case Instance Diagram Overlay Name: cockpit.caseInstance.diagram.overlay Case Instance Diagram Plugin Name: cockpit.caseInstance.diagram.plugin Diagram overlay plugins are a little different from other plugins. This plugin point does not receive a DOM node to render into but an instance of the Diagram viewer to create an overlay. See Process Definition Diagram Overlay for an example. This additional data is passed into the render function: caseDefinitionId caseInstanceId Repository Resource Action Name: cockpit.repository.resource.action This additional data is passed into the render function: deploymentId resourceId Repository Resource Detail Name: cockpit.repository.resource.detail This additional data is passed into the render function: deploymentId resourceId Open Task Dashboard Name: cockpit.tasks.dashboard Incident Action Name: cockpit.incident.action This additional data is passed into the render function: incidentId",
    "url": "/manual/latest/webapps/cockpit/extend/plugins/index.html"
  },
  {
    "id": "manual/latest/webapps/cockpit/index.html",
    "title": "Cockpit | docs.cibseven.org",
    "content": "CIB seven Cockpit is a web application for monitoring and operations. It provides access to deployed BPMN processes and DMN decisions, allows searching though running and ended instances and performing operations on these. The Cockpit architecture is extensible allowing it to be extended through plugins. Cockpit & History Levels A big part of Cockpit’s functionality relies on historical data, and some of this historical data is only provided through the FULL History Level. Therefore, to gain the full feature set of Cockpit, and not suffer any UX degradation due to unavailable data, History Level FULL should be set.",
    "url": "/manual/latest/webapps/cockpit/index.html"
  },
  {
    "id": "manual/latest/webapps/cockpit/tasks-dashboard/index.html",
    "title": "Open Tasks Dashboard | docs.cibseven.org",
    "content": "You can use the open tasks dashboard to see how the open tasks are distributed by individual factors. Refer to the Cockpit Plugins section for information about adding a custom open task dashboard plugin. Open Tasks Assignments by type In this category you can see how many open tasks exist. There is also an overview which shows how the open tasks are distributed. Assignment by group This category provides you an overview which shows how all open tasks which are assigned to a group are distributed between the individual groups.",
    "url": "/manual/latest/webapps/cockpit/tasks-dashboard/index.html"
  },
  {
    "id": "manual/latest/webapps/index.html",
    "title": "Web Applications | docs.cibseven.org",
    "content": "Docs Get Started CIB seven Security cibseven.org CIB seven 1.1 Introduction Download Licenses Implemented Standards Architecture Overview Supported Environments Extensions Third-Party Libraries CIB seven License Book Public API User Guide Process Engine Process Engine Bootstrapping Process Engine API Process Engine Concepts Process Variables Process Instance Modification Process Instance Restart Delegation Code Expression Language Scripting Templating Custom Code & Security External Tasks Connectors Process Versioning Process Instance Migration Database Database Schema Database Configuration Microsoft SQL Server and Azure SQL Database Configuration MySQL Database Configuration Performance History History configuration User operation log History cleanup Custom implementation Deployment Cache Password Hashing Password Policy Transactions in Processes The Job Executor Multi-Tenancy Id Generators Metrics Incidents Process Engine Plugins Identity Service Authorization Service Deployments Process Diagram Visualization Time zones Decisions Configuration Repository Decision Service Decisions in BPMN & CMMN History Batch Batch operations Error Handling Diagnostics data Process Applications The Process Application class The processes.xml Deployment Descriptor Process Application Event Listeners Process Application Resource Access Maven Project Templates (Archetypes) Runtime Container Integration CIB seven Services JNDI Bindings for CIB seven Services Apache Tomcat WildFly Job Execution with Managed Resources CIB seven Run Spring Framework Integration Bootstrapping Transactions Deployment Spring Bean Resolving Testing Spring Boot Integration Version Compatibility Configuration REST API Web Applications Process Applications Spring Eventing Bridge Developing and Testing Spring Security OAuth2 Integration Quarkus Integration Version Compatibility Configuration Engine CDI Integration Resource Deployments CDI and Java EE Integration JTA Transaction Integration Expression Resolving Contextual Programming Model Built-In Beans CDI Event Bridge Testing Assert Examples Model API BPMN Model API Read a Model Create a Model Delegation Code Fluent Builder API Repository Service Extension Elements CMMN Model API Read a Model Create a Model Delegation Code Repository Service Extension Elements Limitations DMN Model API Read a Model Create a Model Repository Service Extension Attributes Data Formats (XML, JSON, Other) Configuring Spin Integration Data Formats in Processes XML JSON User Task Forms JSF Task Forms DMN Engine Embed Evaluate Decisions Expressions FEEL Engine Type Handling Custom Functions Spin Integration Legacy Behavior Data Types Testing Logging Security Instructions External Task Client Spring Boot Starter Version Compatibility Reference REST API Overview Configure Authentication Usage with a Pre-Built Distribution Embed the API Hypertext Application Language (HAL) Variables in the REST API Date Format OpenAPI Specification ↗ Javadoc ↗ BPMN 2.0 Tasks Service Task Send Task User Task Business Rule Task Script Task Receive Task Manual Task Task Markers Gateways Data-based Exclusive Gateway (XOR) Conditional and Default Sequence Flows Parallel Gateway Inclusive Gateway Event-based Gateway Events Start Events None Events Message Events Timer Events Error Events Escalation Events Signal Events Cancel and Compensation Events Conditional Events Link Events Terminate Events Subprocess Embedded Subprocess Call Activity Event Subprocess Transaction Subprocess Extension Reference Extension Elements Extension Attributes DMN 1.3 Decision Table Input Output Rule Hit Policy Decision Literal Expression Decision Requirements Graph FEEL Legacy FEEL Reference Data Types Language Elements Extension Reference Extension Attributes CMMN 1.1 Classic vs Fluent API CMMN Concepts Plan Items and Item Definitions Plan Item Lifecycles Entry and Exit Criteria Tasks Human Task Process Task Case Task Decision Task Grouping Tasks Stage Milestones Sentries Markers Manual Activation Rule Required Rule Auto Complete Repetition Rule Extension Reference Extension Elements Extension Attributes Migration between Specification Versions 1.0 to 1.1 Forms Embedded Forms Controls Text Inputs Textareas Date Inputs Boolean Inputs Selects Hidden Input Fields File Upload and Download BPMN Event Buttons Javascript The cam-script Directive Available API Participating in the Form Lifecycle Debugging Scripts Generating a Business Key Examples Lifecycle and Events Working with Json Data Working with Java Objects Integrating the Forms SDK Getting a Distribution Bootstrapping AngularJS Integration Full Example Spin Dataformats XML Reading XML Manipulating XML Writing XML Querying XML Mapping XML Configuring XML Handling JSON Reading JSON Writing JSON Querying JSON Mapping JSON Configuring JSON Handling Extending Spin Connectors HTTP Connector SOAP Connector Extending Connect Deployment Descriptors bpm-platform.xml processes.xml Tags <job-executor /> <process-archive /> <process-engine /> Installation Database Schema Remote Engine Distribution Shared Engine Distribution Tomcat Pre-Packaged Distribution Manual Installation Configuration JBoss EAP/WildFly Manual Installation Configuration Docker Spring Boot Web Applications Admin User Management Group Management Tenant Management Authorization Management System Management Configuration Plugins Cockpit Dashboard BPMN Processes Dashboard Process Definition View Process Instance View Failed Jobs Suspension Collapsed Subprocesses DMN Decisions Dashboard Decision Definition View Decision Instance View Deployments Open Tasks Dashboard Extending Configuration Plugins Tasklist Working with Tasklist Dashboard Filters User Assignment Task Lifecycle Plugins Configuration Accessibility Welcome Plugins Configuration Shared Configuration Options Authentication Cookie Security CSRF Prevention HTTP Header Security Examples Notices Update & Migration Rolling Update Camunda Migration Web Applications Admin Web application for user management Cockpit Web application for monitoring and operations Tasklist Web application for human task management Welcome Entry point web application with user profile Shared Configuration Options Shared options for Web Application configuration :( Back to top cibseven.org and docs.cibseven.org are part of CIB seven project — Privacy Statement – CIB software GmbH The CIB seven documentation is based on Camunda 7 Docs from Camunda. Some redesign & naming adoptation was made. The content on this site is licensed under a Creative Commons Attribution-ShareAlike 3.0 Unported License.",
    "url": "/manual/latest/webapps/index.html"
  },
  {
    "id": "manual/latest/webapps/shared-options/authentication/index.html",
    "title": "Authentication | docs.cibseven.org",
    "content": "Authentication means verifying a user’s identity against the CIB seven web apps. A user authenticates against the web apps on the login page by providing a username and password. If the authentication is successful, the user gets access to the web apps and can work on tasks in Tasklist or perform operations in Cockpit, for example. The authentication information consists of the following: Process engine name Username Group memberships Tenant memberships Authorized applications (Tasklist, Cockpit, Admin) The CIB seven web apps correlate the authentication information against authorizations to determine what data the user can query for and which operations the user can perform. We implemented authentication with the help of a Java EE/Jakarta ServletFilter. Cache By default, after a successful login, the web apps keep a copy of the authentication information in memory for five minutes. This information is cached, and therefore we call this behavior authentication cache. The authentication cache is a performance optimization to prevent performing for each REST API request multiple database queries that potentially retrieve the same authentication information repeatedly given it didn’t change. Read the security implications of the authentication cache in our Security Instructions. Time to live The time to live defines how long the cache is used for an HTTP session by the web apps before they recreate it and query for the authentication information again from the database. You can change the cacheTimeToLive configuration property with the following allowed values: Set the parameter value to a time duration in milliseconds between 1 and 263-1. Set the parameter value to 0, effectively leading to querying for the authentication information on each REST API request. Remove the <init-param>...</init-param> entirely or change the parameter value to <param-value/> to keep the cache for the lifetime of the HTTP session. Configuration This section describes how to configure the authentication cache time to live. Spring Boot You can find the configuration properties for the Spring Boot Starter in the User Guide. Java EE/Jakarta Servlet Application Servers/Runtimes This is what the web.xml-based configuration looks like: <!-- Authentication filter --> <filter> <filter-name>Authentication Filter</filter-name> <filter-class>org.cibseven.bpm.webapp.impl.security.auth.AuthenticationFilter</filter-class> <init-param> <param-name>cacheTimeToLive</param-name> <param-value>0</param-value> <!-- cache disabled --> </init-param> </filter> <filter-mapping> <filter-name>Authentication Filter</filter-name> <url-pattern>/*</url-pattern> <dispatcher>REQUEST</dispatcher> </filter-mapping> Container-Based Authentication CIB seven supports a broad range of containers, including Tomcat, Wildfly. Using Container-Based Authentication, it is possible to move the authentication action to the container level, which will then make the authentication result available to the CIB seven Web Applications. Heads-up! Please provide an implementation for the ReadOnlyIdentityProvider interface so that queries return the results of your identity provider to make Container-Based Authentication work. Enabling Container-Based Authentication The Container-Based Authentication implementation for the Web Applications is switched off by default, but can be activated by adding a servlet filter in the web.xml as follows: <!-- Container Based Authentication filter --> <filter> <filter-name>Container Based Authentication Filter</filter-name> <filter-class>org.cibseven.bpm.webapp.impl.security.auth.ContainerBasedAuthenticationFilter</filter-class> <init-param> <param-name>authentication-provider</param-name> <param-value>org.cibseven.bpm.engine.rest.security.auth.impl.ContainerBasedAuthenticationProvider</param-value> </init-param> </filter> <filter-mapping> <filter-name>Container Based Authentication Filter</filter-name> <url-pattern>/*</url-pattern> <dispatcher>REQUEST</dispatcher> </filter-mapping> Container-Based Authentication for Single Sign-On The CIB seven Web Applications can also integrate with a Single Sign-On implementation when the Container-Based Authentication servlet filter is enabled.",
    "url": "/manual/latest/webapps/shared-options/authentication/index.html"
  },
  {
    "id": "manual/latest/webapps/shared-options/cookie-security/index.html",
    "title": "Cookie Security | docs.cibseven.org",
    "content": "CIB seven Web applications use cookies to preserve user sessions and to prevent CSRF attacks. This page explains how these cookies should be configured to increase the security. The Web applications set the following cookies: Session Cookie (JSESSIONID) Supposed to remember the authenticated user after the login CSRF Prevention Cookie (XSRF-TOKEN) Supposed to prevent Cross-Site Request Forgery (CSRF) by sending a newly generated token along with each modifying request What are the properties supposed to be? This section describes the purpose of security-related cookie properties. You can find more information about Secure and HttpOnly as well as SameSite cookies in Mozilla’s Developer Guide. Secure When enabling the Secure flag, the browser does not send the cookie via a plain (insecure) HTTP connection. To provide a seamless getting started experience, we disabled the Secure flag by default for all cookies. However, you can easily enable the Secure flag. When the Secure flag is present, some browsers prevent cookies from being sent via a plain (insecure) HTTP connection. Heads-up! It is highly recommended to use an HTTPS connection and enable the Secure flag. HttpOnly When enabling the HttpOnly flag, the cookie cannot be read via JavaScript to mitigate cross-site scripting (XSS) attacks. SameSite When enabling the SameSite flag, the browser only sends the cookie if the client performs the request from the same domain that initially set the cookie. In case of a cross-site request, the browser will not send the cookie. Heads-up! The standard related to SameSite recently changed. Most current browser versions treat cookies without SameSite attributes as ‘SameSite=Lax’. Have a look at SameSite cookies in Mozilla’s Developer Guide. What are the limitations? The following section lists the limitations of the cookie security settings. Absence of HttpOnly for the CSRF Cookie For the CSRF Cookie, the HttpOnly flag is absent and not configurable to ensure the functionality of the Web applications. Aforementioned is due to the reason that the CSRF cookie must be readable by the JavaScript HTTP Client to guarantee that the browser sends the token along with every modifying request. Absence of SameSite for the Session Cookie In the following pre-packaged distributions, the SameSite property is absent by default since the Java Container manages the cookie and the latest Servlet specification does currently not support the SameSite property: JBoss EAP/WildFly IBM WebSphere Oracle Weblogic For all other distributions, the SameSite flag is enabled by default. Heads-up! The absence of the SameSite property does not have any negative impact on the security of the Web applications: The SameSite property is supposed to ensure protection from CSRF attacks. With the CSRF Protection Filter, there already exists a dedicated protection mechanism for such scenarios. What are the defaults? The following table shows the default configuration of the Web applications. Property Name Session Cookie CSRF Cookie HttpOnly true – Secure false false SameSite Lax * Lax * * The SameSite property is not supported for IBM WebSphere and disabled by default for both cookies. The Session Cookie also has no SameSite attribute by default on JBoss EAP/WildFly and Oracle Weblogic. SameSite & Firefox Firefox prevents sending the Cookie to the server for all subsequent requests until the next restart … … on Strict when opening the Webapps from a cross-origin (GET) … on Lax when a modifying request (e. g. POST) is performed from a cross-origin How to configure? This section describes how to configure the Session Cookie as well as the CSRF Cookie. Session Cookie Here you can find how to configure the session cookie for the following containers: Tomcat JBoss EAP & Wildfly Spring Boot CSRF Cookie In the CSRF Prevention documentation, you can find how to configure the CSRF Cookie.",
    "url": "/manual/latest/webapps/shared-options/cookie-security/index.html"
  },
  {
    "id": "manual/latest/webapps/shared-options/csrf-prevention/index.html",
    "title": "CSRF Prevention | docs.cibseven.org",
    "content": "A CSRF filter is enabled by default, validating each modifying request performed through the webapps. The filter implements a (per-session) Synchronization Token method for CSRF validation with an optional Same Origin with Standard Headers verification. In Spring Boot Starter, the configuration needs to be made in the application.yaml. Please read more about it here. If you would like to enable the additional Same Origin with Standard Headers verification, the targetOrigin init-parameter should be set in the web.xml file of your application. That, and some additional optional initialization parameters are: <!-- CSRF Prevention filter --> <filter> <filter-name>CsrfPreventionFilter</filter-name> <filter-class>org.cibseven.bpm.webapp.impl.security.filter.CsrfPreventionFilter</filter-class> <init-param> <param-name>targetOrigin</param-name> <param-value>http://example.com</param-value> </init-param> <init-param> <param-name>denyStatus</param-name> <param-value>404</param-value> </init-param> <init-param> <param-name>randomClass</param-name> <param-value>java.security.SecureRandom</param-value> </init-param> <init-param> <param-name>entryPoints</param-name> <param-value>/api/engine/engine/default/history/task/count, /api/engine/engine/default/history/variable/count</param-value> </init-param> <init-param> <param-name>enableSecureCookie</param-name> <param-value>true</param-value> <!-- default value is false --> </init-param> <init-param> <param-name>enableSameSiteCookie</param-name> <param-value>true</param-value> <!-- default value is true --> </init-param> </filter> <filter-mapping> <filter-name>CsrfPreventionFilter</filter-name> <url-pattern>/*</url-pattern> </filter-mapping> Name Description targetOrigin Application expected deployment domain: the domain name through which the webapps are accessed. If nothing is set, the Same Origin with Standard Headers verification is not performed. denyStatus HTTP response status code that is used when rejecting denied request. The default value is 403. randomClass The name of the class to use to generate tokens. The class must be an instance of `java.util.Random`. If not set, the default value of `java.security.SecureRandom` will be used. entryPoints Entry points are URLs that will not be tested for the presence of a valid token. They are used to provide a way to navigate back to the protected apps after navigating away from them. enableSecureCookie If set to true, the cookie flag Secure is enabled. The default value is false. enableSameSiteCookie If set to false, the cookie flag SameSite is disabled. The default value is true. The default value of the SameSite cookie is LAX and it can be changed via sameSiteCookieOption configuration property. sameSiteCookieOption Can be configured either to STRICT or LAX. Note: This property is ignored when enableSameSiteCookie is set to false. sameSiteCookieValue A custom value for the cookie property. Note: This property is ignored when enableSameSiteCookie is set to false. cookieName A custom value to change the cookie name. The default value is XSRF-TOKEN. Note: Please make sure to additionally change the cookie name for each webapp (e. g. Cockpit ) separately.",
    "url": "/manual/latest/webapps/shared-options/csrf-prevention/index.html"
  },
  {
    "id": "manual/latest/webapps/shared-options/header-security/index.html",
    "title": "HTTP Header Security | docs.cibseven.org",
    "content": "The HTTP Header Security mechanism allows you to add security-related response headers which enable browser-side security mechanisms. What are the headers supposed to be? This section briefly describes the purpose of the headers. You can find more information about the XSS Protection, Content Security Policy, Content-Type Options as well as Strict Transport Security header in Mozilla’s Developer Guide. XSS Protection If the XSS Protection header is enabled some cross-site scripting (XSS) attacks are detected, and the malicious parts of the page are either sanitized, or the rendering of the page is blocked entirely. Content Security Policy The Content Security Policy is a mighty tool to prevent cross-site scripting and code injection attacks. It is a common practice to extend CIB seven web applications by custom scripts and forms. Our default Content Security Policy defines some exceptions to ensure our web apps, your embedded forms, and embedded form scripts work out of the box. Default Policy The header value of the default policy looks as follows: base-uri 'self'; script-src $NONCE 'strict-dynamic' 'unsafe-eval' https: 'self' 'unsafe-inline'; style-src 'unsafe-inline' 'self'; default-src 'self'; img-src 'self' data:; block-all-mixed-content; form-action 'self'; frame-ancestors 'none'; object-src 'none'; sandbox allow-forms allow-scripts allow-same-origin allow-popups allow-downloads; Where $NONCE is a placeholder that is replaced by a random generated secure string. This nonce can be then used to enable inline scripts in the index.html pages using another placeholder called $CSP_NONCE: <script type=\"application/javascript\" nonce=\"$CSP_NONCE\"> Heads-up! If you have custom inline scripts defined, make sure to add the aforementioned nonce attribute to the script tag, otherwise they will be ignored by the browser. Policy Details We encourage you to use a strict Content Security Policy. This section describes what our default policy contains: base-uri 'self' The URI of the HTML Base Tag must not point to a cross-origin script-src $NONCE 'strict-dynamic' 'unsafe-eval' https: 'self' 'unsafe-inline'; The browser only executes inline scripts that are explicitly whitelisted by adding a backend generated nonce to each script tag included in the index.html asset. JavaScript’s eval(…) calls must be allowed to execute cam-script in Tasklist. If there are no embedded forms in your application, it’s recommended to remove the 'unsafe-eval' directive. The second part (https: 'self' 'unsafe-inline') is a fallback for browsers that don’t support strict-dynamic yet (non CSP3 compliant browser). Script resources must not point to a cross-origin. Inline scripts must be allowed since the web applications make use of it. style-src 'unsafe-inline' 'self' Style resources must not point to a cross-origin. Inline styles must be allowed since the web applications make use of it. default-src 'self' Any other unspecified resources must not point to a cross-origin. img-src 'self' data: Images must not point to a cross-origin. Data URIs are allowed since the web applications make use of it. block-all-mixed-content When accessed via HTTPS, all resources loaded via HTTP are blocked. Mixed content is allowed when the site is accessed via HTTP. form-action 'self' A form must not be submitted against a cross-origin. JavaScript in the action attribute of a form is not executed. frame-ancestors 'none' Embedding the web applications via an iframe is forbidden; mitigates clickjacking attacks. object-src 'none' Resources embedded via object, embed or applet tags are not loaded. Mitigates the exploitation of bugs that are included in third-party plugins (e.g. Adobe Flash, Java Applets, etc.) sandbox allow-forms allow-scripts allow-same-origin allow-popups allow-downloads The site is rendered inside a sandbox. Submitting forms, executing scripts, accessing the local storage, opening popups as well as downloading files must be allowed since the web applications make use of these mechanisms. Heads-up! Keep in mind a stricter configuration than the one introduced above might break the functionality of the web applications. Content-Type Options If the Content-Type Options header is enabled, the browser uses the mime type declared in the Content-Type header to render a resource and prevents trying to guess the mime type by inspecting the actual content of the byte stream (sniffing). Strict Transport Security When enabled, the browser remembers that the Webapps must be accessed via HTTPS. After the initial HTTPS request, all subsequent requests will be redirected to HTTPS on the client-level — even though the user tries to access the Webapps via HTTP. Heads-up! The Strict Transport Security header is disabled by default. When going into production, it is highly recommended to enable Strict Transport Security and Strengthen the Base Configuration to protect the Webapps against man-in-the-middle attacks. When accessing the Webapps via HTTP, the Strict Transport Security header is ignored. Therefore, make sure to redirect HTTP requests to HTTPS. Base Configuration After enabling the Strict Transport Security header, the base configuration is relatively lax: max-age=31536000 Strengthen the Base Configuration We encourage you to use a stricter configuration. Here you can find hints on how to strengthen the Base Configuration. Please also see the section on How to Configure? Max Age The higher the value, the better: after expiration, the Webapps can be accessed via HTTP, which is prone to be exploited by attackers. Include Subdomains If you can answer the questions below with yes, you should consider enabling the includeSubdomains flag: Are the Webapps the only web services provided under your domain? Additionally to the main domain, are there any subdomains redirected to the Webapps (e.g., www.example.com is redirected to example.com)? Preload To even avoid the initial HTTP request (redirected to HTTPS), you can submit your domain to the Preload List Service maintained by Google and set the Strict Transport Security header according to the Submission Requirements with the help of the config property hstsValue. Where to Configure? Choose a container from the list and learn where to configure the HTTP Security Headers: Tomcat JBoss EAP & Wildfly Spring Boot How to Configure? The following table shows the possible configuration settings and the default behavior: Name Attribute Configuration Default X-XSS-Protection xssProtectionDisabled The header can be entirely disabled if set to true. Allowed set of values is true and false. false xssProtectionOption The allowed set of values: BLOCK: If the browser detects a cross-site scripting attack, the page is blocked completely SANITIZE: If the browser detects a cross-site scripting attack, the page is sanitized from suspicious parts (value 0) Note: Is ignored when xssProtectionDisabled is set to true Cannot be set in conjunction with xssProtectionValue BLOCK xssProtectionValue A custom value for the header can be specified. Note: Is ignored when xssProtectionDisabled is set to true Cannot be set in conjunction with xssProtectionOption 1; mode=block Content-Security-Policy contentSecurityPolicyDisabled The header can be entirely disabled if set to true. Allowed set of values is true and false. false contentSecurityPolicyValue A custom value for the header can be specified. Note: Property is ignored when contentSecurityPolicyDisabled is set to true base-uri 'self' X-Content-Type-Options contentTypeOptionsDisabled The header can be entirely disabled if set to true. Allowed set of values is true and false. false contentTypeOptionsValue A custom value for the header can be specified. Note: Property is ignored when contentSecurityPolicyDisabled is set to true nosniff Strict-Transport-Security hstsDisabled Set to false to enable the header. The header is disabled by default. Allowed set of values is true and false. true hstsMaxAge Amount of seconds, the browser should remember to access the webapp via HTTPS. Note: Corresponds by default to one year Is ignored when hstsDisabled is true Cannot be set in conjunction with hstsValue Allows a maximum value of 231-1 31536000 hstsIncludeSubdomainsDisabled HSTS is additionally to the domain of the webapp enabled for all its subdomains. Note: Is ignored when hstsDisabled is true Cannot be set in conjunction with hstsValue true hstsValue A custom value for the header can be specified. Note: Is ignored when hstsDisabled is true Cannot be set in conjunction with hstsMaxAge or hstsIncludeSubdomainsDisabled max-age=31536000",
    "url": "/manual/latest/webapps/shared-options/header-security/index.html"
  },
  {
    "id": "manual/latest/webapps/shared-options/index.html",
    "title": "Shared Configuration Options | docs.cibseven.org",
    "content": "The Camunda Web Applications come with several common configuration options. These options cover the operation on all the available Camunda web applications.",
    "url": "/manual/latest/webapps/shared-options/index.html"
  },
  {
    "id": "manual/latest/webapps/tasklist/accessibility/index.html",
    "title": "Accessibility | docs.cibseven.org",
    "content": "It is possible to use the Tasklist only with the keyboard. You can use the TAB-key to navigate to the sections of the Tasklist. To interact with an element you have focused, press ENTER. Keyboard Shortcuts To make working with the Tasklist easier, you can use keyboard shortcuts to jump to certain parts of the Tasklist or perform special operations. Per default, we support the following actions via keyboard shortcuts: Shortcut Action CTRL + ALT + C Claim the currently selected task CTRL + SHIFT + F Set the keyboard focus to the first filter in the filter list CTRL + ALT + L Set the keyboard focus to the first task in the list of tasks CTRL + ALT + F Set the keyboard focus to the first input field in an embedded task form CTRL + ALT + P Open the start process modal dialog All these shortcuts can be modified or removed using the Tasklist configuration file. You can access a list of all available shortcuts via the Keyboard Shortcuts link at the top of the Tasklist page.",
    "url": "/manual/latest/webapps/tasklist/accessibility/index.html"
  },
  {
    "id": "manual/latest/webapps/tasklist/configuration/index.html",
    "title": "Configuration | docs.cibseven.org",
    "content": "You can override the default configuration of Tasklist using a central configuration file located in app/tasklist/scripts/config.js. The following configuration options are available: Date Format Dates can be configured by specifying a dateFormat object. The values of the properties of this object must be strings representing date formats in accordance with moment.js. Following date formats are used within Tasklist: monthName represents the name of a month (e.g., January). day represents the number of a day in a month (1..31). abbr represents a short format of a date including time. normal represents the standard format of a date including time. long represents a verbose format of a date including time and day of the week. short represents a short format of a date excluding time. Example export default { // … \"dateFormat\": { \"monthName\": \"MMM\", \"long\": \"LLLL\" } } Localization Tasklist can be localized. CIB seven maintains English and German translation files. You can find and download community maintained translation files at the Camunda webapp translations repository. The localization of Tasklist is contained in the app/tasklist/locales/ directory. This directory contains a separate localization file for every available language. The file name consists of the language code and the suffix .json (e.g., en.json). Tasklist uses a locale file corresponding to the language settings of the browser. You can set the availableLocales property in the configuration file to provide a list of available locales. Every locale which is contained in this list must have a locale file in the locales directory with the corresponding language code. If the browser uses a language which is not available, Tasklist uses the locale which is defined via the fallbackLocale property in the configuration file: export default { // … \"locales\": { \"availableLocales\": [\"en\", \"de\"], \"fallbackLocale\": \"en\" } } To create a new localization for Tasklist, copy the provided language file, translate it and save it as new localization file with the corresponding language code. To make the new translation available, add it to the list of available locales in the configuration file. Custom Scripts Tasklist allows you to include arbitrary JavaScript files. This allows you to extend Tasklist with custom code. The script file might contain a custom frontend module. Tasklist shares the frontend module structure with Cockpit Plugins. Add your files to the customScripts property of the app/tasklist/scripts/config.js file: export default { // … customScripts: ['custom-module/module.js'] } This includes a custom-module/module.js file. The path is relative to the app/tasklist folder in the CIB seven webapp .war file. You can find a complete example about how to use customScripts to develop a Tasklist Plugin in the CIB seven examples repository. Shortcuts If you want to change the keyboard shortcuts for certain tasklist operations, you can change the key-combination and the description of the shortcuts in the shortcuts section of the config file. Removing an existing entry from the list will disable this shortcut (you can still perform the operation normally within the tasklist, i.e. removing the Claim Task shortcut will not remove the ability to claim a task either with the mouse or with the normal keyboard navigation). You can also add additional shortcuts. If you do so, whenever the user presses the registered combination of keys, an angular event in the form of shortcut:{{nameOfShortcut}} will be broadcasted across the application. A Tasklist plugin can then react to this event. Logo and Header Color You can change the visual aspects of Tasklist. The user stylesheet file is located in app/tasklist/styles/user-styles.css. This file contains CSS which is loaded into Tasklist and can override the standard styles. .navbar-brand { /* hides the \"Tasklist\" text */ text-indent: -999em; /* put your logo */ background-image: url(./path/to/the/logo.png); /* sets the width to match the logo's width */ width: 80px; } /* changes the header bottom border color */ [cam-widget-header] { border-bottom-color: blue; } Note: you can also change the app name (Tasklist) and vendor (CIB seven) by changing the app/tasklist/scripts/config.js configuration file as follow: export default { // … app: { name: 'Todos', vendor: 'Company' } } Change CSRF Cookie Name The default name of the CSRF Cookie is XSRF-TOKEN. When using other applications within the same-origin, the CSRF mechanisms could interfere with each other. To avoid the name conflict, you can change the name of the CSRF cookie in the config.js file as follows: export default { // … csrfCookieName: 'MY-XSRF-TOKEN' } Note: Please make sure to change the CSRF cookie name also on server-side. Disable Welcome Message for new Users First-time visitors are shown a message directing them to the CIB seven welcome page. If you do not want this message to be shown, you can disable it by adjusting the config.js as follows: export default { // … disableWelcomeMessage: true } Note: This does only affect the Tasklist login page. For other webapps, you need to adjust the corresponding config file as well. Assign Process Instance Id to Task Comments When creating a Task Comment, the process instance ID is not assigned by default. Queries for comments by process instance ID will not include those comments. When you set the flag assignProcessInstanceIdToTaskComment to true, Tasklist assigns both the task id and the process instance id to newly created Task Comments. This allows you to query Task Comments by process instance id and by task id. export default { // … assignProcessInstanceIdToTaskComment: true } Advanced Styles Customization In addition to the basic user-styles.css file, you can edit the source style- and layout files using less to change the overall appearance of Tasklist. If you want to customize the interface with less, you should probably start by having a look at the variables defined in the following files: node_modules/camunda-commons-ui/node_modules/bootstrap/less/variables.less defines the original Bootstrap variables node_modules/camunda-commons-ui/resources/less/cam-variables.less overrides some Bootstrap variables (above) and add some custom ones Compiling with Grunt From within the cibseven-bpm-webapp directory: grunt build:tasklist The command will build the frontend assets (of Tasklist), styles included.",
    "url": "/manual/latest/webapps/tasklist/configuration/index.html"
  },
  {
    "id": "manual/latest/webapps/tasklist/dashboard/index.html",
    "title": "Dashboard | docs.cibseven.org",
    "content": "On the dashboard of Tasklist you see an overview of pending tasks. On the left side of the screen, an overview of the filters is displayed. On the upper right side of the screen, you can set a follow-up or due date, you can claim, unclaim and reassign tasks and you can add comments. Underneath that section, the embedded form is displayed (please note that external task forms cannot be displayed here), you can switch to the task history, you can see the diagram view or you can view the description of the user task. Toggle view Tasklist offers you the option of toggling the view options on the dashboard. You can select to have a focus on the filters, the filter results, the task view or to display the full dashboard. To do so, hit the respective toggle view button. At any time, you can choose to instantly set full focus on the task view by hitting the expand button. Start a process To start a process instance via Tasklist, click on Start process in the header menu and select a process out of the displayed list of process definitions. If no process definitions are listed here, please verify that your process application is deployed correctly. Depending on whether you have defined a start form for your process it will be displayed now. Otherwise you get a notification that no form has been defined for starting the process. In this case, a generic start form will be displayed and Tasklist will offer the option of adding variables to the process instance. Create a standalone task Tasklist offers you the possibility of creating standalone tasks. To do so, click on the Create task button. In the screen that appears, you can define a name of the task, the assignee and you can add a description. Once you click on Save, the task is created. Now the standalone task becomes visible in the filter results and can be handled. Variables can be added and the Task can be completed. Once the task has been completed, the data is flushed to the database and the task is no longer visible in Tasklist. Filter results Here you can see an overview of all tasks for the selected filter. The filter with the lowest priority is displayed first. After selecting the appropriate filter, you will see an overview of all tasks, sorted by a specified criteria (by default it is sorted by the creation date). You can change the sorting of the tasks by clicking on the name of the sorting property. You can toggle between ascending and descending order. You can sort by more than one property by adding additional properties with the plus button. The sorting is performed in a hierarchical manner (i.e., first by the property displayed first, then by the second, etc). You can also sort by the value of variables, which allows for use cases like sorting invoices by the value of their amount. To start working on the task, simply select the task. Search for tasks Above the filter results, you have the option of searching for user tasks within the selected filter results. To do so, click in the search box and select the parameters to search for. You can also begin typing to find the required parameter faster. Depending on the selected property, you have to specify the value of the property. Some properties also allow operators other than equal, e.g., 'like', which allows to search for a task where the entered value is a substring of the property value. The 'in' operator allows you to provide a comma-separated list of possible values. If you are searching for variables, you also have to enter the variable name you want to search for. If the filter you have selected has defined labels for variables, you can select the label of the variable as variable name. Otherwise (if there is no label definition for a variable), you have to enter the variable name to search for it. If you change the filter selection, the search will be performed on the selected filter and the results will be updated accordingly. If you are searching for a variable of type string, which has a numeric, boolean or null value, you have to wrap the value in single quotes (e.g '93288' or 'NULL'). Furthermore, you can copy a link to the current search query to your clipboard by clicking on the button and you can save search queries to your local browser storage by clicking on the button and inserting a name in the drop down menu that appears. You can then retrieve the search query by clicking on the button and selecting the chosen name in the drop down menu. Case insensitive search Sometimes it is not relevant for your search whether the value is capitalized or not. For search queries for Process-, Task- and Case Variables, you can configure if the search should be performed case sensitive or case insensitive. A case insensitive search for 'Fruits Inc.' will also return matches for values like 'fruits inc.' or 'FRUITS Inc.'. When your search contains one of the Variables mentioned above, two checkboxes appear. You can choose the case handling for the variable name and variable value independently. The option applies to all variable queries within the same search. IN operator Tasklist provides IN operator support for the following query criteria: Tenant ID Process instance ID By default, the criteria defined in the search are linked together with a logical AND (conjunctive normal form). Occasionally, you may search for multiple query criterion values. The IN operator allows searching for multiple values where any of the values match. To use the IN operator, select a query criterion that supports the IN operator, and provide the values as a comma-separated list. To adjust the comma-separated list of values, start editing by clicking on the value. You can expand the value in a modal dialog for easier editing by clicking on the button. Task view On the right section of the dashboard, you can see the task view. Here you can work on tasks and perform the following operational actions. Set due dates and follow-up dates In the upper section of the task view, you can set a due date and follow-up date for the selected task. A due date can be set to determine when the task needs to be completed and a follow-up date can be set as a reminder or for monitoring purposes. Claim, unclaim, and reassign tasks Within the task view, you can claim, unclaim and reassign tasks. To claim a task, simply select Claim. Unclaim a task by hitting the button next to the username of a claimed task and reassign a task to a different user by clicking on the username and inserting the username of the user you want to assign the task to. You can also assign tasks to user groups by clicking on Add Groups. Comments In Tasklist you can add and view comments on specific tasks. After selecting a task from the filter results, click on Add Comment at the top of the task view section to add a comment to the selected task. The comments of a task can be viewed in the task history. Task Detail Tabs In the lower section of the task view there are several tabs which can be selected to display both the task form itself and additional information related to this user task. Task form view - The Form tab, which is selected by default, displays the task form (provided that the task form is an embedded, generated or generic task form). Here you can work on and complete the task. Task history - The History tab displays the history of this user task. Here you can see detailed information, such as the assignment history, updates to the due date and follow-up dates and claiming and unclaiming of tasks. Comments are also displayed here. Diagram view - The Diagram tab shows the diagram of the process definition. The current user task is highlighted in this diagram. Task description - Open the Description tab to inspect the User Task description. Have a look at the BPMN 2.0 reference for more information about descriptions of tasks.",
    "url": "/manual/latest/webapps/tasklist/dashboard/index.html"
  },
  {
    "id": "manual/latest/webapps/tasklist/filters/index.html",
    "title": "Filters | docs.cibseven.org",
    "content": "In Tasklist, you can create and select filters. You can use these filters to create lists of tasks, sorted by specified criteria. To create a filter, select Create a Filter. You will then see a screen as depicted in the above image. You have several options to configure your filter: General - Specify the name and description of the filter as well as assigning a color. Assign a priority to determine the order in which the filters are displayed on the dashboard. You can choose to have the filter automatically refresh the filter results by selecting the checkbox Auto-Refresh.The default refresh interval is 10 seconds. Permissions - Specify which users or groups can see the filter. You can set the filter as globally accessible by selecting the checkbox Accessible by all users. A permission that is set here is equivalent to a READ permission which can also be set in Camunda Admin. In case you want to assign other permissions, you can do so in the Authorizations tab in Camunda Admin. Criteria - Specify which tasks will be displayed when selecting the filter. A key and a value must be inserted. There are various keys which can be selected from the categories Process Instance (ID, Business Key), Process Definition (ID, Key, Name), Case Instance (ID, Business Key), Case Definition (ID, Key, Name), Other (Process Instance state, Activity instance ID, Execution ID), User/Group (Assignee, Owner, Candidate User or Group, Involved user, Unassigned, Delegation State), Task (Definition Key, Name, Description, Priority) and Dates (Created date, Due date, Follow up date). Keys marked with a * accept expressions as value. Variables - Specify which variables are displayed in the filter results section of the dashboard. Setting variables here has no influence on which tasks are displayed. To set the variables, you need to insert a Name, which is the coded name of the variable, and a Label, which defines what the variable will be named in the filter results. Expressions in Filters Several of the filter criteria accept expressions as values. These expressions are written in JUEL. In filters which are related to times and dates, you can use the dateTime class, which returns a Joda-Time DateTime object. Security Consideration Filter expressions can be abused to execute arbitrary code when the query is evaluated. It is therefore required that any user authorized to create filters is trusted in this respect. The default behavior of evaluating filter expressions can be deactivated in the process engine configuration. See the section on security considerations for custom code for details. Common Filters In the table below we list some of the more common and useful filters that you can create in Tasklist and how to set them up. Filter name Description Criterion Key Criterion Value All my tasks Displays all tasks assigned to the currently logged in user Assignee $ { currentUser() } Tasks of a specific user Displays all tasks assigned to a specified user Assignee User ID of the user (e.g., demo) All my groups Displays all tasks assigned to a user group of which the currently logged on user is a member Candidate Groups ${ currentUserGroups() } Tasks of a specific group Displays all tasks assigned to a specific user group Candidate Groups Group name (e.g., accounting) Unclaimed tasks of a specific group Displays all tasks assigned to a specific user group which have not been claimed yet Candidate Groups, Unassigned Group name (e.g., accounting), N/A Unassigned tasks Displays all tasks that have not yet been claimed Unassigned N/A Overdue tasks Displays all tasks that have a due date set in the past Due Before ${ now() } Tasks due today Displays all tasks that have a due date set for the current date Due After, Due Before ${ dateTime().withTimeAtStartOfDay() }, ${ dateTime().withTimeAtStartOfDay() .plusDays(1).minusSeconds(1) } Tasks due after a specific date Displays all tasks that have a due date set after a specified date Due After The specified date in accordance with ISO 8601 (e.g., 2015-01-01T00:00:01) Tasks due within a specific timespan Displays all tasks that have a due date set within a specified timespan (in this example, within 2 days) Due After, Due Before Expressions specifying the timespan (e.g., ${ now() }, ${ dateTime().plusDays(2) }) Tasks due after a specific timespan Displays all tasks that have a due date set after a specified timespan (in this example, after 2 days) Due After An expression specifying the timespan (e.g.,${ dateTime().plusDays(2) }) Tasks with a certain priority Displays all tasks that are marked with a specified priority (in this example, priority 10) Priority 10 Follow-up tasks Displays all tasks that have a follow-up date set in the past Follow Up Before ${ now() }",
    "url": "/manual/latest/webapps/tasklist/filters/index.html"
  },
  {
    "id": "manual/latest/webapps/tasklist/index.html",
    "title": "Tasklist | docs.cibseven.org",
    "content": "Tasklist is a web application that allows you to work on User Tasks. Tasklist is part of the CIB seven distribution and ready to use by opening http://localhost:8080/camunda/app/tasklist.",
    "url": "/manual/latest/webapps/tasklist/index.html"
  },
  {
    "id": "manual/latest/webapps/tasklist/task-lifecycle/index.html",
    "title": "Task Lifecycle | docs.cibseven.org",
    "content": "The diagram below shows the task lifecycle and supported transitions supported by Camunda. To get to know how to programmatically work with the lifecycle in your application, refer to the Java-API Reference .",
    "url": "/manual/latest/webapps/tasklist/task-lifecycle/index.html"
  },
  {
    "id": "manual/latest/webapps/tasklist/tasklist-plugins/index.html",
    "title": "Plugins | docs.cibseven.org",
    "content": "Plugin Compatibility Please note that the code of Tasklist plugins might need to be migrated when updating CIB seven to a higher version (e.g. CSS styles). Tasklist uses the concept of plugins to add own functionality without having to extend or hack the Tasklist web application. For further details about the concepts behind plugins, please read the Cockpit plugins section. Difference between Cockpit and Tasklist plugins: To publish the plugin with Tasklist, its class name must be put into a file called org.cibseven.bpm.tasklist.plugin.spi.TasklistPlugin that resides in the directory META-INF/services. The plugin mechanism of Tasklist does not allow to provide additional SQL queries by using MyBatis mappings. Plugin Points Here you can see the various points at which you are able to add your own plugins. Name: tasklist.navbar.action. Name: tasklist.task.action. Name: tasklist.header. Name: tasklist.task.detail. This plugin points properties contain the attribute label, which will be rendered in the navigation even when the plugin is not selected. properties: { label: \"My Plugin\" } This additional data is passed into the render function: taskId Name: tasklist.list. Name: tasklist.card. This additional data is passed into the render function: taskId Configure where to place your plugin as shown in the following example: var ViewConfig = [ 'ViewsProvider', function(ViewsProvider) { ViewsProvider.registerDefaultView('tasklist.task.detail', { id: 'sub-tasks', priority: 20, label: 'Sub Tasks' }); }]; For more information on creating and configuring your own plugin, please have a look at the following examples: How to build the server side How to build the client side",
    "url": "/manual/latest/webapps/tasklist/tasklist-plugins/index.html"
  },
  {
    "id": "manual/latest/webapps/tasklist/user-assignment/index.html",
    "title": "User Assignment | docs.cibseven.org",
    "content": "For users to be able to work on the tasks they should work on, they must be able to find these tasks. Enabling users to find “their” tasks requires the correct interaction between the initial assignment of the task and the filters configured in Tasklist. This works as follows: Initial Assignment: when a task is created, it is initially assigned to a user or group according to the configuration in the BPMN process (or the CMMN case). Building Filters: filters then allow users to find tasks which are assigned to them or to the groups they belong to. Claiming group tasks: if a task is not directly assigned to a given user, the user must claim the task before working on it. Implementing Initial Assignment You can read up on how to implement the inital user assignment for BPMN User Tasks and CMMN Human Tasks in the corresponding reference sections: Implementing user assignments for BPMN User Tasks Implementing user assignments for CMMN Human Tasks Claiming a task in Tasklist In Tasklist, a user can ony work on a task (i.e., filling in the task form) if the task is assigned to that user. This means that a user must claim a task if it is not yet assigned to him. Claiming a task sets the assignee of the task to the user who claimed the task. See the Claiming, unclaiming and reassigning tasks section for more information.",
    "url": "/manual/latest/webapps/tasklist/user-assignment/index.html"
  },
  {
    "id": "manual/latest/webapps/tasklist/working-with-tasklist/index.html",
    "title": "Working with Tasklist | docs.cibseven.org",
    "content": "In the following example we will walk through a typical human workflow scenario. In our prepackaged distribution, Tasklist has four demo users which belong to different user groups. Sign in with the user demo. Start a Process To start a process instance via Tasklist, click on Start process in the header menu of the dashboard and select a process out of the displayed list of process definitions. If no process definitions are listed here, please verify that your process application is deployed correctly and you have the required permissions* to start a process. For our example, start the Invoice Receipt process. After selecting the process to start, complete the start form. Hit Start to continue to the next step in our example. *Permissions: CREATE_INSTANCE and READ permissions on Process definition level, and CREATE permission for all Process instances. Create a Filter On the dashboard you can now create a filter which displays this task. For our example, we will create a filter to display all tasks assigned to the currently signed in user and which belong to the process definition Invoice Receipt. To do so, click on Create a Filter and insert a name for the filter, e.g., My invoice tasks. Then click on Criteria and on Add Criterion. Next, click on the empty Key field, select Name in the Process Definition submenu and insert Invoice Receipt into the Value field. Click on Add Criterion again, select Assignee in the User/Group submenu of the key field and insert ${ currentUser() } into the value field. We want to publish this filter to our colleagues as well. To do this, click on Permissions and tick the box at Accessible by all users. As a final step, click on Save to create the filter. Now you can see the filter on the left side of the dashboard. Click on the filter to display the user tasks. See the Filters section for more information. Claim Tasks First we need to claim this task to be able to work on it. To do so, click on Claim in the task view section. You can also reassign the task to another user by clicking on Demo Demo. A text field will appear into which you can insert the user that you want to assign this task to. See the Claiming, unclaiming and reassigning tasks section for more information. Working on Tasks After creating the filter, we now want to start working on a task. We can do so by selecting the task in the filter results. On the right side, you will see the task form to work on as an embedded form. In our example task form you are asked to approve an invoice (or not). To complete the task, either tick the checkbox at Do you approve? or not and click on Complete. For our example, tick the checkbox and complete the task. Then have a look at the filter results. Now you will see that the Prepare Bank Transfer task has been created. When you submit the task form, the task is completed and the process continues in the engine. Furthermore, you can visualize the process model by clicking on the Diagram tab in the task view section of the dashboard. See the Task Forms section for more information. Set Follow-Up Date Let’s assume that this task was assigned to the user just before the end of his working day. Because we want to hurry out, we will set a follow-up date (reminder) for this task so that we don’t forget about it when we get back to the office. To do so, click on Set follow-up date in the task view section and select a date in the calendar that is displayed. We can also set an exact time for the follow-up. See the Follow-Up section for more information. Comment a Task Now we want to add a comment for other Tasklist users to see. To do so, click on Add Comment at the top of the task view section and insert the comment, e.g., “Hi Mary, please review this task”. The comment can now be seen in the task history. See the Comments section for more information. Set Due Date Last but not least, we want to set a due date for this task, to ensure that the task is handled on time. To do so, click on Set due date in the task view section and select a date in the calendar that is displayed. You can also set an exact time. See the Due Dates section for more information. This concludes our example task. Now we will elaborate on the functions that Tasklist offers.",
    "url": "/manual/latest/webapps/tasklist/working-with-tasklist/index.html"
  },
  {
    "id": "manual/latest/webapps/welcome/configuration/index.html",
    "title": "Configuration | docs.cibseven.org",
    "content": "You can override the default configuration of the Welcome application by using a central configuration file, located in app/welcome/scripts/config.js. The following configuration options are available: Custom links Can be used to add some useful links for the user, such as other applications or intranet sites. Example export default { // … links: [ { label: 'Camunda Forum', href: 'https://forum.camunda.org', description: 'Forum for Camnuda BPM users and developers' }, // ... ] } Logo and Header Color You can change the visual aspects of Welcome. The user stylesheet file is located in app/welcome/styles/user-styles.css. This file contains CSS which is loaded into Welcome and can override the standard styles. .navbar-brand { /* hides the \"Camunda Welcome\" text */ text-indent: -999em; /* put your logo */ background-image: url(./path/to/the/logo.png); /* sets the width to match the logo's width */ width: 80px; } /* changes the header bottom border color */ [cam-widget-header] { border-bottom-color: blue; } Note: you can also change the app name (Welcome) and vendor (Camunda) by changing the app/welcome/scripts/config.js configuration file as follow: export default { // … app: { name: 'Welcome', vendor: 'Company' } } Localization Welcome can be localized. Camunda maintains English and German translation files. You can find and download community maintained translation files at the Camunda webapp translations repository. The localization of the Welcome application is contained in the app/welcome/locales/ directory. This directory contains a separate localization file for every available language. The file name consists of the language code and the suffix .json (e.g., en.json). The Welcome application uses a locale file corresponding to the language settings of the browser. You can set the availableLocales property in the configuration file to provide a list of available locales. Every locale which is contained in this list must have a locale file in the locales directory with the corresponding language code. If the browser uses a language which is not available, the Welcome application uses the locale which is defined via the fallbackLocale property in the configuration file: export default { // … \"locales\": { \"availableLocales\": [\"en\", \"de\"], \"fallbackLocale\": \"en\" } } To create a new localization for the Welcome application, copy the provided language file, translate it and save it as a new localization file with the corresponding language code. To make the new translation available, add it to the list of available locales in the configuration file. Change CSRF Cookie Name The default name of the CSRF Cookie is XSRF-TOKEN. When using other applications within the same-origin, the CSRF mechanisms could interfere with each other. To avoid the name conflict, you can change the name of the CSRF cookie in the config.js file as follows: export default { // … csrfCookieName: 'MY-XSRF-TOKEN' }; Note: Please make sure to change the CSRF cookie name also on server-side. Disable Welcome Message for new Users First-time visitors are shown a message directing them to the camunda welcome page. If you do not want this message to be shown, you can disable it by adjusting the config.js as follows: export default { // … disableWelcomeMessage: true }; Note: This does only affect the Welcome login page. For other webapps, you need to adjust the corresponding config file as well.",
    "url": "/manual/latest/webapps/welcome/configuration/index.html"
  },
  {
    "id": "manual/latest/webapps/welcome/index.html",
    "title": "Welcome | docs.cibseven.org",
    "content": "The Welcome application presents links to the applications the user has access to. It features a user profile in which the user can change his name, email address and password. The application can also have configurable custom links, for example for intranet or other useful resources.",
    "url": "/manual/latest/webapps/welcome/index.html"
  },
  {
    "id": "manual/latest/webapps/welcome/welcome-plugins/index.html",
    "title": "Plugins | docs.cibseven.org",
    "content": "In addition to the configurable custom links, plugins can be used to add functionality to the Welcome application. For further details about the concepts behind plugins, please read the Cockpit plugins section. Please note that the Welcome application just offers frontend only plugins. Plugin point Name: welcome.dashboard. Name: welcome.profile.",
    "url": "/manual/latest/webapps/welcome/welcome-plugins/index.html"
  },
  {
    "id": "security/index.html",
    "title": "Product Security Guide | docs.cibseven.org",
    "content": "This page describes CIB seven (also referred to as the 'software') from a security perspective. It has four parts: 1. Security Policy: Describes the software's security policy, including how we deal with security issues and how the security of the software is continuously maintained. 2. Instructions for operating the software securely: Provides an overview of how to secure a CIB seven installation. In order to secure a CIB seven installation, CIB seven itself must be configured correctly and it must be integrated correctly into its environment. This section also identifies areas where we consider security issues to be relevant for the specific CIB seven product and listed those in the subsequent sections. Compliance for those areas is ensured based on common industry best practices and influenced by security requirements of standards like OWASP Top 10 and others. 3. Security Notices: Announcements of known vulnerabilities for which fix releases and/or practical workarounds are available. 4. Reporting a Vulnerability: Explains how to report a security vulnerability to our team.",
    "url": "/security/index.html"
  },
  {
    "id": "security/notices/index.html",
    "title": "Security Notices | docs.cibseven.org",
    "content": "On this page, we publish security notices after fixes are available. Fixes are available as alpha or minor releases of the CIB seven platform. Notices Notice 120 Publication Date: October 18th, 2024 Product affected: Cawemo On-Premises Impact: The version of libcurl shipped with cawemo-websockets was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-8096 How to determine if the installation is affected Cawemo On-Premises 1.9.21 or lower is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerability Solution Camunda has provided the 1.9.22 release for the cawemo-websockets Docker image which contains a fix for the above-mentioned CVE. Notice 119 Publication Date: October 14th, 2024 Product affected Camunda 7 Impact The version of Apache Tomcat shipped with the Camunda Tomcat distribution, Camunda Run, and transitively pulled in by the Camunda Spring Boot starter had the following vulnerability: CVE-2024-38286 How to determine if the installation is affected Camunda 7 Tomcat is used or Camunda 7 Run is used or Camunda 7 Spring Boot Starter is used. See the NIST link above for detailed description of the circumstances required to exploit the vulnerability. Solution Camunda has provided the releases 7.19.15, 7.20.8, 7.21.4, 7.22.0-alpha5 which contain a fix. Notice 118 Publication Date: October 7th, 2024 Product affected: Cawemo On-Premises Impact: The versions of libcrypto3, libssl3, and openssl shipped with cawemo-restapi were affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-6119 The version of spring-webmvc shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-38816 The version of path-to-regexp shipped with cawemo-webapp was affected by the following vulnerability: https://github.com/pillarjs/path-to-regexp/security/advisories/GHSA-9wv6-86v2-598j The version of @sentry/browser shipped with cawemo-webapp was affected by the following vulnerability: https://github.com/getsentry/sentry-javascript/security/advisories/GHSA-593m-55hh-j8gv The version of @cookie shipped with cawemo-webapp was affected by the following vulnerability: https://github.com/jshttp/cookie/security/advisories/GHSA-pxg6-pf52-xh8x The versions of libcrypto3, libssl3, and openssl shipped with cawemo-websockets were affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-6119 How to determine if the installation is affected Cawemo On-Premises 1.9.20 or lower is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided 1.9.21 releases for the cawemo-restapi, cawemo-webapp, and cawemo-websockets Docker images which contain fixes for the above-mentioned CVEs. Notice 117 Publication Date: September 16th, 2024 Product affected Camunda 7 Impact The version of Apache Tomcat shipped with the Camunda Tomcat distribution, Camunda Run, and transitively pulled in by the Camunda Spring Boot starter had the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-34750 How to determine if the installation is affected Camunda 7 Tomcat is used or Camunda 7 Run is used or Camunda 7 Spring Boot Starter is used. See the NIST link above for detailed description of the circumstances required to exploit the vulnerability. Solution Camunda has provided the releases 7.22.0-alpha5, 7.21.4, 7.20.8, 7.19.15 which contain a fix. Notice 116 Publication Date: August 30th, 2024 Product affected: Cawemo On-Premises Impact: The version of the Java runtime shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-21147 The version of spring-security-core shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-38810 The version of axios shipped with cawemo-webapp was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-39338 The version of libcurl shipped with cawemo-websockets was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-7264 How to determine if the installation is affected Cawemo On-Premises 1.9.19 or lower is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided 1.9.20 releases for the cawemo-restapi, cawemo-webapp, and cawemo-websockets Docker images which contain fixes for the above-mentioned CVEs. Notice 115 Publication Date: August 6th, 2024 Product affected: Cawemo On-Premises Impact: The versions of libcrypto3 and libssl3 shipped with cawemo-restapi, cawemo-webapp and cawemo-websockets were affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-5535 The version of openssl shipped with cawemo-websockets was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-5535 The version of libcurl shipped with cawemo-websockets was affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2024-6197 https://nvd.nist.gov/vuln/detail/CVE-2024-6874 The version of spring-web shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2016-1000027 How to determine if the installation is affected Cawemo On-Premises 1.9.18 or lower is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided 1.9.19 releases for the cawemo-restapi, cawemo-webapp, and cawemo-websockets Docker images which contain fixes for the above-mentioned CVEs. Notice 114 Publication Date: July 1st, 2024 Product affected Camunda 7 Impact: The version of angular-translate, included in the Camunda web applications, had a cross-site scripting (XSS) vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-33665 How to determine if the installation is affected You use the Camunda 7 web applications. You use a custom plugin that introduces custom translation strings. An attacker can provide forged input to the custom plugin that passes it to the angular-translate library. Solution Camunda has provided the releases 7.22.0-alpha3, 7.21.3, 7.20.7, 7.19.14 which contain a fix. Notice 113 Publication Date: July 1st, 2024 Product affected Camunda 7 Impact The version of Apache Tomcat shipped with the Camunda Tomcat distribution, Camunda Run, and transitively pulled in by the Camunda Spring Boot starter had the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2024-23672 https://nvd.nist.gov/vuln/detail/CVE-2024-24549 How to determine if the installation is affected Camunda 7 Tomcat is used or Camunda 7 Run is used or Camunda 7 Spring Boot Starter is used. See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities. Solution Camunda has provided the releases 7.22.0-alpha3, 7.21.3, 7.20.7, 7.19.14 which contain a fix. Notice 112 Publication Date: June 28th, 2024 Product affected: Cawemo On-Premises Impact: The versions of libcrypto3 and libssl3 shipped with cawemo-restapi, cawemo-webapp and cawemo-websockets were affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-4603 The versions of busybox, busybox-binsh and ssl_client shipped with cawemo-restapi, cawemo-webapp and cawemo-websockets were affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2023-42363 https://nvd.nist.gov/vuln/detail/CVE-2023-42364 https://nvd.nist.gov/vuln/detail/CVE-2023-42365 https://nvd.nist.gov/vuln/detail/CVE-2023-42366 The version of undertow-core shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-6162 The version of libxml2 shipped with cawemo-websockets was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-34459 The version of openssl shipped with cawemo-websockets was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-4603 How to determine if the installation is affected Cawemo On-Premises 1.9.17 or lower is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided 1.9.18 releases for the cawemo-restapi, cawemo-webapp, and cawemo-websockets Docker images which contain fixes for the above-mentioned CVEs. Notice 111 Publication Date: June 12th, 2024 Product affected: Camunda 7 Impact: Camunda Forms contained a Regular Expression Denial of Service (ReDoS) vulnerability, which could render the page unresponsive. How to determine if the installation is affected You are using Camunda Forms. An attacker can deploy a specially crafted Camunda Form. Solution Camunda has provided the following releases, which contain a fix: Camunda 7.19.13, 7.20.6, 7.21.2, 7.22.0-alpha2. Notice 110 Publication Date: May 14th, 2024 Product affected: Camunda 7 Impact: The version of the MySQL JDBC connector included in the Camunda 7 Docker images had a vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2023-22102 How to determine if the installation is affected The Camunda Platform 7 Docker containers are used. MySQL is used for the database connection. Solution Camunda has provided the following releases which contain a fix: Camunda 7.19.12, 7.20.5, 7.21.1, 7.22.0-alpha1 Notice 109 Publication Date: May 13th, 2024 Product affected: Cawemo On-Premises Impact: The versions of libcrypto3 and libssl3 shipped with cawemo-restapi, cawemo-webapp and cawemo-websockets were affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-2511 The version of undertow-core shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-1459 The version of spring-web shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-22262 The version of xnio-api shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2023-5685 The version of formidable shipped with cawemo-webapp was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-29622 The version of openssl shipped with cawemo-websockets was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-2511 How to determine if the installation is affected Cawemo On-Premises 1.9.16 or lower is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided 1.9.17 releases for the cawemo-restapi, cawemo-webapp, and cawemo-websockets Docker images which contain fixes for the above-mentioned CVEs. Notice 108 Publication Date: May 3rd, 2024 Product affected: Camunda 7 Impact: The version of AngularJS, included in the Camunda web applications, had a backtracking vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-21490 How to determine if the installation is affected You use the Camunda 7 web applications. You use a custom plugin that utilizes the AngularJS ng-srcset directive. An attacker can provide forged input to the custom plugin that passes it to the ng-srcset directive. Solution Camunda has provided the following releases which contain a fix: Camunda 7.19.12, 7.20.5, 7.21.0-alpha3. Notice 107 Publication Date: May 3rd, 2024 Product affected: Camunda 7 Impact: The version of the PostgreSQL JDBC driver used in the Camunda Platform 7 Docker images had a vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-1597 How to determine if the installation is affected You use the Camunda 7 Docker images. You connect to a PostgreSQL database. Solution Camunda has provided the following releases which contain a fix: Camunda 7.19.12, 7.20.5, 7.21.0-alpha4 Notice 106 Publication Date: April 08th, 2024 Product affected: Cawemo On-Premises Impact: The version of netty-coded-http shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-29025 The version of spring-web shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-22259 The version of spring-security-core shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-22257 The version of c-ares shipped with cawemo-websockets was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-25629 How to determine if the installation is affected Cawemo On-Premises 1.9.15 or lower is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided 1.9.16 releases for the cawemo-restapi, and cawemo-websockets Docker images which contain fixes for the above-mentioned CVEs. Notice 105 Publication Date: March 15th, 2024 Product affected: Cawemo On-Premises Impact: The version of spring-web shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-22243 The version of postgresql shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-1597 The version of jose shipped with cawemo-webapp was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-28176 The version of follow-redirects shipped with cawemo-webapp was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-28849 The version of libxml2 shipped with cawemo-websockets was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2024-25062 How to determine if the installation is affected Cawemo On-Premises 1.9.14 or lower is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided 1.9.15 releases for the cawemo-restapi, cawemo-webapp, and cawemo-websockets Docker images which contain fixes for the above-mentioned CVEs. Notice 104 Publication Date: March 1st, 2024 Product affected Camunda 7 Impact The version of follow-redirects, included in the Camunda Run SwaggerUI had an Improper Input Validation vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2023-26159 How to determine if the installation is affected You expose Camunda Run SwaggerUI publicly by operating it without the --production flag or in combination with the --swaggerui flag. Solution Camunda has provided the releases 7.21.0-alpha3, 7.20.4, 7.19.11, 7.18.15, which contain a fix. Notice 103 Publication Date: February 12th, 2024 Product affected: Cawemo On-Premises Impact: The versions of libcrypto3 and libssl3 shipped with cawemo-restapi were affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2023-6129 CVE-2023-6237 The versions of libcrypto3 and libssl3 shipped with cawemo-webapp were affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2023-6129 CVE-2023-6237 The version of follow-redirects shipped with cawemo-webapp was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2023-26159 The versions of libcrypto3 and libssl3 shipped with cawemo-websockets were affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2023-6129 CVE-2023-6237 How to determine if the installation is affected Cawemo On-Premises 1.9.12 or lower is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided 1.9.13 releases for the cawemo-restapi, cawemo-webapp, and cawemo-websockets Docker images which contain fixes for the above-mentioned CVEs. Notice 102 Publication Date: February 12th, 2024 Product affected Camunda 7 Impact The version of Logback shipped with Camunda Run, Camunda RPA Bridge, and transitively pulled in by the Camunda Spring Boot Starter had a denial-of-service vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2023-6378 Logback versions 1.3.12 and 1.4.12 already tried to fix CVE-2023-6378 but were still affected by: https://nvd.nist.gov/vuln/detail/CVE-2023-6481 The Camunda releases listed under the Solution section fix both CVEs CVE-2023-6378 as well as CVE-2023-6481. How to determine if the installation is affected Camunda RPA Bridge, Camunda Run or Camunda Spring Boot Starter is used AND the logback-receiver component is enabled and also reachable by the attacker. See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities. Solution Camunda has provided the releases 7.21.0-alpha3, 7.20.3, 7.19.10, 7.18.14, and RPA Bridge 1.1.11, which contain a fix. Notice 101 Publication Date: January 3rd, 2024 Product affected: Cawemo On-Premises Impact: The versions of ch.qos.logback:logback-classic and ch.qos.logback:logback-core shipped with cawemo-restapi were affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2023-6378 The version of ch.qos.logback:logback-core shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2023-6481 The version of org.springframework.boot:spring-boot shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2023-34055 The version of libcurl shipped with cawemo-websockets was affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2023-46218 https://nvd.nist.gov/vuln/detail/CVE-2023-46219 How to determine if the installation is affected Cawemo On-Premises 1.9.11 or lower is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided 1.9.12 releases for the cawemo-restapi, cawemo-webapp, and cawemo-websockets Docker images which contain fixes for the above-mentioned CVEs. Notice 100 Publication Date: December 11th, 2023 Product affected Camunda Platform 7 Impact The version of axios, included in the Camunda Run SwaggerUI, had a Cross-Site Request Forgery (CSRF) vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2023-45857 How to determine if the installation is affected You expose Camunda Run SwaggerUI publicly by operating it without the --production flag or in combination with the --swaggerui flag. Solution Camunda has provided the releases 7.21.0-alpha2, 7.20.2, 7.19.9, 7.18.13 which contain a fix. Notice 99 Publication Date: December 11th, 2023 Product affected Camunda Platform 7 Impact Camunda Spring Boot Starter and Camunda Run had an Insertion of Sensitive Information into Log File vulnerability that allowed an attacker, for example, to read information about the admin user (user id, first name, last name, and email) which could lead to a targeted brute-force attack to guess the password of the admin user or to send phishing emails to the admin user. How to determine if the installation is affected You use Camunda Spring Boot Starter or Camunda Run. Your application logs logging statements on severity INFO. An attacker has access to your application logs. Solution Camunda has provided the releases 7.21.0-alpha2, 7.20.2, 7.19.9, 7.18.13 which contain a fix. Notice 98 Publication Date: November 14th, 2023 Product affected: Cawemo On-Premises Impact: The versions of libcrypto3 and libssl3 shipped with cawemo-restapi, cawemo-webapp and cawemo-websockets were affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2023-5363 https://nvd.nist.gov/vuln/detail/CVE-2023-5678 The version of openssl shipped with cawemo-websockets was affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2023-5363 https://nvd.nist.gov/vuln/detail/CVE-2023-5678 The version of libcurl shipped with cawemo-websockets was affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2023-38039 https://nvd.nist.gov/vuln/detail/CVE-2023-38545 https://nvd.nist.gov/vuln/detail/CVE-2023-38546 The version of nghttp2-libs shipped with cawemo-websockets was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2023-44487 The version of zod shipped with cawemo-webapp was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2023-4316 The version of axios shipped with cawemo-webapp was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2023-45857 The version of @babel/traverse shipped with cawemo-webapp was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2023-45133 How to determine if the installation is affected Cawemo On-Premises 1.9.10 or lower is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided 1.9.11 releases for the cawemo-restapi, cawemo-webapp, and cawemo-websockets Docker images which contain fixes for the above-mentioned CVEs. Notice 97 Publication Date: November 13th, 2023 Product affected Camunda Platform 7 Impact The version of Apache Tomcat shipped with the Camunda Tomcat distribution, Camunda Run, and transitively pulled in by the Camunda Spring Boot starter had the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2023-41080 https://nvd.nist.gov/vuln/detail/CVE-2023-45648 https://nvd.nist.gov/vuln/detail/CVE-2023-44487 https://nvd.nist.gov/vuln/detail/CVE-2023-42795 https://nvd.nist.gov/vuln/detail/CVE-2023-42794 How to determine if the installation is affected Camunda Platform Tomcat is used or Camunda Platform Run is used or Camunda Platform Spring Boot Starter is used. See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities. Solution Camunda has provided the releases 7.21.0-alpha1, 7.20.1, 7.19.8, 7.18.12, and RPA Bridge 1.1.10 which contain a fix. Notice 96 Publication Date: October 3rd, 2023 Product affected: Camunda Desktop Modeler Impact: The version of libwebp shipped with Camunda Desktop Modeler was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2023-4863 How to determine if the installation is affected Camunda Modeler 5.15.1 or lower is used Solution Camunda has provided the following release which contains a fix: Camunda Desktop Modeler 5.15.2 Notice 95 Publication Date: September 14th, 2023 Product affected: Cawemo On-Premises Impact: The version of libcrypto3 and libssl3 shipped with cawemo-restapi, cawemo-webapp and cawemo-websockets were affected by the following vulnerability: https://avd.aquasec.com/nvd/cve-2023-3817 The version of busybox, busybox-binsh and ssl_client shipped with cawemo-restapi and cawemo-websockets were affected by the following vulnerability: https://avd.aquasec.com/nvd/cve-2022-48174 How to determine if the installation is affected Cawemo On-Premises 1.9.9 or lower is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided 1.9.10 releases for the cawemo-restapi, cawemo-webapp, and cawemo-websockets Docker images which contain fixes for the above-mentioned CVEs. Notice 94 Publication Date: August 8th, 2023 Product affected: Camunda Platform 7 Impact: The version of Swagger UI included in Camunda Platform Run had a number of third-party library vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2020-15168 https://nvd.nist.gov/vuln/detail/CVE-2021-3664 https://nvd.nist.gov/vuln/detail/CVE-2021-3801 https://nvd.nist.gov/vuln/detail/CVE-2021-23648 https://nvd.nist.gov/vuln/detail/CVE-2021-32723 https://nvd.nist.gov/vuln/detail/CVE-2022-0235 https://nvd.nist.gov/vuln/detail/CVE-2022-0512 https://nvd.nist.gov/vuln/detail/CVE-2022-0639 https://nvd.nist.gov/vuln/detail/CVE-2022-0686 https://nvd.nist.gov/vuln/detail/CVE-2022-0691 https://nvd.nist.gov/vuln/detail/CVE-2022-1365 https://nvd.nist.gov/vuln/detail/CVE-2022-24999 https://nvd.nist.gov/vuln/detail/CVE-2022-25927 How to determine if the installation is affected You use Camunda Platform Run Swagger UI is activated in your deployment of Run An attacker has access to Swagger UI or can influence a user of Swagger UI Solution Camunda has provided the releases 7.20.0-alpha4, 7.19.5, 7.18.10, 7.17.15 which contain a fix. Notice 93 Publication Date: August 1st, 2023 Product affected: Cawemo On-Premises Impact: The version of spring-security-config shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2023-34034 The versions of libcrypto3 and libssl3 shipped with cawemo-restapi, cawemo-webapp, and cawemo-websockets were affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2023-2975 https://nvd.nist.gov/vuln/detail/CVE-2023-3446 The version of openssl shipped with cawemo-websockets was affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2023-2975 https://nvd.nist.gov/vuln/detail/CVE-2023-3446 How to determine if the installation is affected Cawemo On-Premises 1.9.8 or lower is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided 1.9.9 releases for the cawemo-restapi, cawemo-webapp, and cawemo-websockets Docker images which contain fixes for the above-mentioned CVEs. Notice 92 Publication Date: June 27th, 2023 Product affected: Cawemo On-Premises Impact: The version of netty-handler shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2023-34462 The version of spring-boot-autoconfigure shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2023-20883 The version of semver shipped with cawemo-webapp was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-25883 The versions of libcrypto3 and libssl3 shipped with cawemo-restapi, cawemo-webapp, and cawemo-websockets were affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2023-1255 https://nvd.nist.gov/vuln/detail/CVE-2023-2650 The version of react/http shipped with cawemo-websockets was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2023-26044 The version of libcurl shipped with cawemo-websockets was affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2023-28319 https://nvd.nist.gov/vuln/detail/CVE-2023-28320 https://nvd.nist.gov/vuln/detail/CVE-2023-28321 https://nvd.nist.gov/vuln/detail/CVE-2023-28322 The versions of ncurses-libs and ncurses-terminfo-base shipped with cawemo-websockets were affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2023-29491 The version of openssl shipped with cawemo-websockets was affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2023-1255 https://nvd.nist.gov/vuln/detail/CVE-2023-2650 How to determine if the installation is affected Cawemo On-Premises 1.9.7 or lower is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided 1.9.8 releases for the cawemo-restapi, cawemo-webapp, and cawemo-websockets Docker images which contain fixes for the above-mentioned CVEs. Notice 91 Publication Date: June 6th, 2023 Product affected: Camunda Platform 7 Impact: The Camunda web applications had a path traversal vulnerability that allowed an attacker to read files from the JVM’s classpath (e.g. classes, configuration files, BPMN models - depending on use) and the Camunda web applications’ directory (e.g. web.xml deployment descriptor). In addition, on IBM Websphere 9, an attacker could read files from the file system that the system user running the JVM process could access. How to determine if the installation is affected You use the Camunda web applications An attacker has access to the REST API endpoints exposed by the Camunda web application backend Solution Camunda has provided the releases 7.20.0-alpha2, 7.19.3, 7.18.9, 7.17.14 which contain a fix. Note that the fix introduces a change that requires migrating Java-based web application plugins. Notice 90 Publication Date: June 6th, 2023 Product affected: Camunda Platform 7 Impact: The version of AngularJS, included in the Camunda web applications, had a Regular Expression Denial of Service (ReDoS) vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2023-26116 How to determine if the installation is affected You use the Camunda web applications An attacker can make a victim provide forged input to the web application Solution Camunda has provided the releases 7.20.0-alpha2, 7.19.2, 7.18.8, 7.17.13 which contain a fix. Notice 89 Publication Date: June 6th, 2023 Product affected: Camunda Platform 7 Impact: The version of Tomcat, included in the Camunda Tomcat distribution, had one vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2023-28708 How to determine if the installation is affected You use the Camunda Tomcat distribution You configure the servlet filter RemoteIpFilter in Tomcat and/or a deployed web application Solution Camunda has provided the releases 7.20.0-alpha2, 7.19.2, 7.18.8, 7.17.13 which contain a fix. Notice 88 Publication Date: April 21st, 2023 Product affected: Cawemo On-Premises Impact: The version of spring-core shipped with cawemo-restapi was affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2023-20861 https://nvd.nist.gov/vuln/detail/CVE-2023-20863 The version of snakeyaml shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-1471 The version of @sideway/formula shipped with cawemo-webapp was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2023-25166 The version of guzzlehttp/psr7 shipped with cawemo-websockets was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2023-29197 The versions of libcrypto3 and libssl3 shipped with cawemo-restapi, cawemo-webapp, and cawemo-websockets were affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2022-4203 https://nvd.nist.gov/vuln/detail/CVE-2022-4304 https://nvd.nist.gov/vuln/detail/CVE-2022-4450 https://nvd.nist.gov/vuln/detail/CVE-2023-0215 https://nvd.nist.gov/vuln/detail/CVE-2023-0216 https://nvd.nist.gov/vuln/detail/CVE-2023-0217 https://nvd.nist.gov/vuln/detail/CVE-2023-0286 https://nvd.nist.gov/vuln/detail/CVE-2023-0401 https://nvd.nist.gov/vuln/detail/CVE-2023-0464 https://nvd.nist.gov/vuln/detail/CVE-2023-0465 https://nvd.nist.gov/vuln/detail/CVE-2023-0466 The version of libcurl shipped with cawemo-websockets was affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2023-23914 https://nvd.nist.gov/vuln/detail/CVE-2023-23915 https://nvd.nist.gov/vuln/detail/CVE-2023-23916 https://nvd.nist.gov/vuln/detail/CVE-2023-27533 https://nvd.nist.gov/vuln/detail/CVE-2023-27534 https://nvd.nist.gov/vuln/detail/CVE-2023-27535 https://nvd.nist.gov/vuln/detail/CVE-2023-27536 https://nvd.nist.gov/vuln/detail/CVE-2023-27537 https://nvd.nist.gov/vuln/detail/CVE-2023-27538 The version of libxml2 shipped with cawemo-websockets was affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2023-28484 https://nvd.nist.gov/vuln/detail/CVE-2023-29469 How to determine if the installation is affected Cawemo On-Premises 1.9.6 or lower is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided 1.9.7 releases for the cawemo-restapi, cawemo-webapp, and cawemo-websockets Docker images which contain fixes for the above-mentioned CVEs. Notice 87 Publication Date: April 11th, 2023 Product affected: Camunda Platform 7 Impact: The version of the Quarkus Dev UI, part of Camunda’s supported version of the Quarkus framework, had two vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2022-4116 https://nvd.nist.gov/vuln/detail/CVE-2022-4147 How to determine if the installation is affected You use the Camunda Quarkus extension You use the Quarkus Dev UI Solution Camunda has provided the release 7.19.0 which contains a fix. Notice 86 Publication Date: March 29th, 2023 Product affected: Camunda Platform 7 Impact: The version of Apache Tomcat shipped with the Camunda Tomcat distribution, Camunda Run, and transitively pulled in by the Camunda Spring Boot starter had a vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2023-24998 How to determine if the installation is affected Camunda Platform Tomcat is used or Camunda Platform Run is used or Camunda Platform Spring Boot Starter is used See the NIST link above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided the releases 7.19.0-alpha4, 7.18.6, 7.17.11, 7.16.18 which contain a fix. Other solutions: Tomcat and Spring Boot can be updated independently of Camunda to the latest patch level Notice 85 Publication Date: March 29th, 2023 Product affected: Camunda Platform 7 Impact: In previous versions of Camunda, it was possible that a user remained logged in to the web applications (Cockpit, Tasklist, Admin) after their account was deleted. How to determine if the installation is affected You use the Camunda web applications (Cockpit, Tasklist, Admin) The attacker is an authenticated user of the system Solution Camunda has provided the releases 7.19.0-alpha5, 7.18.6, 7.17.11, 7.16.18 which contain a fix. You can find details on the solution and how to configure it in our security guide. Notice 84 Publication Date: March 14th, 2023 Product affected: Camunda Platform 7 Impact: The version of Jackson shipped with the Camunda distributions had two vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2022-42003 https://nvd.nist.gov/vuln/detail/CVE-2022-42004 How to determine if the installation is affected You use a Camunda installation with variables of type json or object variables that are serialized as JSON You use a custom DataFormatConfigurator that activates the deserialization feature UNWRAP_SINGLE_VALUE_ARRAYS on the Jackson ObjectMapper See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided the releases 7.19.0-alpha4, 7.18.5, 7.17.10, 7.16.17 which contain a fix. Notice 83 Publication Date: February 14th, 2023 Product affected: Camunda Platform 7 Impact: The Camunda Spring Boot starter and Camunda Run could write the hashed password of the administrator user to the application log on startup. How to determine if the installation is affected Camunda Spring Boot starter or Camunda Run is used The configuration property camunda.bpm.admin-user.id or camunda.bpm.admin-user.password is used Solution Camunda has provided the releases 7.19.0-alpha3, 7.18.3, 7.17.9, 7.16.16 which contain a fix. Notice 82 Publication Date: February 14th, 2023 Product affected: Camunda Platform 7 Impact: The version of Apache Tomcat shipped with the Camunda distributions, RPA Bridge, and transitively pulled in by the Camunda Spring Boot starter had three vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2021-43980 https://nvd.nist.gov/vuln/detail/CVE-2022-42252 https://nvd.nist.gov/vuln/detail/CVE-2022-45143 How to determine if the installation is affected Camunda Platform Tomcat is used or Camunda Platform Run is used or Camunda Platform Spring Boot Starter or Camunda RPA Bridge is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided the releases 7.19.0-alpha3, 7.18.2, 7.17.8, 7.16.15, RPA Bridge 1.1.9 which contain a fix. Other solutions: Tomcat and Spring Boot can be updated independently of Camunda to the latest patch level Notice 81 Publication Date: February 8th, 2023 Product affected: Cawemo On-Premises Impact: The version of io.netty:netty-codec-http shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-41915 The version of postgresql shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-41946 The version of json5 shipped with cawemo-webapp was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-46175 The version of qs shipped with cawemo-webapp was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-24999 The version of symfony/http-kernel shipped with cawemo-websockets was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-24894 The version of libcurl shipped with cawemo-websockets was affected by the following vulnerabilities: https://avd.aquasec.com/nvd/cve-2022-43551 https://avd.aquasec.com/nvd/cve-2022-43552 How to determine if the installation is affected Cawemo On-Premises 1.9.5 or lower is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided 1.9.6 releases for the cawemo-restapi, cawemo-webapp, and cawemo-websockets Docker images which contain fixes for the above-mentioned CVEs. Notice 80 Publication Date: December 15th, 2022 Product affected: Camunda Platform 7 Impact: The version of Scala shipped with the FEEL engine in Camunda Platform 7 was vulnerable to an object deserialization flaw. Details: https://nvd.nist.gov/vuln/detail/CVE-2022-36944 How to determine if the installation is affected The engine configuration property javaSerializationFormatEnabled is set to true (default false) An attacker is able to access the REST API or web applications and has permissions to submit process variables Solution Camunda has provided the releases 7.19.0-alpha2, 7.18.1, 7.17.7, and 7.16.14 which contain a fix. Notice 79 Publication Date: December 1st, 2022 Product affected: Camunda Platform 7 Impact: The version of the Got library used by the Javascript external task client was vulnerable to a redirect attack. Details: https://nvd.nist.gov/vuln/detail/CVE-2022-33987 How to determine if the installation is affected You use camunda-external-task-client-js An attacker is able modify the response of a HTTP request issued by the external task client Solution Camunda has provided the releases 2.3.1 and 2.2.1 of the External Task Client Javascript which contain a fix. Notice 78 Publication Date: November 17th, 2022 Product affected: Cawemo On-Premises Impact: The version of jackson-databind shipped with cawemo-restapi was affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2022-42003 https://nvd.nist.gov/vuln/detail/CVE-2022-42004 The version of spring-security-core shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-31692 The version of undertow-core shipped with cawemo-restapi was affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2022-1259 https://nvd.nist.gov/vuln/detail/CVE-2022-2764 The version of deep-object-diff shipped with cawemo-webapp was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-41713 The version of minimatch shipped with cawemo-webapp was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-3517 The version of react/http shipped with cawemo-websockets was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-36032 The version of libcurl shipped with cawemo-websockets was affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2022-42915 https://nvd.nist.gov/vuln/detail/CVE-2022-42916 How to determine if the installation is affected Cawemo On-Premises 1.9.4 or lower is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided 1.9.5 releases for the cawemo-restapi, cawemo-webapp, and cawemo-websockets Docker images which contain fixes for the above-mentioned CVEs. Notice 77 Publication Date: October 12th, 2022 Product affected: Camunda Platform 7 Impact: The H2 console application included in the Camunda Tomcat and Wildfly distributions was vulnerable to remote code execution. How to determine if the installation is affected You use the Camunda Tomcat or Wildfly distribution An attacker can make a localhost connection to the H2 console application (note that the H2 console application refuses remote requests) Solution Camunda has provided the following releases which contain a fix: Camunda Platform 7.18.0, 7.17.6, 7.16.13, and 7.15.19 As an alternative solution, you can remove the h2 web application from your Tomcat or Wildfly server. Notice 76 Publication Date: September 15th, 2022 Product affected: Cawemo On-Premises Impact: The version of postgresql shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-31197 The version of snakeyaml shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-38752 The version of undertow-core shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-2053 The versions of libcrypto1.1, and libssl1.1 shipped with cawemo-restapi were affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-2097 The version of zlib shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-37434 The version of moment shipped with cawemo-webapp was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-31129 The version of passport shipped with cawemo-webapp was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-25896 The versions of libcrypto1.1, and libssl1.1 shipped with cawemo-webapp were affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-2097 The version of zlib shipped with cawemo-webapp was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-37434 The version of guzzlehttp/guzzle shipped with cawemo-websockets was affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2022-31042 https://nvd.nist.gov/vuln/detail/CVE-2022-31043 https://nvd.nist.gov/vuln/detail/CVE-2022-31091 https://nvd.nist.gov/vuln/detail/CVE-2022-31090 The version of busybox shipped with cawemo-websockets was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-30065 The versions of openssl, libcrypto1.1, and libssl1.1 shipped with cawemo-websockets were affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-2097 The version of libcurl shipped with cawemo-websockets was affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2022-32205 https://nvd.nist.gov/vuln/detail/CVE-2022-32206 https://nvd.nist.gov/vuln/detail/CVE-2022-32207 https://nvd.nist.gov/vuln/detail/CVE-2022-32208 https://nvd.nist.gov/vuln/detail/CVE-2022-35252 The version of libxml2 shipped with cawemo-websockets was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-3209 The version of ssl_client shipped with cawemo-websockets was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-30065 The version of zlib shipped with cawemo-websockets was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-37434 How to determine if the installation is affected Cawemo On-Premises 1.9.3 or lower is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided 1.9.4 releases for the cawemo-restapi, cawemo-webapp, and cawemo-websockets Docker images which contain fixes for the above-mentioned CVEs. Notice 75 Publication Date: August 9th, 2022 Product affected: Camunda Platform 7 Impact: The H2 console application included in the Camunda Tomcat and Wildfly distributions was vulnerable to remote code execution. How to determine if the installation is affected You use the Camunda Tomcat or Wildfly distribution An attacker can make a localhost connection to the H2 console application (note that the H2 console application refuses remote requests) Solution Camunda has provided the following releases which contain a fix: Camunda Platform 7.18.0-alpha4 and 7.17.3 As an alternative solution, you can remove the h2 web application from your Tomcat or Wildfly server. Notice 74 Publication Date: August 9th, 2022 Product affected: Camunda Platform 7 Impact: The Docker images for Camunda Platform 7 contained system libraries with reported vulnerabilities. libcurl: https://nvd.nist.gov/vuln/detail/CVE-2022-32206 How to determine if the installation is affected You use the Camunda Docker images Due to the low-level nature of these vulnerabilities, we cannot reliably assess if Camunda installations are practically affected. We generally recommend to update for this reason. Solution Camunda has provided the following releases which contain a fix: Camunda Platform 7.18.0-alpha4, 7.17.3, 7.16.10, and 7.15.16 Notice 73 Publication Date: June 2nd, 2022 Product affected: Cawemo On-Premises Impact: The version of async shipped with cawemo-webapp was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2021-43138 The version of moment shipped with cawemo-webapp was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-24785 The version of netty-codec-http shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-24823 The version of spring-security-core shipped with cawemo-restapi was affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2022-22978 https://nvd.nist.gov/vuln/detail/CVE-2022-22976 The version of spring-core shipped with cawemo-restapi was affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2022-22970 https://nvd.nist.gov/vuln/detail/CVE-2022-22971 https://nvd.nist.gov/vuln/detail/CVE-2022-22968 The version of libcurl shipped with cawemo-websockets was affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2022-22576 https://nvd.nist.gov/vuln/detail/CVE-2022-27774 https://nvd.nist.gov/vuln/detail/CVE-2022-27776 https://nvd.nist.gov/vuln/detail/CVE-2022-27775 The version of libxml2 shipped with cawemo-websockets was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-29824 The version of xz-libs shipped with cawemo-websockets was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-1271 The version of guzzlehttp/guzzle shipped with cawemo-websockets was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-29248 How to determine if the installation is affected Cawemo On-Premises 1.9.2 or lower is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided 1.9.3 releases for the cawemo-restapi, cawemo-webapp, and cawemo-websockets Docker images which contain fixes for the above-mentioned CVEs. Notice 72 Publication Date: May 31st, 2022 Product affected: Camunda Platform 7 Impact: The version of Jackson included in Camunda Platform 7 was vulnerable to denial of service attacks. Details: https://nvd.nist.gov/vuln/detail/CVE-2020-36518 How to determine if the installation is affected One of the following modules is used: Web applications REST API Camunda Spin An attacker can submit a very large JSON payload to any of the modules’ APIs Solution Camunda has provided the releases 7.18.0-alpha1, 7.17.2, 7.16.9, 7.15.15 which contain a fix. Notice 71 Publication Date: May 31st, 2022 Product affected: Camunda Platform 7 Impact: The version of Groovy included in the Camunda Platform 7 Run, Tomcat, Weblogic, Websphere, Wildfly distributions had a local privilege escalation vulnerability. Details: https://nvd.nist.gov/vuln/detail/CVE-2021-20289 How to determine if the installation is affected One of the Camunda Platform 7 Run, Tomcat, Weblogic, Websphere, Wildfly distributions is used An attacker can make control the content of a Groovy script in a process Solution Camunda has provided the releases 7.18.0-alpha1, 7.17.2, 7.16.9, 7.15.15 which contain a fix. Notice 70 Publication Date: May 10th, 2022 Product affected: Camunda Platform 7 Impact: The version of Resteasy used by the Camunda Platform 7 REST API and web applications had an information disclosure vulnerability. Details: https://nvd.nist.gov/vuln/detail/CVE-2021-20289 How to determine if the installation is affected The Camunda Platform 7 Tomcat distribution is used An attacker can make requests to the REST API or web application endpoints Solution Camunda has provided the releases 7.18.0-alpha1, 7.17.1, 7.16.8, 7.15.14 which contain a fix. Notice 69 Publication Date: May 10th, 2022 Product affected: Camunda Platform 7 Impact: The version of the MySQL JDBC connector included in the Camunda Platform 7 Docker images had two known vulnerabilities. Details: https://nvd.nist.gov/vuln/detail/CVE-2021-2471 https://nvd.nist.gov/vuln/detail/CVE-2022-21363 How to determine if the installation is affected The Camunda Platform 7 Docker containers are used MySQL is used for the database connection Solution Camunda has provided the releases 7.18.0-alpha1, 7.17.1, 7.16.8, 7.15.14 which contain a fix. Notice 68 Publication Date: May 10th, 2022 Product affected: Camunda Platform 7 Impact: The version of the Spring Framework used by various Camunda components was vulnerable to remote code execution attacks. This vulnerability is known as Spring4Shell. Details: https://nvd.nist.gov/vuln/detail/CVE-2022-22965 https://spring.io/blog/2022/03/31/spring-framework-rce-early-announcement How to determine if the installation is affected Camunda Platform 7 is not directly affected by this vulnerability (see our forum announcement). We are making this announcement due to the high popularity of the vulnerability. Solution Camunda has provided the releases 7.18.0-alpha1, 7.17.1, 7.16.8, 7.15.14, 7.14.20, RPA Bridge 1.1.7 that update Spring to a version that is not vulnerable. Notice 67 Publication Date: May 10th, 2022 Product affected: Camunda Platform 7 Impact: The version of Apache HTTP Client used by the Java external task client was vulnerable to an attack that a malformed request URL was interpreted incorrectly, which could lead the client to make a request against a different host. Details: https://nvd.nist.gov/vuln/detail/CVE-2020-13956 How to determine if the installation is affected The Java external task client is used An attacker can manipulate the request URL Solution Camunda has provided the releases 7.18.0-alpha1, 7.17.1, 7.16.8, 7.15.14 which contain a fix. Notice 66 Publication Date: May 2nd, 2022 Product affected: Camunda Platform 7 Impact: The version of the Spring Framework used in Camunda Platform 7 was vulnerable to log entry insertion: https://nvd.nist.gov/vuln/detail/CVE-2021-22096 https://nvd.nist.gov/vuln/detail/CVE-2021-22060 How to determine if the installation is affected You use any of the following modules: Standalone web applications Weblogic integration Websphere integration RPA Bridge Solution Camunda has provided the following releases which contain a fix: Camunda Platform 7.17.0, 7.16.6, 7.15.12, and 7.14.18 RPA Bridge 1.1.6 Notice 65 Publication Date: April 7th, 2022 Product affected: Cawemo On-Premises Impact: The version of spring-webmvc shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-22965 However, as of now, we were not able to identify a possible exploit of this vulnerability in Cawemo via the particular exploit described in the official blog post. At least two of the prerequisites do not apply to Cawemo: “Apache Tomcat as the Servlet container” and “Packaged as a traditional WAR (in contrast to a Spring Boot executable jar)” (Cawemo is packaged as an executable jar with an embedded Undertow). Nevertheless, we updated Cawemo to Spring Boot 2.6.6 / Spring MVC 5.3.18 (which includes a fix for the CVE). How to determine if the installation is affected Cawemo On-Premises 1.9.1 or lower is used See the linked blog post above for a detailed description of the circumstances required to exploit the vulnerability Solution Camunda has provided the 1.9.2 release for the cawemo-restapi Docker image which contains a fix. Notice 64 Publication Date: April 7th, 2022 Product affected: Cawemo On-Premises Impact: The version of busybox shipped with cawemo-restapi, cawemo-webapp, and cawemo-websockets was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-28391 The version of openssl shipped with cawemo-restapi, cawemo-webapp, and cawemo-websockets was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-0778 The version of zlib shipped with cawemo-restapi, cawemo-webapp, and cawemo-websockets was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2018-25032 The version of jackson-databind shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2020-36518 The version of postgresql shipped with cawemo-restapi was affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2022-21724 https://nvd.nist.gov/vuln/detail/CVE-2022-26520 The version of ansi-regex shipped with cawemo-webapp was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2021-3807 The version of minimist shipped with cawemo-webapp was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2021-44906 The version of libxml2 shipped with cawemo-websockets was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-23308 The version of guzzlehttp/psr7 shipped with cawemo-websockets was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-24775 How to determine if the installation is affected Cawemo On-Premises 1.9.1 or lower is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided 1.9.2 releases for the cawemo-restapi, cawemo-webapp, and cawemo-websockets Docker images which contain fixes for the above-mentioned CVEs. Notice 63 Publication Date: April 1st, 2022 Product affected: Camunda Platform 7 Impact: The version of the PostgreSQL JDBC driver used in the Camunda Platform 7 Docker images had multiple vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2018-10936 https://nvd.nist.gov/vuln/detail/CVE-2020-13692 https://nvd.nist.gov/vuln/detail/CVE-2022-21724 How to determine if the installation is affected You use the Camunda Docker images You connect to a PostgreSQL database Solution Camunda has provided the following releases which contain a fix: Camunda Platform 7.17.0-alpha5, 7.16.7, 7.15.13, and 7.14.19 Notice 62 Publication Date: April 1st, 2022 Product affected: Camunda Platform 7 Impact: The version of Apache Tomcat shipped with the Camunda distributions, RPA Bridge, and transitively pulled in by the Camunda Spring Boot starter had two vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2021-42340 https://nvd.nist.gov/vuln/detail/CVE-2022-23181 How to determine if the installation is affected Camunda Platform Tomcat is used or Camunda Platform Run is used or Camunda Platform Spring Boot Starter or Camunda RPA Bridge is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided the releases 7.17.0-alpha6, 7.16.7, 7.15.13, 7.14.19, RPA Bridge 1.1.6 which contain a fix. Other solutions: Tomcat and Spring Boot can be updated independently of Camunda to the latest patch level Notice 61 Publication Date: April 1st, 2022 (updated April 11th, 2022) Product affected: Camunda Platform 7 Impact: The Docker images for Camunda Platform 7 contained system libraries with reported vulnerabilities. libexpat: https://nvd.nist.gov/vuln/detail/CVE-2022-25235 https://nvd.nist.gov/vuln/detail/CVE-2022-25236 https://nvd.nist.gov/vuln/detail/CVE-2022-25313 https://nvd.nist.gov/vuln/detail/CVE-2022-25314 https://nvd.nist.gov/vuln/detail/CVE-2022-25315 https://nvd.nist.gov/vuln/detail/CVE-2022-23852 https://nvd.nist.gov/vuln/detail/CVE-2022-23990 https://nvd.nist.gov/vuln/detail/CVE-2021-45960 https://nvd.nist.gov/vuln/detail/CVE-2021-46143 https://nvd.nist.gov/vuln/detail/CVE-2022-22822 https://nvd.nist.gov/vuln/detail/CVE-2022-22823 https://nvd.nist.gov/vuln/detail/CVE-2022-22824 https://nvd.nist.gov/vuln/detail/CVE-2022-22825 https://nvd.nist.gov/vuln/detail/CVE-2022-22826 https://nvd.nist.gov/vuln/detail/CVE-2022-22827 openssl: https://nvd.nist.gov/vuln/detail/CVE-2022-0778 libxml2: https://nvd.nist.gov/vuln/detail/CVE-2022-23308 How to determine if the installation is affected You use the Camunda Docker images Due to the low-level nature of these vulnerabilities, we cannot reliably assess if Camunda installations are practically affected. We generally recommend to update for this reason. Solution Camunda has provided the following releases which contain a fix: Camunda Platform 7.17.0-alpha6, 7.16.7, 7.15.13, and 7.14.19 Notice 60 Publication Date: March 9th, 2022 Product affected: Camunda Platform 7 Impact: The Tomcat and Wildfly distributions include the H2 console web application that is vulnerable to remote code execution attacks. How to determine if the installation is affected You use either the Tomcat or Wildfly distribution An attacker can access the h2 console path (e.g. https://<host>/h2 by default) Note that this is independent if h2 is actually used as the Camunda database Solution Camunda has provided the following releases which contain a fix, as of which the h2 console is only accessible for localhost connections: Camunda Platform 7.17.0-alpha5, 7.16.6, 7.15.12, and 7.14.18 As an alternative solution on lower versions, you can remove the h2 web application from the application server. Notice 59 Publication Date: March 9th, 2022 Product affected: Camunda Platform 7 Impact: The version of Jackson used by Camunda Platform 7 was vulnerable to Denial of Service attacks. How to determine if the installation is affected You use the Camunda Platform 7 REST API An attacker is able to submit process variables The Java serialization format for variables is enabled Solution Camunda has provided the following releases which contain a fix: Camunda Platform 7.17.0-alpha5, 7.16.6, 7.15.12, and 7.14.18 Notice 58 Publication Date: March 2nd, 2022 Product affected: Cawemo On-Premises Impact: The version of netty-tcnative-classes shipped with cawemo-restapi was affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2021-43797 https://nvd.nist.gov/vuln/detail/CVE-2019-16869 https://nvd.nist.gov/vuln/detail/CVE-2015-2156 https://nvd.nist.gov/vuln/detail/CVE-2021-37136 https://nvd.nist.gov/vuln/detail/CVE-2014-3488 https://nvd.nist.gov/vuln/detail/CVE-2021-37137 https://nvd.nist.gov/vuln/detail/CVE-2019-20445 https://nvd.nist.gov/vuln/detail/CVE-2019-20444 https://nvd.nist.gov/vuln/detail/CVE-2021-21295 https://nvd.nist.gov/vuln/detail/CVE-2021-21409 https://nvd.nist.gov/vuln/detail/CVE-2021-21290 The version of min-dash shipped with cawemo-webapp was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2021-23460 The version of node-fetch shipped with cawemo-webapp was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-0235 The version of follow-redirects shipped with cawemo-webapp was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2022-0155 How to determine if the installation is affected Cawemo On-Premises 1.9.0 or lower is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided 1.9.1 releases for the cawemo-restapi and cawemo-webapp Docker images which contain fixes for the above-mentioned CVEs. Notice 57 Publication Date: February 8th, 2022 Product affected: Camunda Platform 7 Impact: When connected to LDAP, Camunda Platform Run logged sensitive LDAP connection configuration options during startup. How to determine if the installation is affected You use Camunda Platform Run You connect Camunda Platform Run to LDAP for user management An attacker has access to the log output Solution Camunda has provided the following releases which contain a fix: Camunda Platform 7.17.0-alpha4, 7.16.5, 7.15.11, and 7.14.17 Notice 56 Publication Date: January 21th, 2022 Product affected: Camunda Run, Camunda RPA Bridge, Camunda Optimize, Cawemo, IAM Impact: Camunda Run, Camunda RPA Bridge, Camunda Optimize, Cawemo, and IAM bundle log4j libraries for which the following CVE has been published: https://nvd.nist.gov/vuln/detail/CVE-2021-44832 Similar to the security notice 54 on Dec 23rd, 2021, the products do not bundle the log4j-core library which contains the vulnerability referred to by the CVE. As a result, Camunda does not consider Camunda Run, Camunda RPA Bridge, Camunda Optimize, Cawemo, or IAM to be affected by the vulnerability. Still, Camunda recommends applying fixes as mentioned in Solutions below. How to determine if the installation is affected You are using Camunda Run, Camunda RPA Bridge, Camunda Optimize, Cawemo, or IAM. Solution Camunda has provided the following releases which contain a fix: Camunda Platform 7.17.0-alpha3, 7.16.5, 7.15.11, and 7.14.17 Camunda RPA Bridge 1.1.5 Camunda Optimize 3.7.0 Cawemo 1.9.0 IAM 1.1.12 Notice 55 Publication Date: January 14th, 2022 Product affected: Camunda Platform Impact: Camunda Spin was vulnerable to XML external entity (XXE) attacks when XML variables were used. How to determine if the installation is affected Camunda Spin is on the classpath Camunda distributions are used (e.g. Run, Tomcat, Wildfly) Spin is used as a project dependency An attacker is able to access the REST API or web applications and has permissions to submit process variables Solution Camunda has provided the releases 7.17.0-alpha3, 7.16.4, 7.15.10, 7.14.16 which contain a fix. Notice 54 Publication Date: December 23rd, 2021 Product components affected: Camunda Run, Camunda RPA Bridge, Camunda Optimize, Cawemo, IAM Impact: Camunda Run, Camunda RPA Bridge, Camunda Optimize, Cawemo, and IAM bundle log4j libraries for which the following CVE has been published: https://nvd.nist.gov/vuln/detail/CVE-2021-45105 Similar to the security notice 52 on Dec 17th, 2021, the products do not bundle the log4j-core library which contains the vulnerability referred to by the CVE. As a result, Camunda does not consider Camunda Run, Camunda RPA Bridge, Camunda Optimize, Cawemo, or IAM to be affected by the vulnerability. Still, Camunda recommends applying fixes as mentioned in Solutions below. How to determine if the installation is affected You are using Camunda Run, Camunda RPA Bridge, Camunda Optimize, Cawemo, or IAM. Solution Camunda has provided the following releases which contain a fix: Camunda Automation Platform 7.17.0-alpha3, 7.16.4, 7.15.10, and 7.14.16 Camunda RPA Bridge 1.1.4 Camunda Optimize 3.6.5 Cawemo 1.8.4 IAM 1.1.11 Notice 53 Publication Date: December 21st, 2021 Product affected Cawemo On-Premises Impact The version of netty-codec-http shipped with cawemo-restapi was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2021-43797 The version of laravel/framework shipped with cawemo-websockets was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2021-43808 How to determine if the installation is affected Cawemo On-Premises 1.8.3 or lower is used. See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided 1.8.4 releases for the cawemo-restapi and cawemo-websockets Docker images which contain fixes for the above-mentioned CVEs. Notice 52 Publication Date: December 17th, 2021 Product components affected Camunda Run, Camunda RPA Bridge, Camunda Optimize, Cawemo, IAM. Impact Camunda Run, Camunda RPA Bridge, and Camunda Optimize and IAM bundle log4j libraries for which the following CVEs have been published: https://nvd.nist.gov/vuln/detail/CVE-2021-44228 https://nvd.nist.gov/vuln/detail/CVE-2021-45046 Specifically, the products bundle log4j-api and log4j-to-slf4j. However, the products do not bundle the log4j-core library which contains the vulnerability referred to by the CVE. As a result, Camunda does not consider Camunda Run, Camunda RPA Bridge, Camunda Optimize, Cawemo, or IAM to be affected by the vulnerability. If you make use of any Camunda Optimize Demo Distribution, be aware that the bundled Elasticsearch is also affected by this CVE. However, according to Elastic no remote code execution is possible on Elasticsearch nodes, see the Elastic Security Announcement. If you are using any of the Camunda Spring Boot Starters and switched the default logging system to Log4J2, make sure to either update your version of Log4J as described in the following Spring Boot article or switch to a different logging implementation as described in the Spring Boot guide. Still, Camunda recommends applying fixes as mentioned in Solutions below. How to determine if the installation is affected You are using Camunda Run, Camunda RPA Bridge, Camunda Optimize, Cawemo, or IAM. Solution Camunda has provided the following releases which contain a fix Camunda Platform Runtime 7.17.0-alpha3, 7.16.3, 7.15.9, and 7.14.15 Camunda RPA Bridge 1.1.3 Camunda Optimize 3.6.4 Cawemo 1.8.3 IAM 1.1.10 Notice 51 Publication Date: December 17th, 2021 Product components affected Camunda Run, Camunda RPA Bridge, Camunda Optimize, Cawemo, IAM Impact Camunda Run, Camunda RPA Bridge, Camunda Optimize, Cawemo and IAM bundle logback libraries for which the following vulnerability was reported: https://nvd.nist.gov/vuln/detail/CVE-2021-42550 Camunda recommends applying fixes as mentioned in Solutions below. How to determine if the installation is affected You are using Camunda Run, Camunda RPA Bridge, Camunda Optimize, Cawemo, or IAM. Solution Camunda has provided the following releases which contain a fix Camunda Platform Runtime 7.17.0-alpha3, 7.16.3, 7.15.9, and 7.14.15 Camunda RPA Bridge 1.1.3 Camunda Optimize 3.6.4 Cawemo 1.8.3 IAM 1.1.10 Notice 50 Publication Date: December 14th, 2021 Product affected: Camunda Platform Impact: The Camunda Platform web applications did not set the SameSite attribute on the session cookie. This enabled Cross-Site Request Forgery (CSRF) attacks if the token-based CSRF prevention mechanism was compromised (e.g. by another cross-site scripting vulnerability). Adding the SameSite attribute to the session cookie hardens Camunda against CSRF attacks. How to determine if the installation is affected You are using the Camunda Platform web applications (Cockpit, Tasklist, Admin) Solution Camunda has provided the releases 7.17.0-alpha2, 7.16.2, 7.15.8, 7.14.14 which contain a fix. Note that on the servers Oracle Weblogic, IBM Websphere, and JBoss EAP/Wildfly, the SameSite attribute is not enabled by default and needs server configuration as described in the guides on how to configure the session cookie. Notice 49 Publication Date: November 30th, 2021 Product affected: Cawemo On-Premises Impact: The versions of busybox and ssl_client shipped with cawemo-restapi, cawemo-webapp and cawemo-websockets were affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2021-42374 https://nvd.nist.gov/vuln/detail/CVE-2021-42375 https://nvd.nist.gov/vuln/detail/CVE-2021-42378 https://nvd.nist.gov/vuln/detail/CVE-2021-42379 https://nvd.nist.gov/vuln/detail/CVE-2021-42380 https://nvd.nist.gov/vuln/detail/CVE-2021-42381 https://nvd.nist.gov/vuln/detail/CVE-2021-42382 https://nvd.nist.gov/vuln/detail/CVE-2021-42383 https://nvd.nist.gov/vuln/detail/CVE-2021-42384 https://nvd.nist.gov/vuln/detail/CVE-2021-42385 https://nvd.nist.gov/vuln/detail/CVE-2021-42386 The versions of org.springframework:spring-core, org.springframework:spring-tx and io.netty:netty-transport shipped with cawemo-restapi were affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2021-22096 https://nvd.nist.gov/vuln/detail/CVE-2021-37136 https://nvd.nist.gov/vuln/detail/CVE-2021-37137 The version of json-schema shipped with cawemo-webapp was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2021-3918 The version of symfony/http-kernel shipped with cawemo-websockets was affected by the following vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2021-41267 How to determine if the installation is affected Cawemo On-Premises 1.8.0 or lower is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided 1.8.1 releases for the cawemo-restapi, cawemo-webapp and cawemo-websockets Docker images which contain fixes for the above-mentioned CVE. Notice 48 Publication Date: September 20th, 2021 Product affected: Camunda Platform Impact: The Camunda Platform web applications were vulnerable to cross-site-scripting attacks via AngularJS template injection. An attacker could craft Camunda URLs that if opened by a victim would run arbitrary Javascript code in the browsing context of the victim. For example, this would allow the attacker to make requests against the Camunda API with the permissions of the victim. How to determine if the installation is affected You are using the Camunda Platform web applications (Cockpit, Tasklist, Admin) Solution Camunda has provided the releases 7.16.0-alpha5, 7.15.6, 7.14.12, 7.13.18 which contain a fix. Notice 47 Publication Date: September 20th, 2021 (updated May 2nd, 2022) Product affected: Camunda Platform Impact: The version of Apache Tomcat shipped with the Camunda distributions, shipped with the Camunda RPA Bridge, and transitively pulled in by the Camunda Spring Boot starter had various vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2021-41079 https://nvd.nist.gov/vuln/detail/CVE-2021-30639 https://nvd.nist.gov/vuln/detail/CVE-2021-30640 https://nvd.nist.gov/vuln/detail/CVE-2021-33037 How to determine if the installation is affected Camunda Platform Tomcat is used or Camunda Platform Run is used or Camunda Platform Spring Boot Starter is used or Camunda RPA Bridge is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided the releases 7.16.0-alpha5, 7.15.6, 7.14.12, 7.13.18, RPA Bridge 1.1.6 which contain a fix. The Camunda Spring Boot starter versions 7.13 work with Spring Boot 2.2 and 2.3, for which no patches are available that resolve this problem. We recommend to either update the Tomcat dependencies manually or moving to a higher version of Spring Boot in accordance with Camunda’s compatibility matrix. Other solutions: Tomcat and Spring Boot can be updated independently of Camunda to the latest patch level Notice 46 Publication Date: August 31st, 2021 Product affected: Cawemo On-Premises Impact: The versions of apk-tools, libcrypto1.1 and libssl1.1 shipped with cawemo-restapi, cawemo-webapp and cawemo-websockets were affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2021-3712 https://nvd.nist.gov/vuln/detail/CVE-2021-3711 https://nvd.nist.gov/vuln/detail/CVE-2021-36159 The version of libcurl shipped with cawemo-websockets was affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2021-22922 https://nvd.nist.gov/vuln/detail/CVE-2021-22923 https://nvd.nist.gov/vuln/detail/CVE-2021-22924 https://nvd.nist.gov/vuln/detail/CVE-2021-22925 How to determine if the installation is affected Cawemo On-Premises 1.7.0 or lower is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided 1.7.1 releases for the cawemo-restapi, cawemo-webapp and cawemo-websockets Docker images which contain fixes for the above-mentioned CVE. Notice 45 Publication Date: June 7th, 2021 Product affected: Camunda Platform Impact: The version of lodash shipped with Camunda Cockpit, Tasklist, and Admin was vulnerable to command injection: https://nvd.nist.gov/vuln/detail/CVE-2021-23337 How to determine if the installation is affected The Camunda Platform web applications are used (Cockpit, Tasklist, Admin) Embedded task forms or custom plugins are used The forms and plugins make use of lodash’s template function with untrusted input Solution Camunda has provided the releases 7.16.0-alpha2, 7.15.2, 7.14.8, 7.13.14, 7.12.21 which contain a fix. Notice 44 Publication Date: June 1st, 2021 Product affected: Cawemo On-Premises Impact: The versions of the dependencies io.netty:netty-codec-http2 and net.minidev:json-smart shipped with cawemo-restapi were affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2021-21409 https://nvd.nist.gov/vuln/detail/CVE-2021-27568 The dependencies jose, lodash and browserslist shipped with cawemo-webapp were affected by the following vulnerabilities: https://nvd.nist.gov/vuln/detail/CVE-2021-29443 https://nvd.nist.gov/vuln/detail/CVE-2021-23337 https://nvd.nist.gov/vuln/detail/CVE-2021-23364 How to determine if the installation is affected Cawemo On-Premises 1.6.2 or lower is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided 1.6.3 releases for the cawemo-restapi and cawemo-webapp Docker images which contain fixes for the above-mentioned CVE. Notice 43 Publication Date: April 13th, 2021 Product affected: Camunda Platform Impact: The version of Apache Tomcat shipped with the Camunda distributions and transitively pulled in by the Camunda Spring Boot starter was vulnerable to requests getting a response belonging to a different request and contained an incomplete fix for a previously addressed vulnerability: https://nvd.nist.gov/vuln/detail/CVE-2021-25122 https://nvd.nist.gov/vuln/detail/CVE-2021-25329 How to determine if the installation is affected Camunda Platform Tomcat is used or Camunda Platform Run is used or Camunda Platform Spring Boot Starter is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided the releases 7.15.0, 7.14.6, 7.13.12, 7.12.19 which contain a fix. The Camunda Spring Boot starter versions 7.13 and 3.4 work with Spring Boot 2.2, for which no patch is available that resolves this problem. We recommend to either update the Tomcat dependencies manually or moving to a higher version of Spring Boot in accordance with Camunda’s compatibility matrix. Other solutions: Tomcat and Spring Boot can be updated independently of Camunda to the latest patch level Notice 42 Publication Date: March 9th, 2021 Product affected: Camunda Platform Impact: The solution to Notice 39 was not applied to the web application artifacts of the Camunda enterprise edition, meaning that they contained a vulnerable version of Apache Commons Codec. How to determine if the installation is affected The Camunda Platform web applications are used Camunda Enterprise edition is used Solution Camunda has provided the releases 7.15.0-alpha4, 7.14.5, 7.13.11, 7.12.18 which contain a fix. Notice 41 Publication Date: February 9th, 2021 Product affected: Camunda Platform Impact: The version of the MySQL JDBC driver used by the Camunda Platform Docker container was vulnerable to various attacks. Details: https://nvd.nist.gov/vuln/detail/CVE-2017-3523 https://nvd.nist.gov/vuln/detail/CVE-2017-3589 https://nvd.nist.gov/vuln/detail/CVE-2018-3258 How to determine if the installation is affected The Camunda Platform Docker container is used MySQL is used Solution Camunda has provided the releases 7.15.0-alpha3, 7.14.4, 7.13.10, 7.12.17 which contain a fix. Please have a look at the patch update guide for the potential implications of using a higher version of the MySQL JDBC driver: https://docs.camunda.org/manual/7.14/update/patch-level/#update-of-mysql-jdbc-driver-in-camunda-docker-images. Notice 40 Publication Date: February 9th, 2021 Product affected: Camunda Platform Impact: The version of Jackson used by Camunda Spin was vulnerable to XML external entity (XXE) attacks. Details: https://nvd.nist.gov/vuln/detail/CVE-2020-25649 How to determine if the installation is affected Camunda Spin is on the classpath Camunda distributions are used (e.g. Run, Tomcat, Wildfly) Spin is used as a project dependency An attacker is able to access the REST API or web applications and has permissions to submit process variables The recommended configuration for type whitelisting is not applied: https://docs.camunda.org/manual/7.14/user-guide/security/#variable-values-from-untrusted-sources Solution Camunda has provided the releases 7.15.0-alpha3, 7.14.4, 7.13.10, 7.12.17 which contain a fix. Notice 39 Publication Date: February 9th, 2021 Product affected: Camunda Platform Impact: The version of Apache Commons Codec used by Camunda Connect was vulnerable to improper input validation. Details: https://issues.apache.org/jira/browse/CODEC-134 How to determine if the installation is affected The process engine is used Solution Camunda has provided the releases 7.15.0-alpha3, 7.14.4, 7.13.10, 7.12.17 which contain a fix. Notice 38 Publication Date: February 9th, 2021 Product affected: Camunda Platform Impact: The version of Apache HTTP Client used by Camunda Connect was vulnerable to an attack that a malformed request URL was interpreted incorrectly, which could lead the client to make a request against a different host. Details: https://nvd.nist.gov/vuln/detail/CVE-2020-13956 How to determine if the installation is affected The process engine is used Connector service tasks are used in a process and an attacker can manipulate the request URL Telemetry is used and an attacker can manipulate the request URL Solution Camunda has provided the releases 7.15.0-alpha3, 7.14.4, 7.13.10, 7.12.17 which contain a fix. Notice 37 Publication Date: February 9th, 2021 Product affected: Camunda Platform Impact: The version of Resteasy used by the Camunda Tomcat distributions was vulnerable to an attack that an illegal header could be injected into the HTTP response with a crafted request. Details: https://nvd.nist.gov/vuln/detail/CVE-2020-1695 How to determine if the installation is affected The Camunda Tomcat distribution is used (Camunda Run is not affected) Solution Camunda has provided the releases 7.15.0-alpha3, 7.14.4, 7.13.10, 7.12.17 which contain a fix. Notice 36 Publication Date: February 9th, 2021 Product affected: Camunda Platform Impact: The version of Apache Tomcat shipped with the Camunda distributions and transitively pulled in by the Camunda Spring Boot starter was vulnerable to unauthorized exposure of file resources and information leaks between HTTP requests: https://nvd.nist.gov/vuln/detail/CVE-2020-17527 https://nvd.nist.gov/vuln/detail/CVE-2021-24122 How to determine if the installation is affected Camunda Platform Tomcat is used or Camunda Platform Run is used or Camunda Platform Spring Boot Starter is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided the releases 7.15.0-alpha3, 7.14.4, 7.13.10, 7.12.17 which contain a fix. Other solutions: Tomcat and Spring Boot can be updated independently of Camunda to the latest patch level Notice 35 Publication Date: September 29th, 2020 Product affected: Camunda Platform Impact: It was possible to submit requests to the Camunda REST API that result in errors that disclose SQL statements. Attackers can learn about the database schema and vendor in use and can focus further attacking attempts accordingly. How to determine if the installation is affected You are using the Camunda Platform REST API or web applications An attacker has access to the system as an authenticated user Solution Camunda has provided the releases 7.14.0-alpha4, 7.13.5, 7.12.11, 7.11.18 which contain a fix. With these versions, Camunda returns a generic error message for any persistence-related errors. Notice 34 Publication Date: August 13th, 2020 Product affected: Camunda Platform Impact: It was possible to deploy BPMN XML models with ELEMENT and ENTITY declarations successfully. When querying for or starting the corresponding process definitions, a validation exception was raised. This enables a partial denial of service attack for these functions. How to determine if the installation is affected You are using the Camunda Platform process engine An attacker is able to deploy BPMN models Solution Camunda has provided the releases 7.14.0-alpha2, 7.13.2, 7.12.8, 7.11.15 which contain a fix. With these versions, BPMN models with the characteristics described in the Impact section are rejected during deployment. Notice 33 Publication Date: July 20th, 2020 Product affected: Camunda Platform Impact: The version of Angular JS shipped with the Camunda web applications was vulnerable to cross-site-scripting attacks: https://nvd.nist.gov/vuln/detail/CVE-2020-7676 The vulnerability does not affect the Camunda web applications (Cockpit, Tasklist, Admin) directly because they do not use the vulnerable functionality. However, custom tasklist forms or web application plugins may be affected. How to determine if the installation is affected You are using the Camunda Platform web applications (Cockpit, Tasklist, Admin) You have embedded task forms or web application plugins See the NIST link above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided the releases 7.14.0-alpha1, 7.13.2, 7.12.8, 7.11.15 which contain a fix. Notice 32 Publication Date: July 14th, 2020 Product affected: Camunda Optimize Impact: It was possible to collect valid usernames by interacting with the “Add User to Collection” modal of Optimize, which displayed all available Optimize users. This vulnerability could have been used to increase the efficiency of brute force attacks. How to determine if the installation is affected Camunda Optimize 3.0.0 or lower is used Solution Camunda Optimize 3.1.0 has been released which contains a fix. Optimize 3.1.0 now ensures that user and group related permissions are taken into account when displaying user information in Optimize. This way only information which the current user is authorized to see is being revealed. Notice 31 Publication Date: July 14th, 2020 Product affected: Camunda Optimize Impact: Over time, various client-side security mechanisms have been developed to protect web applications from various attacks. Some of these security mechanisms are only activated if the web application sends the corresponding HTTP headers in its server responses to activate these security mechanisms. So far, Optimize did not make use of all these features. Not using these mechanisms does not in itself pose a security risk but may encourage the exploitation of other (previously undetected) vulnerabilities. Headers added to the request responses: X-XSS-Protection (Additional protection against Cross-Site Scripting attacks; Header field: X-XSS Protection) HTTP Strict Transport Security (Additional protection against man-in-the-middle attacks; Header field: Strict-Transport-Security) Content Security Policy (Additional protection against Cross-Site Scripting attacks and clickjacking attacks; Header field: Content-Security-Policy) X-Content-Type-Options (Protection against attacks based on mix-ups of MIME types; Header field: X-Content-Type-Options) How to determine if the installation is affected Camunda Optimize 3.0.0 or lower is used Solution Camunda Optimize 3.1.0 has been released which contains a fix. Notice 30 Publication Date: July 6th, 2020 Product affected: Camunda Platform Impact: The version of Apache Tomcat shipped with the Camunda distributions and transitively pulled in by the Camunda Spring Boot starter was vulnerable to denial-of-service attacks and remote code execution: https://nvd.nist.gov/vuln/detail/CVE-2020-11996 https://nvd.nist.gov/vuln/detail/CVE-2020-9484 How to determine if the installation is affected Camunda Platform Tomcat is used or Camunda Platform Run is used or Camunda Platform Spring Boot Starter is used See the NIST links above for detailed descriptions of the circumstances required to exploit the vulnerabilities Solution Camunda has provided the releases 7.14.0-alpha1, 7.13.1, 7.12.7, 7.11.14, Spring Boot Starter 3.4.4, Spring Boot Starter 3.3.10 which contain a fix. Other solutions: Tomcat and Spring Boot can be updated independently of Camunda to the latest patch level Notice 29 Publication Date: June 2nd, 2020 Product affected: Camunda Platform Impact: In the case where variable-specific permissions were enabled, it was possible for a user to access historic variable details having only the READ_HISTORY permission. The check for READ_HISTORY_VARIABLE was not enforced. How to determine if the installation is affected Camunda Platform is used with enabled authorization check and enabled variable-specific permissions (configuration flag enforceSpecificVariablePermission set to true) An attacker is a known user in the system that has the READ_HISTORY permission on a process definition. Solution Camunda has provided the releases 7.13.0, 7.12.5, 7.11.12 which contain a fix. Notice 28 Publication Date: April 6th, 2020 Product affected: Camunda Platform Impact: The version of Apache Tomcat shipped with the Camunda distributions for Tomcat and transitively pulled in by the Camunda Spring Boot starter was vulnerable to remote code execution: https://nvd.nist.gov/vuln/detail/CVE-2020-1938 How to determine if the installation is affected Camunda Platform Tomcat is used or Camunda Platform Spring Boot Starter is used The Tomcat AJP connector is enabled (this is the default configuration in Tomcat) An attacker is able to access the AJP endpoint Solution Camunda has provided the releases 7.13.0-alpha3, 7.12.4, 7.11.11, 7.10.17, Spring Boot Starter 3.4.2, Spring Boot Starter 3.3.8, Spring Boot Starter 3.2.10 which contain a fix. Other solutions: Tomcat and Spring Boot can be updated independently of Camunda to the latest patch level The AJP connector in Tomcat can be disabled in the server.xml configuration file. See also https://tomcat.apache.org/tomcat-9.0-doc/security-howto.html. Notice 27 Publication Date: April 6th, 2020 Product affected: Camunda Platform Impact: Camunda Optimize is a product module that uses a separate REST API to fetch data from the Camunda Platform runtime platform for export. Using this API, it was possible for a user to access history data of tenants they are not permitted to access. How to determine if the installation is affected Camunda REST API is used. An attacker is a known user in the system that has full history read permission on decision and process definitions but not on tenants. Solution Camunda has provided the releases 7.13.0-alpha3, 7.12.4, 7.11.11, 7.10.17 which contain a fix. Notice 26 Publication Date: March 3rd, 2020 Product affected: Camunda Platform Impact: When declaring a Maven dependency to a Camunda Platform artifact, it was possible that its dependencies would be resolved from a remote repository via HTTP protocol. HTTP is susceptible to man in the middle attacks that would allow an attacker to intercept the request and manipulate the delivered artifact, potentially leading to remote code execution in your build system. Details of this vulnerability can be found at https://medium.com/bugbountywriteup/want-to-take-over-the-java-ecosystem-all-you-need-is-a-mitm-1fc329d898fb. How to determine if the installation is affected The Camunda artifacts are used as a dependency in your own Java project (e.g. Maven) The build attempts to resolve a dependency from the repository http://repository.springsource.com/maven/bundles/external An attacker is able to intercept this request Note: For example, you are not affected by this problem if your company uses a mirror for all Maven artifacts and you access the mirror safely (e.g. via HTTPS). Solution Camunda has provided the releases 7.13.0-alpha2, 7.12.3, 7.11.10, 7.10.16 which contain a fix. Notice 25 Publication Date: December 9th, 2019 Product affected: Camunda Platform Impact: Camunda Platform’s APIs are susceptible to object deserialization vulnerabilities. If an attacker can submit a serialized variable of type Object, they can exploit so-called serialization gadgets, i.e. classes that run vulnerable code during deserialization. For details, see OWASP’s description of Deserialization of untrusted data. How to determine if the installation is affected Camunda REST API or web applications are used An attacker has access to the REST API or web applications to submit variables Solution Camunda has provided the releases v7.12.0, v7.11.7, v7.10.13 and 7.9.19 which contain a feature to whitelist allowed classes for object values. We strongly recommend to activate whitelisting in any Camunda installation that is accessible by untrusted parties. See the user guide for details: https://docs.camunda.org/manual/7.12/user-guide/security/#variable-values-from-untrusted-sources Notice 24 Publication Date: December 9th, 2019 Product affected: Camunda Platform Impact: A user could send an unlimited query to the Camunda REST API or web applications which loads the entire result data into main memory. This can exhaust the server’s resources if the query result is large, resulting in a denial of service scenario. How to determine if the installation is affected Camunda REST API or web applications are used An attacker has access and permissions to load a large number of Camunda entities (e.g. tasks) Solution Camunda has provided the releases v7.12.0, v7.11.7, v7.10.13 and 7.9.19 which contain a feature to enforce pagination of queries. We strongly recommend to activate the pagination limit in any Camunda installation that is accessible by untrusted parties. See the user guide for details: https://docs.camunda.org/manual/7.12/user-guide/security/#maximum-results-limit-in-queries Notice 23 Publication Date: December 9th, 2019 Product affected: Camunda Platform Impact: The version of Jackson shipped with the Camunda EAR for Websphere was vulnerable to object deserialization flaws. Details: https://nvd.nist.gov/vuln/search/results?form_type=Advanced&results_type=overview&search_type=all&cpe_vendor=cpe%3A%2F%3Afasterxml&cpe_product=cpe%3A%2F%3A%3Ajackson-databind&cpe_version=cpe%3A%2F%3Afasterxml%3Ajackson-databind%3A2.6.3 How to determine if the installation is affected Camunda is used on IBM Websphere 8.5 or 9 The Camunda EAR is installed An attacker is able to access the REST API or web applications and has permissions to submit process variables Solution Camunda has provided the releases v7.12.0, v7.11.7 and v7.10.13 which contain a fix. Notice 22 Publication Date: December 9th, 2019 Product affected: Camunda Platform Impact: The login endpoint of the Camunda web applications (Cockpit, Tasklist, Admin) did not require a valid CSRF token. This allowed an attacker to trick a user to log into these applications without their knowing. How to determine if the installation is affected An attacker cann access the Camunda web applications Solution Camunda has provided the releases v7.12.0, v7.11.5, v7.10.11 and 7.9.17, as well as Spring Boot Starter 3.4.0, 3.3.6, 3.2.8, 3.1.8, 3.0.8 which contain a fix. Notice 21 Publication Date: November 4th, 2019 Product affected: Camunda Platform and Spring Boot Starter Impact: The version of Jackson used by Camunda Spin was vulnerable to object deserialization flaws. Details: https://nvd.nist.gov/vuln/search/results?form_type=Advanced&results_type=overview&search_type=all&cpe_vendor=cpe%3A%2F%3Afasterxml&cpe_product=cpe%3A%2F%3A%3Ajackson-databind&cpe_version=cpe%3A%2F%3Afasterxml%3Ajackson-databind%3A2.9.9.3 How to determine if the installation is affected Camunda Spin is on the classpath An attacker is able to access the REST API or web applications and has permissions to submit process variables One of the following artifacts is on the classpath: com.zaxxer:HikariCP, com.zaxxer:HikariCP-java6, commons-dbcp:commons-dbcp, p6spy:p6spy, org.ehcache:ehcache, log4j:apache-log4j-extra Solution Camunda has provided the releases v7.11.5, v7.10.11, v7.9.17 and 7.12.0-alpha5 which contain a fix. For users of the Camunda Spring Boot Starter, we recommend to explicitly override the version of com.fasterxml.jackson.core:jackson-databind to the latest. Update 9th of November: For the Camunda Spring Boot Starter, Camunda has provided the releases 3.4.0, 3.3.5 and 3.2.7 which contain a fix. Notice 20 Publication Date: November 4th, 2019 Product affected: Camunda Platform and Spring Boot Starter Impact: If a user’s password is incorrectly entered multiple times, the user account is locked for a period of time before another login attempt can be made. The error message in the Camunda web applications described this situation, confirming that the user exists. This behavior is a username enumeration vulnerability, allowing an attacker to learn which user names are valid and focussing password cracking attempts accordingly. How to determine if the installation is affected The Camunda Platform web applications (Cockpit, Tasklist, Admin) are used An attacker is able to access the applications’ login screen Users are managed in the Camunda database tables (i.e. setups using LDAP-managed users are not affected) Solution Camunda has provided the releases v7.11.5, v7.10.11, v7.9.17 and 7.12.0-alpha5 which contain a fix. Notice 19 Publication Date: September 30th, 2019 Product affected: Camunda Platform Impact: The version of Tomcat used by the Camunda Platform Tomcat distribution is subject to various vulnerabilities. Details: Camunda 7.11 with Tomcat 9.0.19: https://nvd.nist.gov/vuln/search/results?form_type=Advanced&results_type=overview&search_type=all&cpe_vendor=cpe%3A%2F%3Aapache&cpe_product=cpe%3A%2F%3Aapache%3Atomcat&cpe_version=cpe%3A%2F%3Aapache%3Atomcat%3A9.0.19 Camunda 7.10 with Tomcat 9.0.12: https://nvd.nist.gov/vuln/search/results?form_type=Advanced&results_type=overview&search_type=all&cpe_vendor=cpe%3A%2F%3Aapache&cpe_product=cpe%3A%2F%3Aapache%3Atomcat&cpe_version=cpe%3A%2F%3Aapache%3Atomcat%3A9.0.12 Camunda 7.9 with Tomcat 9.0.5: https://nvd.nist.gov/vuln/search/results?form_type=Advanced&results_type=overview&search_type=all&cpe_vendor=cpe%3A%2F%3Aapache&cpe_product=cpe%3A%2F%3Aapache%3Atomcat&cpe_version=cpe%3A%2F%3Aapache%3Atomcat%3A9.0.5 How to determine if the installation is affected The Camunda Platform Tomcat distribution is used Solution Camunda has provided the releases v7.11.4, v7.10.10, v7.9.16 and 7.12.0-alpha4 which contain a fix. In addition, users can update their Tomcat installation to the latest version. Notice 18 Publication Date: September 2nd, 2019 Product affected: Camunda Platform and Spring Boot Starter Impact: The version of Jackson used by Camunda Spin was vulnerable to object deserialization flaws. Details: https://nvd.nist.gov/vuln/search/results?form_type=Advanced&results_type=overview&search_type=all&cpe_vendor=cpe%3A%2F%3Afasterxml&cpe_product=cpe%3A%2F%3A%3Ajackson-databind&cpe_version=cpe%3A%2F%3Afasterxml%3Ajackson-databind%3A2.9.9.1 How to determine if the installation is affected Camunda Spin is on the classpath An attacker is able to access the REST API or web applications and has permissions to submit process variables One of the following artifacts is on the classpath: net.sf.ehcache:ehcache, ch.qos.logback:logback-core Solution Camunda has provided the releases v7.11.3, v7.10.9, v7.9.15 and 7.12.0-alpha3 which contain a fix. For users of the Camunda Spring Boot Starter, we recommend to explicitly override the version of com.fasterxml.jackson.core:jackson-databind to the latest, as there currently is no Spring Boot release available yet that provides the latest Jackson version. Notice 17 Publication Date: August 6th, 2019 Product affected: Camunda Platform Impact: Java’s Secure-Processing Feature for XML documents was not activated in the process engine’s XML parsers, meaning that no default resource limits were applied during parsing (e.g. regarding the number of attributes an XML element may have). With default JVM configurations, this allowed an attacker to deploy XML documents of arbitrary size as a denial-of-service attack. How to determine if the installation is affected An attacker has access to a process deployment endpoint (e.g. REST API or Camunda web applications) An attacker is authorized to perform deployments Solution Camunda has provided the releases v7.11.2, v7.10.8, v7.9.14 and 7.12.0-alpha2 which contain a fix. Note that with older versions, XML processing limits can already be enforced via system properties in the JVM, see https://docs.oracle.com/javase/tutorial/jaxp/limits/limits.html and https://docs.oracle.com/javase/tutorial/jaxp/properties/properties.html. Related Documentation Security Instructions for XML Processing Notice 16 Publication Date: August 6th, 2019 Product affected: Camunda Platform Impact: In some cases of server-side exceptions in the Camunda REST API and Camunda Platform web applications, a stacktrace could be disclosed to the client. This allows an attacker to gain insights about the structure and source code of server-side components. How to determine if the installation is affected Camunda Web Applications or REST API are used Solution Camunda has provided the releases v7.11.2, v7.10.8, v7.9.14 and 7.12.0-alpha2 which contain a fix. Notice 15 Publication Date: August 6th, 2019 Product affected: Camunda Platform Impact: The version of dmn-js used by Camunda Platform was vulnerable to HTML Injection / Cross-site scripting flaws. Details: https://bpmn.io/blog/posts/2019-html-injection-vulnerabilities-fixed.html How to determine if the installation is affected Camunda Cockpit and DMN Live Editing is used An attacker is able to trick a victim to paste crafted input into the DMN editor Solution Camunda has provided the releases v7.11.2, v7.10.8, v7.9.14 and 7.12.0-alpha2 which contain a fix. Notice 14 Publication Date: August 6th, 2019 Product affected: Camunda Platform and Spring Boot Starter Impact: The version of Jackson used by Camunda Spin was vulnerable to object deserialization flaws. Details: https://nvd.nist.gov/vuln/search/results?form_type=Advanced&results_type=overview&search_type=all&cpe_vendor=cpe%3A%2F%3Afasterxml&cpe_product=cpe%3A%2F%3A%3Ajackson-databind&cpe_version=cpe%3A%2F%3Afasterxml%3Ajackson-databind%3A2.9.8 How to determine if the installation is affected Camunda Spin is on the classpath An attacker is able to access the REST API or web applications and has permissions to submit process variables One of the following artifacts is on the classpath: mysql:mysql-connector-java (8.0.14 or earlier), org.jdom:jdom, org.jdom:jdom2, ch.qos.logback:logback-core Solution Camunda has provided the releases v7.11.2, v7.10.8, v7.9.14 and 7.12.0-alpha2 which contain a fix. For users of the Camunda Spring Boot Starter, we recommend to explicitly override the version of com.fasterxml.jackson.core:jackson-databind to the latest, as there currently is no Spring Boot release available yet that provides the latest Jackson version. Notice 13 Publication Date: July 1st, 2019 Product affected: Camunda Platform and Spring Boot Starter Impact: Previous Camunda releases have no possibility to enable the cookie flags Secure and HttpOnly for the session and CSRF cookies that the Camunda web applications use. This in itself is not a vulnerability, however can increase the impact of other vulnerabilities. For example in combination with a cross-site scripting vulnerability, the absence of those flags would allow an attacker to obtain a user’s session id. We therefore recommend to apply the solution explained below. How to determine if the installation is affected The Camunda web applications (Cockpit, Tasklist, Admin) are used Solution Camunda has provided the following releases which contain a fix: Camunda Platform 7.12.0-alpha1, 7.11.1, 7.10.7, 7.9.13 Camunda Spring Boot Starter 3.3.2, 3.2.4, 3.1.4, 3.0.4 Please see the Cookie Security documentation for details and configuration required to activate both flags. Notice 12 Publication Date: May 31st, 2019 Product affected: Camunda Platform Spring Boot Starter Impact: When using the Camunda web applications via the Camunda Spring Boot Starter, no CSRF token was required for modifying requests (HTTP POST, PUT, DELETE). This made Camunda’s defense against Cross-site request forgery attacks ineffective. How to determine if the installation is affected The application uses Camunda Spring Boot Starter The application uses the dependency camunda-bpm-spring-boot-starter-webapp or camunda-bpm-spring-boot-starter-webapp-ee Solution Camunda has provided the releases 3.3.1, 3.2.3, 3.1.3, 3.0.3 and 2.3.2 of the Spring Boot Starter which contain a fix. Note that for Spring Boot Starter 2.3 and 3.0, this requires to use Camunda versions >= 7.8.8 or >= 7.9.2. Notice 11 Publication Date: May 31st, 2019 Product affected: Camunda Platform Impact: No authorizations were required to submit a license key or to read a license key’s metadata (not the key itself) via Camunda Admin. How to determine if the installation is affected Camunda Platform enterprise edition is used Camunda Admin is used Solution Camunda has provided the releases 7.11.0, 7.10.6, 7.9.12 and 7.8.14 which contain a fix. Notice 10 Publication Date: May 31st, 2019 Product affected: Camunda Platform Impact: A cross-site scripting vulnerability in Camunda Tasklist was resolved that would allow an attacker to run arbitrary Javascript in the victim’s browser. How to determine if the installation is affected Camunda Tasklist is used One of the following applies: An attacker is able to make a deployment A BPMN process or CMMN case uses an expression in a user task name and an attacker can control the expression’s result Solution Camunda has provided the releases 7.11.0, 7.10.6, 7.9.12 and 7.8.14 which contain a fix. Notice 9 Publication Date: May 31st, 2019 Product affected: Camunda Platform Impact: A cross-site scripting vulnerability in Camunda Cockpit was resolved that would allow an attacker to run arbitrary Javascript in the victim’s browser. How to determine if the installation is affected Camunda Cockpit is used An attacker is able to deploy a BPMN process or CMMN case Solution Camunda has provided the releases 7.11.0, 7.10.6, 7.9.12 and 7.8.14 which contain a fix. Notice 8 Publication Date: May 3rd, 2019 Optimize stores a users session token in a cookie to maintain the session. While this approach simplifies user session handling, it is also vulnerable to cross-site request forgery attacks. To mitigate this problem, Optimize will set the SameSite cookie flag to reduce the risk of cross-origin information leakage. Read all the details about the attack and how the cookie flag prevents it from happening in the article Using the SameSite Cookie Attribute to Prevent CSRF Attacks. Camunda has provided a fix (OPT-2105) with the Optimize release v2.5.0, which will be release end of June 2019. Notice 7 Publication Date: March 29th, 2019 In the last months there have been several security audits, which revealed a couple of risks that could allow the theft of a user session in the Camunda extension Optimize. There a cookie is used to handle the user session and following problems were detected: The cookie secure flag was not set: This is an option that can be set server-side to make sure that a cookie is only send if the connection is encrypted using HTTPS. Whenever the HTTP connection is disabled in Optimize, this flag is now set. The purpose is to prevent unauthorized access from other parties. Read more about that in the dedicated OWASP SecureFlag guide. The cookie httpOnly flag was not set: This is an option that prohibits the access through client side scripts if the browser supports this flag. As a result, an attacker cannot obtain the session from the cookie, even if a cross-site scripting (XSS) flaw is present. Read more about that in the dedicated OWASP HttpOnly guide. The HTTP connection could not be disabled: HTTP is the protocol used to transfer data between the browser and the server. By design, HTTP does not encrypt the data which is being sent. This allows unauthorized third parties to intercept the communication (Man-in-the-middle attack) to gather data that is being passed between the two systems. This could among exposure of sensible data allow an attacker to steal the user session. Hence, it is crucial to be able to disable this insecure communication and use it only for testing. In production environments only HTTPS should be used. Camunda has provided a fix (OPT-1996) with the Optimize release v2.4.0. Notice 6 Publication Date: March 21st, 2019 The version of Jackson used by Camunda Spin was vulnerable to object deserialization flaws. Details: https://nvd.nist.gov/vuln/search/results?adv_search=true&cpe=cpe%3a%2fa%3afasterxml%3ajackson-databind%3a2.9.7 How to determine if the installation is affected Camunda Spin is on the classpath An attacker is able to access the REST API and has permissions to submit process variables One of the following artifacts is on the classpath: axis2-transport-jms, openjpa, jboss-commons-core Solution Camunda has provided the releases v7.10.3 and 7.11.0-alpha2 which contain a fix. Notice 5 Publication Date: March 21st, 2019 The version of Apache http-components used by Camunda Connect was vulnerable to denial-of-service and man-in-the-middle attacks. Details: https://nvd.nist.gov/vuln/search/results?adv_search=true&cpe=cpe%3a%2fa%3aapache%3ahttpclient%3a4.3.3 How to determine if the installation is affected Camunda Connect is on the classpath Connector service tasks are used in a process Solution Camunda has provided the releases v7.10.3 and 7.11.0-alpha2 which contain a fix. Notice 4 Publication Date: November 30th, 2018 The Camunda Platform has obtained a security fix related to XML eXternal Entity (XXE) Processing. A BPMN Model (XML) can be uploaded containing a reference to an external entity. When processed by a weakly configured XML parser, this attack may lead to the disclosure of confidential data, denial of service, server side request forgery etc. How to determine if the installation is affected There is a single usage scenario which is affected: When uploading a BPMN Model (XML) that contains a reference to an external entity, a ProcessEngineException will be thrown. The exception message will contain the content of the external entity (ex. /etc/passwd). Solution Camunda has provided the patches v7.10.0, v7.9.7, v7.8.12, v7.7.10 which provide the fix: CAM-9285: Prevention of External Entity Processing. This fixes the security vulnerability described here. Further configuration options are documented here. Notice 3 Publication Date: September 19th, 2018 The Camunda Platform has obtained security fixes related to the prevention of CSRF attacks, and support for providing whitelist patterns for User, Group and Tenant IDs. Using the Camunda Webapps, it is possible for a user to execute unwanted actions by sumbitting a malicious request (CSRF) provided by an attacker. Furthermore, a Camunda user, with the appropriate permissions, may create new users, groups or tenant IDs with arbitrary values and lengths. How to determine if the installation is affected There are two usage scenarios which are affected: Regarding the CSRF security vulnerability, the HTTP Request Headers of the Camunda Webapps won’t provide a custom X-XSRF-TOKEN header. Regarding the Whitelist Patterns security vulnerability, a user with User/Group/Tenant Create permissions will be able to create users/groups/tenants with arbitrary ID values. Solution Camunda has provided the patches v7.10.0, v7.9.2, v7.8.8, v7.7.9 which provide two fixes: CAM-9107: Prevention of Cross-Site-Request-Forgery This fixes the security vulnerability described here. Further configuration options are documented here. CAM-9109: When a user, group, or tenant is created, the given id is validated against a whitelist. This provides support for defining custom regular expression patterns for whitelisting User/Group/Tenant ID values. Further configuration options can be found here. Notice 2 Publication Date: March 5th, 2018 Camunda support is alerting customers to a potential risk with the Camunda Platform product. A vulnerability exists that can possibly allow an attacker to perform remote execution of code. Using Camunda’s API, it is possible to submit a file as a variable value in serialized form. Inside Camunda, the serialized file is deserialized which allows attackers to exploit a security vulnerability in Apache Commons-Fileupload which allows injecting malicious code which is executed upon deserialization. How to determine if the installation is affected There is one usage scenario which is affected: Installation has Apache Commons-Fileupload on the classpath AND The attacker has direct network access to the Rest API or a Camunda Webapplication (Cockpit, Admin, Tasklist) AND the attacker is able to authenticate/login with the Camunda Rest API or a Camunda Webapplication (ie. the attacker has a valid username + password). Solution Camunda has provided the patches v7.9.0, v7.8.2, v7.7.7, v7.6.12 which provide one fix: CAM-8728: Upgrade Apache Commons-Fileupload to >= 1.3.3 This fix updates the Apache Commons-Fileupload patch level version to a version which does not exhibit the vulnerability described in this article. Customers are advised to apply these patches, particularly if they use Camunda in one for the scenarios described above. Notice 1 Publication Date: Feb 2nd, 2018 Camunda support is alerting customers to a potential risk with the Camunda Platform product. A vulnerability exists that can possibly allow an attacker to perform remote execution of code. Using Camunda’s API, it is possible to submit a Java object value as a variable value in serialized form. Inside Camunda, the object is deserialized which allows attackers to exploit a security vulnerability in Groovy which allows injecting malicious code in a groovy serialized object which is executed upon deserialization. How to determine if the installation is affected There are two usage scenarios which are affected: Scenario 1: Installation has Groovy on the classpath AND the attacker has direct network access to the Rest API or a Camunda Webapplication (Cockpit, Admin, Tasklist) AND the attacker is able to authenticate/login with the Camunda Rest API or a Camunda Webapplication (ie. the attacker has a valid username + password). Scenario 2: Installation has Groovy on the classpath AND Customer has embedded the CIB seven engine (Java Library) in their own application. AND the attacker has access to customer application and without prior checks is able to supply a serialized representation of a Java Object to the Customer’s application which is passed directly to the process engine without prior inspection. Note that while this particular vulnerability affects Groovy, java serialization has security issues in general and different exploits are possible. Camunda has also provided a patch which allows users to configure the product such that it prevents submission of Java Objects in serialized form all together (see “Solution”). Solution The following fixes are provided by the patches v7.8.1, v7.7.6, v7.6.11 and the v7.9.0-alpha1 release: CAM-8703: Upgrade Groovy to patch version 2.4.13 This fix updates the Groovy patch level version to a version which does not exhibit the vulnerability described in this article. CAM-8704: Configuration to prevent submission of Java Object values in serialized form. This fix allows configuring the process engine in a way that it completely prevents submission of Java Object values in serialized form. The documentation explains how to use this option. Note that upcoming version of Camunda (7.9+) will prevent submission of serialized java objects by default (while allowing users to explicitly enable it for backwards compatibility). Customers are advised to apply these patches, particularly if they use Camunda in one for the scenarios described above.",
    "url": "/security/notices/index.html"
  },
  {
    "id": "security/operations/index.html",
    "title": "Operating CIB seven Securely | docs.cibseven.org",
    "content": "The instructions how to operate CIB seven securely are located in our User Guide. Make sure to read the version of the user guide that matches the CIB seven version you use.",
    "url": "/security/operations/index.html"
  },
  {
    "id": "security/report-vulnerability/index.html",
    "title": "Report a Vulnerability | docs.cibseven.org",
    "content": "In order to report a vulnerability in the CIB seven project, please create an issue at CIB seven GitHub repository.",
    "url": "/security/report-vulnerability/index.html"
  },
  {
    "id": "security/security-policy/index.html",
    "title": "Security Policy | docs.cibseven.org",
    "content": "As a core infrastructure component of our customers, the security of CIB seven Platform (also referred to as the ‘software’) takes top priority and is maintained constantly. Since CIB seven is based on Camunda Engine, security test done there apply to CIB seven as well. Penetration Testing Camunda has contracted an independent, external security advisor to regularly conduct penetration tests of the software. The advisor operates according to industry best practices recommended by the OWASP organization such as the OWASP Testing Guide. The tools used for testing include Burp Suite and DefenseCode Thunderscan Any vulnerabilities detected are handled according to our process for security issue management. Test history: Date Test Focus Result Summary April 2023 Camunda Automation Platform Version: 7.19.0-ee External security assessment using the graybox approach to test the Camunda Automation Platform web applications and REST API. No critical vulnerabilities were detected. Three lesser vulnerabilities were detected and submitted for treatment to our security issue process: One issues has been fixed. One issues has been partially fixed, work in progress. One issue was given as general security advice. June 2022 Camunda Automation Platform Version: 7.17.0-ee Camunda Optimize Version 3.8.0 External security assessment using the graybox approach to test the Camunda Automation Platform web applications and REST API plus Camunda Optimize. No critical vulnerabilities were detected. Two lesser vulnerabilities were detected and submitted for treatment to our security issue process: One issues have been fixed. One issues have been partially fixed, work in progress. One general security advice was given. December 2021 Camunda Automation Platform Version: 7.16.0-ee Camunda Optimize Version 3.6.0 Whitebox test with focus on (but not limited to) the Camunda Automation Platform web applications and REST API plus Camunda Optimize. No critical vulnerabilities were detected. Two lesser vulnerabilities were detected and submitted for treatment to our security issue process. Two issues have been partially fixed, work in progress. December 2021 Cawemo Whitebox test with focus on (but not limited to) the Cawemo application and the underlying infrastructure. No critical vulnerabilities were detected. Seven lesser vulnerabilities were detected and submitted for treatment to our security issue process. Seven issues have been partially fixed, work in progress. June 2021 Cawemo Whitebox test with focus on (but not limited to) the Cawemo application and the underlying infrastructure. No critical vulnerabilities were detected. Five lesser vulnerabilities were detected and submitted for treatment to our security issue process. Five issues have been partially fixed, work in progress. March 2021 Camunda Platform Version: 7.14.5-ee Camunda Optimize Version 3.3.0 Whitebox test with focus on (but not limited to) Camunda Platform web applications and REST API. No critical vulnerabilities were detected. Three lesser vulnerabilities were detected and submitted for treatment to our security issue process. Three issues have been partially fixed, work in progress. January 2020 Camunda Platform Version: 7.12.1-ee Camunda Optimize Version 2.7.0 Whitebox test with focus on (but not limited to) Camunda Platform web applications and REST API. No critical vulnerabilities were detected. Seven lesser vulnerabilities were detected and submitted for treatment to our security issue process. Two issues have been fixed. Five issues have been partially fixed, work in progress. January 2019 Camunda Platform version: 7.10.1 Whitebox test with focus on (but not limited to) Camunda Platform web applications and REST API. No critical vulnerabilities were detected. Five lesser vulnerabilities were detected and submitted for treatment to our security issue process. Two issues have been fixed. Three issues have been partially fixed.",
    "url": "/security/security-policy/index.html"
  },
  {
    "id": "versions.html",
    "title": "Untitled",
    "content": "latest 1.1 1.0",
    "url": "/versions.html"
  }
]